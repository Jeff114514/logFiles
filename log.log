UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0815 08:32:09.315810  8943 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0815 08:32:10.337002  8943 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=gpugraph_enable_hbm_table_collision_stat,sync_nccl_allreduce,mklml_dir,use_autotune,use_mkldnn,use_virtual_memory_auto_growth,multi_node_sample_use_gpu_table,pir_subgraph_saving_dir,enable_tracker_all2all,gemm_use_half_precision_compute_type,cusparselt_dir,tracer_onednn_ops_off,enable_fusion_fallback,cudnn_batchnorm_spatial_persistent,static_runtime_data_save_path,graph_get_neighbor_id,cudnn_exhaustive_search,dataloader_use_file_descriptor,new_executor_sequential_run,prim_enable_dynamic,einsum_opt,host_trace_level,gpu_allocator_retry_time,eager_delete_scope,run_kp_kernel,print_allocator_trace_info,cublaslt_device_best_config,apply_pass_to_program,prim_backward,gpugraph_enable_gpu_direct_access,win_cuda_bin_dir,new_executor_use_local_scope,enable_dependency_builder_debug_info,reallocate_gpu_memory_in_mb,enable_cinn_auto_tune,tensorrt_dir,accuracy_check_rtol_bf16,sync_after_alloc,executor_log_deps_every_microseconds,lapack_dir,enable_cse_in_dy2st,enable_gpu_memory_usage_log,cublaslt_exhaustive_search_times,prim_forward,prim_skip_dynamic,manually_trans_conv_filter,cudnn_exhaustive_search_times,accuracy_check_rtol_fp32,logging_pir_py_code_dump_symbolic_dims,enable_opt_get_features,use_shm_cache,convert_all_blocks,use_auto_growth_pinned_allocator,paddle_num_threads,initial_cpu_memory_in_mb,gpugraph_offload_gather_copy_maxsize,deny_cinn_ops,gpugraph_force_device_batch_num_equal,free_when_no_cache_hit,prim_all,conv2d_disable_cudnn,op_dir,multiple_of_cupti_buffer_size,inner_op_parallelism,enable_graph_multi_node_sampling,use_fast_math,set_to_1d,nccl_blocking_wait,logging_trunc_pir_py_code,low_precision_op_list,tracer_onednn_ops_on,new_executor_serial_run,fuse_parameter_memory_size,benchmark,call_stack_level,search_cache_max_number,query_dest_rank_by_multi_node,cublas_dir,use_cinn,graph_load_in_parallel,sort_sum_gradient,fleet_executor_with_standalone,enable_neighbor_list_use_uva,selected_gpus,enable_unused_var_check,cudnn_deterministic,pir_apply_shape_optimization_pass,gpugraph_storage_mode,graph_metapath_split_opt,pir_apply_inplace_pass,custom_device_mem_record,memory_fraction_of_eager_deletion,add_dependency_for_communication_op,enable_auto_detect_gpu_topo,enable_pir_api,get_host_by_name_time,gpugraph_merge_grads_segment_size,init_allocated_mem,cuda_dir,accuracy_check_atol_bf16,dist_threadpool_size,enable_sparse_inner_gather,gpugraph_load_node_list_into_hbm,fast_eager_deletion_mode,fraction_of_cpu_memory_to_use,ir_inplace_kernel_blacklist,new_executor_static_build,check_nan_inf_level,cache_inference_while_scope,enable_gpu_memory_usage_log_mb,fuse_parameter_groups_size,graph_embedding_split_infer_mode,enable_pir_in_executor_trace_run,tracer_profile_fname,static_executor_perfstat_filepath,use_auto_growth_v2,nccl_dir,check_infer_symbolic,prim_enabled,fraction_of_gpu_memory_to_use,use_cuda_managed_memory,enable_api_kernel_fallback,enable_blaslt_global_search,enable_record_memory,enable_auto_rdma_trans,print_sub_graph_dir,enable_dump_main_program,cusolver_dir,gpugraph_offload_param_extends,enable_collect_shape,fraction_of_cuda_pinned_memory_to_use,mkl_dir,use_stream_safe_cuda_allocator,enable_all2all_use_fp16,use_pinned_memory,reader_queue_speed_test_mode,auto_growth_chunk_size_in_mb,cinn_compile_thread_num,disable_dyshape_in_train,use_cuda_malloc_async_allocator,check_kernel_launch,pinned_memory_as_cpu_backend,cinn_subgraph_graphviz_dir,enable_async_trace,enable_cinn_compile_cache,accuracy_check_rtol_fp16,auto_free_cudagraph_allocations_on_launch,enable_exit_when_partial_worker,enable_cinn_accuracy_check,log_memory_stats,jit_engine_type,gpu_memory_limit_mb,cse_max_count,cudnn_dir,local_exe_sub_scope_limit,cuda_malloc_async_pool_memory_throttle_ratio,accuracy_check_atol_fp32,curand_dir,logging_pir_py_code_dir,nvidia_package_dir,cuda_memory_async_pool_realease_threshold,dygraph_debug,gpugraph_debug_gpu_memory,conv_workspace_size_limit,use_stride_kernel,new_executor_use_inplace,enable_fuse_parallel_matmul_pass,embedding_deterministic,gpugraph_hbm_table_load_factor,prim_check_ops,enable_cublas_tensor_op_math,use_system_allocator,use_xqa_optim,gpugraph_slot_feasign_max_num,allocator_strategy,graph_neighbor_size_percent,gpugraph_parallel_stream_num,enable_adjust_op_order,pir_broadcast_tree_limit,free_idle_chunk,dynamic_static_unified_comm,accuracy_check_atol_fp16,dump_chunk_info,gpugraph_enable_print_op_debug,prim_forward_blacklist,gpugraph_parallel_copyer_split_maxsize,cusparse_dir,eager_delete_tensor_gb,all_blocks_convert_trt,check_nan_inf,enable_pir_with_pt_in_dy2st,logging_pir_py_code_int_tensor_element_limit,initial_gpu_memory_in_mb,cupti_dir,enable_interpretercore_launch_cinn,enable_pir_in_executor,allreduce_record_one_event,allow_cinn_ops,max_inplace_grad_add,async_trace_count,new_executor_use_cuda_graph,gpugraph_sparse_table_storage_mode,tensor_operants_mode,gpugraph_offload_param_stat,gpugraph_dedup_pull_push_mode,save_static_runtime_data,gpugraph_enable_segment_merge_grads,trt_ibuilder_cache,pir_debug,alloc_fill_value,benchmark_nccl,npu_storage_format,print_ir 
1901: I0815 08:32:10.337116  8943 init.cc:108] After Parse: argc is 2
1901: I0815 08:32:16.008380  8943 scope.cc:202] Create variable X
1901: I0815 08:32:16.008466  8943 scope.cc:202] Create variable Out
1901: I0815 08:32:16.008482  8943 scope.cc:202] Create variable MedianIndex
1901: I0815 08:32:16.008677  8943 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0815 08:32:16.009361  8943 allocator_facade.cc:212] selected allocator strategy:1
1901: I0815 08:32:16.009680  8943 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0815 08:32:18.621124  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.621193  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.621356  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.621368  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.622629  8943 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 08:32:18.622663  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.622717  8943 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 08:32:18.622725  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.623253  8943 pybind.cc:1827] need skip: 0
1901: I0815 08:32:18.623359  8943 pybind.cc:1827] need skip: 0
1901: I0815 08:32:18.623811  8943 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 08:32:18.624215  8943 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 08:32:18.624235  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 08:32:18.624328  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 08:32:18.624346  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 08:32:18.627754  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:18.628522  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.628542  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.628556  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:18.631793  8943 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 08:32:18.631815  8943 scope.cc:202] Create variable feed
1901: I0815 08:32:18.631906  8943 program_interpreter.cc:243] New Executor is Running.
1901: I0815 08:32:18.631915  8943 interpreter_util.cc:1169] Creating Variables
1901: I0815 08:32:18.631924  8943 scope.cc:202] Create variable MedianIndex
1901: I0815 08:32:18.631937  8943 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x45204290 type is 7
1901: I0815 08:32:18.631949  8943 scope.cc:202] Create variable Out
1901: I0815 08:32:18.631955  8943 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45204800 type is 7
1901: I0815 08:32:18.631959  8943 scope.cc:202] Create variable Out@GRAD
1901: I0815 08:32:18.631963  8943 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x45204cb0 type is 7
1901: I0815 08:32:18.631968  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.631969  8943 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x452057f0 type is 7
1901: I0815 08:32:18.631973  8943 scope.cc:202] Create variable X@GRAD
1901: I0815 08:32:18.631976  8943 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45205a60 type is 7
1901: I0815 08:32:18.631981  8943 scope.cc:202] Create variable _generated_var_0
1901: I0815 08:32:18.631984  8943 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45205ca0 type is 7
1901: I0815 08:32:18.631989  8943 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 08:32:18.631994  8943 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45205f00 type is 7
1901: I0815 08:32:18.631999  8943 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45204c00 type is 9
1901: I0815 08:32:18.632004  8943 scope.cc:202] Create variable fetch
1901: I0815 08:32:18.632007  8943 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45205c80 type is 10
1901: I0815 08:32:18.632138  8943 interpreter_util.cc:594] Static build: 0
1901: I0815 08:32:18.632146  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.632151  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.632156  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0815 08:32:18.632823  8943 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0815 08:32:18.633119  8943 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0815 08:32:18.634232  8943 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0815 08:32:18.634480  8943 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.634510  8943 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.634688  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.634698  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.634718  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.639250  8943 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639276  8943 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639298  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.639401  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.639528  8943 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639540  8943 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639600  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.639622  8943 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0815 08:32:18.639657  8943 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639667  8943 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639684  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 08:32:18.639791  8943 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639803  8943 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.639820  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 08:32:18.639950  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.639981  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.640007  8943 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:18.640017  8943 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4527f740Variable Type 7
1901: I0815 08:32:18.640050  8943 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:18.640077  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.640125  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.640147  8943 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.640285  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:18.640329  8943 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 08:32:18.640977  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.641027  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.642517  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.642545  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.642606  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.642616  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.643364  8943 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 08:32:18.643383  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.643416  8943 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 08:32:18.643424  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.643738  8943 pybind.cc:1827] need skip: 0
1901: I0815 08:32:18.643800  8943 pybind.cc:1827] need skip: 0
1901: I0815 08:32:18.644152  8943 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 08:32:18.644243  8943 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 08:32:18.644251  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 08:32:18.644348  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 08:32:18.644361  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 08:32:18.646625  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:18.647179  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.647195  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.647200  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:18.651144  8943 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 08:32:18.651170  8943 scope.cc:202] Create variable feed
1901: I0815 08:32:18.651218  8943 interpreter_util.cc:1169] Creating Variables
1901: I0815 08:32:18.651228  8943 scope.cc:202] Create variable MedianIndex
1901: I0815 08:32:18.651233  8943 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x44e24650 type is 7
1901: I0815 08:32:18.651244  8943 scope.cc:202] Create variable Out
1901: I0815 08:32:18.651252  8943 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43fc3230 type is 7
1901: I0815 08:32:18.651255  8943 scope.cc:202] Create variable Out@GRAD
1901: I0815 08:32:18.651258  8943 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x436e29a0 type is 7
1901: I0815 08:32:18.651263  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.651266  8943 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x451c2e10 type is 7
1901: I0815 08:32:18.651270  8943 scope.cc:202] Create variable X@GRAD
1901: I0815 08:32:18.651273  8943 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44e38e90 type is 7
1901: I0815 08:32:18.651278  8943 scope.cc:202] Create variable _generated_var_0
1901: I0815 08:32:18.651280  8943 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44e38f10 type is 7
1901: I0815 08:32:18.651285  8943 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 08:32:18.651288  8943 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44e38f90 type is 7
1901: I0815 08:32:18.651293  8943 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44e062a0 type is 9
1901: I0815 08:32:18.651297  8943 scope.cc:202] Create variable fetch
1901: I0815 08:32:18.651319  8943 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44e38ef0 type is 10
1901: I0815 08:32:18.651434  8943 interpreter_util.cc:594] Static build: 0
1901: I0815 08:32:18.651443  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.651448  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.651453  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:18.651525  8943 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.651546  8943 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.651620  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.651629  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.651647  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.652242  8943 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652259  8943 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652276  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.652348  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.652417  8943 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652428  8943 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652472  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.652508  8943 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652516  8943 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652534  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 08:32:18.652609  8943 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652621  8943 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652637  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 08:32:18.652743  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.652757  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.652774  8943 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:18.652781  8943 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x452c8580Variable Type 7
1901: I0815 08:32:18.652802  8943 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:18.652822  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.652842  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.652859  8943 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.652923  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:18.652949  8943 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 08:32:18.653420  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 08:32:18.653461  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.655329  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:18.655579  8943 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ab0b7e0 for it.
1901: I0815 08:32:18.655635  8943 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:18.656581  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:18.656653  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:18.657258  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x45204cd0)  to GradNodeAccumulation (addr: 0x35984860)
1901: I0815 08:32:18.657430  8943 dygraph_functions.cc:51757] Running AD API: mean
1901: I0815 08:32:18.657460  8943 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:18.657560  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.657585  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43dae690)  to NanmedianGradNode (addr: 0x45204cd0)
1901: I0815 08:32:18.657703  8943 backward.cc:442] Run in Backward
1901: I0815 08:32:18.657716  8943 backward.cc:113] Start Backward
1901: I0815 08:32:18.657744  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:18.657804  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.657840  8943 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43dae690
1901: I0815 08:32:18.657857  8943 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0815 08:32:18.657903  8943 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:18.657986  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.658012  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:18.658025  8943 backward.cc:335] Node: MeanGradNode addr:0x43dae690, Found pending node: NanmedianGradNode addr: 0x45204cd0
1901: I0815 08:32:18.658033  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:18.658067  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x45204cd0
1901: I0815 08:32:18.658082  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:18.658109  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:18.658169  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:18.658193  8943 backward.cc:335] Node: NanmedianGradNode addr:0x45204cd0, Found pending node: GradNodeAccumulation addr: 0x35984860
1901: I0815 08:32:18.658201  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:18.658217  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x35984860
1901: I0815 08:32:18.658231  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:18.658239  8943 accumulation_node.cc:40] Move Tensor ptr: 0x4527eff0
1901: I0815 08:32:18.658247  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:18.658252  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0815 08:32:18.668141  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:18.668428  8943 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:18.668493  8943 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1ab0b7e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0815 08:32:18.734175  8943 pir_interpreter.cc:161] PirInterpreter(): 0x476305a0 on Place(gpu:0)
1901: I0815 08:32:18.734225  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.734252  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_1
1901: I0815 08:32:18.734261  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_2
1901: I0815 08:32:18.734268  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_3
1901: I0815 08:32:18.734275  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_4
1901: I0815 08:32:18.734282  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_5
1901: I0815 08:32:18.734289  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_6
1901: I0815 08:32:18.734295  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_7
1901: I0815 08:32:18.734309  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_8
1901: I0815 08:32:18.734315  8943 scope.cc:202] Create variable 0x476305a01723710738734206892_inner_var_9
1901: I0815 08:32:18.734323  8943 scope.cc:202] Create variable fetch0@fetch
1901: I0815 08:32:18.734768  8943 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 08:32:18.734779  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.734782  8943 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0815 08:32:18.734836  8943 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x4762ec90
1901: 1 -> 0x476305a01723710738734206892_inner_var_1 -> 0x47630580
1901: 2 -> 0x476305a01723710738734206892_inner_var_2 -> 0x4762ce50
1901: 3 -> 0x476305a01723710738734206892_inner_var_3 -> 0x4762fc90
1901: 4 -> 0x476305a01723710738734206892_inner_var_4 -> 0x4762ebe0
1901: 5 -> 0x476305a01723710738734206892_inner_var_5 -> 0x47630c40
1901: 6 -> 0x476305a01723710738734206892_inner_var_6 -> 0x47631060
1901: 7 -> 0x476305a01723710738734206892_inner_var_7 -> 0x47631480
1901: 8 -> 0x476305a01723710738734206892_inner_var_8 -> 0x4762dae0
1901: 9 -> 0x476305a01723710738734206892_inner_var_9 -> 0x476318a0
1901: 10 -> fetch0@fetch -> 0x476320b0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0815 08:32:18.735823  8943 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0815 08:32:18.748389  8983 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 08:32:18.748565  8983 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x476305a01723710738734206892_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.748708  8983 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x476305a01723710738734206892_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0815 08:32:18.749343  8981 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 08:32:18.749372  8980 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 08:32:18.751366  8982 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 08:32:18.748411  8984 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 08:32:18.748487  8985 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 08:32:18.752414  8985 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.752485  8985 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 08:32:18.752568  8985 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476305a01723710738734206892_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_3:[dtype=;place=;dim=;lod={};, 0x476305a01723710738734206892_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.753125  8985 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476305a01723710738734206892_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x476305a01723710738734206892_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:18.753193  8985 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x476305a01723710738734206892_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.753268  8985 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.753296  8985 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x476305a01723710738734206892_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:18.753350  8985 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x476305a01723710738734206892_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x476305a01723710738734206892_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.753506  8985 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.753545  8985 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x476305a01723710738734206892_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x476305a01723710738734206892_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:18.753597  8985 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x476305a01723710738734206892_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476305a01723710738734206892_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.753680  8985 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:18.753708  8985 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x476305a01723710738734206892_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476305a01723710738734206892_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:18.753746  8985 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x476305a01723710738734206892_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476305a01723710738734206892_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x476305a01723710738734206892_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.753823  8985 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x476305a01723710738734206892_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476305a01723710738734206892_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x476305a01723710738734206892_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 08:32:18.756402  8984 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476305a01723710738734206892_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.756486  8984 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.756621  8984 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476305a01723710738734206892_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476305a01723710738734206892_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 08:32:18.756659  8984 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x476305a01723710738734206892_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.756685  8984 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 08:32:18.756721  8984 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x476305a01723710738734206892_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 08:32:18.757428  8943 pir_interpreter.cc:1766] main_thread_blocker_(0x47630710) got event_name: TaskCompletion
1901: I0815 08:32:18.757491  8943 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 08:32:18.761083  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.761176  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.761276  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.764405  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.766388  8980 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 2214583493211925249 to 582535791940451453 , after update, data is {current : 19996, peak : 40000}.
1901: I0815 08:32:18.766439  8980 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 2214583493211925249 to 11777889612868958020 , after update, data is {current : 0, peak : 330659}.
1901: I0815 08:32:18.767575  8983 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 17227443003520563314 to 582535791940451453 , after update, data is {current : 20000, peak : 40000}.
1901: I0815 08:32:18.772384  8984 thread_data_registry.h:135] Add data {current : 20000, peak : 40000} from thread 582535791940451453 to 11777889612868958020 , after update, data is {current : 20000, peak : 40000}.
1901: I0815 08:32:18.773913  8985 thread_data_registry.h:135] Add data {current : 20000, peak : 40000} from thread 11777889612868958020 to 12429590720850588845 , after update, data is {current : 20000, peak : 40000}.
1901: I0815 08:32:18.773952  8985 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 11777889612868958020 to 12429590720850588845 , after update, data is {current : 120000, peak : 440631}.
1901: I0815 08:32:18.775830  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:18.776515  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:18.777113  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.777156  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.777177  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:18.783138  8943 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 08:32:18.783211  8943 scope.cc:202] Create variable feed
1901: I0815 08:32:18.783283  8943 interpreter_util.cc:1169] Creating Variables
1901: I0815 08:32:18.783327  8943 scope.cc:202] Create variable MedianIndex
1901: I0815 08:32:18.783347  8943 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47649550 type is 7
1901: I0815 08:32:18.783368  8943 scope.cc:202] Create variable Out
1901: I0815 08:32:18.783383  8943 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47648ae0 type is 7
1901: I0815 08:32:18.783401  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.783416  8943 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x476494d0 type is 7
1901: I0815 08:32:18.783432  8943 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47648b00 type is 9
1901: I0815 08:32:18.783448  8943 scope.cc:202] Create variable fetch
1901: I0815 08:32:18.783464  8943 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x476498b0 type is 10
1901: I0815 08:32:18.783569  8943 interpreter_util.cc:594] Static build: 0
1901: I0815 08:32:18.783588  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.783605  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.783636  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:18.783720  8943 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.783752  8943 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.783847  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.783871  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.783907  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.784538  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.784586  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.784623  8943 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:18.784641  8943 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4764d8f0Variable Type 7
1901: I0815 08:32:18.784677  8943 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:18.784710  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.784750  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.784781  8943 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.784845  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:18.784888  8943 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 08:32:18.784960  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.784986  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.785018  8943 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:18.785035  8943 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x476515c0Variable Type 7
1901: I0815 08:32:18.785063  8943 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:18.785089  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.785120  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.785146  8943 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.785197  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:18.785252  8943 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 08:32:18.785607  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.785665  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.789474  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.789547  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.789644  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:18.789667  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.792042  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:18.792750  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:18.793344  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.793390  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.793411  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:18.795955  8943 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 08:32:18.796116  8943 interpreter_util.cc:1169] Creating Variables
1901: I0815 08:32:18.796146  8943 scope.cc:202] Create variable MedianIndex
1901: I0815 08:32:18.796166  8943 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x4767f4c0 type is 7
1901: I0815 08:32:18.796187  8943 scope.cc:202] Create variable Out
1901: I0815 08:32:18.796203  8943 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4767e7f0 type is 7
1901: I0815 08:32:18.796219  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.796234  8943 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4767f1f0 type is 7
1901: I0815 08:32:18.796250  8943 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47648b00 type is 9
1901: I0815 08:32:18.796267  8943 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x476498b0 type is 10
1901: I0815 08:32:18.796368  8943 interpreter_util.cc:594] Static build: 0
1901: I0815 08:32:18.796389  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:18.796412  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:18.796428  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:18.796506  8943 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.796540  8943 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.796638  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.796662  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.796695  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:18.797331  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.797389  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.797425  8943 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:18.797442  8943 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47683960Variable Type 7
1901: I0815 08:32:18.797484  8943 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:18.797518  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.797556  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.797588  8943 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.797650  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:18.797690  8943 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 08:32:18.797760  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.797784  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:18.797814  8943 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:18.797832  8943 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47683980Variable Type 7
1901: I0815 08:32:18.797857  8943 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:18.797883  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.797914  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:18.797940  8943 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.797987  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:18.798024  8943 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 08:32:18.798420  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.798477  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:18.912151  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ab0b7e0 for it.
1901: I0815 08:32:18.912612  8943 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:18.912683  8943 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:18.913321  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:18.913370  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:18.914711  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ab0b7e0 for it.
1901: I0815 08:32:18.914884  8943 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:18.914939  8943 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:18.916177  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:18.916218  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:18.918852  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ab0b7e0 for it.
1901: I0815 08:32:18.919059  8943 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:18.919108  8943 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 08:32:18.922709  8943 pir_interpreter.cc:161] PirInterpreter(): 0x47660720 on Place(gpu:0)
1901: I0815 08:32:18.922748  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.922771  8943 scope.cc:202] Create variable 0x476607201723710738922737404_inner_var_1
1901: I0815 08:32:18.922780  8943 scope.cc:202] Create variable 0x476607201723710738922737404_inner_var_2
1901: I0815 08:32:18.922788  8943 scope.cc:202] Create variable 0x476607201723710738922737404_inner_var_3
1901: I0815 08:32:18.922797  8943 scope.cc:202] Create variable 0x476607201723710738922737404_inner_var_4
1901: I0815 08:32:18.922806  8943 scope.cc:202] Create variable fetch0@fetch
1901: I0815 08:32:18.923246  8943 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 08:32:18.923259  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.923264  8943 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47658740
1901: 1 -> 0x476607201723710738922737404_inner_var_1 -> 0x4768afe0
1901: 2 -> 0x476607201723710738922737404_inner_var_2 -> 0x4527f960
1901: 3 -> 0x476607201723710738922737404_inner_var_3 -> 0x449d7600
1901: 4 -> 0x476607201723710738922737404_inner_var_4 -> 0x47639e70
1901: 5 -> fetch0@fetch -> 0x47659e00
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 08:32:18.924372  8987 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 08:32:18.924398  8989 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 08:32:18.924818  8991 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 08:32:18.924372  8988 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 08:32:18.924372  8990 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 08:32:18.928355  8992 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 08:32:18.928432  8992 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476607201723710738922737404_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.928499  8992 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476607201723710738922737404_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 08:32:18.928550  8992 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476607201723710738922737404_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476607201723710738922737404_inner_var_3:[dtype=;place=;dim=;lod={};, 0x476607201723710738922737404_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.929137  8992 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476607201723710738922737404_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476607201723710738922737404_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x476607201723710738922737404_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:18.932399  8990 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476607201723710738922737404_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476607201723710738922737404_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.932489  8990 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.932600  8990 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476607201723710738922737404_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476607201723710738922737404_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:18.932649  8990 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x476607201723710738922737404_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.932674  8990 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:18.932689  8990 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x476607201723710738922737404_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:18.934370  8943 pir_interpreter.cc:1766] main_thread_blocker_(0x47660890) got event_name: TaskCompletion
1901: I0815 08:32:18.934427  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:18.935380  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:18.935648  8943 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:18.935710  8943 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1ab0b7e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 08:32:18.939118  8943 pir_interpreter.cc:161] PirInterpreter(): 0x4763aa90 on Place(gpu:0)
1901: I0815 08:32:18.939157  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.939180  8943 scope.cc:202] Create variable 0x4763aa901723710738939146968_inner_var_1
1901: I0815 08:32:18.939190  8943 scope.cc:202] Create variable 0x4763aa901723710738939146968_inner_var_2
1901: I0815 08:32:18.939198  8943 scope.cc:202] Create variable 0x4763aa901723710738939146968_inner_var_3
1901: I0815 08:32:18.939206  8943 scope.cc:202] Create variable 0x4763aa901723710738939146968_inner_var_4
1901: I0815 08:32:18.939215  8943 scope.cc:202] Create variable fetch0@fetch
1901: I0815 08:32:18.939623  8943 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 08:32:18.939636  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.939639  8943 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x476837b0
1901: 1 -> 0x4763aa901723710738939146968_inner_var_1 -> 0x47683830
1901: 2 -> 0x4763aa901723710738939146968_inner_var_2 -> 0x4767fa00
1901: 3 -> 0x4763aa901723710738939146968_inner_var_3 -> 0x1aaa3f80
1901: 4 -> 0x4763aa901723710738939146968_inner_var_4 -> 0x47658110
1901: 5 -> fetch0@fetch -> 0x4763c0f0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 08:32:18.941457  8997 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 08:32:18.959403  8995 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 08:32:18.960341  8998 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 08:32:18.960448  8998 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4763aa901723710738939146968_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.960515  8998 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4763aa901723710738939146968_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 08:32:18.960559  8998 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4763aa901723710738939146968_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4763aa901723710738939146968_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4763aa901723710738939146968_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.961120  8998 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4763aa901723710738939146968_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4763aa901723710738939146968_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4763aa901723710738939146968_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:18.961333  8995 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4763aa901723710738939146968_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4763aa901723710738939146968_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.961439  8995 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:18.961565  8995 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4763aa901723710738939146968_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4763aa901723710738939146968_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:18.961625  8995 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4763aa901723710738939146968_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:18.961663  8995 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:18.961689  8995 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4763aa901723710738939146968_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:18.961753  8943 pir_interpreter.cc:1766] main_thread_blocker_(0x4763ac00) got event_name: TaskCompletion
1901: I0815 08:32:18.961784  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:18.962339  8996 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 08:32:18.963796  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ab0b7e0 for it.
1901: I0815 08:32:18.964087  8943 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:18.964145  8943 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:18.960350  8994 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 08:32:18.962342  8993 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 08:32:18.967686  8943 pir_interpreter.cc:161] PirInterpreter(): 0x452bac10 on Place(gpu:0)
1901: I0815 08:32:18.967727  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.967751  8943 scope.cc:202] Create variable 0x452bac101723710738967717382_inner_var_1
1901: I0815 08:32:18.967761  8943 scope.cc:202] Create variable 0x452bac101723710738967717382_inner_var_2
1901: I0815 08:32:18.967769  8943 scope.cc:202] Create variable 0x452bac101723710738967717382_inner_var_3
1901: I0815 08:32:18.967779  8943 scope.cc:202] Create variable 0x452bac101723710738967717382_inner_var_4
1901: I0815 08:32:18.967788  8943 scope.cc:202] Create variable fetch0@fetch
1901: I0815 08:32:18.968247  8943 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 08:32:18.968258  8943 scope.cc:202] Create variable X
1901: I0815 08:32:18.968262  8943 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47648230
1901: 1 -> 0x452bac101723710738967717382_inner_var_1 -> 0x476482b0
1901: 2 -> 0x452bac101723710738967717382_inner_var_2 -> 0x476543f0
1901: 3 -> 0x452bac101723710738967717382_inner_var_3 -> 0x476638c0
1901: 4 -> 0x452bac101723710738967717382_inner_var_4 -> 0x47654370
1901: 5 -> fetch0@fetch -> 0x1aaa5c50
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 08:32:18.981379  8999 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 08:32:19.002388  9002 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 08:32:19.002478  9000 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 08:32:19.004454  9001 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 08:32:19.007391  9003 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 08:32:19.009399  9004 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 08:32:19.009474  9004 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x452bac101723710738967717382_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.009536  9004 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x452bac101723710738967717382_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 08:32:19.009580  9004 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x452bac101723710738967717382_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x452bac101723710738967717382_inner_var_3:[dtype=;place=;dim=;lod={};, 0x452bac101723710738967717382_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.010131  9004 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x452bac101723710738967717382_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x452bac101723710738967717382_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x452bac101723710738967717382_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.011379  9003 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x452bac101723710738967717382_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x452bac101723710738967717382_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.011431  9003 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.011518  9003 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x452bac101723710738967717382_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x452bac101723710738967717382_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.011560  9003 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x452bac101723710738967717382_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.011580  9003 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.011597  9003 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x452bac101723710738967717382_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.012336  8943 pir_interpreter.cc:1766] main_thread_blocker_(0x452bad80) got event_name: TaskCompletion
1901: I0815 08:32:19.012389  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.012776  8943 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0815 08:32:19.012946  8943 unary_infer_sym.cc:1363] NanmedianOpInferSymbolicShape
1901: I0815 08:32:19.089373  8987 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 11777889612868958020 to 3630773486018628395 , after update, data is {current : -4, peak : 0}.
1901: I0815 08:32:19.089413  8987 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 11777889612868958020 to 3630773486018628395 , after update, data is {current : -36, peak : 0}.
1901: I0815 08:32:19.094388  8990 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 2977492262332744736 to 3630773486018628395 , after update, data is {current : 0, peak : 4}.
1901: I0815 08:32:19.102380  8992 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 1587417808150736031 to 3630773486018628395 , after update, data is {current : 0, peak : 16}.
1901: I0815 08:32:19.102423  8992 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 1587417808150736031 to 3630773486018628395 , after update, data is {current : -18, peak : 330659}.
1901: I0815 08:32:19.112390  8993 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 2979717615246536813 to 3630773486018628395 , after update, data is {current : -2, peak : 16}.
1901: I0815 08:32:19.112432  8993 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 2979717615246536813 to 3630773486018628395 , after update, data is {current : -36, peak : 330659}.
1901: I0815 08:32:19.113487  8995 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 7948171802960935798 to 3630773486018628395 , after update, data is {current : 2, peak : 16}.
1901: I0815 08:32:19.122380  8998 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 8821521895975949215 to 3630773486018628395 , after update, data is {current : 2, peak : 16}.
1901: I0815 08:32:19.122416  8998 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 8821521895975949215 to 3630773486018628395 , after update, data is {current : -18, peak : 330659}.
1901: I0815 08:32:19.125370  8999 thread_data_registry.h:135] Add data {current : 2, peak : 16} from thread 3630773486018628395 to 611694206237475448 , after update, data is {current : 6, peak : 16}.
1901: I0815 08:32:19.125409  8999 thread_data_registry.h:135] Add data {current : -18, peak : 330659} from thread 3630773486018628395 to 13230939523908740817 , after update, data is {current : 0, peak : 330659}.
1901: I0815 08:32:19.130407  9003 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 611694206237475448 to 13230939523908740817 , after update, data is {current : 6, peak : 16}.
1901: I0815 08:32:19.137368  9004 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 13230939523908740817 to 12429590720850588845 , after update, data is {current : 20006, peak : 40000}.
1901: I0815 08:32:19.137394  9004 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 13230939523908740817 to 12429590720850588845 , after update, data is {current : 200000, peak : 560633}.
1901: I0815 08:32:19.160735  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.160928  8943 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7efd50a27c00), and remaining 0
1901: I0815 08:32:19.161068  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.161109  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.161454  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.162518  8943 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.162612  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.162642  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.162845  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.163637  8943 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.163709  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.163734  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.163895  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.164552  8943 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.164628  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.164651  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.164811  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0815 08:32:19.165547  8943 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.165602  8943 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7efd50a18e00), and remaining 0
1901: I0815 08:32:19.165654  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.165675  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.166164  8943 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.166227  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.166249  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.166751  8943 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.166811  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.166832  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.167239  8943 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.167297  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.167328  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.167896  8943 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.167958  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.167977  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.168169  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.168814  8943 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.168886  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.168908  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.169063  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.169744  8943 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.169809  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.169831  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.170019  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.174958  8943 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.175109  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.175146  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.175412  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.176230  8943 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.176316  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.176343  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.176554  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.177227  8943 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.177294  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.177328  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.177491  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.178210  8943 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.178277  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.178354  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.178525  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.179201  8943 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.179270  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.179292  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.179456  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.180145  8943 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.180209  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.180230  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.180426  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.181042  8943 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.181108  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.181130  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.181289  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.181811  8943 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.181875  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.181897  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.182046  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.187016  8943 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.187119  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.187153  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.187361  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.188114  8943 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.188185  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.188210  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.188529  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0815 08:32:19.208233  8943 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.208370  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.208418  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.208709  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.210381  8943 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.210471  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.210505  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.210757  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.212236  8943 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.212352  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.212383  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.212589  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.213896  8943 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.213971  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.213997  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.214275  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.215555  8943 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.215628  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.215654  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.215852  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.221694  8943 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.221815  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.221853  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.222117  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.223644  8943 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.223735  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.223766  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.223979  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.225256  8943 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.225340  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.225366  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.225641  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.227023  8943 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.227103  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.227128  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.227339  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.228597  8943 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.228667  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.228690  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.228926  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.230151  8943 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.230221  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.230244  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.234606  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.236394  8943 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.236503  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.236541  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.236779  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.238174  8943 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.238260  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.238289  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.238505  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.239888  8943 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.239972  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.239997  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.240191  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.246002  8943 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.246120  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.246157  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.246433  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.247848  8943 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.247932  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.247962  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.248175  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.248991  8943 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.249060  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.249085  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.249272  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.252674  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.252712  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.253661  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.253681  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.258670  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.258713  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.259804  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.259831  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.260648  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.260666  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.263602  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.264154  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.264717  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.265244  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.265776  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.266752  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:19.266765  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:19.266772  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:19.276587  8943 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 08:32:19.276726  8943 interpreter_util.cc:1169] Creating Variables
1901: I0815 08:32:19.276736  8943 scope.cc:202] Create variable X
1901: I0815 08:32:19.276743  8943 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47949ea0 type is 7
1901: I0815 08:32:19.276752  8943 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47648b00 type is 9
1901: I0815 08:32:19.276758  8943 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x476498b0 type is 10
1901: I0815 08:32:19.276763  8943 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 08:32:19.276768  8943 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x47949210 type is 7
1901: I0815 08:32:19.276773  8943 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 08:32:19.276777  8943 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x47949e00 type is 7
1901: I0815 08:32:19.276782  8943 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 08:32:19.276785  8943 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x47949fe0 type is 7
1901: I0815 08:32:19.276790  8943 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 08:32:19.276794  8943 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x4794a0c0 type is 7
1901: I0815 08:32:19.276798  8943 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 08:32:19.276803  8943 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x4794a1f0 type is 7
1901: I0815 08:32:19.276808  8943 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 08:32:19.276811  8943 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x4794a3b0 type is 7
1901: I0815 08:32:19.276815  8943 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 08:32:19.276819  8943 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x4794a5c0 type is 7
1901: I0815 08:32:19.276823  8943 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 08:32:19.276826  8943 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x4794a820 type is 7
1901: I0815 08:32:19.276831  8943 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 08:32:19.276835  8943 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x4794aa80 type is 7
1901: I0815 08:32:19.276839  8943 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 08:32:19.276844  8943 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x47948bb0 type is 7
1901: I0815 08:32:19.277009  8943 interpreter_util.cc:594] Static build: 0
1901: I0815 08:32:19.277014  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:19.277020  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:19.277025  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:19.277105  8943 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.277124  8943 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.277201  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.277209  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.277228  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.277519  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.277735  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.277747  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.277765  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.277899  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.278090  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.278100  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.278115  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.278237  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.282560  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.282603  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.282634  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.282909  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.283128  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.283138  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.283156  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.283326  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.283527  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.283538  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.283558  8943 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.283566  8943 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a22670Variable Type 7
1901: I0815 08:32:19.283596  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.283617  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.283643  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.283659  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.283708  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.283728  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 08:32:19.283775  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.283783  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.283800  8943 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.283805  8943 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47956990Variable Type 7
1901: I0815 08:32:19.283820  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.283833  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.283849  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.283864  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.283896  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.283923  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 08:32:19.283968  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.283977  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.283993  8943 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.283996  8943 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x479676d0Variable Type 7
1901: I0815 08:32:19.284011  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.284022  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.284039  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.284050  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.284080  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.284091  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 08:32:19.284132  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.284140  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.284154  8943 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.284159  8943 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4795d280Variable Type 7
1901: I0815 08:32:19.284173  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.284183  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.284198  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.284209  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.284238  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.284250  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 08:32:19.284286  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.284292  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.284317  8943 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.284322  8943 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47959000Variable Type 7
1901: I0815 08:32:19.284335  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.284348  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.284363  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.284374  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.284404  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.284415  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 08:32:19.285126  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.285154  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.285169  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.285184  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.285198  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 08:32:19.296986  8943 pir_interpreter.cc:161] PirInterpreter(): 0x47a79810 on Place(gpu:0)
1901: I0815 08:32:19.297039  8943 scope.cc:202] Create variable X
1901: I0815 08:32:19.297063  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_1
1901: I0815 08:32:19.297071  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_2
1901: I0815 08:32:19.297080  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_3
1901: I0815 08:32:19.297087  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_4
1901: I0815 08:32:19.297096  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_5
1901: I0815 08:32:19.297103  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_6
1901: I0815 08:32:19.297111  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_7
1901: I0815 08:32:19.297119  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_8
1901: I0815 08:32:19.297127  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_9
1901: I0815 08:32:19.297134  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_10
1901: I0815 08:32:19.297142  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_11
1901: I0815 08:32:19.297150  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_12
1901: I0815 08:32:19.297159  8943 scope.cc:202] Create variable fetch0@fetch
1901: I0815 08:32:19.297173  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_14
1901: I0815 08:32:19.297180  8943 scope.cc:202] Create variable fetch1@fetch
1901: I0815 08:32:19.297188  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_16
1901: I0815 08:32:19.297196  8943 scope.cc:202] Create variable fetch2@fetch
1901: I0815 08:32:19.297204  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_18
1901: I0815 08:32:19.297212  8943 scope.cc:202] Create variable fetch3@fetch
1901: I0815 08:32:19.297219  8943 scope.cc:202] Create variable 0x47a798101723710739297023342_inner_var_20
1901: I0815 08:32:19.297227  8943 scope.cc:202] Create variable fetch4@fetch
1901: I0815 08:32:19.297752  8943 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 08:32:19.297765  8943 scope.cc:202] Create variable X
1901: I0815 08:32:19.297770  8943 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47a4c080
1901: 1 -> 0x47a798101723710739297023342_inner_var_1 -> 0x47956790
1901: 2 -> 0x47a798101723710739297023342_inner_var_2 -> 0x479f68f0
1901: 3 -> 0x47a798101723710739297023342_inner_var_3 -> 0x45281b80
1901: 4 -> 0x47a798101723710739297023342_inner_var_4 -> 0x4794dac0
1901: 5 -> 0x47a798101723710739297023342_inner_var_5 -> 0x479faf50
1901: 6 -> 0x47a798101723710739297023342_inner_var_6 -> 0x479f6580
1901: 7 -> 0x47a798101723710739297023342_inner_var_7 -> 0x47967860
1901: 8 -> 0x47a798101723710739297023342_inner_var_8 -> 0x47a9e8b0
1901: 9 -> 0x47a798101723710739297023342_inner_var_9 -> 0x47956e70
1901: 10 -> 0x47a798101723710739297023342_inner_var_10 -> 0x47a9e2d0
1901: 11 -> 0x47a798101723710739297023342_inner_var_11 -> 0x47967320
1901: 12 -> 0x47a798101723710739297023342_inner_var_12 -> 0x47956910
1901: 13 -> fetch0@fetch -> 0x47949060
1901: 14 -> 0x47a798101723710739297023342_inner_var_14 -> 0x47950b10
1901: 15 -> fetch1@fetch -> 0x4767c870
1901: 16 -> 0x47a798101723710739297023342_inner_var_16 -> 0x4795b920
1901: 17 -> fetch2@fetch -> 0x47a686e0
1901: 18 -> 0x47a798101723710739297023342_inner_var_18 -> 0x4767c850
1901: 19 -> fetch3@fetch -> 0x4766a500
1901: 20 -> 0x47a798101723710739297023342_inner_var_20 -> 0x47a686c0
1901: 21 -> fetch4@fetch -> 0x4796f400
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 08:32:19.300346  9007 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 08:32:19.300499  9008 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 08:32:19.300346  9006 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 08:32:19.303334  9005 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 08:32:19.300354  9009 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 08:32:19.304396  9009 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.304483  9009 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 08:32:19.304551  9009 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47a798101723710739297023342_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.304876  9009 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.305035  9009 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a798101723710739297023342_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.305094  9009 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_5:[dtype=;place=;dim=;lod={};, 0x47a798101723710739297023342_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.305208  9009 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.305348  9009 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a798101723710739297023342_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.305397  9009 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_7:[dtype=;place=;dim=;lod={};, 0x47a798101723710739297023342_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.305501  9009 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.305639  9009 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a798101723710739297023342_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.305681  9009 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_9:[dtype=;place=;dim=;lod={};, 0x47a798101723710739297023342_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.305814  9009 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.305959  9009 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a798101723710739297023342_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.305994  9009 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_11:[dtype=;place=;dim=;lod={};, 0x47a798101723710739297023342_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306109  9009 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.306257  9009 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a798101723710739297023342_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a798101723710739297023342_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.306373  9008 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306442  9008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.306541  9008 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.306634  9008 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306655  9008 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.306667  9008 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.306689  9008 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306703  9008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.306732  9008 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.306766  9008 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306779  9008 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.306790  9008 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.306808  9008 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306823  9008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.306847  9008 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.306875  9008 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306888  9008 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.306870  9006 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.306933  9006 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.307018  9006 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.307080  9006 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.307097  9006 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.307109  9006 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.306897  9008 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.310350  9007 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.310427  9007 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.310535  9007 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a798101723710739297023342_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a798101723710739297023342_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.310623  9007 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.310647  9007 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.310660  9007 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a798101723710739297023342_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.311331  8943 pir_interpreter.cc:1766] main_thread_blocker_(0x47a79980) got event_name: TaskCompletion
1901: I0815 08:32:19.311381  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.311432  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.311446  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.311460  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.311472  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.320550  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.320758  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.320803  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.321084  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.321193  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x479f4ff0)  to GradNodeAccumulation (addr: 0x35984860)
1901: I0815 08:32:19.321424  8943 backward.cc:459] Run in Grad
1901: I0815 08:32:19.321440  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.321497  8943 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x479f4ff0 to ptr: 0x47963750
1901: I0815 08:32:19.321514  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.321564  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.321599  8943 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x35984860 to ptr: 0x47926ca0
1901: I0815 08:32:19.321628  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47963750
1901: I0815 08:32:19.321635  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.321676  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.321753  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.321760  8943 backward.cc:335] Node: NanmedianGradNode addr:0x47963750, Found pending node: GradNodeAccumulation addr: 0x47926ca0
1901: I0815 08:32:19.321765  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.321794  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47926ca0
1901: I0815 08:32:19.321799  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.321803  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.321810  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.321813  8943 backward.cc:435] Finish Backward
1901: I0815 08:32:19.323009  8943 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 08:32:19.323026  8943 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 08:32:19.323163  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.323189  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.323362  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.323441  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x479f4ff0)  to GradNodeAccumulation (addr: 0x35984860)
1901: I0815 08:32:19.323570  8943 backward.cc:442] Run in Backward
1901: I0815 08:32:19.323575  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.323582  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.323616  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.323642  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x479f4ff0
1901: I0815 08:32:19.323649  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.323681  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.323745  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.323768  8943 backward.cc:335] Node: NanmedianGradNode addr:0x479f4ff0, Found pending node: GradNodeAccumulation addr: 0x35984860
1901: I0815 08:32:19.323774  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.323791  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x35984860
1901: I0815 08:32:19.323796  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.323801  8943 accumulation_node.cc:40] Move Tensor ptr: 0x479f56c0
1901: I0815 08:32:19.323803  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.323807  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.327172  8943 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0815 08:32:19.327996  8943 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.328162  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.328192  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.328402  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47943760)  to GradNodeAccumulation (addr: 0x1ab764b0)
1901: I0815 08:32:19.328545  8943 backward.cc:442] Run in Backward
1901: I0815 08:32:19.328552  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.328559  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.328595  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.328621  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47943760
1901: I0815 08:32:19.328629  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.328661  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.328714  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.328737  8943 backward.cc:335] Node: NanmedianGradNode addr:0x47943760, Found pending node: GradNodeAccumulation addr: 0x1ab764b0
1901: I0815 08:32:19.328742  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.328758  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1ab764b0
1901: I0815 08:32:19.328763  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.328766  8943 accumulation_node.cc:40] Move Tensor ptr: 0x451ca900
1901: I0815 08:32:19.328769  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.328773  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.330502  8943 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.330605  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.330633  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.330893  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.330991  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x479f4ff0)  to GradNodeAccumulation (addr: 0x1ab764b0)
1901: I0815 08:32:19.331143  8943 backward.cc:459] Run in Grad
1901: I0815 08:32:19.331151  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.331169  8943 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x479f4ff0 to ptr: 0x47943760
1901: I0815 08:32:19.331177  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.331208  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.331233  8943 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1ab764b0 to ptr: 0x47926ca0
1901: I0815 08:32:19.331254  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47943760
1901: I0815 08:32:19.331259  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.331291  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.331442  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.331524  8943 backward.cc:335] Node: NanmedianGradNode addr:0x47943760, Found pending node: GradNodeAccumulation addr: 0x47926ca0
1901: I0815 08:32:19.331547  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.331583  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47926ca0
1901: I0815 08:32:19.331604  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.331619  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.331638  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.331655  8943 backward.cc:435] Finish Backward
1901: I0815 08:32:19.332876  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.333019  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.333070  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.333271  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.339308  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.339469  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.339521  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.391268  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.395370  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.397030  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.397065  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.398377  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.398547  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.398589  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.398890  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.403826  8943 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.403997  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.404042  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.404347  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.405078  8943 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.405171  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.405202  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.405396  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.405977  8943 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.406052  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.406077  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.406252  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.406858  8943 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.406916  8943 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7efd50a19200), and remaining 0
1901: I0815 08:32:19.406972  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.406996  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.407508  8943 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.407574  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.407595  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.408071  8943 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.408136  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.408160  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.412812  8943 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.412915  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.412948  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.413559  8943 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.413636  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.413662  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.413879  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.414522  8943 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.414608  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.414633  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.414808  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.415439  8943 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.415510  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.415535  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.415694  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.416278  8943 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.416363  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.416388  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.416558  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.417158  8943 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.417228  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.417253  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.421505  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.422276  8943 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.422446  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.422485  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.422686  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.423318  8943 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.423395  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.423422  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.423583  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.424185  8943 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.424260  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.424285  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.424463  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.425092  8943 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.425163  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.425189  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.425370  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.425938  8943 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.426010  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.426035  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.426208  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.430984  8943 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.431083  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.431115  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.431313  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.432071  8943 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.432145  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.432173  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.432353  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.432942  8943 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.433015  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.433038  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.433220  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.433954  8943 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.434019  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.434043  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.434216  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.434891  8943 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.434967  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.434990  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.435168  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.440054  8943 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.440151  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.440182  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.440399  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.441109  8943 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.441179  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.441205  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.441424  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.442054  8943 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.442121  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.442144  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.442343  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.442960  8943 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.443033  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.443058  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.443228  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.443866  8943 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.443933  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.443955  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.444123  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.449023  8943 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.449127  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.449159  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.449407  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.450110  8943 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.450182  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.450207  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.450407  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.451026  8943 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x1ab764b0 for it.
1901: I0815 08:32:19.451092  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.451115  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.451314  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.451920  8943 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.451984  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.452006  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.452178  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.452791  8943 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.452857  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.452879  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.453055  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.457909  8943 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.458012  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.458043  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.458251  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.458946  8943 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.459026  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.459051  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.459242  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.459934  8943 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.460018  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.460044  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.460239  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.460832  8943 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.460898  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.460922  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.461095  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.461841  8943 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.461915  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.461941  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.462136  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.469218  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.469264  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.470016  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.470038  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.471550  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.471571  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.472257  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.472272  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.472898  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.472913  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.474751  9007 thread_data_registry.h:135] Add data {current : -4, peak : 0} from thread 17340996655941800369 to 611694206237475448 , after update, data is {current : -8, peak : 0}.
1901: I0815 08:32:19.474772  9007 thread_data_registry.h:135] Add data {current : 4, peak : 8} from thread 17340996655941800369 to 611694206237475448 , after update, data is {current : 8, peak : 8}.
1901: I0815 08:32:19.475028  9006 thread_data_registry.h:135] Add data {current : -8, peak : 0} from thread 611694206237475448 to 18392880003490601035 , after update, data is {current : -20, peak : 0}.
1901: I0815 08:32:19.475051  9006 thread_data_registry.h:135] Add data {current : 8, peak : 8} from thread 611694206237475448 to 18392880003490601035 , after update, data is {current : 20, peak : 20}.
1901: I0815 08:32:19.475273  9008 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 18392880003490601035 to 1587417808150736031 , after update, data is {current : 0, peak : 1260}.
1901: I0815 08:32:19.475294  9008 thread_data_registry.h:135] Add data {current : 20, peak : 20} from thread 18392880003490601035 to 1587417808150736031 , after update, data is {current : 20, peak : 20}.
1901: I0815 08:32:19.476418  9009 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 1587417808150736031 to 12429590720850588845 , after update, data is {current : 0, peak : 260}.
1901: I0815 08:32:19.476454  9009 thread_data_registry.h:135] Add data {current : 20, peak : 20} from thread 1587417808150736031 to 12429590720850588845 , after update, data is {current : 20026, peak : 40000}.
1901: I0815 08:32:19.476459  9009 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 1587417808150736031 to 12429590720850588845 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 08:32:19.481529  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.482079  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.482576  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.483111  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.483594  8943 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 08:32:19.484613  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:19.484655  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:19.484673  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:19.495828  8943 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 08:32:19.495971  8943 interpreter_util.cc:1169] Creating Variables
1901: I0815 08:32:19.495997  8943 scope.cc:202] Create variable X
1901: I0815 08:32:19.496013  8943 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47a94bd0 type is 7
1901: I0815 08:32:19.496032  8943 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47648b00 type is 9
1901: I0815 08:32:19.496047  8943 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x476498b0 type is 10
1901: I0815 08:32:19.496062  8943 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 08:32:19.496075  8943 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x47a941a0 type is 7
1901: I0815 08:32:19.496090  8943 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 08:32:19.496104  8943 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x47a68410 type is 7
1901: I0815 08:32:19.496119  8943 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 08:32:19.496130  8943 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x47a94d50 type is 7
1901: I0815 08:32:19.496145  8943 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 08:32:19.496157  8943 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x47a94e80 type is 7
1901: I0815 08:32:19.496177  8943 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 08:32:19.496201  8943 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x47a950e0 type is 7
1901: I0815 08:32:19.496217  8943 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 08:32:19.496228  8943 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x47a953d0 type is 7
1901: I0815 08:32:19.496243  8943 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 08:32:19.496254  8943 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x47a955c0 type is 7
1901: I0815 08:32:19.496268  8943 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 08:32:19.496280  8943 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x47953b00 type is 7
1901: I0815 08:32:19.496294  8943 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 08:32:19.496312  8943 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x47953d20 type is 7
1901: I0815 08:32:19.496326  8943 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 08:32:19.496338  8943 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x47953f80 type is 7
1901: I0815 08:32:19.496497  8943 interpreter_util.cc:594] Static build: 0
1901: I0815 08:32:19.496515  8943 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 08:32:19.496529  8943 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 08:32:19.496543  8943 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 08:32:19.496629  8943 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.496661  8943 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.496745  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.496767  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.496796  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.497074  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.497296  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.497334  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.497362  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.497506  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.497704  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.497728  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.497754  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.497892  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.498085  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.498109  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.498134  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.498291  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.498510  8943 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.498536  8943 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.498562  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.498708  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.498910  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.498935  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.498963  8943 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.498979  8943 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a968c0Variable Type 7
1901: I0815 08:32:19.499013  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.499042  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.499076  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.499102  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.499153  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.499186  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 08:32:19.499239  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.499260  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.499284  8943 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.503315  8943 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x479287f0Variable Type 7
1901: I0815 08:32:19.503413  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.503465  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.503518  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.503553  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.503638  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.503693  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 08:32:19.503799  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.503822  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.503851  8943 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.503866  8943 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4796fa80Variable Type 7
1901: I0815 08:32:19.503893  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.503916  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.503944  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.503968  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.504012  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.504036  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 08:32:19.504094  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.504117  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.504139  8943 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.504153  8943 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47972000Variable Type 7
1901: I0815 08:32:19.504175  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.504195  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.504220  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.504242  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.504284  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.504314  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 08:32:19.504369  8943 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.504390  8943 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 08:32:19.504429  8943 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 08:32:19.504444  8943 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47928120Variable Type 7
1901: I0815 08:32:19.504469  8943 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 08:32:19.504491  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.504516  8943 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 08:32:19.504539  8943 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.504580  8943 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 08:32:19.504604  8943 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 08:32:19.505231  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.505296  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.505368  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.505400  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 08:32:19.505426  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 08:32:19.516899  8943 pir_interpreter.cc:161] PirInterpreter(): 0x47909bf0 on Place(gpu:0)
1901: I0815 08:32:19.516973  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_1
1901: I0815 08:32:19.516996  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_2
1901: I0815 08:32:19.517014  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_3
1901: I0815 08:32:19.517030  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_4
1901: I0815 08:32:19.517046  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_5
1901: I0815 08:32:19.517064  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_6
1901: I0815 08:32:19.517081  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_7
1901: I0815 08:32:19.517098  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_8
1901: I0815 08:32:19.517114  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_9
1901: I0815 08:32:19.517132  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_10
1901: I0815 08:32:19.517150  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_11
1901: I0815 08:32:19.517169  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_12
1901: I0815 08:32:19.517195  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_14
1901: I0815 08:32:19.517217  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_16
1901: I0815 08:32:19.517238  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_18
1901: I0815 08:32:19.517258  8943 scope.cc:202] Create variable 0x47909bf01723710739516950095_inner_var_20
1901: I0815 08:32:19.517709  8943 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x4796f710
1901: 1 -> 0x47909bf01723710739516950095_inner_var_1 -> 0x47961220
1901: 2 -> 0x47909bf01723710739516950095_inner_var_2 -> 0x479611c0
1901: 3 -> 0x47909bf01723710739516950095_inner_var_3 -> 0x47a94100
1901: 4 -> 0x47909bf01723710739516950095_inner_var_4 -> 0x47988020
1901: 5 -> 0x47909bf01723710739516950095_inner_var_5 -> 0x479838f0
1901: 6 -> 0x47909bf01723710739516950095_inner_var_6 -> 0x4794e490
1901: 7 -> 0x47909bf01723710739516950095_inner_var_7 -> 0x4768b4f0
1901: 8 -> 0x47909bf01723710739516950095_inner_var_8 -> 0x47689210
1901: 9 -> 0x47909bf01723710739516950095_inner_var_9 -> 0x6407230
1901: 10 -> 0x47909bf01723710739516950095_inner_var_10 -> 0x479773f0
1901: 11 -> 0x47909bf01723710739516950095_inner_var_11 -> 0x1aaa7230
1901: 12 -> 0x47909bf01723710739516950095_inner_var_12 -> 0x47a7ef90
1901: 13 -> fetch0@fetch -> 0x47949060
1901: 14 -> 0x47909bf01723710739516950095_inner_var_14 -> 0x1ac83c60
1901: 15 -> fetch1@fetch -> 0x4767c870
1901: 16 -> 0x47909bf01723710739516950095_inner_var_16 -> 0x1ad05060
1901: 17 -> fetch2@fetch -> 0x47a686e0
1901: 18 -> 0x47909bf01723710739516950095_inner_var_18 -> 0x47957040
1901: 19 -> fetch3@fetch -> 0x4766a500
1901: 20 -> 0x47909bf01723710739516950095_inner_var_20 -> 0x4763d350
1901: 21 -> fetch4@fetch -> 0x4796f400
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 08:32:19.520340  9011 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 08:32:19.520356  9012 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 08:32:19.522336  9010 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 08:32:19.523355  9014 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 08:32:19.523413  9014 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.523478  9014 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 08:32:19.523536  9014 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47909bf01723710739516950095_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.523905  9014 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.524071  9014 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47909bf01723710739516950095_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.524134  9014 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_5:[dtype=;place=;dim=;lod={};, 0x47909bf01723710739516950095_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.524266  9014 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.520340  9013 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 08:32:19.524365  9013 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.524411  9013 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.524416  9014 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47909bf01723710739516950095_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.524479  9014 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_7:[dtype=;place=;dim=;lod={};, 0x47909bf01723710739516950095_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.524603  9012 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.524662  9012 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.524737  9012 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.525008  9013 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.525215  9014 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.525476  9014 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47909bf01723710739516950095_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.525560  9014 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_9:[dtype=;place=;dim=;lod={};, 0x47909bf01723710739516950095_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.525750  9014 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.525923  9014 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47909bf01723710739516950095_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.525992  9014 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_11:[dtype=;place=;dim=;lod={};, 0x47909bf01723710739516950095_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.526147  9014 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.526320  9014 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47909bf01723710739516950095_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47909bf01723710739516950095_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 08:32:19.526340  9011 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.526449  9011 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.526526  9011 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.526607  9011 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.526660  9011 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.526679  9011 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.526716  9011 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.526750  9011 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.526791  9011 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.526840  9011 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.526877  9011 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.526894  9011 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.526333  9010 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_0
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 08:32:19.527348  9010 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 08:32:19.527416  9010 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_0
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47909bf01723710739516950095_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47909bf01723710739516950095_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.527470  9010 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_0
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.527490  9010 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.527498  9010 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_0
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.525274  9012 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.529335  9012 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.529350  9012 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.525312  9013 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.529418  9013 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.529423  9013 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47909bf01723710739516950095_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 08:32:19.529484  8943 pir_interpreter.cc:1766] main_thread_blocker_(0x47909d60) got event_name: TaskCompletion
1901: I0815 08:32:19.529505  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.529529  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.529537  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.529546  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.529554  8943 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 08:32:19.531880  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x47941030 for it.
1901: I0815 08:32:19.532024  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.532064  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.532320  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.532419  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47986190)  to GradNodeAccumulation (addr: 0x47941030)
1901: I0815 08:32:19.532581  8943 backward.cc:459] Run in Grad
1901: I0815 08:32:19.532590  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.532609  8943 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47986190 to ptr: 0x476a54e0
1901: I0815 08:32:19.532620  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.532665  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.532692  8943 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x47941030 to ptr: 0x47926ca0
1901: I0815 08:32:19.532714  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x476a54e0
1901: I0815 08:32:19.532721  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.532758  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.532836  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.532843  8943 backward.cc:335] Node: NanmedianGradNode addr:0x476a54e0, Found pending node: GradNodeAccumulation addr: 0x47926ca0
1901: I0815 08:32:19.532848  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.532876  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47926ca0
1901: I0815 08:32:19.532881  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.532884  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.532889  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.532893  8943 backward.cc:435] Finish Backward
1901: I0815 08:32:19.534750  8943 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 08:32:19.534775  8943 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 08:32:19.534898  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.534926  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.535104  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.535182  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47986190)  to GradNodeAccumulation (addr: 0x47941030)
1901: I0815 08:32:19.535297  8943 backward.cc:442] Run in Backward
1901: I0815 08:32:19.535312  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.535320  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.535514  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.535604  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47986190
1901: I0815 08:32:19.535615  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.535671  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.535748  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.535789  8943 backward.cc:335] Node: NanmedianGradNode addr:0x47986190, Found pending node: GradNodeAccumulation addr: 0x47941030
1901: I0815 08:32:19.535797  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.535815  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47941030
1901: I0815 08:32:19.535820  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.535823  8943 accumulation_node.cc:40] Move Tensor ptr: 0x47a7c1b0
1901: I0815 08:32:19.535826  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.535830  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.536697  8943 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.536859  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.536890  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.537091  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x476a54e0)  to GradNodeAccumulation (addr: 0x35984860)
1901: I0815 08:32:19.537257  8943 backward.cc:442] Run in Backward
1901: I0815 08:32:19.537264  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.537273  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.537320  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.537346  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x476a54e0
1901: I0815 08:32:19.537353  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.537384  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.537432  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.537454  8943 backward.cc:335] Node: NanmedianGradNode addr:0x476a54e0, Found pending node: GradNodeAccumulation addr: 0x35984860
1901: I0815 08:32:19.537460  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.537477  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x35984860
1901: I0815 08:32:19.537482  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.537485  8943 accumulation_node.cc:40] Move Tensor ptr: 0x4527eff0
1901: I0815 08:32:19.537490  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.537494  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.538450  8943 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.538542  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.538575  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.538801  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.538894  8943 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x476a54e0)  to GradNodeAccumulation (addr: 0x35984860)
1901: I0815 08:32:19.539039  8943 backward.cc:459] Run in Grad
1901: I0815 08:32:19.539049  8943 backward.cc:113] Start Backward
1901: I0815 08:32:19.539072  8943 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x476a54e0 to ptr: 0x47986190
1901: I0815 08:32:19.539079  8943 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 08:32:19.539111  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.539135  8943 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x35984860 to ptr: 0x47926ca0
1901: I0815 08:32:19.539160  8943 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47986190
1901: I0815 08:32:19.539165  8943 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 08:32:19.539196  8943 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.539376  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.539384  8943 backward.cc:335] Node: NanmedianGradNode addr:0x47986190, Found pending node: GradNodeAccumulation addr: 0x47926ca0
1901: I0815 08:32:19.539391  8943 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 08:32:19.539407  8943 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47926ca0
1901: I0815 08:32:19.539412  8943 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.539414  8943 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 08:32:19.539420  8943 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 08:32:19.539424  8943 backward.cc:435] Finish Backward
1901: I0815 08:32:19.540547  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.540632  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.540657  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.540833  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.542344  8943 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x35984860 for it.
1901: I0815 08:32:19.542392  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.542409  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.545027  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.545066  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.546123  8943 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 08:32:19.546144  8943 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 08:32:19.547029  8943 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 08:32:19.547049  8943 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 08:32:19.547163  8943 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 08:32:19.547169  8943 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 08:32:19.547228  8943 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 08:32:19.547233  8943 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 08:32:19.547291  8943 dygraph_functions.cc:82227] Running AD API: arange
1901: I0815 08:32:19.547374  8943 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.547580  8943 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0815 08:32:19.547600  8943 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.547619  8943 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0815 08:32:19.547688  8943 dygraph_functions.cc:14224] Running AD API: cast
1901: I0815 08:32:19.547703  8943 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.547775  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0815 08:32:19.547842  8943 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 08:32:19.547856  8943 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 08:32:19.548085  8943 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: test_nanmedian failed
1901:  ss.E.................
1901: ======================================================================
1901: ERROR: test_check_output (test_nanmedian.TestNanmedianFP16Op)
1901: ----------------------------------------------------------------------
1901: Traceback (most recent call last):
1901:   File "/home/code/Paddle/build/test/legacy_test/test_nanmedian.py", line 617, in test_check_output
1901:     self.check_output(check_pir=True)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2934, in check_output
1901:     res = self.check_output_with_place(
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2786, in check_output_with_place
1901:     symbol_checker.check()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2637, in check
1901:     self.infer_and_compare_symbol()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2645, in infer_and_compare_symbol
1901:     self.op_test._infer_and_compare_symbol(place)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1712, in _infer_and_compare_symbol
1901:     self._compare_symbol(program, outs)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1633, in _compare_symbol
1901:     shape_analysis.get_shape_or_data_for_var(
1901: RuntimeError: (PreconditionNotMet) The op operand index [1] must less than operands size[1].
1901:   [Hint: Expected index < num_operands_, but received index:1 >= num_operands_:1.] (at /home/code/Paddle/paddle/pir/src/core/operation.cc:420)
1901: 
1901: 
1901: ----------------------------------------------------------------------
1901: Ran 21 tests in 3.542s
1901: 
1901: FAILED (errors=1, skipped=2)
1901: 
1901: I0815 08:32:19.549585  8943 mmap_allocator.cc:348] PID: 8943, MemoryMapFdSet: set size - 0
1901: I0815 08:32:19.562122  8943 mmap_allocator.cc:348] PID: 8943, MemoryMapFdSet: set size - 0
1901: I0815 08:32:19.650384  9011 thread_data_registry.h:135] Add data {current : -8, peak : 0} from thread 18392880003490601035 to 1587417808150736031 , after update, data is {current : -12, peak : 0}.
1901: I0815 08:32:19.650502  9011 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 18392880003490601035 to 1587417808150736031 , after update, data is {current : 0, peak : 4}.
1901: I0815 08:32:19.653475  9012 thread_data_registry.h:135] Add data {current : -4, peak : 0} from thread 17340996655941800369 to 1587417808150736031 , after update, data is {current : -16, peak : 0}.
1901: I0815 08:32:19.653506  9012 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 17340996655941800369 to 1587417808150736031 , after update, data is {current : 0, peak : 4}.
1901: I0815 08:32:19.653616  9013 thread_data_registry.h:135] Add data {current : -4, peak : 0} from thread 17227443003520563314 to 1587417808150736031 , after update, data is {current : -20, peak : 0}.
1901: I0815 08:32:19.653623  9013 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 17227443003520563314 to 1587417808150736031 , after update, data is {current : 0, peak : 4}.
1901: I0815 08:32:19.654356  9010 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 1587417808150736031 to 582535791940451453 , after update, data is {current : 0, peak : 1252}.
1901: I0815 08:32:19.654376  9010 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 1587417808150736031 to 582535791940451453 , after update, data is {current : 0, peak : 16}.
1901: I0815 08:32:19.657430  9014 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 582535791940451453 to 12429590720850588845 , after update, data is {current : 0, peak : 260}.
1901: I0815 08:32:19.657455  9014 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 582535791940451453 to 12429590720850588845 , after update, data is {current : 20026, peak : 40000}.
1901: I0815 08:32:19.657460  9014 thread_data_registry.h:135] Add data {current : 0, peak : 1252} from thread 582535791940451453 to 12429590720850588845 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 08:32:19.896982  8943 mmap_allocator.cc:348] PID: 8943, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................***Failed   11.79 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  11.99 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
