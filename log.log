UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0815 07:26:11.767264 31649 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0815 07:26:12.550693 31649 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=enable_blaslt_global_search,log_memory_stats,enable_dump_main_program,use_mkldnn,prim_skip_dynamic,enable_pir_in_executor,embedding_deterministic,use_cuda_managed_memory,query_dest_rank_by_multi_node,use_auto_growth_v2,print_sub_graph_dir,use_cuda_malloc_async_allocator,eager_delete_scope,dygraph_debug,dynamic_static_unified_comm,gpugraph_enable_segment_merge_grads,use_pinned_memory,print_ir,cudnn_exhaustive_search_times,graph_neighbor_size_percent,enable_api_kernel_fallback,auto_free_cudagraph_allocations_on_launch,free_when_no_cache_hit,multi_node_sample_use_gpu_table,new_executor_use_inplace,enable_cublas_tensor_op_math,check_kernel_launch,mkl_dir,gpugraph_offload_param_stat,enable_record_memory,apply_pass_to_program,paddle_num_threads,executor_log_deps_every_microseconds,custom_device_mem_record,cudnn_deterministic,fraction_of_cuda_pinned_memory_to_use,initial_gpu_memory_in_mb,cinn_subgraph_graphviz_dir,cudnn_batchnorm_spatial_persistent,new_executor_serial_run,convert_all_blocks,pir_broadcast_tree_limit,max_inplace_grad_add,npu_storage_format,use_stride_kernel,enable_auto_rdma_trans,enable_tracker_all2all,local_exe_sub_scope_limit,cusolver_dir,enable_interpretercore_launch_cinn,dump_chunk_info,gpugraph_load_node_list_into_hbm,op_dir,cusparse_dir,dataloader_use_file_descriptor,logging_pir_py_code_dir,prim_enabled,new_executor_use_local_scope,accuracy_check_rtol_fp16,fuse_parameter_groups_size,logging_pir_py_code_dump_symbolic_dims,cublas_dir,lapack_dir,gpugraph_sparse_table_storage_mode,logging_trunc_pir_py_code,ir_inplace_kernel_blacklist,tensor_operants_mode,nccl_dir,use_stream_safe_cuda_allocator,use_xqa_optim,enable_exit_when_partial_worker,prim_forward,sync_nccl_allreduce,win_cuda_bin_dir,enable_collect_shape,enable_pir_api,host_trace_level,conv_workspace_size_limit,new_executor_use_cuda_graph,initial_cpu_memory_in_mb,enable_pir_with_pt_in_dy2st,accuracy_check_atol_fp16,prim_enable_dynamic,cupti_dir,cublaslt_exhaustive_search_times,gpugraph_enable_print_op_debug,fleet_executor_with_standalone,memory_fraction_of_eager_deletion,low_precision_op_list,sync_after_alloc,cuda_dir,cudnn_exhaustive_search,gpugraph_debug_gpu_memory,pir_debug,free_idle_chunk,search_cache_max_number,gpugraph_slot_feasign_max_num,check_nan_inf_level,use_cinn,prim_all,enable_cinn_accuracy_check,enable_unused_var_check,graph_metapath_split_opt,pinned_memory_as_cpu_backend,fraction_of_cpu_memory_to_use,pir_apply_shape_optimization_pass,enable_pir_in_executor_trace_run,async_trace_count,nvidia_package_dir,nccl_blocking_wait,accuracy_check_atol_fp32,cublaslt_device_best_config,run_kp_kernel,accuracy_check_atol_bf16,multiple_of_cupti_buffer_size,alloc_fill_value,gpu_allocator_retry_time,gemm_use_half_precision_compute_type,prim_check_ops,inner_op_parallelism,einsum_opt,reader_queue_speed_test_mode,tracer_onednn_ops_off,gpu_memory_limit_mb,gpugraph_parallel_copyer_split_maxsize,graph_embedding_split_infer_mode,enable_neighbor_list_use_uva,enable_cinn_auto_tune,call_stack_level,jit_engine_type,use_virtual_memory_auto_growth,deny_cinn_ops,fraction_of_gpu_memory_to_use,gpugraph_offload_param_extends,tracer_profile_fname,cache_inference_while_scope,static_runtime_data_save_path,allocator_strategy,prim_backward,fast_eager_deletion_mode,prim_forward_blacklist,new_executor_sequential_run,graph_load_in_parallel,enable_fuse_parallel_matmul_pass,use_auto_growth_pinned_allocator,enable_graph_multi_node_sampling,accuracy_check_rtol_bf16,save_static_runtime_data,fuse_parameter_memory_size,enable_fusion_fallback,selected_gpus,enable_cinn_compile_cache,manually_trans_conv_filter,trt_ibuilder_cache,use_fast_math,pir_subgraph_saving_dir,gpugraph_storage_mode,cuda_malloc_async_pool_memory_throttle_ratio,cse_max_count,cusparselt_dir,use_shm_cache,dist_threadpool_size,curand_dir,gpugraph_merge_grads_segment_size,all_blocks_convert_trt,tracer_onednn_ops_on,sort_sum_gradient,conv2d_disable_cudnn,cuda_memory_async_pool_realease_threshold,gpugraph_force_device_batch_num_equal,gpugraph_dedup_pull_push_mode,disable_dyshape_in_train,eager_delete_tensor_gb,accuracy_check_rtol_fp32,enable_opt_get_features,get_host_by_name_time,tensorrt_dir,new_executor_static_build,add_dependency_for_communication_op,check_nan_inf,static_executor_perfstat_filepath,mklml_dir,gpugraph_offload_gather_copy_maxsize,auto_growth_chunk_size_in_mb,cinn_compile_thread_num,enable_async_trace,enable_gpu_memory_usage_log_mb,logging_pir_py_code_int_tensor_element_limit,enable_sparse_inner_gather,check_infer_symbolic,enable_auto_detect_gpu_topo,set_to_1d,init_allocated_mem,gpugraph_enable_hbm_table_collision_stat,pir_apply_inplace_pass,gpugraph_parallel_stream_num,enable_cse_in_dy2st,graph_get_neighbor_id,print_allocator_trace_info,benchmark_nccl,cudnn_dir,use_autotune,gpugraph_enable_gpu_direct_access,allreduce_record_one_event,benchmark,enable_all2all_use_fp16,use_system_allocator,enable_dependency_builder_debug_info,allow_cinn_ops,reallocate_gpu_memory_in_mb,enable_adjust_op_order,enable_gpu_memory_usage_log,gpugraph_hbm_table_load_factor 
1901: I0815 07:26:12.550807 31649 init.cc:108] After Parse: argc is 2
1901: I0815 07:26:17.556182 31649 scope.cc:202] Create variable X
1901: I0815 07:26:17.556265 31649 scope.cc:202] Create variable Out
1901: I0815 07:26:17.556282 31649 scope.cc:202] Create variable MedianIndex
1901: I0815 07:26:17.556458 31649 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0815 07:26:17.557135 31649 allocator_facade.cc:212] selected allocator strategy:1
1901: I0815 07:26:17.557428 31649 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0815 07:26:20.017971 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.018034 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.018182 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.018193 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.019248 31649 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 07:26:20.019273 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.019325 31649 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 07:26:20.019333 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.019793 31649 pybind.cc:1827] need skip: 0
1901: I0815 07:26:20.019889 31649 pybind.cc:1827] need skip: 0
1901: I0815 07:26:20.020323 31649 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 07:26:20.020686 31649 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 07:26:20.020704 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 07:26:20.020785 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 07:26:20.020798 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 07:26:20.023922 31649 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 07:26:20.024657 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.024673 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.024693 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 07:26:20.027746 31649 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 07:26:20.027763 31649 scope.cc:202] Create variable feed
1901: I0815 07:26:20.027849 31649 program_interpreter.cc:243] New Executor is Running.
1901: I0815 07:26:20.027858 31649 interpreter_util.cc:1169] Creating Variables
1901: I0815 07:26:20.027866 31649 scope.cc:202] Create variable MedianIndex
1901: I0815 07:26:20.027878 31649 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x4457b6b0 type is 7
1901: I0815 07:26:20.027890 31649 scope.cc:202] Create variable Out
1901: I0815 07:26:20.027895 31649 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4457bba0 type is 7
1901: I0815 07:26:20.027900 31649 scope.cc:202] Create variable Out@GRAD
1901: I0815 07:26:20.027904 31649 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4457c050 type is 7
1901: I0815 07:26:20.027907 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.027911 31649 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4457cc80 type is 7
1901: I0815 07:26:20.027915 31649 scope.cc:202] Create variable X@GRAD
1901: I0815 07:26:20.027922 31649 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4457cef0 type is 7
1901: I0815 07:26:20.027928 31649 scope.cc:202] Create variable _generated_var_0
1901: I0815 07:26:20.027932 31649 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4457d130 type is 7
1901: I0815 07:26:20.027937 31649 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 07:26:20.027941 31649 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x4457d390 type is 7
1901: I0815 07:26:20.027946 31649 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4457b630 type is 9
1901: I0815 07:26:20.027951 31649 scope.cc:202] Create variable fetch
1901: I0815 07:26:20.027954 31649 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4457d110 type is 10
1901: I0815 07:26:20.028079 31649 interpreter_util.cc:594] Static build: 0
1901: I0815 07:26:20.028086 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.028092 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.028096 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0815 07:26:20.028725 31649 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0815 07:26:20.028959 31649 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0815 07:26:20.030308 31649 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0815 07:26:20.030504 31649 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.030539 31649 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.030689 31649 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.030697 31649 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.030715 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.035145 31649 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035164 31649 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035182 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.035269 31649 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.035365 31649 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035377 31649 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035436 31649 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.035461 31649 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0815 07:26:20.035486 31649 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035495 31649 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035512 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 07:26:20.035606 31649 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035617 31649 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035634 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 07:26:20.035753 31649 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.035777 31649 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.035799 31649 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 07:26:20.035807 31649 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445fafb0Variable Type 7
1901: I0815 07:26:20.035830 31649 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 07:26:20.035854 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.035879 31649 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.035902 31649 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.036023 31649 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 07:26:20.036060 31649 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 07:26:20.036646 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.036692 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.037740 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.037761 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.037806 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.037815 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.038453 31649 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 07:26:20.038471 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.038504 31649 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 07:26:20.038512 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.038791 31649 pybind.cc:1827] need skip: 0
1901: I0815 07:26:20.038846 31649 pybind.cc:1827] need skip: 0
1901: I0815 07:26:20.039160 31649 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 07:26:20.039234 31649 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 07:26:20.039242 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 07:26:20.039317 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 07:26:20.039328 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 07:26:20.041397 31649 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 07:26:20.041886 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.041900 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.041904 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 07:26:20.045389 31649 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 07:26:20.045406 31649 scope.cc:202] Create variable feed
1901: I0815 07:26:20.045435 31649 interpreter_util.cc:1169] Creating Variables
1901: I0815 07:26:20.045444 31649 scope.cc:202] Create variable MedianIndex
1901: I0815 07:26:20.045449 31649 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x439bef70 type is 7
1901: I0815 07:26:20.045455 31649 scope.cc:202] Create variable Out
1901: I0815 07:26:20.045459 31649 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x445759f0 type is 7
1901: I0815 07:26:20.045464 31649 scope.cc:202] Create variable Out@GRAD
1901: I0815 07:26:20.045468 31649 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4413f6b0 type is 7
1901: I0815 07:26:20.045472 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.045477 31649 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x439bb560 type is 7
1901: I0815 07:26:20.045481 31649 scope.cc:202] Create variable X@GRAD
1901: I0815 07:26:20.045485 31649 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x439bd060 type is 7
1901: I0815 07:26:20.045490 31649 scope.cc:202] Create variable _generated_var_0
1901: I0815 07:26:20.045492 31649 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x439bd0e0 type is 7
1901: I0815 07:26:20.045497 31649 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 07:26:20.045501 31649 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x439bd160 type is 7
1901: I0815 07:26:20.045506 31649 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44123d10 type is 9
1901: I0815 07:26:20.045511 31649 scope.cc:202] Create variable fetch
1901: I0815 07:26:20.045516 31649 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x439bd0c0 type is 10
1901: I0815 07:26:20.045605 31649 interpreter_util.cc:594] Static build: 0
1901: I0815 07:26:20.045612 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.045616 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.045620 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 07:26:20.045665 31649 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.045676 31649 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.045724 31649 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.045732 31649 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.045748 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.046231 31649 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046247 31649 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046260 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.046320 31649 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.046382 31649 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046393 31649 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046432 31649 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.046464 31649 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046473 31649 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046489 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 07:26:20.046561 31649 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046571 31649 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046586 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 07:26:20.046682 31649 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.046692 31649 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.046707 31649 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 07:26:20.046713 31649 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44105530Variable Type 7
1901: I0815 07:26:20.046729 31649 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 07:26:20.046744 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.046761 31649 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.046775 31649 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.046829 31649 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 07:26:20.046851 31649 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 07:26:20.047264 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 07:26:20.047307 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.048914 31649 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19e837b0 for it.
1901: I0815 07:26:20.049098 31649 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19eee480 for it.
1901: I0815 07:26:20.049146 31649 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19eb6830 for it.
1901: I0815 07:26:20.050052 31649 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 07:26:20.050117 31649 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 07:26:20.050666 31649 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x44558bf0)  to GradNodeAccumulation (addr: 0x19e837b0)
1901: I0815 07:26:20.050818 31649 dygraph_functions.cc:51757] Running AD API: mean
1901: I0815 07:26:20.050846 31649 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 07:26:20.050930 31649 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.050952 31649 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x439bb5d0)  to NanmedianGradNode (addr: 0x44558bf0)
1901: I0815 07:26:20.051067 31649 backward.cc:442] Run in Backward
1901: I0815 07:26:20.051079 31649 backward.cc:113] Start Backward
1901: I0815 07:26:20.051102 31649 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 07:26:20.051156 31649 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.051189 31649 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x439bb5d0
1901: I0815 07:26:20.051211 31649 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0815 07:26:20.051256 31649 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 07:26:20.051337 31649 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.051362 31649 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 07:26:20.051373 31649 backward.cc:335] Node: MeanGradNode addr:0x439bb5d0, Found pending node: NanmedianGradNode addr: 0x44558bf0
1901: I0815 07:26:20.051383 31649 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 07:26:20.051416 31649 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x44558bf0
1901: I0815 07:26:20.051436 31649 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 07:26:20.051465 31649 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 07:26:20.051520 31649 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 07:26:20.051544 31649 backward.cc:335] Node: NanmedianGradNode addr:0x44558bf0, Found pending node: GradNodeAccumulation addr: 0x19e837b0
1901: I0815 07:26:20.051551 31649 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 07:26:20.051570 31649 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x19e837b0
1901: I0815 07:26:20.051581 31649 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 07:26:20.051590 31649 accumulation_node.cc:40] Move Tensor ptr: 0x445f8a80
1901: I0815 07:26:20.051594 31649 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 07:26:20.051600 31649 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0815 07:26:20.060628 31649 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19e837b0 for it.
1901: I0815 07:26:20.060796 31649 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19eb6830 for it.
1901: I0815 07:26:20.060846 31649 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19eee480 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0815 07:26:20.111734 31649 pir_interpreter.cc:161] PirInterpreter(): 0x46824560 on Place(gpu:0)
1901: I0815 07:26:20.111786 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.111815 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_1
1901: I0815 07:26:20.111825 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_2
1901: I0815 07:26:20.111835 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_3
1901: I0815 07:26:20.111841 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_4
1901: I0815 07:26:20.111850 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_5
1901: I0815 07:26:20.111857 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_6
1901: I0815 07:26:20.111863 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_7
1901: I0815 07:26:20.111871 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_8
1901: I0815 07:26:20.111879 31649 scope.cc:202] Create variable 0x468245601723706780111764908_inner_var_9
1901: I0815 07:26:20.111886 31649 scope.cc:202] Create variable fetch0@fetch
1901: I0815 07:26:20.112293 31649 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 07:26:20.112318 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.112322 31649 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0815 07:26:20.112368 31649 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x46822ba0
1901: 1 -> 0x468245601723706780111764908_inner_var_1 -> 0x46824540
1901: 2 -> 0x468245601723706780111764908_inner_var_2 -> 0x46820540
1901: 3 -> 0x468245601723706780111764908_inner_var_3 -> 0x46823c50
1901: 4 -> 0x468245601723706780111764908_inner_var_4 -> 0x46822ab0
1901: 5 -> 0x468245601723706780111764908_inner_var_5 -> 0x46824b90
1901: 6 -> 0x468245601723706780111764908_inner_var_6 -> 0x46824e80
1901: 7 -> 0x468245601723706780111764908_inner_var_7 -> 0x468252a0
1901: 8 -> 0x468245601723706780111764908_inner_var_8 -> 0x46821940
1901: 9 -> 0x468245601723706780111764908_inner_var_9 -> 0x468256c0
1901: 10 -> fetch0@fetch -> 0x46825ed0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0815 07:26:20.113313 31649 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0815 07:26:20.113560 31686 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 07:26:20.113648 31687 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 07:26:20.113785 31688 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 07:26:20.113788 31689 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 07:26:20.113788 31690 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 07:26:20.113842 31687 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_0
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x468245601723706780111764908_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.113879 31691 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 07:26:20.113974 31687 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_0
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x468245601723706780111764908_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0815 07:26:20.113958 31691 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.114029 31691 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 07:26:20.114090 31691 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x468245601723706780111764908_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_3:[dtype=;place=;dim=;lod={};, 0x468245601723706780111764908_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.114602 31691 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x468245601723706780111764908_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x468245601723706780111764908_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 07:26:20.114634 31691 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x468245601723706780111764908_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.114688 31691 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.114704 31691 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x468245601723706780111764908_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 07:26:20.114738 31691 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x468245601723706780111764908_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x468245601723706780111764908_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.114792 31691 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.114861 31691 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x468245601723706780111764908_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x468245601723706780111764908_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 07:26:20.114887 31691 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x468245601723706780111764908_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x468245601723706780111764908_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.114972 31691 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 07:26:20.114989 31691 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x468245601723706780111764908_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x468245601723706780111764908_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 07:26:20.115013 31691 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x468245601723706780111764908_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x468245601723706780111764908_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x468245601723706780111764908_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.115099 31691 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x468245601723706780111764908_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x468245601723706780111764908_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x468245601723706780111764908_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 07:26:20.115180 31687 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_0
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x468245601723706780111764908_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.115217 31687 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.115329 31687 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_0
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x468245601723706780111764908_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x468245601723706780111764908_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 07:26:20.115366 31687 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_0
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x468245601723706780111764908_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.115393 31687 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.115423 31687 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_0
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x468245601723706780111764908_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 07:26:20.115460 31649 pir_interpreter.cc:1766] main_thread_blocker_(0x468246d0) got event_name: TaskCompletion
1901: I0815 07:26:20.115492 31649 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.118639 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.118669 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.118737 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.118748 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.119951 31686 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 6861570046802977391 to 9288194339081651781 , after update, data is {current : -20004, peak : 16}.
1901: I0815 07:26:20.119972 31686 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 6861570046802977391 to 9288194339081651781 , after update, data is {current : 0, peak : 330659}.
1901: I0815 07:26:20.120146 31687 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 10317253471491394998 to 9288194339081651781 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 07:26:20.120347 31691 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 9288194339081651781 to 4545940847367113801 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 07:26:20.120359 31691 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 9288194339081651781 to 4545940847367113801 , after update, data is {current : 120000, peak : 440631}.
1901: I0815 07:26:20.121817 31649 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 07:26:20.122435 31649 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 07:26:20.122962 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.122978 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.122984 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 07:26:20.125319 31649 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 07:26:20.125337 31649 scope.cc:202] Create variable feed
1901: I0815 07:26:20.125370 31649 interpreter_util.cc:1169] Creating Variables
1901: I0815 07:26:20.125381 31649 scope.cc:202] Create variable MedianIndex
1901: I0815 07:26:20.125387 31649 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x4683d9b0 type is 7
1901: I0815 07:26:20.125398 31649 scope.cc:202] Create variable Out
1901: I0815 07:26:20.125402 31649 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4683cf40 type is 7
1901: I0815 07:26:20.125409 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.125413 31649 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4683d930 type is 7
1901: I0815 07:26:20.125418 31649 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4683cf60 type is 9
1901: I0815 07:26:20.125424 31649 scope.cc:202] Create variable fetch
1901: I0815 07:26:20.125429 31649 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4683dd60 type is 10
1901: I0815 07:26:20.125505 31649 interpreter_util.cc:594] Static build: 0
1901: I0815 07:26:20.125514 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.125520 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.125526 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 07:26:20.125586 31649 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.125602 31649 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.125674 31649 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.125684 31649 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.125705 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.126212 31649 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.126230 31649 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.126250 31649 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 07:26:20.126257 31649 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46841e00Variable Type 7
1901: I0815 07:26:20.126277 31649 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 07:26:20.126317 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.126343 31649 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.126363 31649 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.126410 31649 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 07:26:20.126435 31649 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 07:26:20.126487 31649 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.126497 31649 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.126514 31649 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 07:26:20.126521 31649 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46845ad0Variable Type 7
1901: I0815 07:26:20.126538 31649 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 07:26:20.126551 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.126571 31649 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.126586 31649 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.126621 31649 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 07:26:20.126652 31649 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 07:26:20.126940 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.126968 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.128288 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.128322 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.128376 31649 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 07:26:20.128387 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.130316 31649 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 07:26:20.130877 31649 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 07:26:20.131335 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.131350 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.131356 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 07:26:20.133605 31649 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 07:26:20.133680 31649 interpreter_util.cc:1169] Creating Variables
1901: I0815 07:26:20.133693 31649 scope.cc:202] Create variable MedianIndex
1901: I0815 07:26:20.133698 31649 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x46874230 type is 7
1901: I0815 07:26:20.133709 31649 scope.cc:202] Create variable Out
1901: I0815 07:26:20.133713 31649 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x46873560 type is 7
1901: I0815 07:26:20.133718 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.133723 31649 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x46873f60 type is 7
1901: I0815 07:26:20.133728 31649 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4683cf60 type is 9
1901: I0815 07:26:20.133733 31649 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4683dd60 type is 10
1901: I0815 07:26:20.133807 31649 interpreter_util.cc:594] Static build: 0
1901: I0815 07:26:20.133816 31649 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 07:26:20.133821 31649 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 07:26:20.133827 31649 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 07:26:20.133870 31649 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.133884 31649 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.133939 31649 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.133949 31649 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.133967 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 07:26:20.134492 31649 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.134508 31649 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.134527 31649 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 07:26:20.134536 31649 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x468786d0Variable Type 7
1901: I0815 07:26:20.134553 31649 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 07:26:20.134570 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.134594 31649 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.134610 31649 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.134651 31649 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 07:26:20.134673 31649 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 07:26:20.134721 31649 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.134730 31649 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 07:26:20.134747 31649 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 07:26:20.134754 31649 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x468786f0Variable Type 7
1901: I0815 07:26:20.134768 31649 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 07:26:20.134783 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.134802 31649 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 07:26:20.134817 31649 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.134852 31649 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 07:26:20.134873 31649 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 07:26:20.135131 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.135159 31649 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 07:26:20.254179 31649 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19eee480 for it.
1901: I0815 07:26:20.254631 31649 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19eb6830 for it.
1901: I0815 07:26:20.254704 31649 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19e837b0 for it.
1901: I0815 07:26:20.255365 31649 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 07:26:20.255414 31649 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 07:26:20.256708 31649 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19eee480 for it.
1901: I0815 07:26:20.256856 31649 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19e837b0 for it.
1901: I0815 07:26:20.256914 31649 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19eb6830 for it.
1901: I0815 07:26:20.258080 31649 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 07:26:20.258118 31649 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 07:26:20.260571 31649 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19eee480 for it.
1901: I0815 07:26:20.260725 31649 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19eb6830 for it.
1901: I0815 07:26:20.260774 31649 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19e837b0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 07:26:20.264185 31649 pir_interpreter.cc:161] PirInterpreter(): 0x46827c80 on Place(gpu:0)
1901: I0815 07:26:20.264215 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.264233 31649 scope.cc:202] Create variable 0x46827c801723706780264208475_inner_var_1
1901: I0815 07:26:20.264243 31649 scope.cc:202] Create variable 0x46827c801723706780264208475_inner_var_2
1901: I0815 07:26:20.264250 31649 scope.cc:202] Create variable 0x46827c801723706780264208475_inner_var_3
1901: I0815 07:26:20.264257 31649 scope.cc:202] Create variable 0x46827c801723706780264208475_inner_var_4
1901: I0815 07:26:20.264267 31649 scope.cc:202] Create variable fetch0@fetch
1901: I0815 07:26:20.264670 31649 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 07:26:20.264684 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.264688 31649 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x445f8f70
1901: 1 -> 0x46827c801723706780264208475_inner_var_1 -> 0x4682a0c0
1901: 2 -> 0x46827c801723706780264208475_inner_var_2 -> 0x46820ac0
1901: 3 -> 0x46827c801723706780264208475_inner_var_3 -> 0x468a21f0
1901: 4 -> 0x46827c801723706780264208475_inner_var_4 -> 0x4684db60
1901: 5 -> fetch0@fetch -> 0x46823fd0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 07:26:20.265246 31693 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 07:26:20.265372 31694 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 07:26:20.265419 31695 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 07:26:20.265465 31696 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 07:26:20.265478 31697 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 07:26:20.265576 31698 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 07:26:20.265616 31698 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46827c801723706780264208475_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.265655 31698 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46827c801723706780264208475_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 07:26:20.265688 31698 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46827c801723706780264208475_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46827c801723706780264208475_inner_var_3:[dtype=;place=;dim=;lod={};, 0x46827c801723706780264208475_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.266134 31698 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46827c801723706780264208475_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46827c801723706780264208475_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46827c801723706780264208475_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 07:26:20.266223 31697 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46827c801723706780264208475_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46827c801723706780264208475_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.266268 31697 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.266337 31697 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46827c801723706780264208475_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46827c801723706780264208475_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 07:26:20.266371 31697 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46827c801723706780264208475_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.266388 31697 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.266402 31697 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46827c801723706780264208475_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 07:26:20.266430 31649 pir_interpreter.cc:1766] main_thread_blocker_(0x46827df0) got event_name: TaskCompletion
1901: I0815 07:26:20.266451 31649 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.267118 31649 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19e837b0 for it.
1901: I0815 07:26:20.267266 31649 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19eb6830 for it.
1901: I0815 07:26:20.267330 31649 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19eee480 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 07:26:20.269687 31649 pir_interpreter.cc:161] PirInterpreter(): 0x4689c000 on Place(gpu:0)
1901: I0815 07:26:20.269711 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.269726 31649 scope.cc:202] Create variable 0x4689c0001723706780269706492_inner_var_1
1901: I0815 07:26:20.269735 31649 scope.cc:202] Create variable 0x4689c0001723706780269706492_inner_var_2
1901: I0815 07:26:20.269745 31649 scope.cc:202] Create variable 0x4689c0001723706780269706492_inner_var_3
1901: I0815 07:26:20.269752 31649 scope.cc:202] Create variable 0x4689c0001723706780269706492_inner_var_4
1901: I0815 07:26:20.269762 31649 scope.cc:202] Create variable fetch0@fetch
1901: I0815 07:26:20.270023 31649 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 07:26:20.270036 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.270040 31649 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x46843eb0
1901: 1 -> 0x4689c0001723706780269706492_inner_var_1 -> 0x46843f30
1901: 2 -> 0x4689c0001723706780269706492_inner_var_2 -> 0x46823a20
1901: 3 -> 0x4689c0001723706780269706492_inner_var_3 -> 0x44552e10
1901: 4 -> 0x4689c0001723706780269706492_inner_var_4 -> 0x46852250
1901: 5 -> fetch0@fetch -> 0x4682efc0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 07:26:20.270570 31699 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 07:26:20.270753 31700 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 07:26:20.270761 31701 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 07:26:20.270843 31702 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 07:26:20.270922 31703 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 07:26:20.270998 31704 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 07:26:20.271032 31704 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4689c0001723706780269706492_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.271062 31704 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4689c0001723706780269706492_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 07:26:20.271095 31704 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4689c0001723706780269706492_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4689c0001723706780269706492_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4689c0001723706780269706492_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.271514 31704 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4689c0001723706780269706492_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4689c0001723706780269706492_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4689c0001723706780269706492_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 07:26:20.271579 31703 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4689c0001723706780269706492_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4689c0001723706780269706492_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.271607 31703 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.271663 31703 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4689c0001723706780269706492_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4689c0001723706780269706492_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 07:26:20.271692 31703 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4689c0001723706780269706492_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.271708 31703 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.271720 31703 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4689c0001723706780269706492_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 07:26:20.271746 31649 pir_interpreter.cc:1766] main_thread_blocker_(0x4689c170) got event_name: TaskCompletion
1901: I0815 07:26:20.271765 31649 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.273001 31649 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19eee480 for it.
1901: I0815 07:26:20.273136 31649 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19eb6830 for it.
1901: I0815 07:26:20.273177 31649 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19e837b0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 07:26:20.275197 31649 pir_interpreter.cc:161] PirInterpreter(): 0x46898a80 on Place(gpu:0)
1901: I0815 07:26:20.275220 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.275235 31649 scope.cc:202] Create variable 0x46898a801723706780275215695_inner_var_1
1901: I0815 07:26:20.275245 31649 scope.cc:202] Create variable 0x46898a801723706780275215695_inner_var_2
1901: I0815 07:26:20.275252 31649 scope.cc:202] Create variable 0x46898a801723706780275215695_inner_var_3
1901: I0815 07:26:20.275261 31649 scope.cc:202] Create variable 0x46898a801723706780275215695_inner_var_4
1901: I0815 07:26:20.275269 31649 scope.cc:202] Create variable fetch0@fetch
1901: I0815 07:26:20.275538 31649 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 07:26:20.275552 31649 scope.cc:202] Create variable X
1901: I0815 07:26:20.275555 31649 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x46841840
1901: 1 -> 0x46898a801723706780275215695_inner_var_1 -> 0x46898a60
1901: 2 -> 0x46898a801723706780275215695_inner_var_2 -> 0x46899200
1901: 3 -> 0x46898a801723706780275215695_inner_var_3 -> 0x4684ee30
1901: 4 -> 0x46898a801723706780275215695_inner_var_4 -> 0x4684d9f0
1901: 5 -> fetch0@fetch -> 0x4684f5f0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 07:26:20.276044 31705 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 07:26:20.276226 31706 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 07:26:20.276247 31707 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 07:26:20.276314 31708 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 07:26:20.276384 31709 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 07:26:20.276439 31710 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 07:26:20.276487 31710 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46898a801723706780275215695_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.276515 31710 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46898a801723706780275215695_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 07:26:20.276543 31710 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46898a801723706780275215695_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46898a801723706780275215695_inner_var_3:[dtype=;place=;dim=;lod={};, 0x46898a801723706780275215695_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.276952 31710 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46898a801723706780275215695_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46898a801723706780275215695_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46898a801723706780275215695_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 07:26:20.277011 31709 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46898a801723706780275215695_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46898a801723706780275215695_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.277029 31709 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 07:26:20.277076 31709 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46898a801723706780275215695_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46898a801723706780275215695_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 07:26:20.277099 31709 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46898a801723706780275215695_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 07:26:20.277114 31709 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.277127 31709 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46898a801723706780275215695_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 07:26:20.277151 31649 pir_interpreter.cc:1766] main_thread_blocker_(0x46898bf0) got event_name: TaskCompletion
1901: I0815 07:26:20.277168 31649 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 07:26:20.277318 31649 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: 
1901: 
1901: --------------------------------------
1901: C++ Traceback (most recent call last):
1901: --------------------------------------
1901: 0   pir::ShapeConstraintIRAnalysis::GetShapeOrDataForValue(pir::Value)
1901: 1   pir::ShapeConstraintIRAnalysis::InferShapeOrDataForValue(pir::Value)
1901: 2   pir::InferSymbolicShapeInterface::Model<paddle::dialect::NanmedianOp>::InferSymbolicShape(pir::Operation*, pir::InferSymbolicShapeContext*)
1901: 3   paddle::dialect::NanmedianOpInferSymbolicShape(pir::Operation*, pir::InferSymbolicShapeContext*)
1901: 
1901: ----------------------
1901: Error Message Summary:
1901: ----------------------
1901: FatalError: `Segmentation fault` is detected by the operating system.
1901:   [TimeInfo: *** Aborted at 1723706780 (unix time) try "date -d @1723706780" if you are using GNU date ***]
1901:   [SignalInfo: *** SIGSEGV (@0x10) received by PID 31649 (TID 0x7fb1ec006740) from PID 16 ***]
1901: 
1901: Segmentation fault
1/1 Test #1901: test_nanmedian ...................***Failed   16.18 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  16.36 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
