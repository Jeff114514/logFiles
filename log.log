UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0816 03:57:21.469409  9572 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0816 03:57:22.256572  9572 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=gpugraph_hbm_table_load_factor,enable_pir_in_executor_trace_run,logging_pir_py_code_int_tensor_element_limit,new_executor_serial_run,prim_backward,cupti_dir,enable_fuse_parallel_matmul_pass,gpugraph_enable_segment_merge_grads,gpugraph_offload_param_stat,fast_eager_deletion_mode,gpu_memory_limit_mb,allow_cinn_ops,gpugraph_debug_gpu_memory,use_cuda_managed_memory,tracer_onednn_ops_on,cudnn_exhaustive_search,nccl_blocking_wait,host_trace_level,convert_all_blocks,new_executor_use_inplace,dynamic_static_unified_comm,memory_fraction_of_eager_deletion,conv_workspace_size_limit,alloc_fill_value,disable_dyshape_in_train,gpugraph_force_device_batch_num_equal,custom_device_mem_record,run_kp_kernel,use_shm_cache,enable_exit_when_partial_worker,auto_growth_chunk_size_in_mb,gpugraph_parallel_copyer_split_maxsize,save_static_runtime_data,use_stride_kernel,pir_apply_inplace_pass,gemm_use_half_precision_compute_type,use_xqa_optim,pinned_memory_as_cpu_backend,reallocate_gpu_memory_in_mb,prim_forward,enable_opt_get_features,enable_pir_with_pt_in_dy2st,embedding_deterministic,cudnn_batchnorm_spatial_persistent,deny_cinn_ops,enable_async_trace,enable_fusion_fallback,accuracy_check_rtol_fp16,cuda_dir,cache_inference_while_scope,jit_engine_type,use_pinned_memory,fraction_of_cuda_pinned_memory_to_use,cublas_dir,inner_op_parallelism,enable_cublas_tensor_op_math,fraction_of_cpu_memory_to_use,cusparse_dir,use_cuda_malloc_async_allocator,print_ir,enable_api_kernel_fallback,accuracy_check_atol_fp16,fuse_parameter_memory_size,cuda_memory_async_pool_realease_threshold,graph_metapath_split_opt,logging_trunc_pir_py_code,static_runtime_data_save_path,cinn_compile_thread_num,all_blocks_convert_trt,dump_chunk_info,multi_node_sample_use_gpu_table,use_auto_growth_pinned_allocator,enable_graph_multi_node_sampling,gpu_allocator_retry_time,graph_neighbor_size_percent,accuracy_check_rtol_fp32,dist_threadpool_size,mklml_dir,auto_free_cudagraph_allocations_on_launch,prim_check_ops,log_memory_stats,use_autotune,enable_gpu_memory_usage_log_mb,prim_enable_dynamic,tracer_profile_fname,sync_nccl_allreduce,new_executor_use_local_scope,check_kernel_launch,enable_adjust_op_order,graph_get_neighbor_id,use_virtual_memory_auto_growth,enable_neighbor_list_use_uva,tensor_operants_mode,tensorrt_dir,cinn_subgraph_graphviz_dir,enable_sparse_inner_gather,enable_pir_api,trt_ibuilder_cache,accuracy_check_atol_fp32,prim_skip_dynamic,local_exe_sub_scope_limit,enable_auto_detect_gpu_topo,enable_cinn_auto_tune,gpugraph_slot_feasign_max_num,cudnn_dir,apply_pass_to_program,conv2d_disable_cudnn,einsum_opt,pir_broadcast_tree_limit,enable_interpretercore_launch_cinn,free_when_no_cache_hit,gpugraph_sparse_table_storage_mode,cse_max_count,enable_record_memory,enable_cinn_compile_cache,low_precision_op_list,cuda_malloc_async_pool_memory_throttle_ratio,win_cuda_bin_dir,curand_dir,eager_delete_scope,cudnn_deterministic,free_idle_chunk,lapack_dir,fleet_executor_with_standalone,manually_trans_conv_filter,prim_all,pir_apply_shape_optimization_pass,pir_subgraph_saving_dir,use_auto_growth_v2,search_cache_max_number,tracer_onednn_ops_off,gpugraph_dedup_pull_push_mode,fraction_of_gpu_memory_to_use,mkl_dir,gpugraph_storage_mode,get_host_by_name_time,new_executor_sequential_run,multiple_of_cupti_buffer_size,prim_forward_blacklist,enable_dependency_builder_debug_info,allreduce_record_one_event,new_executor_static_build,static_executor_perfstat_filepath,eager_delete_tensor_gb,selected_gpus,cusolver_dir,gpugraph_enable_hbm_table_collision_stat,enable_tracker_all2all,cublaslt_exhaustive_search_times,paddle_num_threads,add_dependency_for_communication_op,allocator_strategy,cusparselt_dir,graph_embedding_split_infer_mode,print_sub_graph_dir,enable_cse_in_dy2st,gpugraph_enable_print_op_debug,logging_pir_py_code_dir,gpugraph_merge_grads_segment_size,op_dir,graph_load_in_parallel,use_cinn,max_inplace_grad_add,pir_debug,ir_inplace_kernel_blacklist,enable_collect_shape,query_dest_rank_by_multi_node,initial_gpu_memory_in_mb,enable_dump_main_program,new_executor_use_cuda_graph,use_fast_math,cublaslt_device_best_config,reader_queue_speed_test_mode,use_mkldnn,sync_after_alloc,accuracy_check_rtol_bf16,use_stream_safe_cuda_allocator,executor_log_deps_every_microseconds,prim_enabled,gpugraph_offload_gather_copy_maxsize,nvidia_package_dir,gpugraph_load_node_list_into_hbm,enable_cinn_accuracy_check,enable_gpu_memory_usage_log,enable_auto_rdma_trans,call_stack_level,benchmark,initial_cpu_memory_in_mb,async_trace_count,gpugraph_enable_gpu_direct_access,cudnn_exhaustive_search_times,use_system_allocator,logging_pir_py_code_dump_symbolic_dims,enable_pir_in_executor,npu_storage_format,enable_all2all_use_fp16,fuse_parameter_groups_size,check_nan_inf,gpugraph_parallel_stream_num,enable_blaslt_global_search,nccl_dir,sort_sum_gradient,check_nan_inf_level,check_infer_symbolic,accuracy_check_atol_bf16,dataloader_use_file_descriptor,init_allocated_mem,enable_unused_var_check,dygraph_debug,benchmark_nccl,gpugraph_offload_param_extends,set_to_1d,print_allocator_trace_info 
1901: I0816 03:57:22.256685  9572 init.cc:108] After Parse: argc is 2
1901: I0816 03:57:27.549422  9572 scope.cc:202] Create variable X
1901: I0816 03:57:27.549508  9572 scope.cc:202] Create variable Out
1901: I0816 03:57:27.549531  9572 scope.cc:202] Create variable MedianIndex
1901: I0816 03:57:27.549705  9572 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0816 03:57:27.550433  9572 allocator_facade.cc:212] selected allocator strategy:1
1901: I0816 03:57:27.550736  9572 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0816 03:57:30.080258  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.080335  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.080504  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.080514  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.081633  9572 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:57:30.081660  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.081704  9572 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:57:30.081712  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.082237  9572 pybind.cc:1827] need skip: 0
1901: I0816 03:57:30.082347  9572 pybind.cc:1827] need skip: 0
1901: I0816 03:57:30.082813  9572 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0816 03:57:30.083213  9572 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0816 03:57:30.083231  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:57:30.083320  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0816 03:57:30.083335  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:57:30.086588  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.087311  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.087329  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.087349  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.090432  9572 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:57:30.090448  9572 scope.cc:202] Create variable feed
1901: I0816 03:57:30.090541  9572 program_interpreter.cc:243] New Executor is Running.
1901: I0816 03:57:30.090550  9572 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:57:30.090559  9572 scope.cc:202] Create variable MedianIndex
1901: I0816 03:57:30.090570  9572 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x452be9a0 type is 7
1901: I0816 03:57:30.090582  9572 scope.cc:202] Create variable Out
1901: I0816 03:57:30.090588  9572 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x452bee90 type is 7
1901: I0816 03:57:30.090592  9572 scope.cc:202] Create variable Out@GRAD
1901: I0816 03:57:30.090596  9572 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x452bf340 type is 7
1901: I0816 03:57:30.090605  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.090610  9572 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x452bffb0 type is 7
1901: I0816 03:57:30.090615  9572 scope.cc:202] Create variable X@GRAD
1901: I0816 03:57:30.090618  9572 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x452c0220 type is 7
1901: I0816 03:57:30.090623  9572 scope.cc:202] Create variable _generated_var_0
1901: I0816 03:57:30.090626  9572 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x452c0460 type is 7
1901: I0816 03:57:30.090631  9572 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0816 03:57:30.090634  9572 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x452c06c0 type is 7
1901: I0816 03:57:30.090639  9572 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x452be920 type is 9
1901: I0816 03:57:30.090643  9572 scope.cc:202] Create variable fetch
1901: I0816 03:57:30.090647  9572 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x452c0440 type is 10
1901: I0816 03:57:30.090775  9572 interpreter_util.cc:594] Static build: 0
1901: I0816 03:57:30.090781  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.090785  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.090790  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0816 03:57:30.091418  9572 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0816 03:57:30.091779  9572 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0816 03:57:30.092864  9572 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0816 03:57:30.093102  9572 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.093138  9572 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.093297  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.093315  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.093334  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.097957  9572 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.097980  9572 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.097998  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.098088  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.098198  9572 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.098210  9572 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.098273  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.098297  9572 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0816 03:57:30.098342  9572 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.098351  9572 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.098369  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:57:30.098502  9572 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.098515  9572 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.098534  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:57:30.098680  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.098707  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.098731  9572 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.098739  9572 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x452c8e90Variable Type 7
1901: I0816 03:57:30.098767  9572 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.098793  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.098841  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.098863  9572 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.098985  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.099018  9572 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:57:30.099608  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.099658  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.100723  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.100746  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.100790  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.100800  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.101435  9572 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:57:30.101454  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.101486  9572 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:57:30.101493  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.101771  9572 pybind.cc:1827] need skip: 0
1901: I0816 03:57:30.101824  9572 pybind.cc:1827] need skip: 0
1901: I0816 03:57:30.102147  9572 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0816 03:57:30.102224  9572 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0816 03:57:30.102233  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:57:30.102298  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0816 03:57:30.102322  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:57:30.104393  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.104882  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.104895  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.104899  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.108606  9572 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:57:30.108623  9572 scope.cc:202] Create variable feed
1901: I0816 03:57:30.108651  9572 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:57:30.108661  9572 scope.cc:202] Create variable MedianIndex
1901: I0816 03:57:30.108665  9572 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x44e49270 type is 7
1901: I0816 03:57:30.108675  9572 scope.cc:202] Create variable Out
1901: I0816 03:57:30.108677  9572 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45286cd0 type is 7
1901: I0816 03:57:30.108682  9572 scope.cc:202] Create variable Out@GRAD
1901: I0816 03:57:30.108685  9572 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44e127a0 type is 7
1901: I0816 03:57:30.108690  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.108693  9572 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44e49430 type is 7
1901: I0816 03:57:30.108698  9572 scope.cc:202] Create variable X@GRAD
1901: I0816 03:57:30.108701  9572 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45286e50 type is 7
1901: I0816 03:57:30.108705  9572 scope.cc:202] Create variable _generated_var_0
1901: I0816 03:57:30.108709  9572 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45286e90 type is 7
1901: I0816 03:57:30.108713  9572 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0816 03:57:30.108717  9572 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44e4aad0 type is 7
1901: I0816 03:57:30.108721  9572 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44e2d1f0 type is 9
1901: I0816 03:57:30.108727  9572 scope.cc:202] Create variable fetch
1901: I0816 03:57:30.108731  9572 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45286e70 type is 10
1901: I0816 03:57:30.108819  9572 interpreter_util.cc:594] Static build: 0
1901: I0816 03:57:30.108825  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.108829  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.108834  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.108878  9572 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.108894  9572 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.108940  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.108949  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.108964  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.109444  9572 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109459  9572 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109472  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.109524  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.109584  9572 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109593  9572 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109632  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.109663  9572 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109670  9572 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109685  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:57:30.109769  9572 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109781  9572 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.109797  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:57:30.109905  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.109917  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.109934  9572 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.109941  9572 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44e4ce60Variable Type 7
1901: I0816 03:57:30.109956  9572 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.109972  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.109990  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.110004  9572 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.110059  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.110081  9572 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:57:30.110512  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:57:30.110548  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.112262  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.112466  9572 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a695010 for it.
1901: I0816 03:57:30.112519  9572 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a6fbc10 for it.
1901: I0816 03:57:30.113497  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.113559  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.114104  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x45297da0)  to GradNodeAccumulation (addr: 0x1a6cb240)
1901: I0816 03:57:30.114262  9572 dygraph_functions.cc:51757] Running AD API: mean
1901: I0816 03:57:30.114290  9572 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.114390  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.114415  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43f32670)  to NanmedianGradNode (addr: 0x45297da0)
1901: I0816 03:57:30.114532  9572 backward.cc:442] Run in Backward
1901: I0816 03:57:30.114543  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.114569  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.114630  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.114665  9572 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43f32670
1901: I0816 03:57:30.114688  9572 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0816 03:57:30.114735  9572 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.114815  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.114840  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.114852  9572 backward.cc:335] Node: MeanGradNode addr:0x43f32670, Found pending node: NanmedianGradNode addr: 0x45297da0
1901: I0816 03:57:30.114861  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.114894  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x45297da0
1901: I0816 03:57:30.114913  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.114941  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.114996  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.115020  9572 backward.cc:335] Node: NanmedianGradNode addr:0x45297da0, Found pending node: GradNodeAccumulation addr: 0x1a6cb240
1901: I0816 03:57:30.115027  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.115043  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a6cb240
1901: I0816 03:57:30.115056  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.115064  9572 accumulation_node.cc:40] Move Tensor ptr: 0x44e0fd80
1901: I0816 03:57:30.115068  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.115073  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0816 03:57:30.124423  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.124591  9572 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6fbc10 for it.
1901: I0816 03:57:30.124644  9572 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a695010 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0816 03:57:30.189095  9572 pir_interpreter.cc:161] PirInterpreter(): 0x476e48c0 on Place(gpu:0)
1901: I0816 03:57:30.189145  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.189177  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_1
1901: I0816 03:57:30.189188  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_2
1901: I0816 03:57:30.189196  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_3
1901: I0816 03:57:30.189203  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_4
1901: I0816 03:57:30.189211  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_5
1901: I0816 03:57:30.189217  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_6
1901: I0816 03:57:30.189225  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_7
1901: I0816 03:57:30.189231  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_8
1901: I0816 03:57:30.189239  9572 scope.cc:202] Create variable 0x476e48c01723780650189125013_inner_var_9
1901: I0816 03:57:30.189245  9572 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:57:30.189846  9572 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:57:30.189862  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.189867  9572 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0816 03:57:30.189913  9572 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x476e2f00
1901: 1 -> 0x476e48c01723780650189125013_inner_var_1 -> 0x476e48a0
1901: 2 -> 0x476e48c01723780650189125013_inner_var_2 -> 0x476e4460
1901: 3 -> 0x476e48c01723780650189125013_inner_var_3 -> 0x476e3fb0
1901: 4 -> 0x476e48c01723780650189125013_inner_var_4 -> 0x476e2e50
1901: 5 -> 0x476e48c01723780650189125013_inner_var_5 -> 0x476e5360
1901: 6 -> 0x476e48c01723780650189125013_inner_var_6 -> 0x476e5780
1901: 7 -> 0x476e48c01723780650189125013_inner_var_7 -> 0x476e5ba0
1901: 8 -> 0x476e48c01723780650189125013_inner_var_8 -> 0x476e2fc0
1901: 9 -> 0x476e48c01723780650189125013_inner_var_9 -> 0x476e5fc0
1901: 10 -> fetch0@fetch -> 0x476e67d0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0816 03:57:30.190860  9572 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0816 03:57:30.191074  9609 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:57:30.191188  9610 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:57:30.191249  9611 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:57:30.191318  9612 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:57:30.191340  9613 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:57:30.191357  9611 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x476e48c01723780650189125013_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.191416  9614 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:57:30.191484  9611 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x476e48c01723780650189125013_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0816 03:57:30.191478  9614 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.191525  9614 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:57:30.191583  9614 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476e48c01723780650189125013_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_3:[dtype=;place=;dim=;lod={};, 0x476e48c01723780650189125013_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.192147  9614 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476e48c01723780650189125013_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x476e48c01723780650189125013_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.192178  9614 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x476e48c01723780650189125013_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.192229  9614 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.192245  9614 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x476e48c01723780650189125013_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.192271  9614 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x476e48c01723780650189125013_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x476e48c01723780650189125013_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.192332  9614 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.192407  9614 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x476e48c01723780650189125013_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x476e48c01723780650189125013_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.192471  9614 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x476e48c01723780650189125013_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476e48c01723780650189125013_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.192538  9614 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.192555  9614 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x476e48c01723780650189125013_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476e48c01723780650189125013_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.192577  9614 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x476e48c01723780650189125013_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476e48c01723780650189125013_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x476e48c01723780650189125013_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.192669  9614 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x476e48c01723780650189125013_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x476e48c01723780650189125013_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x476e48c01723780650189125013_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:57:30.192745  9611 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476e48c01723780650189125013_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.192771  9611 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.192867  9611 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476e48c01723780650189125013_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650189125013_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0816 03:57:30.192898  9611 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x476e48c01723780650189125013_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.192920  9611 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.192952  9611 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x476e48c01723780650189125013_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0816 03:57:30.192984  9572 pir_interpreter.cc:1766] main_thread_blocker_(0x476e4a30) got event_name: TaskCompletion
1901: I0816 03:57:30.193011  9572 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.196435  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.196465  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.196528  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.196538  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.197758  9609 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 2376050946743183320 to 15676526495895478699 , after update, data is {current : -20004, peak : 16}.
1901: I0816 03:57:30.197782  9609 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 2376050946743183320 to 15676526495895478699 , after update, data is {current : 0, peak : 330659}.
1901: I0816 03:57:30.197988  9611 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 14324504148503424245 to 15676526495895478699 , after update, data is {current : 20000, peak : 40004}.
1901: I0816 03:57:30.198132  9614 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 15676526495895478699 to 10905371182797837941 , after update, data is {current : 20000, peak : 40004}.
1901: I0816 03:57:30.198143  9614 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 15676526495895478699 to 10905371182797837941 , after update, data is {current : 120000, peak : 440631}.
1901: I0816 03:57:30.199539  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.200117  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.200609  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.200624  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.200630  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.202957  9572 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:57:30.202975  9572 scope.cc:202] Create variable feed
1901: I0816 03:57:30.203008  9572 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:57:30.203017  9572 scope.cc:202] Create variable MedianIndex
1901: I0816 03:57:30.203023  9572 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47753780 type is 7
1901: I0816 03:57:30.203032  9572 scope.cc:202] Create variable Out
1901: I0816 03:57:30.203035  9572 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47752d10 type is 7
1901: I0816 03:57:30.203042  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.203047  9572 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47753700 type is 7
1901: I0816 03:57:30.203053  9572 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47752d30 type is 9
1901: I0816 03:57:30.203059  9572 scope.cc:202] Create variable fetch
1901: I0816 03:57:30.203068  9572 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47753b30 type is 10
1901: I0816 03:57:30.203145  9572 interpreter_util.cc:594] Static build: 0
1901: I0816 03:57:30.203151  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.203158  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.203162  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.203217  9572 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.203231  9572 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.203312  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.203323  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.203346  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.203856  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.203872  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.203892  9572 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.203900  9572 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47757b10Variable Type 7
1901: I0816 03:57:30.203920  9572 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.203943  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.203967  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.203984  9572 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.204028  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.204052  9572 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:57:30.204102  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.204111  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.204129  9572 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.204138  9572 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4775b7f0Variable Type 7
1901: I0816 03:57:30.204151  9572 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.204166  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.204186  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.204201  9572 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.204236  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.204267  9572 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0816 03:57:30.204567  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.204599  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.205947  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.205971  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.206023  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.206033  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.207938  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.208513  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.208946  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.208959  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.208964  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.211225  9572 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:57:30.211297  9572 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:57:30.211318  9572 scope.cc:202] Create variable MedianIndex
1901: I0816 03:57:30.211324  9572 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47737960 type is 7
1901: I0816 03:57:30.211333  9572 scope.cc:202] Create variable Out
1901: I0816 03:57:30.211339  9572 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47736c90 type is 7
1901: I0816 03:57:30.211345  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.211350  9572 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47737690 type is 7
1901: I0816 03:57:30.211356  9572 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47752d30 type is 9
1901: I0816 03:57:30.211362  9572 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47753b30 type is 10
1901: I0816 03:57:30.211441  9572 interpreter_util.cc:594] Static build: 0
1901: I0816 03:57:30.211447  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.211453  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.211457  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.211499  9572 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.211513  9572 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.211567  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.211577  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.211596  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.212122  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.212138  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.212158  9572 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.212167  9572 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4773be00Variable Type 7
1901: I0816 03:57:30.212184  9572 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.212201  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.212224  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.212240  9572 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.212281  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.212313  9572 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:57:30.212363  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.212373  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.212391  9572 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.212399  9572 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4773be20Variable Type 7
1901: I0816 03:57:30.212412  9572 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.212427  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.212447  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.212462  9572 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.212497  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.212519  9572 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0816 03:57:30.212783  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.212811  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.331912  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a695010 for it.
1901: I0816 03:57:30.332348  9572 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6fbc10 for it.
1901: I0816 03:57:30.332430  9572 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.333068  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.333117  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.334388  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a695010 for it.
1901: I0816 03:57:30.334533  9572 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.334589  9572 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a6fbc10 for it.
1901: I0816 03:57:30.335788  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.335827  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.338268  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a695010 for it.
1901: I0816 03:57:30.338433  9572 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6fbc10 for it.
1901: I0816 03:57:30.338481  9572 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0816 03:57:30.341874  9572 pir_interpreter.cc:161] PirInterpreter(): 0x476e48c0 on Place(gpu:0)
1901: I0816 03:57:30.341912  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.341938  9572 scope.cc:202] Create variable 0x476e48c01723780650341901809_inner_var_1
1901: I0816 03:57:30.341949  9572 scope.cc:202] Create variable 0x476e48c01723780650341901809_inner_var_2
1901: I0816 03:57:30.341959  9572 scope.cc:202] Create variable 0x476e48c01723780650341901809_inner_var_3
1901: I0816 03:57:30.341967  9572 scope.cc:202] Create variable 0x476e48c01723780650341901809_inner_var_4
1901: I0816 03:57:30.341979  9572 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:57:30.342379  9572 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:57:30.342396  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.342401  9572 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x476ef050
1901: 1 -> 0x476e48c01723780650341901809_inner_var_1 -> 0x476ef0d0
1901: 2 -> 0x476e48c01723780650341901809_inner_var_2 -> 0x4775be90
1901: 3 -> 0x476e48c01723780650341901809_inner_var_3 -> 0x47715ae0
1901: 4 -> 0x476e48c01723780650341901809_inner_var_4 -> 0x47736a30
1901: 5 -> fetch0@fetch -> 0x4770b360
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0816 03:57:30.343106  9616 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:57:30.343271  9617 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:57:30.343307  9618 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:57:30.343343  9619 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:57:30.343377  9620 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:57:30.343462  9621 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:57:30.343506  9621 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650341901809_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.343551  9621 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650341901809_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:57:30.343593  9621 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476e48c01723780650341901809_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650341901809_inner_var_3:[dtype=;place=;dim=;lod={};, 0x476e48c01723780650341901809_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.344085  9621 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476e48c01723780650341901809_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476e48c01723780650341901809_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x476e48c01723780650341901809_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.344169  9620 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476e48c01723780650341901809_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476e48c01723780650341901809_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.344205  9620 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.344270  9620 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476e48c01723780650341901809_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476e48c01723780650341901809_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.344310  9620 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x476e48c01723780650341901809_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.344331  9620 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.344344  9620 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x476e48c01723780650341901809_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.344377  9572 pir_interpreter.cc:1766] main_thread_blocker_(0x476e4a30) got event_name: TaskCompletion
1901: I0816 03:57:30.344400  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.344910  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.345050  9572 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6fbc10 for it.
1901: I0816 03:57:30.345093  9572 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a695010 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0816 03:57:30.347178  9572 pir_interpreter.cc:161] PirInterpreter(): 0x4771b970 on Place(gpu:0)
1901: I0816 03:57:30.347203  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.347219  9572 scope.cc:202] Create variable 0x4771b9701723780650347198299_inner_var_1
1901: I0816 03:57:30.347229  9572 scope.cc:202] Create variable 0x4771b9701723780650347198299_inner_var_2
1901: I0816 03:57:30.347234  9572 scope.cc:202] Create variable 0x4771b9701723780650347198299_inner_var_3
1901: I0816 03:57:30.347242  9572 scope.cc:202] Create variable 0x4771b9701723780650347198299_inner_var_4
1901: I0816 03:57:30.347249  9572 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:57:30.347512  9572 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:57:30.347525  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.347528  9572 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x476eb240
1901: 1 -> 0x4771b9701723780650347198299_inner_var_1 -> 0x476eb280
1901: 2 -> 0x4771b9701723780650347198299_inner_var_2 -> 0x476eb5a0
1901: 3 -> 0x4771b9701723780650347198299_inner_var_3 -> 0x45290e80
1901: 4 -> 0x4771b9701723780650347198299_inner_var_4 -> 0x47719480
1901: 5 -> fetch0@fetch -> 0x476ee840
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0816 03:57:30.348070  9622 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:57:30.348273  9623 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:57:30.348282  9624 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:57:30.348359  9625 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:57:30.348433  9626 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:57:30.348497  9627 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:57:30.348531  9627 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4771b9701723780650347198299_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.348555  9627 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4771b9701723780650347198299_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:57:30.348583  9627 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4771b9701723780650347198299_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4771b9701723780650347198299_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4771b9701723780650347198299_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.348991  9627 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4771b9701723780650347198299_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4771b9701723780650347198299_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4771b9701723780650347198299_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.349057  9626 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4771b9701723780650347198299_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4771b9701723780650347198299_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.349092  9626 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.349151  9626 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4771b9701723780650347198299_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4771b9701723780650347198299_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.349184  9626 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4771b9701723780650347198299_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.349203  9626 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.349216  9626 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4771b9701723780650347198299_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.349248  9572 pir_interpreter.cc:1766] main_thread_blocker_(0x4771bae0) got event_name: TaskCompletion
1901: I0816 03:57:30.349269  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.350386  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a695010 for it.
1901: I0816 03:57:30.350533  9572 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6fbc10 for it.
1901: I0816 03:57:30.350574  9572 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0816 03:57:30.352571  9572 pir_interpreter.cc:161] PirInterpreter(): 0x1a665260 on Place(gpu:0)
1901: I0816 03:57:30.352594  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.352609  9572 scope.cc:202] Create variable 0x1a6652601723780650352590266_inner_var_1
1901: I0816 03:57:30.352619  9572 scope.cc:202] Create variable 0x1a6652601723780650352590266_inner_var_2
1901: I0816 03:57:30.352625  9572 scope.cc:202] Create variable 0x1a6652601723780650352590266_inner_var_3
1901: I0816 03:57:30.352634  9572 scope.cc:202] Create variable 0x1a6652601723780650352590266_inner_var_4
1901: I0816 03:57:30.352641  9572 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:57:30.352901  9572 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:57:30.352913  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.352917  9572 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x476f1b60
1901: 1 -> 0x1a6652601723780650352590266_inner_var_1 -> 0x1a665240
1901: 2 -> 0x1a6652601723780650352590266_inner_var_2 -> 0x1a665aa0
1901: 3 -> 0x1a6652601723780650352590266_inner_var_3 -> 0x1a665b00
1901: 4 -> 0x1a6652601723780650352590266_inner_var_4 -> 0x4775d2f0
1901: 5 -> fetch0@fetch -> 0x476e9470
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0816 03:57:30.353423  9628 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:57:30.353623  9629 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:57:30.353639  9630 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:57:30.353698  9631 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:57:30.353794  9632 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:57:30.353869  9633 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:57:30.353909  9633 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1a6652601723780650352590266_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.353936  9633 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1a6652601723780650352590266_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:57:30.353964  9633 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x1a6652601723780650352590266_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1a6652601723780650352590266_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1a6652601723780650352590266_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.354424  9633 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x1a6652601723780650352590266_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1a6652601723780650352590266_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x1a6652601723780650352590266_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.354491  9632 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a6652601723780650352590266_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x1a6652601723780650352590266_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.354525  9632 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.354581  9632 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a6652601723780650352590266_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x1a6652601723780650352590266_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.354614  9632 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a6652601723780650352590266_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.354632  9632 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.354645  9632 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a6652601723780650352590266_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.354674  9572 pir_interpreter.cc:1766] main_thread_blocker_(0x1a6653d0) got event_name: TaskCompletion
1901: I0816 03:57:30.354694  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.354858  9572 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0816 03:57:30.354969  9572 unary_infer_sym.cc:1363] NanmedianOpInferSymbolicShape
1901: I0816 03:57:30.354980  9572 unary_infer_sym.cc:1373] axis_list: 0
1901: I0816 03:57:30.354987  9572 unary_infer_sym.cc:1377] x_dim: 2
1901: I0816 03:57:30.354992  9572 unary_infer_sym.cc:1379] x_rank: 2
1901: I0816 03:57:30.354996  9572 unary_infer_sym.cc:1387] axis_list is empty
1901: I0816 03:57:30.355005  9572 unary_infer_sym.cc:1446] out_dim: 0
1901: I0816 03:57:30.355010  9572 unary_infer_sym.cc:1447] median_dim: 1
1901: I0816 03:57:30.355054  9572 pir.cc:2451] Start compare shape and data.
1901: I0816 03:57:30.356248  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.356273  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.356334  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.356343  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.358055  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.358515  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.358920  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.358933  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.358938  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.360806  9572 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:57:30.360874  9572 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:57:30.360884  9572 scope.cc:202] Create variable MedianIndex
1901: I0816 03:57:30.360889  9572 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x46171ba0 type is 7
1901: I0816 03:57:30.360896  9572 scope.cc:202] Create variable Out
1901: I0816 03:57:30.360903  9572 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x461713c0 type is 7
1901: I0816 03:57:30.360906  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.360910  9572 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x46171d30 type is 7
1901: I0816 03:57:30.360914  9572 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47752d30 type is 9
1901: I0816 03:57:30.360919  9572 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47753b30 type is 10
1901: I0816 03:57:30.360996  9572 interpreter_util.cc:594] Static build: 0
1901: I0816 03:57:30.361002  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.361006  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.361009  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.361054  9572 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.361068  9572 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.361129  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.361138  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.361156  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.361614  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.361630  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.361646  9572 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.361653  9572 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46176240Variable Type 7
1901: I0816 03:57:30.361670  9572 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.361686  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.361708  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.361724  9572 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.361766  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.361793  9572 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:57:30.361840  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.361850  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.361863  9572 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.361869  9572 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x461766d0Variable Type 7
1901: I0816 03:57:30.361882  9572 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.361894  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.361912  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.361923  9572 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.361955  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.361981  9572 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0816 03:57:30.362290  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.362323  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.362769  9572 pybind.cc:1827] need skip: 0
1901: I0816 03:57:30.408814  9616 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 15676526495895478699 to 572477238842385709 , after update, data is {current : 2, peak : 4}.
1901: I0816 03:57:30.408828  9616 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 15676526495895478699 to 1910529952821838203 , after update, data is {current : -36, peak : 0}.
1901: I0816 03:57:30.409065  9620 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 7160960028345166860 to 572477238842385709 , after update, data is {current : 6, peak : 6}.
1901: I0816 03:57:30.409195  9621 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 14324504148503424245 to 572477238842385709 , after update, data is {current : 6, peak : 16}.
1901: I0816 03:57:30.409205  9621 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 14324504148503424245 to 1910529952821838203 , after update, data is {current : -18, peak : 330659}.
1901: I0816 03:57:30.409396  9622 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 11249180679530958053 to 572477238842385709 , after update, data is {current : 4, peak : 16}.
1901: I0816 03:57:30.409405  9622 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 11249180679530958053 to 1910529952821838203 , after update, data is {current : -36, peak : 330659}.
1901: I0816 03:57:30.409570  9626 thread_data_registry.h:135] Add data {current : 4, peak : 16} from thread 572477238842385709 to 5222664800398036372 , after update, data is {current : 4, peak : 16}.
1901: I0816 03:57:30.409749  9627 thread_data_registry.h:135] Add data {current : 4, peak : 16} from thread 5222664800398036372 to 2335558206623114361 , after update, data is {current : 8, peak : 16}.
1901: I0816 03:57:30.409758  9627 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 5222664800398036372 to 1910529952821838203 , after update, data is {current : -18, peak : 330659}.
1901: I0816 03:57:30.409919  9628 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 1910529952821838203 to 2335558206623114361 , after update, data is {current : 6, peak : 16}.
1901: I0816 03:57:30.409926  9628 thread_data_registry.h:135] Add data {current : -18, peak : 330659} from thread 1910529952821838203 to 1658495422971064834 , after update, data is {current : 0, peak : 330659}.
1901: I0816 03:57:30.410079  9632 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 2335558206623114361 to 1658495422971064834 , after update, data is {current : 6, peak : 16}.
1901: I0816 03:57:30.410256  9633 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 1658495422971064834 to 10905371182797837941 , after update, data is {current : 20006, peak : 40004}.
1901: I0816 03:57:30.410267  9633 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 1658495422971064834 to 10905371182797837941 , after update, data is {current : 180000, peak : 560633}.
1901: I0816 03:57:30.415392  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.415499  9572 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7f8996018e00), and remaining 0
1901: I0816 03:57:30.415594  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.415628  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.415870  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.416740  9572 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.416821  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.416846  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.417006  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.417697  9572 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.417769  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.417795  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.417945  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.418569  9572 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.418641  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.418668  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.418823  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0816 03:57:30.419513  9572 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.419565  9572 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f8996019000), and remaining 0
1901: I0816 03:57:30.419617  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.419641  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.420105  9572 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.420169  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.420192  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.420650  9572 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.420712  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.420737  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.421144  9572 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.421205  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.421228  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.421797  9572 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.421865  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.421890  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.422084  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.422724  9572 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.422796  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.422821  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.422977  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.423679  9572 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.423750  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.423775  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.423969  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.424589  9572 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.424662  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.424687  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.424845  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.425511  9572 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.425581  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.425606  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.425796  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.426447  9572 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.426519  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.426544  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.426700  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.427407  9572 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.427479  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.427505  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.427666  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.428339  9572 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.428413  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.428438  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.428591  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.429281  9572 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.429364  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.429390  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.429580  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.430203  9572 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.430274  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.430308  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.430469  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.430994  9572 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.431058  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.431083  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.431228  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.431902  9572 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.431968  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.431993  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.432140  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.432794  9572 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.432862  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.432886  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.433138  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0816 03:57:30.435165  9572 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.435236  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.435262  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.435451  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.436807  9572 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.436879  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.436904  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.437109  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.438437  9572 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.438510  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.438535  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.438712  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.439929  9572 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.440001  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.440027  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.440284  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.441519  9572 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.441591  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.441615  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.441795  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.443091  9572 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.443163  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.443189  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.443375  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.444677  9572 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.444749  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.444777  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.444954  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.446171  9572 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.446244  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.446270  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.446520  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.447837  9572 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.447911  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.447937  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.448117  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.449339  9572 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.449412  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.449437  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.449640  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.450865  9572 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.450938  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.450963  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.451143  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.452443  9572 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.452517  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.452543  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.452720  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.453933  9572 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.454006  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.454031  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.454206  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.455499  9572 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.455571  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.455596  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.455772  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.456992  9572 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.457065  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.457091  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.457266  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.458473  9572 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.458545  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.458571  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.458747  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.459484  9572 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.459554  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.459579  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.459751  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.462550  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.462576  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.463404  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.463426  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.464180  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.464200  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.464974  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.464996  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.465747  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.465768  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.468223  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.468765  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.469273  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.469802  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.470319  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.471139  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.471155  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.471161  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.475996  9572 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:57:30.476073  9572 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:57:30.476086  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.476092  9572 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47a74e20 type is 7
1901: I0816 03:57:30.476104  9572 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47752d30 type is 9
1901: I0816 03:57:30.476110  9572 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47753b30 type is 10
1901: I0816 03:57:30.476118  9572 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0816 03:57:30.476122  9572 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x47a74190 type is 7
1901: I0816 03:57:30.476130  9572 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0816 03:57:30.476133  9572 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x47a74d80 type is 7
1901: I0816 03:57:30.476140  9572 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0816 03:57:30.476145  9572 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x4773af40 type is 7
1901: I0816 03:57:30.476150  9572 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0816 03:57:30.476154  9572 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x47a73bb0 type is 7
1901: I0816 03:57:30.476161  9572 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0816 03:57:30.476167  9572 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x47a74f30 type is 7
1901: I0816 03:57:30.476172  9572 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0816 03:57:30.476177  9572 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x47a750f0 type is 7
1901: I0816 03:57:30.476182  9572 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0816 03:57:30.476187  9572 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x47a75300 type is 7
1901: I0816 03:57:30.476193  9572 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0816 03:57:30.476202  9572 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x47a75560 type is 7
1901: I0816 03:57:30.476207  9572 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0816 03:57:30.476210  9572 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x47a757c0 type is 7
1901: I0816 03:57:30.476217  9572 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0816 03:57:30.476220  9572 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x47a75a20 type is 7
1901: I0816 03:57:30.479239  9572 interpreter_util.cc:594] Static build: 0
1901: I0816 03:57:30.479250  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.479256  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.479260  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.479324  9572 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.479338  9572 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.479395  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.479404  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.479419  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.479635  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.479820  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.479830  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.479846  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.479955  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.480129  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.480139  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.480154  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.480258  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.480427  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.480437  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.480453  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.480579  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.480762  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.480772  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.480787  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.480906  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.481082  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481092  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481107  9572 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.481114  9572 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47b3b910Variable Type 7
1901: I0816 03:57:30.481132  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.481148  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.481170  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.481184  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.481220  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.481235  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:57:30.481272  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481281  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481294  9572 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.481309  9572 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a768f0Variable Type 7
1901: I0816 03:57:30.481324  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.481336  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.481353  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.481365  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.481395  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.481417  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0816 03:57:30.481456  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481465  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481479  9572 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.481485  9572 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a76130Variable Type 7
1901: I0816 03:57:30.481498  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.481509  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.481523  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.481534  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.481564  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.481575  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0816 03:57:30.481611  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481618  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481631  9572 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.481637  9572 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47b39f40Variable Type 7
1901: I0816 03:57:30.481648  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.481659  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.481673  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.481683  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.481709  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.481720  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0816 03:57:30.481752  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481760  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.481771  9572 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.481777  9572 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x477c1000Variable Type 7
1901: I0816 03:57:30.481789  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.481801  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.481812  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.481824  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.481851  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.481863  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0816 03:57:30.482376  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.482406  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.482424  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.482440  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.482456  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0816 03:57:30.488751  9572 pir_interpreter.cc:161] PirInterpreter(): 0x47b8aee0 on Place(gpu:0)
1901: I0816 03:57:30.488785  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.488808  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_1
1901: I0816 03:57:30.488819  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_2
1901: I0816 03:57:30.488828  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_3
1901: I0816 03:57:30.488839  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_4
1901: I0816 03:57:30.488847  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_5
1901: I0816 03:57:30.488857  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_6
1901: I0816 03:57:30.488863  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_7
1901: I0816 03:57:30.488873  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_8
1901: I0816 03:57:30.488880  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_9
1901: I0816 03:57:30.488890  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_10
1901: I0816 03:57:30.488898  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_11
1901: I0816 03:57:30.488909  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_12
1901: I0816 03:57:30.488919  9572 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:57:30.488932  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_14
1901: I0816 03:57:30.488941  9572 scope.cc:202] Create variable fetch1@fetch
1901: I0816 03:57:30.488950  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_16
1901: I0816 03:57:30.488960  9572 scope.cc:202] Create variable fetch2@fetch
1901: I0816 03:57:30.488968  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_18
1901: I0816 03:57:30.488977  9572 scope.cc:202] Create variable fetch3@fetch
1901: I0816 03:57:30.488986  9572 scope.cc:202] Create variable 0x47b8aee01723780650488775757_inner_var_20
1901: I0816 03:57:30.488994  9572 scope.cc:202] Create variable fetch4@fetch
1901: I0816 03:57:30.489282  9572 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:57:30.489296  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.489313  9572 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47a75ed0
1901: 1 -> 0x47b8aee01723780650488775757_inner_var_1 -> 0x47a75ef0
1901: 2 -> 0x47b8aee01723780650488775757_inner_var_2 -> 0x47a54a10
1901: 3 -> 0x47b8aee01723780650488775757_inner_var_3 -> 0x47aeafb0
1901: 4 -> 0x47b8aee01723780650488775757_inner_var_4 -> 0x4774a040
1901: 5 -> 0x47b8aee01723780650488775757_inner_var_5 -> 0x46175ec0
1901: 6 -> 0x47b8aee01723780650488775757_inner_var_6 -> 0x47a54de0
1901: 7 -> 0x47b8aee01723780650488775757_inner_var_7 -> 0x47b52380
1901: 8 -> 0x47b8aee01723780650488775757_inner_var_8 -> 0x47b36300
1901: 9 -> 0x47b8aee01723780650488775757_inner_var_9 -> 0x47b3a6d0
1901: 10 -> 0x47b8aee01723780650488775757_inner_var_10 -> 0x47a6d5a0
1901: 11 -> 0x47b8aee01723780650488775757_inner_var_11 -> 0x477c1fc0
1901: 12 -> 0x47b8aee01723780650488775757_inner_var_12 -> 0x47aeb000
1901: 13 -> fetch0@fetch -> 0x47a76d90
1901: 14 -> 0x47b8aee01723780650488775757_inner_var_14 -> 0x47a75e10
1901: 15 -> fetch1@fetch -> 0x47b3aed0
1901: 16 -> 0x47b8aee01723780650488775757_inner_var_16 -> 0x47a76d70
1901: 17 -> fetch2@fetch -> 0x47a762e0
1901: 18 -> 0x47b8aee01723780650488775757_inner_var_18 -> 0x47b3aeb0
1901: 19 -> fetch3@fetch -> 0x47b52950
1901: 20 -> 0x47b8aee01723780650488775757_inner_var_20 -> 0x47a762c0
1901: 21 -> fetch4@fetch -> 0x47b71530
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0816 03:57:30.490787  9634 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:57:30.490813  9635 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:57:30.490840  9636 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:57:30.490872  9637 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:57:30.490916  9638 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:57:30.490955  9638 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.491005  9638 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0816 03:57:30.491058  9638 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650488775757_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.491288  9638 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.491451  9638 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47b8aee01723780650488775757_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.491503  9638 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_5:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650488775757_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.491523  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.491557  9637 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.491641  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.491706  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.491727  9637 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.491735  9638 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.491740  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.491917  9638 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47b8aee01723780650488775757_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.491998  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.491995  9638 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_7:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650488775757_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492020  9637 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.492054  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.492105  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492120  9637 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.492130  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.492218  9638 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.492372  9638 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47b8aee01723780650488775757_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.492427  9638 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_9:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650488775757_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492432  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492457  9637 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.492492  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.492539  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492554  9637 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.492564  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.492631  9638 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.492805  9638 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47b8aee01723780650488775757_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.492857  9638 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_11:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650488775757_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492866  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492882  9637 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.492924  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.492972  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.492988  9637 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.492998  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.493063  9638 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.493220  9638 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650488775757_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47b8aee01723780650488775757_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.493276  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.493291  9637 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.493323  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650488775757_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650488775757_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.493356  9637 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.493372  9637 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.493384  9637 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650488775757_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.493413  9572 pir_interpreter.cc:1766] main_thread_blocker_(0x47b8b050) got event_name: TaskCompletion
1901: I0816 03:57:30.493438  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.493463  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.493475  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.493486  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.493494  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.495154  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.495244  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.495271  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.495491  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.495592  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47b3be40)  to GradNodeAccumulation (addr: 0x47755a00)
1901: I0816 03:57:30.495731  9572 backward.cc:459] Run in Grad
1901: I0816 03:57:30.495748  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.495802  9572 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47b3be40 to ptr: 0x47a63370
1901: I0816 03:57:30.495813  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.495858  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.495900  9572 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x47755a00 to ptr: 0x47746020
1901: I0816 03:57:30.495929  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47a63370
1901: I0816 03:57:30.495939  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.495972  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.496062  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.496071  9572 backward.cc:335] Node: NanmedianGradNode addr:0x47a63370, Found pending node: GradNodeAccumulation addr: 0x47746020
1901: I0816 03:57:30.496078  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.496104  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47746020
1901: I0816 03:57:30.496112  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.496116  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.496124  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.496129  9572 backward.cc:435] Finish Backward
1901: I0816 03:57:30.496883  9572 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0816 03:57:30.496901  9572 dygraph_functions.cc:77659] { Input: []} 
1901: I0816 03:57:30.497007  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.497031  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.497175  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.497248  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47a63370)  to GradNodeAccumulation (addr: 0x47755a00)
1901: I0816 03:57:30.497354  9572 backward.cc:442] Run in Backward
1901: I0816 03:57:30.497361  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.497370  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.497401  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.497432  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47a63370
1901: I0816 03:57:30.497440  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.497469  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.497529  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.497555  9572 backward.cc:335] Node: NanmedianGradNode addr:0x47a63370, Found pending node: GradNodeAccumulation addr: 0x47755a00
1901: I0816 03:57:30.497562  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.497581  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47755a00
1901: I0816 03:57:30.497587  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.497593  9572 accumulation_node.cc:40] Move Tensor ptr: 0x47a63d40
1901: I0816 03:57:30.497596  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.497601  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.500595  9572 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0816 03:57:30.501122  9572 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.501238  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.501264  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.501442  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47aeb550)  to GradNodeAccumulation (addr: 0x1a6cb240)
1901: I0816 03:57:30.501546  9572 backward.cc:442] Run in Backward
1901: I0816 03:57:30.501554  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.501562  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.501593  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.501617  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47aeb550
1901: I0816 03:57:30.501626  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.501655  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.501703  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.501727  9572 backward.cc:335] Node: NanmedianGradNode addr:0x47aeb550, Found pending node: GradNodeAccumulation addr: 0x1a6cb240
1901: I0816 03:57:30.501735  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.501753  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a6cb240
1901: I0816 03:57:30.501761  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.501767  9572 accumulation_node.cc:40] Move Tensor ptr: 0x4529db90
1901: I0816 03:57:30.501772  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.501776  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.502527  9572 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.502606  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.502631  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.502854  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.502954  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47a63370)  to GradNodeAccumulation (addr: 0x1a6cb240)
1901: I0816 03:57:30.503073  9572 backward.cc:459] Run in Grad
1901: I0816 03:57:30.503083  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.503098  9572 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47a63370 to ptr: 0x47aebed0
1901: I0816 03:57:30.503105  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.503136  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.503161  9572 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1a6cb240 to ptr: 0x47746020
1901: I0816 03:57:30.503181  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47aebed0
1901: I0816 03:57:30.503188  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.503218  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.503365  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.503374  9572 backward.cc:335] Node: NanmedianGradNode addr:0x47aebed0, Found pending node: GradNodeAccumulation addr: 0x47746020
1901: I0816 03:57:30.503381  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.503398  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47746020
1901: I0816 03:57:30.503405  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.503410  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.503415  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.503422  9572 backward.cc:435] Finish Backward
1901: I0816 03:57:30.504329  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.504411  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.504437  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.504598  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.506038  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.506094  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.506117  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.510890  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.510917  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.512177  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.512203  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.513154  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.513253  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.513286  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.513517  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.514145  9572 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.514227  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.514254  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.514442  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.515075  9572 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.515152  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.515180  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.515358  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.515929  9572 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.516006  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.516034  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.516206  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.516814  9572 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.516867  9572 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f8996019400), and remaining 0
1901: I0816 03:57:30.516924  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.516950  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.517453  9572 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.517529  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.517554  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.518076  9572 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.518150  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.518177  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.518664  9572 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.518738  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.518764  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.519270  9572 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.519351  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.519378  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.519603  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.520165  9572 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.520242  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.520269  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.520462  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.521061  9572 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.521136  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.521164  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.521366  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.521943  9572 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.522022  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.522049  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.522222  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.522828  9572 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.522920  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.522949  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.523164  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.523742  9572 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.523820  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.523849  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.524024  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.524642  9572 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.524727  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.524755  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.524919  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.525527  9572 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.525606  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.525635  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.525802  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.526432  9572 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.526508  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.526536  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.526702  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.527276  9572 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.527364  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.527392  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.527563  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.528072  9572 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.528126  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.528146  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.528268  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.528882  9572 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.528947  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.528972  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.529119  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.529770  9572 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.529847  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.529875  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.530076  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.530774  9572 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.530845  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.530870  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.531042  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.531710  9572 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.531781  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.531806  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.532033  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.532683  9572 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.532753  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.532778  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.532955  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.533602  9572 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.533671  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.533696  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.533970  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.534597  9572 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.534667  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.534693  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.534865  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.535486  9572 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.535555  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.535580  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.535753  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.536392  9572 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.536461  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.536486  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.536659  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.537294  9572 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.537374  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.537400  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.537603  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.538229  9572 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.538297  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.538333  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.538528  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.539135  9572 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.539206  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.539230  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.539417  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.540020  9572 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.540089  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.540113  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.540285  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.540899  9572 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.540971  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.540995  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.541184  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.541798  9572 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.541868  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.541893  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.542059  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.542688  9572 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.542757  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.542783  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.542953  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.543634  9572 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.543711  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.543740  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.543927  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.544524  9572 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.544595  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.544620  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.544791  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.545528  9572 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.545606  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.545635  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.545822  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.547772  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.547794  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.548403  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.548421  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.549017  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.549036  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.549665  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.549683  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.550283  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.550320  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.551980  9637 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 7160960028345166860 to 14324504148503424245 , after update, data is {current : 0, peak : 1260}.
1901: I0816 03:57:30.551990  9637 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 7160960028345166860 to 14324504148503424245 , after update, data is {current : 20, peak : 24}.
1901: I0816 03:57:30.552445  9638 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 14324504148503424245 to 10905371182797837941 , after update, data is {current : 0, peak : 260}.
1901: I0816 03:57:30.552459  9638 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 14324504148503424245 to 10905371182797837941 , after update, data is {current : 20026, peak : 40004}.
1901: I0816 03:57:30.552464  9638 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 14324504148503424245 to 10905371182797837941 , after update, data is {current : 162560, peak : 560633}.
1901: I0816 03:57:30.553941  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.554383  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.554800  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.555210  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.555630  9572 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:57:30.556422  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.556437  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.556442  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.560459  9572 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:57:30.560500  9572 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:57:30.560509  9572 scope.cc:202] Create variable X
1901: I0816 03:57:30.560514  9572 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47759f10 type is 7
1901: I0816 03:57:30.560520  9572 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47752d30 type is 9
1901: I0816 03:57:30.560532  9572 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47753b30 type is 10
1901: I0816 03:57:30.560536  9572 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0816 03:57:30.560540  9572 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x477594e0 type is 7
1901: I0816 03:57:30.560545  9572 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0816 03:57:30.560549  9572 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x477592d0 type is 7
1901: I0816 03:57:30.560552  9572 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0816 03:57:30.560555  9572 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x4775a050 type is 7
1901: I0816 03:57:30.560560  9572 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0816 03:57:30.560564  9572 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x4775a260 type is 7
1901: I0816 03:57:30.560567  9572 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0816 03:57:30.560570  9572 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x4775a470 type is 7
1901: I0816 03:57:30.560575  9572 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0816 03:57:30.560578  9572 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x4775a760 type is 7
1901: I0816 03:57:30.560582  9572 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0816 03:57:30.560585  9572 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x4775a970 type is 7
1901: I0816 03:57:30.560591  9572 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0816 03:57:30.560595  9572 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x47759350 type is 7
1901: I0816 03:57:30.560598  9572 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0816 03:57:30.560601  9572 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x4615e2f0 type is 7
1901: I0816 03:57:30.560606  9572 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0816 03:57:30.560608  9572 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x4615e550 type is 7
1901: I0816 03:57:30.560724  9572 interpreter_util.cc:594] Static build: 0
1901: I0816 03:57:30.560731  9572 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:57:30.560734  9572 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:57:30.560739  9572 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:57:30.560788  9572 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.560801  9572 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.560851  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.560859  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.560874  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.561022  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.561204  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.561215  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.561231  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.561352  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.561527  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.561538  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.561553  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.561658  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.561827  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.561837  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.561851  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.561977  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.562162  9572 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.562172  9572 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.562187  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.562319  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.562497  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.562507  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.562523  9572 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.562530  9572 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47b6df60Variable Type 7
1901: I0816 03:57:30.562546  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.562562  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.562583  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.562597  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.562633  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.562649  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:57:30.562685  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.562695  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.562707  9572 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.562713  9572 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47b53b70Variable Type 7
1901: I0816 03:57:30.562726  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.562738  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.562754  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.562767  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.562798  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.562826  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0816 03:57:30.562865  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.562872  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.562885  9572 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.562891  9572 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a7e7a0Variable Type 7
1901: I0816 03:57:30.562903  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.562916  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.562928  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.562940  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.562969  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.562983  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0816 03:57:30.563016  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.563025  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.563037  9572 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.563043  9572 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47758ef0Variable Type 7
1901: I0816 03:57:30.563055  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.563066  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.563081  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.563092  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.563120  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.563133  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0816 03:57:30.563162  9572 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.563171  9572 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:57:30.563184  9572 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:57:30.563190  9572 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47af93c0Variable Type 7
1901: I0816 03:57:30.563201  9572 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:57:30.563211  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.563225  9572 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:57:30.563236  9572 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.563266  9572 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:57:30.563277  9572 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0816 03:57:30.563823  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.563853  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.563870  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.563887  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:57:30.563905  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0816 03:57:30.569239  9572 pir_interpreter.cc:161] PirInterpreter(): 0x47b8aee0 on Place(gpu:0)
1901: I0816 03:57:30.569271  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_1
1901: I0816 03:57:30.569281  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_2
1901: I0816 03:57:30.569288  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_3
1901: I0816 03:57:30.569296  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_4
1901: I0816 03:57:30.569310  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_5
1901: I0816 03:57:30.569319  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_6
1901: I0816 03:57:30.569324  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_7
1901: I0816 03:57:30.569334  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_8
1901: I0816 03:57:30.569339  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_9
1901: I0816 03:57:30.569348  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_10
1901: I0816 03:57:30.569355  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_11
1901: I0816 03:57:30.569362  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_12
1901: I0816 03:57:30.569377  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_14
1901: I0816 03:57:30.569389  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_16
1901: I0816 03:57:30.569401  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_18
1901: I0816 03:57:30.569411  9572 scope.cc:202] Create variable 0x47b8aee01723780650569259468_inner_var_20
1901: I0816 03:57:30.569641  9572 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47b71840
1901: 1 -> 0x47b8aee01723780650569259468_inner_var_1 -> 0x47b83730
1901: 2 -> 0x47b8aee01723780650569259468_inner_var_2 -> 0x47ae8d60
1901: 3 -> 0x47b8aee01723780650569259468_inner_var_3 -> 0x477bfc40
1901: 4 -> 0x47b8aee01723780650569259468_inner_var_4 -> 0x47b8c820
1901: 5 -> 0x47b8aee01723780650569259468_inner_var_5 -> 0x47b838c0
1901: 6 -> 0x47b8aee01723780650569259468_inner_var_6 -> 0x47a52480
1901: 7 -> 0x47b8aee01723780650569259468_inner_var_7 -> 0x47b52590
1901: 8 -> 0x47b8aee01723780650569259468_inner_var_8 -> 0x47a54ff0
1901: 9 -> 0x47b8aee01723780650569259468_inner_var_9 -> 0x47ae9120
1901: 10 -> 0x47b8aee01723780650569259468_inner_var_10 -> 0x47b6e1d0
1901: 11 -> 0x47b8aee01723780650569259468_inner_var_11 -> 0x477230c0
1901: 12 -> 0x47b8aee01723780650569259468_inner_var_12 -> 0x477272d0
1901: 13 -> fetch0@fetch -> 0x47a76d90
1901: 14 -> 0x47b8aee01723780650569259468_inner_var_14 -> 0x47a5f6b0
1901: 15 -> fetch1@fetch -> 0x47b3aed0
1901: 16 -> 0x47b8aee01723780650569259468_inner_var_16 -> 0x47a5f6d0
1901: 17 -> fetch2@fetch -> 0x47a762e0
1901: 18 -> 0x47b8aee01723780650569259468_inner_var_18 -> 0x476ec590
1901: 19 -> fetch3@fetch -> 0x47b52950
1901: 20 -> 0x47b8aee01723780650569259468_inner_var_20 -> 0x477148c0
1901: 21 -> fetch4@fetch -> 0x47b71530
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0816 03:57:30.570832  9639 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:57:30.570849  9640 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:57:30.570878  9641 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:57:30.570909  9642 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:57:30.570935  9643 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:57:30.570956  9643 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.570988  9643 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0816 03:57:30.571022  9643 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.571190  9643 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.571344  9643 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.571393  9643 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_5:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.571409  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.571442  9642 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.571525  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.571544  9643 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.571581  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.571601  9642 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.571609  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.571717  9643 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.571758  9643 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_7:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.571765  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.571779  9642 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.571846  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.571895  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.571913  9642 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.571918  9643 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.571918  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572060  9643 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.572099  9643 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_9:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.572106  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.572119  9642 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.572158  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572196  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572212  9642 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.572218  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572273  9643 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.572423  9643 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.572463  9643 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_11:[dtype=;place=;dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.572468  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.572481  9642 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.572512  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572556  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572571  9642 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.572576  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572631  9643 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.572780  9643 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47b8aee01723780650569259468_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47b8aee01723780650569259468_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:57:30.572822  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:57:30.572836  9642 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:57:30.572861  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47b8aee01723780650569259468_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47b8aee01723780650569259468_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572893  9642 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572908  9642 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.572913  9642 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47b8aee01723780650569259468_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:57:30.572940  9572 pir_interpreter.cc:1766] main_thread_blocker_(0x47b8b050) got event_name: TaskCompletion
1901: I0816 03:57:30.572964  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.572988  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.572999  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.573009  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.573016  9572 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:57:30.574697  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6cb240 for it.
1901: I0816 03:57:30.574784  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.574810  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.574980  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.575074  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46171d50)  to GradNodeAccumulation (addr: 0x1a6cb240)
1901: I0816 03:57:30.575196  9572 backward.cc:459] Run in Grad
1901: I0816 03:57:30.575206  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.575224  9572 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x46171d50 to ptr: 0x46176b00
1901: I0816 03:57:30.575235  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.575269  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.575296  9572 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1a6cb240 to ptr: 0x47746020
1901: I0816 03:57:30.575330  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46176b00
1901: I0816 03:57:30.575337  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.575371  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.575441  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.575451  9572 backward.cc:335] Node: NanmedianGradNode addr:0x46176b00, Found pending node: GradNodeAccumulation addr: 0x47746020
1901: I0816 03:57:30.575456  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.575481  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47746020
1901: I0816 03:57:30.575489  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.575493  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.575498  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.575502  9572 backward.cc:435] Finish Backward
1901: I0816 03:57:30.576138  9572 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0816 03:57:30.576156  9572 dygraph_functions.cc:77659] { Input: []} 
1901: I0816 03:57:30.576241  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.576264  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.576434  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.576512  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46171d50)  to GradNodeAccumulation (addr: 0x1a6cb240)
1901: I0816 03:57:30.576601  9572 backward.cc:442] Run in Backward
1901: I0816 03:57:30.576607  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.576615  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.576646  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.576671  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46171d50
1901: I0816 03:57:30.576680  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.576707  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.576766  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.576793  9572 backward.cc:335] Node: NanmedianGradNode addr:0x46171d50, Found pending node: GradNodeAccumulation addr: 0x1a6cb240
1901: I0816 03:57:30.576802  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.576819  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a6cb240
1901: I0816 03:57:30.576826  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.576830  9572 accumulation_node.cc:40] Move Tensor ptr: 0x477556b0
1901: I0816 03:57:30.576834  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.576838  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.577322  9572 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.577432  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.577457  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.577620  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x4667aa50)  to GradNodeAccumulation (addr: 0x47755a00)
1901: I0816 03:57:30.577719  9572 backward.cc:442] Run in Backward
1901: I0816 03:57:30.577728  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.577734  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.577765  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.577802  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x4667aa50
1901: I0816 03:57:30.577811  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.577839  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.577890  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.577915  9572 backward.cc:335] Node: NanmedianGradNode addr:0x4667aa50, Found pending node: GradNodeAccumulation addr: 0x47755a00
1901: I0816 03:57:30.577922  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.577939  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47755a00
1901: I0816 03:57:30.577946  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.577950  9572 accumulation_node.cc:40] Move Tensor ptr: 0x4771da80
1901: I0816 03:57:30.577953  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.577957  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.578696  9572 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.578778  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.578804  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.578985  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.579077  9572 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x4667aa50)  to GradNodeAccumulation (addr: 0x47755a00)
1901: I0816 03:57:30.579195  9572 backward.cc:459] Run in Grad
1901: I0816 03:57:30.579206  9572 backward.cc:113] Start Backward
1901: I0816 03:57:30.579218  9572 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x4667aa50 to ptr: 0x46176b00
1901: I0816 03:57:30.579227  9572 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:57:30.579257  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.579280  9572 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x47755a00 to ptr: 0x47746020
1901: I0816 03:57:30.579309  9572 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46176b00
1901: I0816 03:57:30.579317  9572 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:57:30.579346  9572 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.579469  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.579478  9572 backward.cc:335] Node: NanmedianGradNode addr:0x46176b00, Found pending node: GradNodeAccumulation addr: 0x47746020
1901: I0816 03:57:30.579484  9572 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:57:30.579499  9572 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47746020
1901: I0816 03:57:30.579506  9572 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.579510  9572 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:57:30.579514  9572 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:57:30.579519  9572 backward.cc:435] Finish Backward
1901: I0816 03:57:30.580425  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.580502  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.580528  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.580686  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.582032  9572 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x47755a00 for it.
1901: I0816 03:57:30.582078  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.582096  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.584156  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.584183  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.585095  9572 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:57:30.585120  9572 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:57:30.585918  9572 dygraph_functions.cc:33459] Running AD API: full
1901: I0816 03:57:30.585937  9572 dygraph_functions.cc:33480] { Input: []} 
1901: I0816 03:57:30.586036  9572 dygraph_functions.cc:33459] Running AD API: full
1901: I0816 03:57:30.586045  9572 dygraph_functions.cc:33480] { Input: []} 
1901: I0816 03:57:30.586103  9572 dygraph_functions.cc:33459] Running AD API: full
1901: I0816 03:57:30.586110  9572 dygraph_functions.cc:33480] { Input: []} 
1901: I0816 03:57:30.586159  9572 dygraph_functions.cc:82227] Running AD API: arange
1901: I0816 03:57:30.586192  9572 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.586416  9572 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0816 03:57:30.586441  9572 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.586460  9572 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0816 03:57:30.586532  9572 dygraph_functions.cc:14224] Running AD API: cast
1901: I0816 03:57:30.586549  9572 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.586630  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.586715  9572 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:57:30.586732  9572 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:57:30.586905  9572 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:57:30.588697  9572 mmap_allocator.cc:348] PID: 9572, MemoryMapFdSet: set size - 0
1901: I0816 03:57:30.600659  9572 mmap_allocator.cc:348] PID: 9572, MemoryMapFdSet: set size - 0
1901: I0816 03:57:30.666700  9642 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 11788581324637168637 to 4310198465314471559 , after update, data is {current : 0, peak : 1252}.
1901: I0816 03:57:30.666710  9642 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 11788581324637168637 to 4310198465314471559 , after update, data is {current : 0, peak : 16}.
1901: I0816 03:57:30.666945  9643 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 4310198465314471559 to 10905371182797837941 , after update, data is {current : 0, peak : 260}.
1901: I0816 03:57:30.666956  9643 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 4310198465314471559 to 10905371182797837941 , after update, data is {current : 20026, peak : 40004}.
1901: I0816 03:57:30.666960  9643 thread_data_registry.h:135] Add data {current : 0, peak : 1252} from thread 4310198465314471559 to 10905371182797837941 , after update, data is {current : 162560, peak : 560633}.
1901: I0816 03:57:30.796219  9572 mmap_allocator.cc:348] PID: 9572, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................   Passed   10.28 sec

The following tests passed:
	test_nanmedian

100% tests passed, 0 tests failed out of 1

Total Test time (real) =  10.45 sec
