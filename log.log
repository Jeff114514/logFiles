UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1561
    Start 1561: test_fake_quantize_op

1561: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_fake_quantize_op"
1561: Test timeout computed to be: 10000000
1561: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1561: WARNING: Logging before InitGoogleLogging() is written to STDERR
1561: I0810 04:04:34.591202  1655 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1561: I0810 04:04:35.390662  1655 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=static_runtime_data_save_path,enable_async_trace,auto_free_cudagraph_allocations_on_launch,dynamic_static_unified_comm,lapack_dir,local_exe_sub_scope_limit,gpugraph_debug_gpu_memory,eager_delete_scope,get_host_by_name_time,tensorrt_dir,logging_trunc_pir_py_code,enable_auto_rdma_trans,new_executor_sequential_run,enable_sparse_inner_gather,host_trace_level,free_idle_chunk,gpu_allocator_retry_time,logging_pir_py_code_int_tensor_element_limit,accuracy_check_atol_bf16,static_executor_perfstat_filepath,multi_node_sample_use_gpu_table,gpugraph_dedup_pull_push_mode,async_trace_count,enable_pir_with_pt_in_dy2st,fleet_executor_with_standalone,memory_fraction_of_eager_deletion,prim_forward,reallocate_gpu_memory_in_mb,initial_cpu_memory_in_mb,use_cinn,use_virtual_memory_auto_growth,tracer_profile_fname,gpugraph_parallel_copyer_split_maxsize,prim_forward_blacklist,cudnn_exhaustive_search,cuda_dir,cuda_memory_async_pool_realease_threshold,nccl_dir,paddle_num_threads,sync_after_alloc,pinned_memory_as_cpu_backend,enable_interpretercore_launch_cinn,initial_gpu_memory_in_mb,pir_subgraph_saving_dir,gpugraph_force_device_batch_num_equal,embedding_deterministic,enable_neighbor_list_use_uva,cusparse_dir,search_cache_max_number,trt_ibuilder_cache,prim_backward,executor_log_deps_every_microseconds,all_blocks_convert_trt,enable_cublas_tensor_op_math,tracer_onednn_ops_on,enable_pir_in_executor,pir_apply_shape_optimization_pass,new_executor_static_build,allocator_strategy,dataloader_use_file_descriptor,cupti_dir,set_to_1d,nvidia_package_dir,prim_check_ops,new_executor_use_inplace,gpugraph_storage_mode,npu_storage_format,enable_fusion_fallback,cache_inference_while_scope,alloc_fill_value,enable_graph_multi_node_sampling,enable_fuse_parallel_matmul_pass,gpugraph_sparse_table_storage_mode,disable_dyshape_in_train,apply_pass_to_program,low_precision_op_list,custom_device_mem_record,use_pinned_memory,print_allocator_trace_info,dist_threadpool_size,sort_sum_gradient,cusolver_dir,deny_cinn_ops,tensor_operants_mode,einsum_opt,cinn_subgraph_graphviz_dir,enable_cse_in_dy2st,use_cuda_managed_memory,accuracy_check_rtol_fp16,print_ir,cudnn_batchnorm_spatial_persistent,max_inplace_grad_add,gemm_use_half_precision_compute_type,enable_cinn_compile_cache,cudnn_dir,conv2d_disable_cudnn,new_executor_use_local_scope,enable_unused_var_check,check_kernel_launch,conv_workspace_size_limit,accuracy_check_atol_fp16,tracer_onednn_ops_off,enable_tracker_all2all,ir_inplace_kernel_blacklist,pir_broadcast_tree_limit,enable_pir_in_executor_trace_run,enable_cinn_accuracy_check,selected_gpus,enable_blaslt_global_search,fraction_of_gpu_memory_to_use,enable_auto_detect_gpu_topo,gpugraph_enable_print_op_debug,eager_delete_tensor_gb,call_stack_level,use_autotune,accuracy_check_atol_fp32,run_kp_kernel,mklml_dir,cublaslt_device_best_config,manually_trans_conv_filter,gpugraph_enable_hbm_table_collision_stat,save_static_runtime_data,use_stride_kernel,use_auto_growth_v2,gpu_memory_limit_mb,graph_metapath_split_opt,cse_max_count,use_stream_safe_cuda_allocator,enable_api_kernel_fallback,cudnn_exhaustive_search_times,gpugraph_slot_feasign_max_num,gpugraph_parallel_stream_num,benchmark_nccl,cusparselt_dir,logging_pir_py_code_dump_symbolic_dims,cublas_dir,sync_nccl_allreduce,log_memory_stats,gpugraph_enable_gpu_direct_access,gpugraph_hbm_table_load_factor,enable_opt_get_features,cuda_malloc_async_pool_memory_throttle_ratio,enable_gpu_memory_usage_log_mb,use_auto_growth_pinned_allocator,use_xqa_optim,convert_all_blocks,init_allocated_mem,use_fast_math,inner_op_parallelism,allreduce_record_one_event,prim_enable_dynamic,new_executor_serial_run,check_nan_inf,enable_cinn_auto_tune,allow_cinn_ops,mkl_dir,nccl_blocking_wait,reader_queue_speed_test_mode,jit_engine_type,gpugraph_offload_param_stat,fuse_parameter_groups_size,accuracy_check_rtol_fp32,enable_collect_shape,graph_get_neighbor_id,use_mkldnn,prim_all,op_dir,accuracy_check_rtol_bf16,enable_dump_main_program,enable_all2all_use_fp16,gpugraph_offload_param_extends,graph_load_in_parallel,benchmark,dygraph_debug,use_cuda_malloc_async_allocator,enable_record_memory,check_nan_inf_level,free_when_no_cache_hit,pir_apply_inplace_pass,use_system_allocator,auto_growth_chunk_size_in_mb,graph_embedding_split_infer_mode,enable_dependency_builder_debug_info,gpugraph_merge_grads_segment_size,check_infer_symbolic,prim_enabled,fast_eager_deletion_mode,curand_dir,cinn_compile_thread_num,fraction_of_cpu_memory_to_use,fuse_parameter_memory_size,win_cuda_bin_dir,enable_pir_api,fraction_of_cuda_pinned_memory_to_use,enable_gpu_memory_usage_log,query_dest_rank_by_multi_node,enable_adjust_op_order,gpugraph_offload_gather_copy_maxsize,multiple_of_cupti_buffer_size,use_shm_cache,gpugraph_load_node_list_into_hbm,new_executor_use_cuda_graph,gpugraph_enable_segment_merge_grads,cudnn_deterministic,logging_pir_py_code_dir,cublaslt_exhaustive_search_times,graph_neighbor_size_percent,add_dependency_for_communication_op,print_sub_graph_dir,prim_skip_dynamic,enable_exit_when_partial_worker,pir_debug,dump_chunk_info 
1561: I0810 04:04:35.390770  1655 init.cc:108] After Parse: argc is 2
1561: I0810 04:04:40.670850  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:40.670903  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:40.671036  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:40.671046  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:40.671550  1655 allocator_facade.cc:212] selected allocator strategy:1
1561: I0810 04:04:40.671823  1655 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1561: I0810 04:04:43.091768  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.092265  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.092773  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.092790  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.092803  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.094980  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.095005  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.095091  1655 program_interpreter.cc:243] New Executor is Running.
1561: I0810 04:04:43.095103  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.095109  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.095120  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4365fad0 type is 7
1561: I0810 04:04:43.095131  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.095134  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4365ec40 type is 7
1561: I0810 04:04:43.095139  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.095141  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4365f700 type is 7
1561: I0810 04:04:43.095145  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.095149  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.095152  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.095220  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.095227  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.095232  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.095234  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: W0810 04:04:43.095842  1655 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1561: I0810 04:04:43.096129  1655 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1561: W0810 04:04:43.097081  1655 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1561: I0810 04:04:43.097323  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.097350  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.097504  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.097513  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.097532  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.097755  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.097780  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.097800  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.097810  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43adf1c0Variable Type 7
1561: I0810 04:04:43.097832  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.097855  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.097904  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.097924  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.098313  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.098366  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.098438  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.098448  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.098464  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.098470  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4365eee0Variable Type 7
1561: I0810 04:04:43.098484  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.098497  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.098516  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.098529  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.098577  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.098608  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.099074  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.099108  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.099128  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.198366  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.198402  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.198472  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.198482  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.201202  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.201779  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.202309  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.202324  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.202330  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.204754  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.204869  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.204880  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.204888  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b1dc30 type is 7
1561: I0810 04:04:43.204900  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.204903  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43b1cd80 type is 7
1561: I0810 04:04:43.204908  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.204913  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43b1d800 type is 7
1561: I0810 04:04:43.204917  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.204923  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.205008  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.205015  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.205020  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.205024  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.205090  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.205108  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.205185  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.205199  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.205219  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.205487  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.205504  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.205523  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.205531  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b263d0Variable Type 7
1561: I0810 04:04:43.205551  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.205572  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.205597  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.205616  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.205910  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.205940  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.205996  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.206009  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.206027  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.206034  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b23810Variable Type 7
1561: I0810 04:04:43.206050  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.206065  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.206084  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.206100  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.206144  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.206173  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.206507  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.206547  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.206568  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.206826  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.208714  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.208735  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.208786  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.208796  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.210723  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.211293  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.211752  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.211766  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.211771  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.214052  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.214125  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.214136  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.214143  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b19a00 type is 7
1561: I0810 04:04:43.214154  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.214157  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43b18ae0 type is 7
1561: I0810 04:04:43.214164  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.214167  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43b195d0 type is 7
1561: I0810 04:04:43.214172  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.214177  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.214255  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.214262  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.214267  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.214272  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.214324  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.214339  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.214395  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.214406  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.214423  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.214560  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.214573  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.214591  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.214598  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b1a580Variable Type 7
1561: I0810 04:04:43.214614  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.214632  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.214651  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.214666  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.214877  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.214900  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.214951  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.214960  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.214978  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.214985  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b5e490Variable Type 7
1561: I0810 04:04:43.215000  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.215014  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.215034  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.215047  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.215088  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.215108  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.215444  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.215484  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.215505  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.217671  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.217859  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.217913  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: I0810 04:04:43.218761  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.218825  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.230054  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.230337  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: I0810 04:04:43.230387  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 04:04:43.236397  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43c2e120 on Place(gpu:0)
1561: I0810 04:04:43.236441  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.236474  1655 scope.cc:202] Create variable 0x43c2e1201723262683236425530_inner_var_1
1561: I0810 04:04:43.236485  1655 scope.cc:202] Create variable 0x43c2e1201723262683236425530_inner_var_2
1561: I0810 04:04:43.236496  1655 scope.cc:202] Create variable 0x43c2e1201723262683236425530_inner_var_3
1561: I0810 04:04:43.236505  1655 scope.cc:202] Create variable 0x43c2e1201723262683236425530_inner_var_4
1561: I0810 04:04:43.236514  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.236523  1655 scope.cc:202] Create variable 0x43c2e1201723262683236425530_inner_var_6
1561: I0810 04:04:43.236532  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.237012  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.237030  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.237035  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: I0810 04:04:43.237088  1655 pir_interpreter.cc:1455] New Executor is Running ...
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43c2e040
1561: 1 -> 0x43c2e1201723262683236425530_inner_var_1 -> 0x43c2e100
1561: 2 -> 0x43c2e1201723262683236425530_inner_var_2 -> 0x43c2c3b0
1561: 3 -> 0x43c2e1201723262683236425530_inner_var_3 -> 0x43c2b7c0
1561: 4 -> 0x43c2e1201723262683236425530_inner_var_4 -> 0x43c2eb30
1561: 5 -> fetch0@fetch -> 0x43c2efa0
1561: 6 -> 0x43c2e1201723262683236425530_inner_var_6 -> 0x43c2eb50
1561: 7 -> fetch1@fetch -> 0x43c2f710
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.237918  1655 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1561: I0810 04:04:43.238142  1693 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.238279  1694 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.238344  1695 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.238409  1696 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.238479  1697 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.238554  1698 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.238606  1698 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.238669  1698 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.238721  1698 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683236425530_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43c2e1201723262683236425530_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.238855  1698 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683236425530_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x43c2e1201723262683236425530_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.238922  1697 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683236425530_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.238932  1696 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683236425530_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.238963  1697 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.238972  1696 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.239042  1697 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683236425530_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.239356  1696 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683236425530_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683236425530_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.239368  1697 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683236425530_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.239393  1697 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.239388  1696 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683236425530_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.239405  1696 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.239413  1697 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683236425530_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.239552  1696 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683236425530_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.239586  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43c2e290) got event_name: TaskCompletion
1561: I0810 04:04:43.239614  1655 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.239691  1655 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.242718  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.242923  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: I0810 04:04:43.242969  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.245605  1693 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 615073227748800691 to 12789917996542635335 , after update, data is {current : 196596, peak : 393216}.
1561: I0810 04:04:43.245623  1693 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 615073227748800691 to 11914039533111944516 , after update, data is {current : 0, peak : 196620}.
1561: I0810 04:04:43.245779  1696 thread_data_registry.h:135] Add data {current : 196596, peak : 393216} from thread 12789917996542635335 to 9879652894666900113 , after update, data is {current : 196620, peak : 393216}.
1561: I0810 04:04:43.245851  1697 thread_data_registry.h:135] Add data {current : 196620, peak : 393216} from thread 9879652894666900113 to 7168305081591625432 , after update, data is {current : 393240, peak : 393240}.
1561: I0810 04:04:43.245966  1698 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 11914039533111944516 to 7168305081591625432 , after update, data is {current : 589836, peak : 786444}.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 04:04:43.246992  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43647c50 on Place(gpu:0)
1561: I0810 04:04:43.247023  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.247042  1655 scope.cc:202] Create variable 0x43647c501723262683247016219_inner_var_1
1561: I0810 04:04:43.247053  1655 scope.cc:202] Create variable 0x43647c501723262683247016219_inner_var_2
1561: I0810 04:04:43.247061  1655 scope.cc:202] Create variable 0x43647c501723262683247016219_inner_var_3
1561: I0810 04:04:43.247072  1655 scope.cc:202] Create variable 0x43647c501723262683247016219_inner_var_4
1561: I0810 04:04:43.247080  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.247092  1655 scope.cc:202] Create variable 0x43647c501723262683247016219_inner_var_6
1561: I0810 04:04:43.247102  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.247468  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.247485  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.247489  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x436465b0
1561: 1 -> 0x43647c501723262683247016219_inner_var_1 -> 0x43c03ca0
1561: 2 -> 0x43647c501723262683247016219_inner_var_2 -> 0x43c2f6f0
1561: 3 -> 0x43647c501723262683247016219_inner_var_3 -> 0x43b125a0
1561: 4 -> 0x43647c501723262683247016219_inner_var_4 -> 0x43b1d650
1561: 5 -> fetch0@fetch -> 0x43c2ef80
1561: 6 -> 0x43647c501723262683247016219_inner_var_6 -> 0x43adf050
1561: 7 -> fetch1@fetch -> 0x43d03300
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.248162  1699 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.248239  1700 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.248272  1701 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.248345  1702 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.248392  1703 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.248440  1704 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.248464  1704 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.248495  1704 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.248524  1704 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43647c501723262683247016219_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43647c501723262683247016219_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.248615  1704 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43647c501723262683247016219_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x43647c501723262683247016219_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.248672  1702 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43647c501723262683247016219_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.248696  1702 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.248683  1703 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43647c501723262683247016219_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.248723  1703 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.249032  1702 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43647c501723262683247016219_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.249068  1703 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43647c501723262683247016219_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43647c501723262683247016219_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.249078  1702 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43647c501723262683247016219_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.249094  1702 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.249097  1703 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43647c501723262683247016219_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.249114  1703 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.249125  1703 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43647c501723262683247016219_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.249234  1702 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43647c501723262683247016219_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.249264  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43647dc0) got event_name: TaskCompletion
1561: I0810 04:04:43.249284  1655 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.249336  1655 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.249526  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:19
1561: I0810 04:04:43.249670  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.249687  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:20
1561: I0810 04:04:43.249702  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.250597  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.250615  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.250662  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.250670  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.252342  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.252802  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.253185  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.253197  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.253202  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.255056  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.255122  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.255133  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.255137  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cb7b50 type is 7
1561: I0810 04:04:43.255144  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.255147  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43cb6cb0 type is 7
1561: I0810 04:04:43.255151  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.255154  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cb7720 type is 7
1561: I0810 04:04:43.255158  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.255162  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.255220  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.255226  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.255229  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.255234  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.255278  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.255293  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.255360  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.255370  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.255385  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.255486  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.255497  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.255511  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.255517  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cc08f0Variable Type 7
1561: I0810 04:04:43.255532  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.255548  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.255568  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.255580  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.255787  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.255810  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.255853  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.255862  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.255877  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.255882  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cb8130Variable Type 7
1561: I0810 04:04:43.255894  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.255906  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.255923  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.255934  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.255970  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.255986  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.256208  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.256242  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.256258  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.256449  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.257586  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.257606  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.257647  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.257653  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.259187  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.259655  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.260015  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.260027  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.260031  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.261868  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.261931  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.261941  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.261945  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b9b540 type is 7
1561: I0810 04:04:43.261951  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.261955  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43b9a650 type is 7
1561: I0810 04:04:43.261958  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.261961  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43b9b110 type is 7
1561: I0810 04:04:43.261965  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.261970  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.262040  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.262046  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.262050  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.262053  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.262086  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.262097  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.262141  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.262151  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.262166  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.262255  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.262265  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.262280  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.262287  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43ba3bf0Variable Type 7
1561: I0810 04:04:43.262310  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.262323  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.262341  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.262353  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.262552  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.262571  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.262611  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.262620  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.262635  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.262641  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43ba10c0Variable Type 7
1561: I0810 04:04:43.262653  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.262665  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.262681  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.262692  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.262725  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.262743  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.262952  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.262981  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.263000  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.264806  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.264999  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: I0810 04:04:43.265043  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.265416  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.265453  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.268496  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.268518  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.268568  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.268577  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.270468  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.271026  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.271474  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.271489  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.271494  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.273713  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.273784  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.273797  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.273802  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cf3f10 type is 7
1561: I0810 04:04:43.273811  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.273815  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43cf3060 type is 7
1561: I0810 04:04:43.273820  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.273824  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cf3ae0 type is 7
1561: I0810 04:04:43.273829  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.273834  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.273903  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.273910  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.273916  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.273919  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.273960  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.273973  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.274025  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.274035  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.274052  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.274164  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.274176  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.274192  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.274200  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cfc370Variable Type 7
1561: I0810 04:04:43.274215  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.274231  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.274251  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.274266  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.274463  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.274487  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.274536  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.274546  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.274562  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.274570  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cf9af0Variable Type 7
1561: I0810 04:04:43.274585  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.274600  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.274616  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.274631  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.274670  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.274690  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.274945  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.274978  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.274999  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.275198  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.276219  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.276270  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.276285  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.276490  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.277616  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.277638  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.277688  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.277698  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.278733  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.278764  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.278811  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.278820  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.279248  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.279340  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.279788  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.280261  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.280282  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.280385  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.280401  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.283733  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.284395  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.284412  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.284417  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.287824  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.287845  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.287875  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.287885  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.287889  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43c32490 type is 7
1561: I0810 04:04:43.287897  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.287904  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43c32a90 type is 7
1561: I0810 04:04:43.287909  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.287912  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43cd4980 type is 7
1561: I0810 04:04:43.287917  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.287922  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43c33770 type is 7
1561: I0810 04:04:43.287927  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.287931  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43c33940 type is 7
1561: I0810 04:04:43.287937  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.287940  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x43cde850 type is 7
1561: I0810 04:04:43.287945  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.287950  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43cdea60 type is 7
1561: I0810 04:04:43.287954  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43c32470 type is 9
1561: I0810 04:04:43.287959  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.287966  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43cde830 type is 10
1561: I0810 04:04:43.288069  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.288076  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.288081  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.288086  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.288136  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288148  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288203  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288213  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288230  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.288398  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288414  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288429  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.288798  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288813  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288880  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.288905  1655 interpreter_util.cc:647] Standalone Executor is Used.
1561: I0810 04:04:43.288942  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288952  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.288971  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.289057  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.289069  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.289085  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.289124  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.289199  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.289211  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.289228  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.289237  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x436509c0Variable Type 7
1561: I0810 04:04:43.289252  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.289268  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.289288  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.289314  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.289508  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.289527  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.289839  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.289871  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.289901  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.292125  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.292315  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.292351  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: I0810 04:04:43.292845  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.292876  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.292964  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd89a0)  to GradNodeAccumulation (addr: 0x19437660)
1561: I0810 04:04:43.293071  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.293088  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.293284  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43cfeed0)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd89a0)
1561: I0810 04:04:43.293402  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.293412  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.293429  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.293471  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.293503  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43cfeed0
1561: I0810 04:04:43.293516  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.293555  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.293627  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.293651  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.293663  1655 backward.cc:335] Node: MeanGradNode addr:0x43cfeed0, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43cd89a0
1561: I0810 04:04:43.293669  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.293702  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd89a0
1561: I0810 04:04:43.293715  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.293728  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.293756  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.293783  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.293792  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd89a0, Found pending node: GradNodeAccumulation addr: 0x19437660
1561: I0810 04:04:43.293795  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.293812  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x19437660
1561: I0810 04:04:43.293819  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.293824  1655 accumulation_node.cc:40] Move Tensor ptr: 0x4363e460
1561: I0810 04:04:43.293828  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.293831  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1561: Warning:
1561: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1561:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1561:   return func(*args, **kwargs)
1561: I0810 04:04:43.381837  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.381857  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.381897  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.381906  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.383477  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.383932  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.384296  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.384317  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.384321  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.386127  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.386191  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.386201  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.386206  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43c4ac90 type is 7
1561: I0810 04:04:43.386211  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.386215  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43c49da0 type is 7
1561: I0810 04:04:43.386219  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.386222  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43c4a860 type is 7
1561: I0810 04:04:43.386226  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.386230  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.386288  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.386293  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.386297  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.386310  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.386345  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.386358  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.386402  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.386410  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.386425  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.386514  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.386524  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.386538  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.386544  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43c4b390Variable Type 7
1561: I0810 04:04:43.386557  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.386570  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.386587  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.386600  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.386788  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.386806  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.386847  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.386855  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.386870  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.386875  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43c4bb00Variable Type 7
1561: I0810 04:04:43.386888  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.386898  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.386914  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.386926  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.386960  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.386978  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.387183  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.387210  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.387228  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.389442  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.389467  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.389515  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.389524  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.391393  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.391947  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.392379  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.392393  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.392398  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.394591  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.394665  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.394677  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.394682  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d65420 type is 7
1561: I0810 04:04:43.394692  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.394695  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43dc6550 type is 7
1561: I0810 04:04:43.394701  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.394704  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43dc6370 type is 7
1561: I0810 04:04:43.394709  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.394716  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.394785  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.394793  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.394796  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.394801  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.394841  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.394855  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.394909  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.394919  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.394937  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.395044  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.395056  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.395073  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.395081  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d6d730Variable Type 7
1561: I0810 04:04:43.395097  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.395112  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.395133  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.395148  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.395349  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.395372  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.395421  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.395432  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.395450  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.395457  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d692b0Variable Type 7
1561: I0810 04:04:43.395471  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.395485  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.395504  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.395519  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.395557  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.395577  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.395826  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.395860  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.395881  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.396085  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.397331  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.397353  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.397403  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.397413  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.399253  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.399821  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.400257  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.400271  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.400276  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.402523  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.402596  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.402607  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.402613  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x19797260 type is 7
1561: I0810 04:04:43.402622  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.402626  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x19796380 type is 7
1561: I0810 04:04:43.402631  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.402635  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19796e30 type is 7
1561: I0810 04:04:43.402640  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.402648  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.402719  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.402726  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.402731  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.402735  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.402774  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.402788  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.402841  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.402851  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.402869  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.402976  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.402987  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.403005  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.403012  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1979f850Variable Type 7
1561: I0810 04:04:43.403028  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.403043  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.403064  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.403079  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.403273  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.403295  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.403353  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.403364  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.403383  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.403389  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1979cd20Variable Type 7
1561: I0810 04:04:43.403403  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.403419  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.403437  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.403451  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.403491  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.403512  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.403760  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.403795  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.403815  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.405541  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.405735  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: I0810 04:04:43.405778  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.406137  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.406169  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.409740  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.409925  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.409968  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 04:04:43.412988  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43c2e120 on Place(gpu:0)
1561: I0810 04:04:43.413020  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.413041  1655 scope.cc:202] Create variable 0x43c2e1201723262683413012543_inner_var_1
1561: I0810 04:04:43.413053  1655 scope.cc:202] Create variable 0x43c2e1201723262683413012543_inner_var_2
1561: I0810 04:04:43.413062  1655 scope.cc:202] Create variable 0x43c2e1201723262683413012543_inner_var_3
1561: I0810 04:04:43.413071  1655 scope.cc:202] Create variable 0x43c2e1201723262683413012543_inner_var_4
1561: I0810 04:04:43.413081  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.413094  1655 scope.cc:202] Create variable 0x43c2e1201723262683413012543_inner_var_6
1561: I0810 04:04:43.413103  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.413470  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.413487  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.413491  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43cd1cf0
1561: 1 -> 0x43c2e1201723262683413012543_inner_var_1 -> 0x1979b350
1561: 2 -> 0x43c2e1201723262683413012543_inner_var_2 -> 0x43cfb8d0
1561: 3 -> 0x43c2e1201723262683413012543_inner_var_3 -> 0x43b5e340
1561: 4 -> 0x43c2e1201723262683413012543_inner_var_4 -> 0x43cf0b80
1561: 5 -> fetch0@fetch -> 0x19796e10
1561: 6 -> 0x43c2e1201723262683413012543_inner_var_6 -> 0x43cd1e60
1561: 7 -> fetch1@fetch -> 0x43ba2d00
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.414289  1705 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.414386  1706 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.414517  1708 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.414531  1707 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.414633  1709 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.414701  1710 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.414764  1710 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.414810  1710 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.414853  1710 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683413012543_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43c2e1201723262683413012543_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.414986  1710 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683413012543_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x43c2e1201723262683413012543_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.415055  1707 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683413012543_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.415053  1709 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683413012543_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.415096  1707 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.415102  1709 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.415169  1707 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683413012543_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.415496  1709 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683413012543_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c2e1201723262683413012543_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.415508  1707 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683413012543_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.415529  1707 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.415529  1709 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683413012543_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.415549  1709 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.415544  1707 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683413012543_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.415699  1709 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683413012543_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.415731  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43c2e290) got event_name: TaskCompletion
1561: I0810 04:04:43.415755  1655 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.415822  1655 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.418033  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1948bc10 for it.
1561: I0810 04:04:43.418238  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.418282  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 04:04:43.421069  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43c4ae60 on Place(gpu:0)
1561: I0810 04:04:43.421099  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.421119  1655 scope.cc:202] Create variable 0x43c4ae601723262683421093450_inner_var_1
1561: I0810 04:04:43.421130  1655 scope.cc:202] Create variable 0x43c4ae601723262683421093450_inner_var_2
1561: I0810 04:04:43.421140  1655 scope.cc:202] Create variable 0x43c4ae601723262683421093450_inner_var_3
1561: I0810 04:04:43.421149  1655 scope.cc:202] Create variable 0x43c4ae601723262683421093450_inner_var_4
1561: I0810 04:04:43.421159  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.421168  1655 scope.cc:202] Create variable 0x43c4ae601723262683421093450_inner_var_6
1561: I0810 04:04:43.421177  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.421551  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.421568  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.421572  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x197be550
1561: 1 -> 0x43c4ae601723262683421093450_inner_var_1 -> 0x197be5f0
1561: 2 -> 0x43c4ae601723262683421093450_inner_var_2 -> 0x43ba99b0
1561: 3 -> 0x43c4ae601723262683421093450_inner_var_3 -> 0x43d6dd40
1561: 4 -> 0x43c4ae601723262683421093450_inner_var_4 -> 0x43cbb6c0
1561: 5 -> fetch0@fetch -> 0x43d76e40
1561: 6 -> 0x43c4ae601723262683421093450_inner_var_6 -> 0x43cbb6e0
1561: 7 -> fetch1@fetch -> 0x43b9b420
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.422293  1711 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.422428  1712 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.422456  1713 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.422516  1714 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.422566  1715 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.422614  1716 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.422650  1716 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.422685  1716 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.422721  1716 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c4ae601723262683421093450_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43c4ae601723262683421093450_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.422816  1716 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c4ae601723262683421093450_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x43c4ae601723262683421093450_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.422880  1714 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c4ae601723262683421093450_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.422905  1714 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.422890  1715 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c4ae601723262683421093450_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.422931  1715 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.422961  1714 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c4ae601723262683421093450_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.423282  1715 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c4ae601723262683421093450_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x43c4ae601723262683421093450_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.423295  1714 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c4ae601723262683421093450_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.423317  1714 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.423321  1715 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c4ae601723262683421093450_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.423341  1715 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.423334  1714 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c4ae601723262683421093450_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 04:04:43.423491  1715 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c4ae601723262683421093450_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 04:04:43.423524  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43c4afd0) got event_name: TaskCompletion
1561: I0810 04:04:43.423544  1655 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.423589  1655 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.423734  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:45
1561: I0810 04:04:43.423813  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.423827  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:46
1561: I0810 04:04:43.423841  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.424609  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.424628  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.424671  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.424679  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.426200  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.426659  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.427018  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.427031  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.427035  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.428836  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.428894  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.428905  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.428910  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b880a0 type is 7
1561: I0810 04:04:43.428915  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.428920  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43daae60 type is 7
1561: I0810 04:04:43.428925  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.428928  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43dab8d0 type is 7
1561: I0810 04:04:43.428932  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.428936  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.428997  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.429003  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.429006  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.429009  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.429044  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.429056  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.429101  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.429109  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.429123  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.429221  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.429231  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.429246  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.429252  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d75730Variable Type 7
1561: I0810 04:04:43.429265  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.429278  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.429293  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.429316  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.429517  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.429538  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.429580  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.429589  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.429603  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.429610  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d75100Variable Type 7
1561: I0810 04:04:43.429621  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.429633  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.429651  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.429662  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.429698  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.429716  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.429930  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.429958  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.429976  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.430133  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.431190  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.431210  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.431250  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.431258  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.432771  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.433212  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.433579  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.433591  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.433595  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.435392  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.435451  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.435460  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.435465  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d7a2b0 type is 7
1561: I0810 04:04:43.435470  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.435477  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d793c0 type is 7
1561: I0810 04:04:43.435482  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.435484  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d79e80 type is 7
1561: I0810 04:04:43.435487  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.435492  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.435552  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.435559  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.435562  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.435565  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.435598  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.435609  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.435652  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.435662  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.435675  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.435762  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.435772  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.435786  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.435793  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43ce4900Variable Type 7
1561: I0810 04:04:43.435806  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.435818  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.435835  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.435847  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.436034  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.436053  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.436089  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.436098  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.436112  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.436118  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d79660Variable Type 7
1561: I0810 04:04:43.436129  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.436141  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.436157  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.436169  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.436201  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.436218  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.436429  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.436457  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.436475  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.438375  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.438562  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.438604  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.438956  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.438988  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.441942  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.441965  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.442016  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.442025  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.443189  1705 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 7594919287204944033 to 9889719130349241767 , after update, data is {current : -393240, peak : 0}.
1561: I0810 04:04:43.443203  1705 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 7594919287204944033 to 9889719130349241767 , after update, data is {current : -393240, peak : 0}.
1561: I0810 04:04:43.443323  1707 thread_data_registry.h:135] Add data {current : 24, peak : 24} from thread 14504803841791198358 to 9889719130349241767 , after update, data is {current : -393216, peak : 24}.
1561: I0810 04:04:43.443361  1709 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 1378916016597506403 to 9889719130349241767 , after update, data is {current : 0, peak : 393216}.
1561: I0810 04:04:43.443545  1710 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 15442270859874700306 to 9889719130349241767 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 04:04:43.443739  1711 thread_data_registry.h:135] Add data {current : 0, peak : 393216} from thread 9889719130349241767 to 9424786137817224901 , after update, data is {current : 24, peak : 393216}.
1561: I0810 04:04:43.443751  1711 thread_data_registry.h:135] Add data {current : -196620, peak : 196620} from thread 9889719130349241767 to 6568079011962314377 , after update, data is {current : 0, peak : 196620}.
1561: I0810 04:04:43.443908  1715 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 8786803354451484824 to 9424786137817224901 , after update, data is {current : 393240, peak : 393240}.
1561: I0810 04:04:43.443981  1714 thread_data_registry.h:135] Add data {current : 393240, peak : 393240} from thread 9424786137817224901 to 11914039533111944516 , after update, data is {current : 196620, peak : 393240}.
1561: I0810 04:04:43.444093  1716 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 6568079011962314377 to 11914039533111944516 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 04:04:43.445595  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.446152  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.446610  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.446625  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.446630  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.448904  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.448979  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.448992  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.448997  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43646330 type is 7
1561: I0810 04:04:43.449007  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.449009  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1979cce0 type is 7
1561: I0810 04:04:43.449014  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.449018  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19796360 type is 7
1561: I0810 04:04:43.449023  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.449028  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.449106  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.449112  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.449117  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.449122  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.449162  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.449177  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.449229  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.449239  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.449255  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.449380  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.449393  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.449411  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.449419  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43dae6f0Variable Type 7
1561: I0810 04:04:43.449434  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.449451  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.449471  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.449486  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.449682  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.449704  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.449753  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.449764  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.449781  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.449788  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43642530Variable Type 7
1561: I0810 04:04:43.449802  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.449817  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.449836  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.449851  1655 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.449889  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.449910  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.450165  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.450198  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.450219  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.450436  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.451046  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.451079  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.451093  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.451215  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.452244  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.452267  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.452327  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.452337  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.453107  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.453128  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.453168  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.453177  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.453532  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.453598  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.453965  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.454061  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.454072  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.454154  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.454162  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.456624  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.457237  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.457252  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.457257  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.460616  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.460634  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.460665  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.460675  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.460680  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43db5c90 type is 7
1561: I0810 04:04:43.460687  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.460696  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43db5e10 type is 7
1561: I0810 04:04:43.460701  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.460705  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43db5760 type is 7
1561: I0810 04:04:43.460711  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.460714  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43db6b50 type is 7
1561: I0810 04:04:43.460719  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.460722  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43db6d70 type is 7
1561: I0810 04:04:43.460727  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.460731  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x43db6fb0 type is 7
1561: I0810 04:04:43.460736  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.460740  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43db7210 type is 7
1561: I0810 04:04:43.460745  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43db5780 type is 9
1561: I0810 04:04:43.460750  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.460754  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43db6f90 type is 10
1561: I0810 04:04:43.460856  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.460863  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.460868  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.460872  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.460920  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.460934  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.460994  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461004  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461022  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.461158  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461171  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461187  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.461373  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461387  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461426  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.461465  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461475  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461494  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.461570  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461581  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.461597  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.462055  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.462144  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.462157  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.462177  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.462184  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x197a58f0Variable Type 7
1561: I0810 04:04:43.462201  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.462218  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.462240  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.462256  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.462461  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.462481  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.463080  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.463116  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.463146  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.464738  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.464937  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.464979  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.465570  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.465607  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.466001  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd4020)  to GradNodeAccumulation (addr: 0x43f6d020)
1561: I0810 04:04:43.466106  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.466131  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.466291  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43cfeed0)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd4020)
1561: I0810 04:04:43.466382  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.466389  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.466399  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.466436  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.466464  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43cfeed0
1561: I0810 04:04:43.466472  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.466498  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.466540  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.466562  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.466570  1655 backward.cc:335] Node: MeanGradNode addr:0x43cfeed0, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43cd4020
1561: I0810 04:04:43.466576  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.466601  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd4020
1561: I0810 04:04:43.466609  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.466621  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.466645  1655 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.466676  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.466683  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd4020, Found pending node: GradNodeAccumulation addr: 0x43f6d020
1561: I0810 04:04:43.466688  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.466703  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x43f6d020
1561: I0810 04:04:43.466710  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.466714  1655 accumulation_node.cc:40] Move Tensor ptr: 0x43dadc10
1561: I0810 04:04:43.466718  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.466722  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.469604  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.469630  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.469679  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.469689  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.471524  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.472082  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.472532  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.472548  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.472553  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.474762  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.474831  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.474843  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.474848  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d551e0 type is 7
1561: I0810 04:04:43.474857  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.474861  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d542f0 type is 7
1561: I0810 04:04:43.474866  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.474869  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d54db0 type is 7
1561: I0810 04:04:43.474874  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.474880  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.474953  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.474960  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.474964  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.474968  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.475008  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.475021  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.475075  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.475085  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.475102  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.475246  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.475260  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.475276  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.475283  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d5dbf0Variable Type 7
1561: I0810 04:04:43.475308  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.475325  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.475347  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.475363  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.475433  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.475455  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.475500  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.475510  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.475528  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.475534  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d54590Variable Type 7
1561: I0810 04:04:43.475548  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.475561  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.475580  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.475594  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.475630  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.475651  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.475898  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.475931  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.475952  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.477687  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.477711  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.477761  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.477770  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.479573  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.480120  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.480552  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.480567  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.480571  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.482758  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.482831  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.482843  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.482849  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e22320 type is 7
1561: I0810 04:04:43.482859  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.482862  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e21470 type is 7
1561: I0810 04:04:43.482867  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.482872  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e21ef0 type is 7
1561: I0810 04:04:43.482877  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.482882  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.482952  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.482959  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.482964  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.482968  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.483007  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.483021  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.483073  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.483084  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.483101  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.483258  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.483270  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.483287  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.483294  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196d3a50Variable Type 7
1561: I0810 04:04:43.483320  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.483336  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.483358  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.483373  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.483443  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.483464  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.483515  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.483525  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.483542  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.483549  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e226e0Variable Type 7
1561: I0810 04:04:43.483563  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.483577  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.483595  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.483609  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.483644  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.483664  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.483911  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.483943  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.483964  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.484162  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.486495  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.486518  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.486572  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.486582  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.488418  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.488983  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.489455  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.489470  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.489475  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.491751  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.491827  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.491839  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.491844  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cc0db0 type is 7
1561: I0810 04:04:43.491854  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.491858  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43c497e0 type is 7
1561: I0810 04:04:43.491863  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.491866  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43bac3d0 type is 7
1561: I0810 04:04:43.491871  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.491878  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.491955  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.491962  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.491966  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.491971  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.492010  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.492024  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.492077  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.492087  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.492105  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.492223  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.492236  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.492254  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.492261  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d714c0Variable Type 7
1561: I0810 04:04:43.492276  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.492292  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.492323  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.492339  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.492410  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.492431  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.492480  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.492491  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.492507  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.492516  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x197bda50Variable Type 7
1561: I0810 04:04:43.492529  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.492542  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.492561  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.492575  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.492611  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.492632  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.492883  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.492918  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.492939  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.494168  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.494328  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.494370  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.494724  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.494755  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.496696  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.496843  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.496886  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 04:04:43.499704  1655 pir_interpreter.cc:161] PirInterpreter(): 0x197a53d0 on Place(gpu:0)
1561: I0810 04:04:43.499735  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.499754  1655 scope.cc:202] Create variable 0x197a53d01723262683499728200_inner_var_1
1561: I0810 04:04:43.499765  1655 scope.cc:202] Create variable 0x197a53d01723262683499728200_inner_var_2
1561: I0810 04:04:43.499775  1655 scope.cc:202] Create variable 0x197a53d01723262683499728200_inner_var_3
1561: I0810 04:04:43.499784  1655 scope.cc:202] Create variable 0x197a53d01723262683499728200_inner_var_4
1561: I0810 04:04:43.499795  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.499804  1655 scope.cc:202] Create variable 0x197a53d01723262683499728200_inner_var_6
1561: I0810 04:04:43.499814  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.500126  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.500141  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.500144  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x197c1130
1561: 1 -> 0x197a53d01723262683499728200_inner_var_1 -> 0x197c1190
1561: 2 -> 0x197a53d01723262683499728200_inner_var_2 -> 0x43d6fa00
1561: 3 -> 0x197a53d01723262683499728200_inner_var_3 -> 0x43ba1270
1561: 4 -> 0x197a53d01723262683499728200_inner_var_4 -> 0x43b87590
1561: 5 -> fetch0@fetch -> 0x43d55940
1561: 6 -> 0x197a53d01723262683499728200_inner_var_6 -> 0x43b875b0
1561: 7 -> fetch1@fetch -> 0x43b97f80
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.500838  1717 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.500905  1718 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.500931  1719 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.500962  1720 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.501000  1721 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.501037  1722 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.501070  1722 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.501106  1722 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.501140  1722 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x197a53d01723262683499728200_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_3:[dtype=;place=;dim=;lod={};, 0x197a53d01723262683499728200_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.501281  1722 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x197a53d01723262683499728200_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x197a53d01723262683499728200_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.501343  1721 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x197a53d01723262683499728200_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.501367  1721 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.501350  1720 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x197a53d01723262683499728200_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.501384  1720 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.501426  1721 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x197a53d01723262683499728200_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.501487  1720 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x197a53d01723262683499728200_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x197a53d01723262683499728200_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.501492  1721 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x197a53d01723262683499728200_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.501518  1721 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.501528  1721 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x197a53d01723262683499728200_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.501559  1720 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x197a53d01723262683499728200_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.501576  1720 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.501600  1720 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x197a53d01723262683499728200_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.501632  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x197a5540) got event_name: TaskCompletion
1561: I0810 04:04:43.501657  1655 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.501691  1655 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.503091  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.503259  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.503312  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 04:04:43.506089  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43d603d0 on Place(gpu:0)
1561: I0810 04:04:43.506120  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.506139  1655 scope.cc:202] Create variable 0x43d603d01723262683506113785_inner_var_1
1561: I0810 04:04:43.506151  1655 scope.cc:202] Create variable 0x43d603d01723262683506113785_inner_var_2
1561: I0810 04:04:43.506161  1655 scope.cc:202] Create variable 0x43d603d01723262683506113785_inner_var_3
1561: I0810 04:04:43.506170  1655 scope.cc:202] Create variable 0x43d603d01723262683506113785_inner_var_4
1561: I0810 04:04:43.506181  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.506193  1655 scope.cc:202] Create variable 0x43d603d01723262683506113785_inner_var_6
1561: I0810 04:04:43.506202  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.506525  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.506541  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.506544  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43ba16a0
1561: 1 -> 0x43d603d01723262683506113785_inner_var_1 -> 0x43ba1700
1561: 2 -> 0x43d603d01723262683506113785_inner_var_2 -> 0x196d46c0
1561: 3 -> 0x43d603d01723262683506113785_inner_var_3 -> 0x43d6b270
1561: 4 -> 0x43d603d01723262683506113785_inner_var_4 -> 0x43ba1890
1561: 5 -> fetch0@fetch -> 0x196f7980
1561: 6 -> 0x43d603d01723262683506113785_inner_var_6 -> 0x43ba18b0
1561: 7 -> fetch1@fetch -> 0x19797510
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.507210  1723 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.507287  1724 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.507334  1725 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.507375  1726 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.507429  1727 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.507452  1728 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.507474  1728 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.507498  1728 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.507520  1728 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43d603d01723262683506113785_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43d603d01723262683506113785_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.507616  1728 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43d603d01723262683506113785_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x43d603d01723262683506113785_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.507673  1726 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d603d01723262683506113785_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.507673  1727 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d603d01723262683506113785_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.507694  1726 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.507710  1727 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.507778  1726 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d603d01723262683506113785_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.507818  1726 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43d603d01723262683506113785_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.507817  1727 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d603d01723262683506113785_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43d603d01723262683506113785_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.507838  1726 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.507853  1727 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43d603d01723262683506113785_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.507853  1726 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43d603d01723262683506113785_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.507876  1727 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.507889  1727 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43d603d01723262683506113785_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.507920  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43d60540) got event_name: TaskCompletion
1561: I0810 04:04:43.507946  1655 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.507977  1655 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.508121  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:71
1561: I0810 04:04:43.508203  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.508220  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:72
1561: I0810 04:04:43.508239  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.509158  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.509181  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.509230  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.509239  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.511058  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.511611  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.512049  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.512063  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.512068  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.514273  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.514364  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.514376  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.514382  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x197a4740 type is 7
1561: I0810 04:04:43.514392  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.514396  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x197a38a0 type is 7
1561: I0810 04:04:43.514401  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.514410  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x197a4310 type is 7
1561: I0810 04:04:43.514415  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.514420  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.514492  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.514499  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.514503  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.514508  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.514549  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.514564  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.514619  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.514629  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.514647  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.514779  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.514793  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.514811  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.514820  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19794930Variable Type 7
1561: I0810 04:04:43.514835  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.514853  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.514874  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.514890  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.514963  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.514986  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.515036  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.515048  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.515065  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.515074  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cc8b20Variable Type 7
1561: I0810 04:04:43.515089  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.515102  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.515121  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.515136  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.515172  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.515193  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.515460  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.515496  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.515518  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.515719  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.516997  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.517020  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.517071  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.517081  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.518395  1717 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 6568079011962314377 to 11634441079075813374 , after update, data is {current : -60160, peak : 0}.
1561: I0810 04:04:43.518414  1717 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 6568079011962314377 to 11634441079075813374 , after update, data is {current : -60160, peak : 0}.
1561: I0810 04:04:43.518626  1721 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 5971604529379543263 to 11634441079075813374 , after update, data is {current : -60000, peak : 160}.
1561: I0810 04:04:43.518702  1720 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 7594919287204944033 to 11634441079075813374 , after update, data is {current : 0, peak : 60000}.
1561: I0810 04:04:43.518834  1722 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 14504803841791198358 to 11634441079075813374 , after update, data is {current : -30080, peak : 30080}.
1561: I0810 04:04:43.519014  1723 thread_data_registry.h:135] Add data {current : 0, peak : 60000} from thread 11634441079075813374 to 11914039533111944516 , after update, data is {current : 196620, peak : 393240}.
1561: I0810 04:04:43.519023  1723 thread_data_registry.h:135] Add data {current : -30080, peak : 30080} from thread 11634441079075813374 to 1378916016597506403 , after update, data is {current : 0, peak : 30080}.
1561: I0810 04:04:43.519189  1726 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 85003864348931170 to 11914039533111944516 , after update, data is {current : 256620, peak : 393240}.
1561: I0810 04:04:43.519232  1727 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 7169957454842235876 to 11914039533111944516 , after update, data is {current : 256780, peak : 393240}.
1561: I0810 04:04:43.519388  1728 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 1378916016597506403 to 11914039533111944516 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 04:04:43.520650  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.521220  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.521694  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.521710  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.521714  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.524017  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.524096  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.524107  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.524113  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43dbf900 type is 7
1561: I0810 04:04:43.524123  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.524127  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43db6f70 type is 7
1561: I0810 04:04:43.524133  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.524140  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d79e60 type is 7
1561: I0810 04:04:43.524145  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.524152  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.524231  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.524238  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.524243  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.524248  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.524287  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.524312  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.524369  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.524379  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.524397  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.524520  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.524534  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.524552  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.524560  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b87420Variable Type 7
1561: I0810 04:04:43.524576  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.524592  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.524613  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.524628  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.524700  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.524724  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.524771  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.524782  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.524801  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.524807  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43629c60Variable Type 7
1561: I0810 04:04:43.524821  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.524837  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.524855  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.524869  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.524906  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.524928  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.525179  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.525214  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.525235  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.526496  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.526649  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.526691  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.527045  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.527078  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.529520  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.529542  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.529595  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.529605  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.531450  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.532007  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.532456  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.532471  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.532476  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.534693  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.534768  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.534780  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.534785  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x19700810 type is 7
1561: I0810 04:04:43.534795  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.534798  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e06da0 type is 7
1561: I0810 04:04:43.534804  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.534808  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x197003e0 type is 7
1561: I0810 04:04:43.534814  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.534821  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.534896  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.534904  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.534909  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.534914  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.534953  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.534966  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.535020  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.535030  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.535048  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.535172  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.535185  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.535203  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.535212  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d5c7a0Variable Type 7
1561: I0810 04:04:43.535228  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.535244  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.535265  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.535281  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.535363  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.535387  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.535435  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.535446  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.535465  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.535472  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43dbe0c0Variable Type 7
1561: I0810 04:04:43.535486  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.535501  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.535521  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.535535  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.535573  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.535593  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.535848  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.535882  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.535904  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.536103  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.536598  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.536630  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.536644  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.536765  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.537740  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.537763  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.537812  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.537822  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.538558  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.538578  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.538616  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.538625  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.538949  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.539012  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.539383  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.539476  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.539486  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.539566  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.539577  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.541993  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.542608  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.542625  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.542630  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.545924  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.545945  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.545976  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.545986  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.545991  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43dfe220 type is 7
1561: I0810 04:04:43.546002  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.546006  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43dfe3a0 type is 7
1561: I0810 04:04:43.546016  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.546020  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43dfdcf0 type is 7
1561: I0810 04:04:43.546025  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.546028  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43dff0e0 type is 7
1561: I0810 04:04:43.546034  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.546038  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43dff300 type is 7
1561: I0810 04:04:43.546044  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.546049  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x43dff540 type is 7
1561: I0810 04:04:43.546056  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.546059  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43dff7a0 type is 7
1561: I0810 04:04:43.546065  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43dfdd10 type is 9
1561: I0810 04:04:43.546072  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.546078  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43dff520 type is 10
1561: I0810 04:04:43.546180  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.546187  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.546192  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.546197  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.546245  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546259  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546322  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546334  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546352  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.546499  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546512  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546528  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.546720  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546733  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546769  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.546808  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546818  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546837  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.546917  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546929  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.546945  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.546981  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.547044  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.547056  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.547073  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.547082  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196d8db0Variable Type 7
1561: I0810 04:04:43.547099  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.547116  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.547137  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.547151  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.547215  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.547233  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.547544  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.547575  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.547606  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.548672  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.548827  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.548868  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.549458  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.549494  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.549592  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x429ef8c0)  to GradNodeAccumulation (addr: 0x43f6d020)
1561: I0810 04:04:43.549674  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.549695  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.549842  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43cfeed0)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x429ef8c0)
1561: I0810 04:04:43.549918  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.549926  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.549934  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.549968  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.549995  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43cfeed0
1561: I0810 04:04:43.550004  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.550027  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.550071  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.550092  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.550101  1655 backward.cc:335] Node: MeanGradNode addr:0x43cfeed0, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x429ef8c0
1561: I0810 04:04:43.550107  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.550132  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x429ef8c0
1561: I0810 04:04:43.550139  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.550153  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.550179  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.550209  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.550216  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x429ef8c0, Found pending node: GradNodeAccumulation addr: 0x43f6d020
1561: I0810 04:04:43.550221  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.550242  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x43f6d020
1561: I0810 04:04:43.550251  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.550254  1655 accumulation_node.cc:40] Move Tensor ptr: 0x4363e610
1561: I0810 04:04:43.550258  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.550263  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.562495  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.562515  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.562556  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.562563  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.564025  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.564482  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.564834  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.564846  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.564850  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.566627  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.566694  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.566704  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.566707  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d411b0 type is 7
1561: I0810 04:04:43.566713  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.566720  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d402c0 type is 7
1561: I0810 04:04:43.566725  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.566727  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d40d80 type is 7
1561: I0810 04:04:43.566732  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.566736  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.566794  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.566800  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.566804  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.566807  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.566840  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.566852  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.566896  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.566905  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.566919  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.567019  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.567031  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.567045  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.567051  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196ed7e0Variable Type 7
1561: I0810 04:04:43.567065  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.567077  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.567095  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.567108  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.567171  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.567190  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.567230  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.567239  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.567253  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.567260  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d420e0Variable Type 7
1561: I0810 04:04:43.567271  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.567283  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.567306  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.567319  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.567353  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.567370  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.567572  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.567600  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.567618  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.573920  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.573940  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.573988  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.573997  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.575695  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.576139  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.576514  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.576527  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.576531  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.578351  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.578430  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.578440  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.578445  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d43a60 type is 7
1561: I0810 04:04:43.578452  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.578457  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e01af0 type is 7
1561: I0810 04:04:43.578461  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.578465  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x196e9010 type is 7
1561: I0810 04:04:43.578470  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.578474  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.578536  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.578542  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.578547  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.578549  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.578584  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.578595  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.578639  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.578648  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.578662  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.578809  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.578820  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.578835  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.578842  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cc6a10Variable Type 7
1561: I0810 04:04:43.578855  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.578869  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.578887  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.578899  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.578969  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.578987  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.579028  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.579037  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.579051  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.579058  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d7d250Variable Type 7
1561: I0810 04:04:43.579069  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.579082  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.579098  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.579110  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.579144  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.579161  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.579375  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.579406  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.579424  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.579593  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.580610  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.580631  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.580672  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.580678  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.582146  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.582610  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.582976  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.582989  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.582993  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.584825  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.584890  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.584900  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.584905  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43c3efe0 type is 7
1561: I0810 04:04:43.584911  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.584916  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x197b6ab0 type is 7
1561: I0810 04:04:43.584923  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.584925  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43c3ec00 type is 7
1561: I0810 04:04:43.584930  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.584934  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.584995  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.585000  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.585004  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.585008  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.585040  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.585052  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.585095  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.585104  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.585119  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.585218  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.585229  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.585243  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.585250  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d86510Variable Type 7
1561: I0810 04:04:43.585263  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.585278  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.585294  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.585314  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.585381  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.585398  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.585438  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.585448  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.585464  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.585469  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cbd070Variable Type 7
1561: I0810 04:04:43.585481  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.585492  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.585510  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.585520  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.585557  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.585574  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.585776  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.585803  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.585820  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.587008  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.587162  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.587210  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.587579  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.587612  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.589577  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.589728  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.589771  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 04:04:43.592550  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43e09280 on Place(gpu:0)
1561: I0810 04:04:43.592581  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.592599  1655 scope.cc:202] Create variable 0x43e092801723262683592574294_inner_var_1
1561: I0810 04:04:43.592612  1655 scope.cc:202] Create variable 0x43e092801723262683592574294_inner_var_2
1561: I0810 04:04:43.592622  1655 scope.cc:202] Create variable 0x43e092801723262683592574294_inner_var_3
1561: I0810 04:04:43.592635  1655 scope.cc:202] Create variable 0x43e092801723262683592574294_inner_var_4
1561: I0810 04:04:43.592646  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.592658  1655 scope.cc:202] Create variable 0x43e092801723262683592574294_inner_var_6
1561: I0810 04:04:43.592669  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.592979  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.592994  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.592998  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43c3e880
1561: 1 -> 0x43e092801723262683592574294_inner_var_1 -> 0x43d5bcd0
1561: 2 -> 0x43e092801723262683592574294_inner_var_2 -> 0x43c3fd70
1561: 3 -> 0x43e092801723262683592574294_inner_var_3 -> 0x43b838b0
1561: 4 -> 0x43e092801723262683592574294_inner_var_4 -> 0x43d6c240
1561: 5 -> fetch0@fetch -> 0x43d6c710
1561: 6 -> 0x43e092801723262683592574294_inner_var_6 -> 0x43d6c260
1561: 7 -> fetch1@fetch -> 0x196de520
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.593669  1729 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.593742  1730 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.593767  1731 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.593811  1732 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.593838  1733 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.593883  1734 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.593900  1734 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.593927  1734 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.593955  1734 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43e092801723262683592574294_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43e092801723262683592574294_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.594082  1734 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43e092801723262683592574294_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x43e092801723262683592574294_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.594139  1733 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e092801723262683592574294_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.594142  1732 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e092801723262683592574294_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.594164  1733 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.594167  1732 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.594275  1732 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e092801723262683592574294_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.594319  1733 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e092801723262683592574294_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43e092801723262683592574294_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.594331  1732 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43e092801723262683592574294_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.594347  1732 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.594344  1733 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43e092801723262683592574294_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.594362  1733 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.594364  1732 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43e092801723262683592574294_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.594369  1733 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43e092801723262683592574294_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.594399  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43e093f0) got event_name: TaskCompletion
1561: I0810 04:04:43.594424  1655 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.594456  1655 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.595839  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.596019  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.596061  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 04:04:43.598810  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43cbc5e0 on Place(gpu:0)
1561: I0810 04:04:43.598839  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.598858  1655 scope.cc:202] Create variable 0x43cbc5e01723262683598833716_inner_var_1
1561: I0810 04:04:43.598870  1655 scope.cc:202] Create variable 0x43cbc5e01723262683598833716_inner_var_2
1561: I0810 04:04:43.598881  1655 scope.cc:202] Create variable 0x43cbc5e01723262683598833716_inner_var_3
1561: I0810 04:04:43.598888  1655 scope.cc:202] Create variable 0x43cbc5e01723262683598833716_inner_var_4
1561: I0810 04:04:43.598898  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.598908  1655 scope.cc:202] Create variable 0x43cbc5e01723262683598833716_inner_var_6
1561: I0810 04:04:43.598917  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.599229  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.599246  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.599248  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43d84210
1561: 1 -> 0x43cbc5e01723262683598833716_inner_var_1 -> 0x43cbc5c0
1561: 2 -> 0x43cbc5e01723262683598833716_inner_var_2 -> 0x43d3e880
1561: 3 -> 0x43cbc5e01723262683598833716_inner_var_3 -> 0x43e08a60
1561: 4 -> 0x43cbc5e01723262683598833716_inner_var_4 -> 0x196d9ab0
1561: 5 -> fetch0@fetch -> 0x196d9f20
1561: 6 -> 0x43cbc5e01723262683598833716_inner_var_6 -> 0x196d9ad0
1561: 7 -> fetch1@fetch -> 0x197b0db0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.599920  1735 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.599997  1736 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.600034  1737 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.600067  1738 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.600102  1739 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.600140  1740 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.600158  1740 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.600179  1740 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.600204  1740 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43cbc5e01723262683598833716_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43cbc5e01723262683598833716_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.600329  1740 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43cbc5e01723262683598833716_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x43cbc5e01723262683598833716_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.600389  1739 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43cbc5e01723262683598833716_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.600423  1739 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.600409  1738 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43cbc5e01723262683598833716_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.600457  1738 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.600533  1739 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43cbc5e01723262683598833716_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.600579  1739 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43cbc5e01723262683598833716_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.600572  1738 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43cbc5e01723262683598833716_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43cbc5e01723262683598833716_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.600600  1739 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.600630  1738 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43cbc5e01723262683598833716_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.600638  1739 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43cbc5e01723262683598833716_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 04:04:43.600656  1738 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.600672  1738 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43cbc5e01723262683598833716_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 04:04:43.600708  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43cbc750) got event_name: TaskCompletion
1561: I0810 04:04:43.600731  1655 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.600764  1655 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.600908  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:97
1561: I0810 04:04:43.600986  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.601001  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:98
1561: I0810 04:04:43.601019  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.601953  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.601975  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.602025  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.602034  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.603420  1729 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 1378916016597506403 to 11634441079075813374 , after update, data is {current : -60160, peak : 0}.
1561: I0810 04:04:43.603430  1729 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 1378916016597506403 to 11634441079075813374 , after update, data is {current : -60160, peak : 0}.
1561: I0810 04:04:43.603708  1733 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 5971604529379543263 to 11634441079075813374 , after update, data is {current : -60000, peak : 160}.
1561: I0810 04:04:43.603781  1732 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 7594919287204944033 to 11634441079075813374 , after update, data is {current : 0, peak : 60000}.
1561: I0810 04:04:43.603910  1734 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 14504803841791198358 to 11634441079075813374 , after update, data is {current : -30080, peak : 30080}.
1561: I0810 04:04:43.604077  1735 thread_data_registry.h:135] Add data {current : 0, peak : 60000} from thread 11634441079075813374 to 9424786137817224901 , after update, data is {current : 160, peak : 60000}.
1561: I0810 04:04:43.604090  1735 thread_data_registry.h:135] Add data {current : -30080, peak : 30080} from thread 11634441079075813374 to 6568079011962314377 , after update, data is {current : 0, peak : 30080}.
1561: I0810 04:04:43.604269  1738 thread_data_registry.h:135] Add data {current : 160, peak : 60000} from thread 9424786137817224901 to 8786803354451484824 , after update, data is {current : 60160, peak : 60160}.
1561: I0810 04:04:43.604359  1739 thread_data_registry.h:135] Add data {current : 60160, peak : 60160} from thread 8786803354451484824 to 11914039533111944516 , after update, data is {current : 316940, peak : 393240}.
1561: I0810 04:04:43.604466  1740 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 6568079011962314377 to 11914039533111944516 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 04:04:43.605600  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.606163  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.606637  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.606653  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.606658  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.609035  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.609114  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.609127  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.609133  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43db4f00 type is 7
1561: I0810 04:04:43.609141  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.609145  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x197b5300 type is 7
1561: I0810 04:04:43.609150  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.609154  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cd2300 type is 7
1561: I0810 04:04:43.609159  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.609164  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.609244  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.609251  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.609256  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.609261  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.609310  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.609325  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.609378  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.609388  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.609406  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.609542  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.609556  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.609575  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.609582  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x436383a0Variable Type 7
1561: I0810 04:04:43.609597  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.609614  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.609635  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.609651  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.609722  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.609745  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.609793  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.609804  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.609822  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.609831  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43638320Variable Type 7
1561: I0810 04:04:43.609844  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.609858  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.609879  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.609892  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.609930  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.609951  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.610201  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.610235  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.610256  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.610486  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.611773  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.611796  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.611846  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.611855  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.613678  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.614228  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.614688  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.614704  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.614709  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.616981  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.617060  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.617072  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.617079  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cc9ce0 type is 7
1561: I0810 04:04:43.617087  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.617091  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43ba87c0 type is 7
1561: I0810 04:04:43.617096  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.617100  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d59f30 type is 7
1561: I0810 04:04:43.617105  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.617110  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.617187  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.617193  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.617198  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.617202  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.617242  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.617255  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.617319  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.617331  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.617348  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.617470  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.617483  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.617501  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.617508  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d571e0Variable Type 7
1561: I0810 04:04:43.617523  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.617540  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.617560  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.617576  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.617645  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.617666  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.617714  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.617724  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.617741  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.617748  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196e9e60Variable Type 7
1561: I0810 04:04:43.617762  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.617776  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.617794  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.617808  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.617846  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.617866  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.618115  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.618155  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.618177  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.619410  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.619561  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.619606  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.619956  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.619988  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.622360  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.622383  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.622432  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.622442  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.624264  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.624831  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.625263  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.625277  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.625283  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.627485  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.627558  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.627570  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.627575  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x19799060 type is 7
1561: I0810 04:04:43.627584  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.627588  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x19798180 type is 7
1561: I0810 04:04:43.627593  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.627597  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19798c30 type is 7
1561: I0810 04:04:43.627602  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.627607  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.627677  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.627684  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.627688  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.627693  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.627732  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.627746  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.627799  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.627808  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.627826  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.627947  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.627960  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.627979  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.627985  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d389a0Variable Type 7
1561: I0810 04:04:43.628000  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.628016  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.628037  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.628053  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.628123  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.628145  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.628191  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.628201  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.628219  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.628226  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x197995c0Variable Type 7
1561: I0810 04:04:43.628239  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.628253  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.628273  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.628286  1655 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.628335  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.628357  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.628608  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.628643  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.628664  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.628860  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.629357  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.629390  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.629402  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.629529  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.630511  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.630533  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.630584  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.630592  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.631323  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.631343  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.631382  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.631390  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.631712  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.631778  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.632138  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.632232  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.632241  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.632334  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.632345  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.634779  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.635388  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.635404  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.635409  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.638684  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.638703  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.638733  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.638743  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.638748  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43f91cb0 type is 7
1561: I0810 04:04:43.638756  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.638762  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43f92250 type is 7
1561: I0810 04:04:43.638767  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.638772  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43f91ba0 type is 7
1561: I0810 04:04:43.638777  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.638782  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43f92f30 type is 7
1561: I0810 04:04:43.638787  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.638789  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43f931a0 type is 7
1561: I0810 04:04:43.638795  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.638799  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x43f933e0 type is 7
1561: I0810 04:04:43.638804  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.638811  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43f93640 type is 7
1561: I0810 04:04:43.638816  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43e3b720 type is 9
1561: I0810 04:04:43.638821  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.638825  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43f933c0 type is 10
1561: I0810 04:04:43.638927  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.638934  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.638938  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.638943  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.638991  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639005  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639058  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639070  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639086  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.639240  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639253  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639268  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.639483  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639497  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639533  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.639573  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639583  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639601  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.639681  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639693  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639709  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.639746  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.639820  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.639832  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.639849  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.639856  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43dc7540Variable Type 7
1561: I0810 04:04:43.639873  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.639889  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.639909  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.639923  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.639988  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.640007  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.640316  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.640352  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.640386  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.641450  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43f6d020 for it.
1561: I0810 04:04:43.641605  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.641645  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.643954  1699 thread_data_registry.h:135] Add data {current : 316940, peak : 393240} from thread 11914039533111944516 to 7989780535813649305 , after update, data is {current : 316964, peak : 393240}.
1561: I0810 04:04:43.643970  1699 thread_data_registry.h:135] Add data {current : -196620, peak : 196620} from thread 11914039533111944516 to 12289716731659279983 , after update, data is {current : 0, peak : 196620}.
1561: I0810 04:04:43.644142  1703 thread_data_registry.h:135] Add data {current : 316964, peak : 393240} from thread 7989780535813649305 to 570376922093768586 , after update, data is {current : 710180, peak : 710180}.
1561: I0810 04:04:43.644212  1702 thread_data_registry.h:135] Add data {current : 710180, peak : 710180} from thread 570376922093768586 to 7168305081591625432 , after update, data is {current : 906800, peak : 1179720}.
1561: I0810 04:04:43.644367  1704 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 12289716731659279983 to 7168305081591625432 , after update, data is {current : 1872864, peak : 2555920}.
1561: I0810 04:04:43.646243  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.646278  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.646418  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43660220)  to GradNodeAccumulation (addr: 0x43f6d020)
1561: I0810 04:04:43.646498  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.646517  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.646662  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43cfeed0)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43660220)
1561: I0810 04:04:43.646728  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.646733  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.646740  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.646767  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.646788  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43cfeed0
1561: I0810 04:04:43.646795  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.646816  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.646863  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.646881  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.646888  1655 backward.cc:335] Node: MeanGradNode addr:0x43cfeed0, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43660220
1561: I0810 04:04:43.646893  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.646912  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43660220
1561: I0810 04:04:43.646919  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.646929  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.646972  1655 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.646999  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.647006  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43660220, Found pending node: GradNodeAccumulation addr: 0x43f6d020
1561: I0810 04:04:43.647009  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.647027  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x43f6d020
1561: I0810 04:04:43.647032  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.647037  1655 accumulation_node.cc:40] Move Tensor ptr: 0x43d75ad0
1561: I0810 04:04:43.647039  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.647042  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.648854  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.648877  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.648927  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.648936  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.650786  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.651350  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.651830  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.651844  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.651849  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.654158  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.654237  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.654248  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.654258  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43ba3930 type is 7
1561: I0810 04:04:43.654264  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.654270  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d43180 type is 7
1561: I0810 04:04:43.654275  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.654279  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19798160 type is 7
1561: I0810 04:04:43.654284  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.654289  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.654381  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.654387  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.654392  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.654397  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.654436  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.654450  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.654510  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.654520  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.654536  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.654740  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.654753  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.654770  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.654778  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d6b560Variable Type 7
1561: I0810 04:04:43.654794  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.654810  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.654831  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.654846  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.654896  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.654918  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.654968  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.654979  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.654996  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.655004  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43c32b20Variable Type 7
1561: I0810 04:04:43.655017  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.655031  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.655050  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.655064  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.655100  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.655120  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.655398  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.655436  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.655457  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.657095  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.657119  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.657168  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.657177  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.658985  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.659547  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.659991  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.660004  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.660009  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.662231  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.662318  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.662331  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.662336  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x196ffce0 type is 7
1561: I0810 04:04:43.662346  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.662349  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d65260 type is 7
1561: I0810 04:04:43.662354  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.662358  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cff330 type is 7
1561: I0810 04:04:43.662364  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.662371  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.662446  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.662453  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.662458  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.662462  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.662503  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.662516  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.662571  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.662582  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.662600  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.662714  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.662726  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.662743  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.662751  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d3f0f0Variable Type 7
1561: I0810 04:04:43.662766  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.662783  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.662803  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.662819  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.662866  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.662891  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.662937  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.662948  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.662964  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.662972  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43dae530Variable Type 7
1561: I0810 04:04:43.662986  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.662999  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.663018  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.663031  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.663070  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.663090  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.663355  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.663393  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.663414  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.663609  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.664856  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.664880  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.664928  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.664937  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.666735  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.667290  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.667753  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.667768  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.667773  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.670018  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.670095  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.670106  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.670112  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d3ffe0 type is 7
1561: I0810 04:04:43.670121  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.670125  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43cfd7c0 type is 7
1561: I0810 04:04:43.670130  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.670135  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d3fbb0 type is 7
1561: I0810 04:04:43.670140  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.670145  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.670221  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.670228  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.670233  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.670238  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.670277  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.670290  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.670356  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.670367  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.670384  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.670497  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.670511  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.670528  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.670535  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196fee40Variable Type 7
1561: I0810 04:04:43.670550  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.670567  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.670586  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.670601  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.670650  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.670671  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.670719  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.670729  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.670747  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.670754  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cca570Variable Type 7
1561: I0810 04:04:43.670768  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.670782  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.670801  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.670814  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.670851  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.670871  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.671120  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.671154  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.671175  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.672315  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.672458  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.672502  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.672849  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.672880  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.674723  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.674866  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.674907  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 04:04:43.678620  1655 pir_interpreter.cc:161] PirInterpreter(): 0x196e9e80 on Place(gpu:0)
1561: I0810 04:04:43.678650  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.678669  1655 scope.cc:202] Create variable 0x196e9e801723262683678643799_inner_var_1
1561: I0810 04:04:43.678680  1655 scope.cc:202] Create variable 0x196e9e801723262683678643799_inner_var_2
1561: I0810 04:04:43.678687  1655 scope.cc:202] Create variable 0x196e9e801723262683678643799_inner_var_3
1561: I0810 04:04:43.678697  1655 scope.cc:202] Create variable 0x196e9e801723262683678643799_inner_var_4
1561: I0810 04:04:43.678705  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.678738  1655 scope.cc:202] Create variable 0x196e9e801723262683678643799_inner_var_6
1561: I0810 04:04:43.678748  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.679057  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.679072  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.679076  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43633940
1561: 1 -> 0x196e9e801723262683678643799_inner_var_1 -> 0x196de500
1561: 2 -> 0x196e9e801723262683678643799_inner_var_2 -> 0x4362fab0
1561: 3 -> 0x196e9e801723262683678643799_inner_var_3 -> 0x43b13530
1561: 4 -> 0x196e9e801723262683678643799_inner_var_4 -> 0x43d41170
1561: 5 -> fetch0@fetch -> 0x43d60a10
1561: 6 -> 0x196e9e801723262683678643799_inner_var_6 -> 0x43cb7b10
1561: 7 -> fetch1@fetch -> 0x43b9b500
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.679774  1741 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.679860  1742 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.679890  1743 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.679932  1744 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.679958  1745 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.680007  1746 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.680028  1746 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.680061  1746 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.680095  1746 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x196e9e801723262683678643799_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_3:[dtype=;place=;dim=;lod={};, 0x196e9e801723262683678643799_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.680219  1746 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x196e9e801723262683678643799_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x196e9e801723262683678643799_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.680275  1744 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196e9e801723262683678643799_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.680298  1744 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.680285  1745 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196e9e801723262683678643799_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.680321  1745 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.680353  1744 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196e9e801723262683678643799_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.680380  1745 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196e9e801723262683678643799_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x196e9e801723262683678643799_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.680382  1744 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x196e9e801723262683678643799_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.680410  1744 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.680423  1744 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x196e9e801723262683678643799_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.680428  1745 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x196e9e801723262683678643799_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.680445  1745 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.680454  1745 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x196e9e801723262683678643799_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.680485  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x196e9ff0) got event_name: TaskCompletion
1561: I0810 04:04:43.680510  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.680536  1655 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.681815  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.681973  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.682015  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 04:04:43.684772  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43c2e120 on Place(gpu:0)
1561: I0810 04:04:43.684801  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.684819  1655 scope.cc:202] Create variable 0x43c2e1201723262683684795509_inner_var_1
1561: I0810 04:04:43.684830  1655 scope.cc:202] Create variable 0x43c2e1201723262683684795509_inner_var_2
1561: I0810 04:04:43.684840  1655 scope.cc:202] Create variable 0x43c2e1201723262683684795509_inner_var_3
1561: I0810 04:04:43.684849  1655 scope.cc:202] Create variable 0x43c2e1201723262683684795509_inner_var_4
1561: I0810 04:04:43.684859  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.684867  1655 scope.cc:202] Create variable 0x43c2e1201723262683684795509_inner_var_6
1561: I0810 04:04:43.684877  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.685175  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.685189  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.685194  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43cfcb30
1561: 1 -> 0x43c2e1201723262683684795509_inner_var_1 -> 0x43cfcb70
1561: 2 -> 0x43c2e1201723262683684795509_inner_var_2 -> 0x43cfcb90
1561: 3 -> 0x43c2e1201723262683684795509_inner_var_3 -> 0x43d348d0
1561: 4 -> 0x43c2e1201723262683684795509_inner_var_4 -> 0x18b7a550
1561: 5 -> fetch0@fetch -> 0x19327890
1561: 6 -> 0x43c2e1201723262683684795509_inner_var_6 -> 0x43cfde60
1561: 7 -> fetch1@fetch -> 0x43d51840
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.685878  1747 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.685956  1748 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.685995  1749 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.686031  1750 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.686061  1751 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.686103  1752 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.686120  1752 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.686144  1752 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.686168  1752 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683684795509_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43c2e1201723262683684795509_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.686264  1752 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683684795509_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x43c2e1201723262683684795509_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.686316  1750 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683684795509_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.686317  1751 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683684795509_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.686337  1750 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.686345  1751 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.686388  1750 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683684795509_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.686425  1751 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683684795509_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683684795509_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.686436  1750 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683684795509_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.686451  1750 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.686456  1751 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683684795509_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.686463  1750 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683684795509_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.686476  1751 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.686486  1751 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683684795509_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.686518  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43c2e290) got event_name: TaskCompletion
1561: I0810 04:04:43.686542  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.686568  1655 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.686705  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:123
1561: I0810 04:04:43.686774  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.686790  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:124
1561: I0810 04:04:43.686807  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.687723  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.687745  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.687794  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.687803  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.689636  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.690188  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.690652  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.690667  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.690672  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.693049  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.693128  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.693140  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.693145  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x19798fe0 type is 7
1561: I0810 04:04:43.693156  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.693159  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d5db50 type is 7
1561: I0810 04:04:43.693164  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.693168  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d83ff0 type is 7
1561: I0810 04:04:43.693173  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.693181  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.693256  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.693264  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.693267  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.693272  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.693321  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.693336  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.693390  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.693400  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.693418  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.693554  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.693567  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.693585  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.693593  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43da7600Variable Type 7
1561: I0810 04:04:43.693607  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.693624  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.693645  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.693661  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.693710  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.693733  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.693782  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.693794  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.693810  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.693817  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x436374d0Variable Type 7
1561: I0810 04:04:43.693831  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.693845  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.693864  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.693878  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.693914  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.693935  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.694192  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.694227  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.694249  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.694451  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.695760  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.695782  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.695830  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.695840  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.697659  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.698206  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.698661  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.698678  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.698683  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.700928  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.701005  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.701017  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.701022  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43daa160 type is 7
1561: I0810 04:04:43.701030  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.701033  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43da31c0 type is 7
1561: I0810 04:04:43.701038  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.701045  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43da2a90 type is 7
1561: I0810 04:04:43.701050  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.701056  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.701131  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.701138  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.701143  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.701148  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.701187  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.701200  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.701253  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.701264  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.701282  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.701406  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.701418  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.701436  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.701443  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43667450Variable Type 7
1561: I0810 04:04:43.701458  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.701474  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.701495  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.701510  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.701558  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.701581  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.701628  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.701639  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.701655  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.701663  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43ba8930Variable Type 7
1561: I0810 04:04:43.701676  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.701689  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.701709  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.701722  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.701758  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.701781  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.702031  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.702065  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.702087  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.703209  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.703366  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.703408  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.703759  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.703790  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.706012  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.706036  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.706086  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.706095  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.707883  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.708441  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.708876  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.708889  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.708894  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.711091  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.711169  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.711180  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.711186  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x196ecb30 type is 7
1561: I0810 04:04:43.711195  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.711199  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43b99210 type is 7
1561: I0810 04:04:43.711205  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.711207  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x196ec750 type is 7
1561: I0810 04:04:43.711212  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.711217  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.711292  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.711308  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.711315  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.711320  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.711360  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.711373  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.711427  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.711437  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.711454  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.711572  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.711584  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.711601  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.711609  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cc20b0Variable Type 7
1561: I0810 04:04:43.711624  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.711640  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.711661  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.711676  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.711723  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.711746  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.711794  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.711804  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.711822  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.711828  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d7f8d0Variable Type 7
1561: I0810 04:04:43.711843  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.711856  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.711875  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.711889  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.711925  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.711946  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.712198  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.712232  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.712255  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.712452  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.712930  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.712961  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.712975  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.713088  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.714053  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.714075  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.714124  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.714133  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.714854  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.714874  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.714913  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.714921  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.715240  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.715310  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.715780  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.715878  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.715888  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.715965  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.715975  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.717077  1747 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 7594919287204944033 to 11634441079075813374 , after update, data is {current : -1680, peak : 240}.
1561: I0810 04:04:43.717088  1747 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 7594919287204944033 to 9889719130349241767 , after update, data is {current : 0, peak : 1920}.
1561: I0810 04:04:43.717250  1750 thread_data_registry.h:135] Add data {current : -1680, peak : 240} from thread 11634441079075813374 to 12289716731659279983 , after update, data is {current : -3600, peak : 240}.
1561: I0810 04:04:43.717326  1751 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 15442270859874700306 to 12289716731659279983 , after update, data is {current : 0, peak : 3600}.
1561: I0810 04:04:43.717442  1752 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 9889719130349241767 to 12289716731659279983 , after update, data is {current : -1920, peak : 1920}.
1561: I0810 04:04:43.719836  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.720515  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.720531  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.720536  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.723984  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.724004  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.724035  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.724043  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.724048  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d371e0 type is 7
1561: I0810 04:04:43.724056  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.724062  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43da6f70 type is 7
1561: I0810 04:04:43.724067  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.724071  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43ccecd0 type is 7
1561: I0810 04:04:43.724076  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.724079  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43da60c0 type is 7
1561: I0810 04:04:43.724084  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.724088  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43da6290 type is 7
1561: I0810 04:04:43.724094  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.724099  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x43d40f30 type is 7
1561: I0810 04:04:43.724105  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.724108  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43d41120 type is 7
1561: I0810 04:04:43.724113  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x196ed440 type is 9
1561: I0810 04:04:43.724119  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.724123  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43d40f10 type is 10
1561: I0810 04:04:43.724231  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.724238  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.724243  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.724248  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.724298  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724321  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724375  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724385  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724402  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.724542  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724555  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724571  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.724722  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724736  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724771  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.724808  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724819  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724838  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.724916  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724928  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.724944  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.724980  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.725044  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.725054  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.725072  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.725080  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1979d470Variable Type 7
1561: I0810 04:04:43.725097  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.725113  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.725132  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.725148  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.725190  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.725208  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.725616  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.725649  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.725678  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.726678  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.726825  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.726866  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.727443  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.727478  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.727573  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd4020)  to GradNodeAccumulation (addr: 0x19437660)
1561: I0810 04:04:43.727655  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.727674  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.727792  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43cfeed0)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd4020)
1561: I0810 04:04:43.727866  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.727874  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.727880  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.727909  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.727934  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43cfeed0
1561: I0810 04:04:43.727942  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.727965  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.728011  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.728031  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.728039  1655 backward.cc:335] Node: MeanGradNode addr:0x43cfeed0, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43cd4020
1561: I0810 04:04:43.728045  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.728070  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd4020
1561: I0810 04:04:43.728077  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.728091  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.728117  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.728147  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.728153  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd4020, Found pending node: GradNodeAccumulation addr: 0x19437660
1561: I0810 04:04:43.728158  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.728179  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x19437660
1561: I0810 04:04:43.728186  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.728190  1655 accumulation_node.cc:40] Move Tensor ptr: 0x43b19640
1561: I0810 04:04:43.728194  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.728199  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.730702  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.730726  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.730774  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.730783  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.732609  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.733162  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.733626  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.733641  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.733645  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.735891  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.735968  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.735980  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.735986  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x197a1440 type is 7
1561: I0810 04:04:43.735996  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.735999  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x197a1420 type is 7
1561: I0810 04:04:43.736004  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.736008  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43626970 type is 7
1561: I0810 04:04:43.736013  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.736021  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.736097  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.736104  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.736109  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.736112  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.736152  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.736166  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.736223  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.736233  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.736251  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.736378  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.736392  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.736413  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.736419  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43643d80Variable Type 7
1561: I0810 04:04:43.736434  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.736450  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.736471  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.736486  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.736533  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.736555  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.736604  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.736614  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.736632  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.736639  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43632640Variable Type 7
1561: I0810 04:04:43.736653  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.736667  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.736685  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.736699  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.736735  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.736755  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.737007  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.737042  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.737063  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.738662  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.738684  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.738734  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.738744  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.740540  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.741087  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.741530  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.741544  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.741549  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.743757  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.743834  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.743845  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.743850  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d678e0 type is 7
1561: I0810 04:04:43.743860  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.743863  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43bab750 type is 7
1561: I0810 04:04:43.743868  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.743872  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43bab570 type is 7
1561: I0810 04:04:43.743877  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.743882  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.743958  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.743965  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.743969  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.743973  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.744014  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.744027  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.744081  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.744091  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.744107  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.744220  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.744232  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.744249  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.744257  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e420f0Variable Type 7
1561: I0810 04:04:43.744271  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.744287  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.744316  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.744333  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.744381  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.744405  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.744452  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.744463  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.744482  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.744488  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e0d740Variable Type 7
1561: I0810 04:04:43.744501  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.744515  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.744534  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.744549  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.744583  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.744603  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.744853  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.744886  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.744907  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.745095  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.746331  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.746354  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.746404  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.746413  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.748203  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.748766  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.749209  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.749223  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.749228  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.751470  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.751546  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.751559  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.751564  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x196d6fa0 type is 7
1561: I0810 04:04:43.751574  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.751577  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43b9e420 type is 7
1561: I0810 04:04:43.751582  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.751586  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43b9ef10 type is 7
1561: I0810 04:04:43.751591  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.751600  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.751673  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.751680  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.751685  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.751689  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.751729  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.751742  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.751796  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.751806  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.751822  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.751935  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.751948  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.751965  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.751972  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cf9dd0Variable Type 7
1561: I0810 04:04:43.751987  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.752003  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.752023  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.752038  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.752085  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.752106  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.752154  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.752164  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.752182  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.752189  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x197a1120Variable Type 7
1561: I0810 04:04:43.752203  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.752216  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.752235  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.752249  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.752285  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.752315  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.752568  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.752602  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.752624  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.753731  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.753875  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.753916  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.754266  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.754297  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.756811  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.756994  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.757036  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 04:04:43.760110  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43c2e120 on Place(gpu:0)
1561: I0810 04:04:43.760141  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.760159  1655 scope.cc:202] Create variable 0x43c2e1201723262683760134996_inner_var_1
1561: I0810 04:04:43.760170  1655 scope.cc:202] Create variable 0x43c2e1201723262683760134996_inner_var_2
1561: I0810 04:04:43.760181  1655 scope.cc:202] Create variable 0x43c2e1201723262683760134996_inner_var_3
1561: I0810 04:04:43.760190  1655 scope.cc:202] Create variable 0x43c2e1201723262683760134996_inner_var_4
1561: I0810 04:04:43.760200  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.760208  1655 scope.cc:202] Create variable 0x43c2e1201723262683760134996_inner_var_6
1561: I0810 04:04:43.760217  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.760528  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.760545  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.760548  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43646960
1561: 1 -> 0x43c2e1201723262683760134996_inner_var_1 -> 0x43daeb70
1561: 2 -> 0x43c2e1201723262683760134996_inner_var_2 -> 0x43d03620
1561: 3 -> 0x43c2e1201723262683760134996_inner_var_3 -> 0x43d5cc70
1561: 4 -> 0x43c2e1201723262683760134996_inner_var_4 -> 0x197ba150
1561: 5 -> fetch0@fetch -> 0x43ffda30
1561: 6 -> 0x43c2e1201723262683760134996_inner_var_6 -> 0x43d6b7a0
1561: 7 -> fetch1@fetch -> 0x43c2bb00
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.761209  1753 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.761281  1754 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.761298  1755 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.761351  1756 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.761384  1757 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.761428  1758 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.761448  1758 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.761478  1758 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.761507  1758 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683760134996_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43c2e1201723262683760134996_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.761620  1758 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683760134996_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x43c2e1201723262683760134996_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.761677  1757 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683760134996_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.761679  1756 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683760134996_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.761710  1757 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.761715  1756 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.761775  1756 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683760134996_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.761811  1757 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683760134996_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x43c2e1201723262683760134996_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.761813  1756 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683760134996_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.761839  1756 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.761850  1756 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683760134996_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.761864  1757 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683760134996_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.761881  1757 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.761891  1757 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683760134996_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.761922  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43c2e290) got event_name: TaskCompletion
1561: I0810 04:04:43.761948  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.761973  1655 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.763240  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.763411  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.763454  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 04:04:43.766180  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43d76fe0 on Place(gpu:0)
1561: I0810 04:04:43.766209  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.766227  1655 scope.cc:202] Create variable 0x43d76fe01723262683766203597_inner_var_1
1561: I0810 04:04:43.766239  1655 scope.cc:202] Create variable 0x43d76fe01723262683766203597_inner_var_2
1561: I0810 04:04:43.766249  1655 scope.cc:202] Create variable 0x43d76fe01723262683766203597_inner_var_3
1561: I0810 04:04:43.766258  1655 scope.cc:202] Create variable 0x43d76fe01723262683766203597_inner_var_4
1561: I0810 04:04:43.766268  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.766278  1655 scope.cc:202] Create variable 0x43d76fe01723262683766203597_inner_var_6
1561: I0810 04:04:43.766289  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.766599  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.766614  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.766618  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43dc7aa0
1561: 1 -> 0x43d76fe01723262683766203597_inner_var_1 -> 0x43f938b0
1561: 2 -> 0x43d76fe01723262683766203597_inner_var_2 -> 0x4983ff0
1561: 3 -> 0x43d76fe01723262683766203597_inner_var_3 -> 0x43b87330
1561: 4 -> 0x43d76fe01723262683766203597_inner_var_4 -> 0x4363a4e0
1561: 5 -> fetch0@fetch -> 0x43db9f30
1561: 6 -> 0x43d76fe01723262683766203597_inner_var_6 -> 0x43db9f10
1561: 7 -> fetch1@fetch -> 0x43e3b3c0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.767282  1759 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.767375  1760 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.767407  1761 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.767441  1762 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.767474  1763 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.767520  1764 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.767537  1764 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.767565  1764 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.767592  1764 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43d76fe01723262683766203597_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43d76fe01723262683766203597_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.767702  1764 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43d76fe01723262683766203597_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x43d76fe01723262683766203597_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.767752  1763 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683766203597_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.767755  1762 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683766203597_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.767778  1763 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.767781  1762 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.767830  1762 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683766203597_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.767864  1763 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683766203597_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683766203597_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.767867  1762 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683766203597_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.767891  1762 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.767903  1762 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683766203597_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 04:04:43.767915  1763 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683766203597_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.767932  1763 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.767946  1763 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683766203597_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.767977  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43d77150) got event_name: TaskCompletion
1561: I0810 04:04:43.768002  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.768026  1655 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.768169  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:149
1561: I0810 04:04:43.768237  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.768253  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:150
1561: I0810 04:04:43.768270  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.769191  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.769213  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.769263  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.769271  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.771090  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.775190  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.775583  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.775596  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.775600  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.777411  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.777505  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.777516  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.777521  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43dfdbf0 type is 7
1561: I0810 04:04:43.777526  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.777530  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43f98a10 type is 7
1561: I0810 04:04:43.777534  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.777537  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43dfd8c0 type is 7
1561: I0810 04:04:43.777542  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.777546  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.777609  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.777616  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.777619  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.777622  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.777655  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.777667  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.777711  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.777720  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.777734  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.777859  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.777870  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.777884  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.777890  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b9c570Variable Type 7
1561: I0810 04:04:43.777902  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.777915  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.777932  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.777945  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.777990  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.778009  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.778050  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.778059  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.778074  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.778079  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4364c100Variable Type 7
1561: I0810 04:04:43.778090  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.778102  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.778118  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.778131  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.778162  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.778178  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.778402  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.778439  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.778455  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.778609  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.779690  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.779708  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.779748  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.779757  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.781214  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.781678  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.782037  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.782049  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.782053  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.783860  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.783926  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.783936  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.783941  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cd79d0 type is 7
1561: I0810 04:04:43.783946  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.783952  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43db2f90 type is 7
1561: I0810 04:04:43.783957  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.783960  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43ba4b30 type is 7
1561: I0810 04:04:43.783964  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.783968  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.784029  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.784035  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.784039  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.784041  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.784075  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.784086  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.784129  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.784137  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.784152  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.784245  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.784256  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.784269  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.784276  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196e81a0Variable Type 7
1561: I0810 04:04:43.784288  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.784310  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.784327  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.784340  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.784382  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.784400  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.784441  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.784451  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.784464  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.784471  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cd7f80Variable Type 7
1561: I0810 04:04:43.784482  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.784493  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.784508  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.784519  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.784551  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.784567  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.784771  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.784799  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.784816  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.785892  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.786034  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.786077  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.786441  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.786473  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.788717  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.788741  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.788791  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.788800  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.790597  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.791146  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.791594  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.791608  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.791613  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.793747  1753 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 9889719130349241767 to 8786803354451484824 , after update, data is {current : 1680, peak : 3600}.
1561: I0810 04:04:43.793759  1753 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 9889719130349241767 to 6568079011962314377 , after update, data is {current : 0, peak : 1920}.
1561: I0810 04:04:43.793911  1757 thread_data_registry.h:135] Add data {current : 240, peak : 240} from thread 5971604529379543263 to 8786803354451484824 , after update, data is {current : 1920, peak : 3600}.
1561: I0810 04:04:43.793985  1756 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 7594919287204944033 to 8786803354451484824 , after update, data is {current : 5520, peak : 5520}.
1561: I0810 04:04:43.794134  1758 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 14504803841791198358 to 6568079011962314377 , after update, data is {current : 1920, peak : 1920}.
1561: I0810 04:04:43.794322  1759 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 85003864348931170 to 8786803354451484824 , after update, data is {current : 3600, peak : 5520}.
1561: I0810 04:04:43.794332  1759 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 85003864348931170 to 6568079011962314377 , after update, data is {current : 0, peak : 1920}.
1561: I0810 04:04:43.794495  1763 thread_data_registry.h:135] Add data {current : 3600, peak : 5520} from thread 8786803354451484824 to 9424786137817224901 , after update, data is {current : 3840, peak : 5520}.
1561: I0810 04:04:43.794565  1762 thread_data_registry.h:135] Add data {current : 3840, peak : 5520} from thread 9424786137817224901 to 12289716731659279983 , after update, data is {current : 3840, peak : 5520}.
1561: I0810 04:04:43.794684  1764 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 6568079011962314377 to 12289716731659279983 , after update, data is {current : -1920, peak : 1920}.
1561: I0810 04:04:43.795552  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.795632  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.795644  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.795655  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43ce6330 type is 7
1561: I0810 04:04:43.795662  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.795668  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d6afd0 type is 7
1561: I0810 04:04:43.795675  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.795678  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cfa630 type is 7
1561: I0810 04:04:43.795683  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.795692  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.795773  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.795780  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.795785  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.795789  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.795830  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.795845  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.795899  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.795909  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.795928  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.796046  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.796059  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.796077  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.796085  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4364c290Variable Type 7
1561: I0810 04:04:43.796100  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.796118  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.796137  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.796154  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.796200  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.796226  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.796274  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.796285  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.796314  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.796322  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x191412e0Variable Type 7
1561: I0810 04:04:43.796337  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.796351  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.796370  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.796386  1655 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.796424  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.796447  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.796703  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.796736  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.796757  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.796954  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.797452  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.797483  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.797497  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.797611  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.798573  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.798595  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.798646  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.798655  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.799371  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.799391  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.799432  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.799440  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.799764  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.799829  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.800184  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.800276  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.800285  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.800377  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.800388  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.802876  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.803529  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.803545  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.803550  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.806951  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.806972  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.807003  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.807011  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.807016  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cd0110 type is 7
1561: I0810 04:04:43.807026  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.807034  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4f7b1d0 type is 7
1561: I0810 04:04:43.807039  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.807044  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4f7ab20 type is 7
1561: I0810 04:04:43.807049  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.807053  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cd0330 type is 7
1561: I0810 04:04:43.807058  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.807062  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43cd0500 type is 7
1561: I0810 04:04:43.807068  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.807075  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x43cd06f0 type is 7
1561: I0810 04:04:43.807080  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.807085  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43cd0900 type is 7
1561: I0810 04:04:43.807089  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43cd00f0 type is 9
1561: I0810 04:04:43.807096  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.807099  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43cd06d0 type is 10
1561: I0810 04:04:43.807206  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.807211  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.807216  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.807220  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.807268  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807279  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807359  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807369  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807387  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.807533  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807547  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807564  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.807721  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807735  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807770  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.807816  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807827  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807847  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.807936  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807948  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.807965  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.808001  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.808066  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.808079  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.808096  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.808104  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196d2170Variable Type 7
1561: I0810 04:04:43.808121  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.808137  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.808157  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.808173  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.808215  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.808234  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.808552  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.808583  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.808612  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.809605  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.809752  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.809793  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.810369  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.810405  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.810500  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x429ef8c0)  to GradNodeAccumulation (addr: 0x19437660)
1561: I0810 04:04:43.810581  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.810601  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.810707  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43cfeed0)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x429ef8c0)
1561: I0810 04:04:43.810781  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.810789  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.810796  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.810828  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.810853  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43cfeed0
1561: I0810 04:04:43.810860  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.810883  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.810925  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.810956  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.810966  1655 backward.cc:335] Node: MeanGradNode addr:0x43cfeed0, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x429ef8c0
1561: I0810 04:04:43.810971  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.810998  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x429ef8c0
1561: I0810 04:04:43.811007  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.811019  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.811048  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.811079  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.811085  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x429ef8c0, Found pending node: GradNodeAccumulation addr: 0x19437660
1561: I0810 04:04:43.811091  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.811112  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x19437660
1561: I0810 04:04:43.811120  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.811125  1655 accumulation_node.cc:40] Move Tensor ptr: 0x43da9fb0
1561: I0810 04:04:43.811128  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.811132  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.812884  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.812908  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.812960  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.812969  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.814877  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.815479  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.815966  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.815981  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.815986  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.818341  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.818418  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.818430  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.818439  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cf1160 type is 7
1561: I0810 04:04:43.818446  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.818452  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d944c0 type is 7
1561: I0810 04:04:43.818457  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.818461  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cf0bd0 type is 7
1561: I0810 04:04:43.818466  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.818471  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.818550  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.818557  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.818562  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.818567  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.818606  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.818620  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.818675  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.818686  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.818703  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.818874  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.818887  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.818905  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.818912  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d73400Variable Type 7
1561: I0810 04:04:43.818928  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.818944  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.818965  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.818980  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.819027  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.819048  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.819096  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.819108  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.819124  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.819131  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cf0db0Variable Type 7
1561: I0810 04:04:43.819144  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.819159  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.819176  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.819190  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.819226  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.819245  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.819507  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.819541  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.819563  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.821167  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.821190  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.821239  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.821249  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.823050  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.823603  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.824030  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.824044  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.824049  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.826328  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.826406  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.826416  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.826422  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e03710 type is 7
1561: I0810 04:04:43.826429  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.826436  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e028e0 type is 7
1561: I0810 04:04:43.826442  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.826445  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e032e0 type is 7
1561: I0810 04:04:43.826450  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.826455  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.826529  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.826535  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.826540  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.826545  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.826584  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.826597  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.826653  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.826663  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.826680  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.826802  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.826813  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.826830  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.826838  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196f0c20Variable Type 7
1561: I0810 04:04:43.826853  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.826869  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.826889  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.826903  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.826951  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.826972  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.827021  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.827031  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.827049  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.827056  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e311f0Variable Type 7
1561: I0810 04:04:43.827069  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.827083  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.827101  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.827116  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.827152  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.827172  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.827432  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.827466  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.827488  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.827673  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.828895  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.828918  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.828966  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.828975  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.831882  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.832458  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.832937  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.832952  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.832957  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.835276  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.835362  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.835376  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.835381  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43c32e10 type is 7
1561: I0810 04:04:43.835390  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.835393  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43c3ff60 type is 7
1561: I0810 04:04:43.835398  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.835402  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x196d7c80 type is 7
1561: I0810 04:04:43.835407  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.835415  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.835495  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.835502  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.835506  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.835510  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.835551  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.835564  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.835618  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.835628  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.835645  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.835767  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.835780  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.835798  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.835805  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b88480Variable Type 7
1561: I0810 04:04:43.835820  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.835836  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.835857  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.835872  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.835918  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.835942  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.835989  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.835999  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.836017  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.836025  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cc9960Variable Type 7
1561: I0810 04:04:43.836038  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.836052  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.836071  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.836084  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.836118  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.836139  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.836397  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.836432  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.836452  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.837584  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.837725  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.837767  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.838114  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.838145  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.839951  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.840094  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.840137  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 04:04:43.842916  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43d76fe0 on Place(gpu:0)
1561: I0810 04:04:43.842947  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.842964  1655 scope.cc:202] Create variable 0x43d76fe01723262683842940143_inner_var_1
1561: I0810 04:04:43.842975  1655 scope.cc:202] Create variable 0x43d76fe01723262683842940143_inner_var_2
1561: I0810 04:04:43.842985  1655 scope.cc:202] Create variable 0x43d76fe01723262683842940143_inner_var_3
1561: I0810 04:04:43.842998  1655 scope.cc:202] Create variable 0x43d76fe01723262683842940143_inner_var_4
1561: I0810 04:04:43.843005  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.843017  1655 scope.cc:202] Create variable 0x43d76fe01723262683842940143_inner_var_6
1561: I0810 04:04:43.843026  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.843339  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.843354  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.843358  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43c39320
1561: 1 -> 0x43d76fe01723262683842940143_inner_var_1 -> 0x43ae1e30
1561: 2 -> 0x43d76fe01723262683842940143_inner_var_2 -> 0x196f4ea0
1561: 3 -> 0x43d76fe01723262683842940143_inner_var_3 -> 0x436504a0
1561: 4 -> 0x43d76fe01723262683842940143_inner_var_4 -> 0x43b80a80
1561: 5 -> fetch0@fetch -> 0x43f95cc0
1561: 6 -> 0x43d76fe01723262683842940143_inner_var_6 -> 0x43d60620
1561: 7 -> fetch1@fetch -> 0x43b92a20
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.844022  1765 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.844092  1766 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.844111  1767 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.844164  1768 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.844187  1769 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.844229  1770 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.844249  1770 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.844283  1770 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.844317  1770 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43d76fe01723262683842940143_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43d76fe01723262683842940143_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.844444  1770 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43d76fe01723262683842940143_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x43d76fe01723262683842940143_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.844509  1768 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683842940143_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.844511  1769 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683842940143_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.844544  1768 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.844552  1769 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.844607  1768 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683842940143_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.844648  1769 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43d76fe01723262683842940143_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43d76fe01723262683842940143_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.844659  1768 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683842940143_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.844677  1768 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.844689  1768 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683842940143_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.844707  1769 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683842940143_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.844725  1769 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.844735  1769 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43d76fe01723262683842940143_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.844767  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43d77150) got event_name: TaskCompletion
1561: I0810 04:04:43.844790  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.844815  1655 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.846086  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.846244  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.846287  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 04:04:43.849035  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43c2e120 on Place(gpu:0)
1561: I0810 04:04:43.849064  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.849082  1655 scope.cc:202] Create variable 0x43c2e1201723262683849058267_inner_var_1
1561: I0810 04:04:43.849093  1655 scope.cc:202] Create variable 0x43c2e1201723262683849058267_inner_var_2
1561: I0810 04:04:43.849104  1655 scope.cc:202] Create variable 0x43c2e1201723262683849058267_inner_var_3
1561: I0810 04:04:43.849114  1655 scope.cc:202] Create variable 0x43c2e1201723262683849058267_inner_var_4
1561: I0810 04:04:43.849125  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.849136  1655 scope.cc:202] Create variable 0x43c2e1201723262683849058267_inner_var_6
1561: I0810 04:04:43.849146  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.849458  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.849474  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.849478  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43b87d90
1561: 1 -> 0x43c2e1201723262683849058267_inner_var_1 -> 0x196d8920
1561: 2 -> 0x43c2e1201723262683849058267_inner_var_2 -> 0x43ae0180
1561: 3 -> 0x43c2e1201723262683849058267_inner_var_3 -> 0x196d8a80
1561: 4 -> 0x43c2e1201723262683849058267_inner_var_4 -> 0x43f954f0
1561: 5 -> fetch0@fetch -> 0x43d5d240
1561: 6 -> 0x43c2e1201723262683849058267_inner_var_6 -> 0x43f95510
1561: 7 -> fetch1@fetch -> 0x43dbe3e0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.850147  1771 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.850226  1772 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.850260  1773 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.850294  1774 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.850340  1775 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.850381  1776 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.850400  1776 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.850428  1776 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.850457  1776 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683849058267_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43c2e1201723262683849058267_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.850569  1776 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c2e1201723262683849058267_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x43c2e1201723262683849058267_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.850620  1775 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683849058267_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.850625  1774 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683849058267_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.850642  1775 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.850647  1774 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.850690  1775 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683849058267_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.850725  1774 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c2e1201723262683849058267_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c2e1201723262683849058267_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.850735  1775 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683849058267_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.850750  1775 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.850747  1774 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683849058267_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.850762  1774 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.850759  1775 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683849058267_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.850771  1774 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c2e1201723262683849058267_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.850800  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43c2e290) got event_name: TaskCompletion
1561: I0810 04:04:43.850823  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.850847  1655 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.850986  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:175
1561: I0810 04:04:43.851054  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.851070  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:176
1561: I0810 04:04:43.851089  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.852010  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.852033  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.852084  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.852094  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.853909  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.854468  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.854904  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.854918  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.854923  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.857134  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.857214  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.857226  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.857234  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x436497a0 type is 7
1561: I0810 04:04:43.857242  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.857249  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e59d30 type is 7
1561: I0810 04:04:43.857254  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.857259  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d5aef0 type is 7
1561: I0810 04:04:43.857263  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.857270  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.857353  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.857362  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.857367  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.857372  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.857412  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.857426  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.857482  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.857493  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.857510  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.857645  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.857659  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.857678  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.857686  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4361c0e0Variable Type 7
1561: I0810 04:04:43.857702  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.857717  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.857738  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.857754  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.857802  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.857825  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.857875  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.857885  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.857901  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.857908  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cb4430Variable Type 7
1561: I0810 04:04:43.857923  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.857936  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.857955  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.857970  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.858006  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.858027  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.858282  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.858327  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.858350  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.858537  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.859833  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.859854  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.859905  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.859915  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.861723  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.862279  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.862735  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.862749  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.862754  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.864980  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.865058  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.865070  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.865078  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e25490 type is 7
1561: I0810 04:04:43.865085  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.865092  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e245a0 type is 7
1561: I0810 04:04:43.865096  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.865100  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e25060 type is 7
1561: I0810 04:04:43.865105  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.865111  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.865185  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.865192  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.865196  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.865200  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.865240  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.865253  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.865316  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.865327  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.865345  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.865468  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.865480  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.865497  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.865505  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e18770Variable Type 7
1561: I0810 04:04:43.865520  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.865536  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.865556  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.865571  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.865618  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.865640  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.865689  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.865700  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.865715  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.865723  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4363bac0Variable Type 7
1561: I0810 04:04:43.865736  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.865751  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.865769  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.865782  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.865818  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.865839  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.866084  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.866117  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.866138  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.867249  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.867408  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.867451  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.867975  1765 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 6568079011962314377 to 11634441079075813374 , after update, data is {current : -3720, peak : 0}.
1561: I0810 04:04:43.867985  1765 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 6568079011962314377 to 11634441079075813374 , after update, data is {current : -3720, peak : 0}.
1561: I0810 04:04:43.868255  1769 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 5971604529379543263 to 11634441079075813374 , after update, data is {current : -3600, peak : 120}.
1561: I0810 04:04:43.868330  1768 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 7594919287204944033 to 11634441079075813374 , after update, data is {current : 0, peak : 3600}.
1561: I0810 04:04:43.868459  1770 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 14504803841791198358 to 11634441079075813374 , after update, data is {current : -1860, peak : 1860}.
1561: I0810 04:04:43.868638  1771 thread_data_registry.h:135] Add data {current : 0, peak : 3600} from thread 11634441079075813374 to 7169957454842235876 , after update, data is {current : 120, peak : 3600}.
1561: I0810 04:04:43.868646  1771 thread_data_registry.h:135] Add data {current : -1860, peak : 1860} from thread 11634441079075813374 to 1378916016597506403 , after update, data is {current : 0, peak : 1860}.
1561: I0810 04:04:43.868808  1774 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 85003864348931170 to 7169957454842235876 , after update, data is {current : 3720, peak : 3720}.
1561: I0810 04:04:43.868880  1775 thread_data_registry.h:135] Add data {current : 3720, peak : 3720} from thread 7169957454842235876 to 12289716731659279983 , after update, data is {current : 7560, peak : 7560}.
1561: I0810 04:04:43.868986  1776 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 1378916016597506403 to 12289716731659279983 , after update, data is {current : -1920, peak : 1920}.
1561: I0810 04:04:43.869503  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.869542  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.872051  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.872074  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.872124  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.872133  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.873962  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.874537  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.874991  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.875006  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.875011  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.877280  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.877370  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.877383  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.877393  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1769c2e0 type is 7
1561: I0810 04:04:43.877399  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.877406  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43cd0130 type is 7
1561: I0810 04:04:43.877411  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.877415  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x1979b0c0 type is 7
1561: I0810 04:04:43.877421  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.877429  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.877506  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.877512  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.877517  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.877521  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.877561  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.877574  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.877629  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.877640  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.877657  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.877784  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.877796  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.877815  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.877822  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19794aa0Variable Type 7
1561: I0810 04:04:43.877838  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.877854  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.877876  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.877892  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.877940  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.877962  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.878011  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.878022  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.878041  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.878047  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x42f0a5d0Variable Type 7
1561: I0810 04:04:43.878062  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.878075  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.878095  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.878108  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.878145  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.878166  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.878432  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.878468  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.878489  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.878680  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.879149  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.879181  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.879194  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.879317  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.880290  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.880326  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.880378  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.880388  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.881099  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.881120  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.881160  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.881168  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.881500  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.881562  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.881927  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.882022  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.882032  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.882113  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.882122  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.884662  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.885286  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.885310  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.885318  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.888655  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.888675  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.888705  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.888715  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.888720  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cf8910 type is 7
1561: I0810 04:04:43.888729  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.888733  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43cf8a90 type is 7
1561: I0810 04:04:43.888738  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.888744  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43cf83e0 type is 7
1561: I0810 04:04:43.888749  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.888753  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e36e40 type is 7
1561: I0810 04:04:43.888758  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.888762  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43e37060 type is 7
1561: I0810 04:04:43.888767  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.888772  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x43e372a0 type is 7
1561: I0810 04:04:43.888777  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.888779  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43e37500 type is 7
1561: I0810 04:04:43.888784  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43cf8400 type is 9
1561: I0810 04:04:43.888792  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.888796  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43e37280 type is 10
1561: I0810 04:04:43.888903  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.888911  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.888914  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.888918  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.888967  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.888980  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889036  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889046  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889065  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.889210  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889225  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889243  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.889396  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889410  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889444  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.889484  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889494  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889513  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.889593  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889604  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889621  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.889658  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.889722  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.889734  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.889752  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.889760  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e52ef0Variable Type 7
1561: I0810 04:04:43.889777  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.889793  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.889813  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.889828  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.889869  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.889886  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.890189  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.890220  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.890250  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.891227  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.891388  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.891429  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.891996  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.892031  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.892133  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43660220)  to GradNodeAccumulation (addr: 0x19437660)
1561: I0810 04:04:43.892213  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.892233  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.892351  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43f97710)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43660220)
1561: I0810 04:04:43.892426  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.892433  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.892441  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.892470  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.892493  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43f97710
1561: I0810 04:04:43.892501  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.892524  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.892571  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.892592  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.892601  1655 backward.cc:335] Node: MeanGradNode addr:0x43f97710, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43660220
1561: I0810 04:04:43.892606  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.892632  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43660220
1561: I0810 04:04:43.892638  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.892652  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.892681  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.892710  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.892717  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43660220, Found pending node: GradNodeAccumulation addr: 0x19437660
1561: I0810 04:04:43.892722  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.892743  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x19437660
1561: I0810 04:04:43.892751  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.892755  1655 accumulation_node.cc:40] Move Tensor ptr: 0x43cc3570
1561: I0810 04:04:43.892758  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.892762  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.895048  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.895068  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.895109  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.895117  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.896579  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.897025  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.897390  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.897403  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.897406  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.899185  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.899251  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.899261  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.899266  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e4b350 type is 7
1561: I0810 04:04:43.899272  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.899277  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e20160 type is 7
1561: I0810 04:04:43.899281  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.899286  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e1e820 type is 7
1561: I0810 04:04:43.899289  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.899293  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.899363  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.899369  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.899374  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.899376  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.899410  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.899421  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.899464  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.899472  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.899487  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.899587  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.899598  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.899612  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.899618  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b8dfb0Variable Type 7
1561: I0810 04:04:43.899631  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.899644  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.899662  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.899674  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.899715  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.899734  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.899773  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.899782  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.899796  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.899801  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e4a690Variable Type 7
1561: I0810 04:04:43.899813  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.899824  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.899839  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.899850  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.899881  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.899899  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.900099  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.900127  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.900146  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.901690  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.901712  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.901762  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.901772  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.904524  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.905036  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.905421  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.905433  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.905437  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.907277  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.907353  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.907363  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.907368  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43dca920 type is 7
1561: I0810 04:04:43.907374  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.907377  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d949d0 type is 7
1561: I0810 04:04:43.907382  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.907384  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43db58d0 type is 7
1561: I0810 04:04:43.907388  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.907393  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.907454  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.907460  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.907464  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.907469  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.907500  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.907511  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.907555  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.907564  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.907578  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.907678  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.907689  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.907703  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.907711  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b1d390Variable Type 7
1561: I0810 04:04:43.907723  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.907737  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.907753  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.907766  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.907807  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.907825  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.907866  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.907874  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.907888  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.907895  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cd0f30Variable Type 7
1561: I0810 04:04:43.907907  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.907917  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.907933  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.907944  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.907976  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.907992  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.908193  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.908221  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.908238  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.908409  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.909418  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.909437  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.909478  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.909485  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.910956  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.911419  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.911788  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.911800  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.911803  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.913641  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.913707  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.913717  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.913722  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43ce9950 type is 7
1561: I0810 04:04:43.913727  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.913733  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x196fb3e0 type is 7
1561: I0810 04:04:43.913736  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.913740  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43dfff40 type is 7
1561: I0810 04:04:43.913743  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.913748  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.913810  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.913816  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.913820  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.913823  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.913856  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.913867  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.913911  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.913919  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.913933  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.914033  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.914044  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.914058  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.914064  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b9da40Variable Type 7
1561: I0810 04:04:43.914076  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.914090  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.914108  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.914119  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.914160  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.914178  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.914219  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.914227  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.914242  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.914247  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e0e100Variable Type 7
1561: I0810 04:04:43.914258  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.914270  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.914285  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.914297  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.914338  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.914356  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.914561  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.914588  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.914606  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.915665  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.915808  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.915851  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.916200  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.916231  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.918025  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.918167  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.918210  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 04:04:43.920964  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43c406c0 on Place(gpu:0)
1561: I0810 04:04:43.920994  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.921013  1655 scope.cc:202] Create variable 0x43c406c01723262683920988535_inner_var_1
1561: I0810 04:04:43.921025  1655 scope.cc:202] Create variable 0x43c406c01723262683920988535_inner_var_2
1561: I0810 04:04:43.921036  1655 scope.cc:202] Create variable 0x43c406c01723262683920988535_inner_var_3
1561: I0810 04:04:43.921046  1655 scope.cc:202] Create variable 0x43c406c01723262683920988535_inner_var_4
1561: I0810 04:04:43.921056  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.921067  1655 scope.cc:202] Create variable 0x43c406c01723262683920988535_inner_var_6
1561: I0810 04:04:43.921077  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.921397  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.921413  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.921417  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43c40be0
1561: 1 -> 0x43c406c01723262683920988535_inner_var_1 -> 0x43e08bb0
1561: 2 -> 0x43c406c01723262683920988535_inner_var_2 -> 0x43d953d0
1561: 3 -> 0x43c406c01723262683920988535_inner_var_3 -> 0x43b8c790
1561: 4 -> 0x43c406c01723262683920988535_inner_var_4 -> 0x43ce97e0
1561: 5 -> fetch0@fetch -> 0x43652210
1561: 6 -> 0x43c406c01723262683920988535_inner_var_6 -> 0x43ce9800
1561: 7 -> fetch1@fetch -> 0x43b9d6e0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.922071  1777 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.922139  1778 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.922150  1779 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.922201  1780 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.922220  1781 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.922260  1782 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.922284  1782 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.922322  1782 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.922353  1782 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c406c01723262683920988535_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43c406c01723262683920988535_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.922456  1782 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43c406c01723262683920988535_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x43c406c01723262683920988535_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.922515  1780 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c406c01723262683920988535_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.922518  1781 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c406c01723262683920988535_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.922552  1780 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.922559  1781 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.922624  1780 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c406c01723262683920988535_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.922650  1781 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43c406c01723262683920988535_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43c406c01723262683920988535_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.922658  1780 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c406c01723262683920988535_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.922677  1780 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.922688  1780 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c406c01723262683920988535_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.922708  1781 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43c406c01723262683920988535_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.922726  1781 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.922740  1781 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43c406c01723262683920988535_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.922767  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43c40830) got event_name: TaskCompletion
1561: I0810 04:04:43.922791  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.922814  1655 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.924095  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.924245  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.924288  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 04:04:43.927026  1655 pir_interpreter.cc:161] PirInterpreter(): 0x43e17350 on Place(gpu:0)
1561: I0810 04:04:43.927054  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.927073  1655 scope.cc:202] Create variable 0x43e173501723262683927049155_inner_var_1
1561: I0810 04:04:43.927083  1655 scope.cc:202] Create variable 0x43e173501723262683927049155_inner_var_2
1561: I0810 04:04:43.927094  1655 scope.cc:202] Create variable 0x43e173501723262683927049155_inner_var_3
1561: I0810 04:04:43.927103  1655 scope.cc:202] Create variable 0x43e173501723262683927049155_inner_var_4
1561: I0810 04:04:43.927114  1655 scope.cc:202] Create variable fetch0@fetch
1561: I0810 04:04:43.927125  1655 scope.cc:202] Create variable 0x43e173501723262683927049155_inner_var_6
1561: I0810 04:04:43.927135  1655 scope.cc:202] Create variable fetch1@fetch
1561: I0810 04:04:43.927444  1655 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 04:04:43.927459  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.927464  1655 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x43d6dfd0
1561: 1 -> 0x43e173501723262683927049155_inner_var_1 -> 0x196d7170
1561: 2 -> 0x43e173501723262683927049155_inner_var_2 -> 0x43f99950
1561: 3 -> 0x43e173501723262683927049155_inner_var_3 -> 0x43ba0040
1561: 4 -> 0x43e173501723262683927049155_inner_var_4 -> 0x43e0dec0
1561: 5 -> fetch0@fetch -> 0x43dfac50
1561: 6 -> 0x43e173501723262683927049155_inner_var_6 -> 0x43dfac10
1561: 7 -> fetch1@fetch -> 0x43e3d1c0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 04:04:43.928119  1783 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 04:04:43.928200  1784 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 04:04:43.928234  1785 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 04:04:43.928261  1786 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 04:04:43.928297  1787 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 04:04:43.928349  1788 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 04:04:43.928369  1788 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.928397  1788 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.928424  1788 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43e173501723262683927049155_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43e173501723262683927049155_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.928519  1788 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43e173501723262683927049155_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x43e173501723262683927049155_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.928565  1787 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e173501723262683927049155_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.928586  1787 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.928584  1786 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e173501723262683927049155_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.928622  1786 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.928642  1787 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e173501723262683927049155_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.928690  1787 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43e173501723262683927049155_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.928689  1786 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43e173501723262683927049155_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43e173501723262683927049155_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.928711  1787 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.928726  1787 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43e173501723262683927049155_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 04:04:43.928737  1786 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43e173501723262683927049155_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 04:04:43.928752  1786 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.928764  1786 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43e173501723262683927049155_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 04:04:43.928791  1655 pir_interpreter.cc:1766] main_thread_blocker_(0x43e174c0) got event_name: TaskCompletion
1561: I0810 04:04:43.928813  1655 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.928838  1655 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 04:04:43.928974  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:201
1561: I0810 04:04:43.929041  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.929057  1655 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:202
1561: I0810 04:04:43.929075  1655 pir.cc:2451] Start compare shape and data.
1561: I0810 04:04:43.929996  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.930018  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.930069  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.930078  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.931885  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.932443  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.932878  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.932893  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.932897  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.935109  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.935187  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.935199  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.935207  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e295e0 type is 7
1561: I0810 04:04:43.935214  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.935220  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43df9e10 type is 7
1561: I0810 04:04:43.935225  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.935230  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43df9c30 type is 7
1561: I0810 04:04:43.935235  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.935240  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.935324  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.935333  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.935336  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.935340  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.935381  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.935395  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.935449  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.935459  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.935478  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.935607  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.935621  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.935637  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.935645  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d3e2f0Variable Type 7
1561: I0810 04:04:43.935660  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.935676  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.935698  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.935712  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.935760  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.935782  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.935832  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.935842  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.935859  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.935866  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e2d820Variable Type 7
1561: I0810 04:04:43.935880  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.935894  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.935912  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.935926  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.935962  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.935982  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.936272  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.936321  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.936342  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.936529  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.937417  1777 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 1378916016597506403 to 11634441079075813374 , after update, data is {current : -3720, peak : 0}.
1561: I0810 04:04:43.937427  1777 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 1378916016597506403 to 11634441079075813374 , after update, data is {current : -3720, peak : 0}.
1561: I0810 04:04:43.937667  1781 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 5971604529379543263 to 11634441079075813374 , after update, data is {current : -3600, peak : 120}.
1561: I0810 04:04:43.937738  1780 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 7594919287204944033 to 11634441079075813374 , after update, data is {current : 0, peak : 3600}.
1561: I0810 04:04:43.937862  1782 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 14504803841791198358 to 11634441079075813374 , after update, data is {current : -1860, peak : 1860}.
1561: I0810 04:04:43.938012  1783 thread_data_registry.h:135] Add data {current : 0, peak : 3600} from thread 11634441079075813374 to 9424786137817224901 , after update, data is {current : 120, peak : 3600}.
1561: I0810 04:04:43.938022  1783 thread_data_registry.h:135] Add data {current : -1860, peak : 1860} from thread 11634441079075813374 to 6568079011962314377 , after update, data is {current : 0, peak : 1860}.
1561: I0810 04:04:43.938169  1786 thread_data_registry.h:135] Add data {current : 120, peak : 3600} from thread 9424786137817224901 to 8786803354451484824 , after update, data is {current : 3720, peak : 3720}.
1561: I0810 04:04:43.938239  1787 thread_data_registry.h:135] Add data {current : 3720, peak : 3720} from thread 8786803354451484824 to 12289716731659279983 , after update, data is {current : 11280, peak : 11280}.
1561: I0810 04:04:43.938341  1788 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 6568079011962314377 to 12289716731659279983 , after update, data is {current : -1920, peak : 1920}.
1561: I0810 04:04:43.939555  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.939580  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.939632  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.939641  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.941488  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.942052  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.942535  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.942550  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.942555  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.944885  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.944963  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.944975  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.944984  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e0dd30 type is 7
1561: I0810 04:04:43.944991  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.944998  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x196d61e0 type is 7
1561: I0810 04:04:43.945003  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.945005  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43ade140 type is 7
1561: I0810 04:04:43.945010  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.945015  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.945094  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.945101  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.945106  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.945109  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.945149  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.945163  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.945217  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.945227  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.945245  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.945380  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.945395  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.945412  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.945420  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1979a7f0Variable Type 7
1561: I0810 04:04:43.945436  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.945451  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.945472  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.945487  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.945534  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.945556  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.945605  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.945616  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.945633  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.945641  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e0de60Variable Type 7
1561: I0810 04:04:43.945653  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.945667  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.945685  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.945699  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.945735  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.945756  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.946002  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.946036  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.946058  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.947201  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.947358  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.947402  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.947751  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.947783  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.950062  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.950086  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.950138  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.950148  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.952047  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.952646  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.953119  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.953133  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.953138  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.955559  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.955638  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.955650  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.955659  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43df89e0 type is 7
1561: I0810 04:04:43.955667  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.955673  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43cf6a80 type is 7
1561: I0810 04:04:43.955678  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.955683  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x197b6f10 type is 7
1561: I0810 04:04:43.955688  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4365fab0 type is 9
1561: I0810 04:04:43.955694  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4365fc70 type is 10
1561: I0810 04:04:43.955773  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.955780  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.955785  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.955789  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.955829  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.955843  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.955899  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.955910  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.955931  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.956058  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.956070  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.956089  1655 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.956096  1655 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196f6190Variable Type 7
1561: I0810 04:04:43.956111  1655 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.956127  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.956148  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.956164  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.956212  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.956234  1655 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.956285  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.956296  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.956326  1655 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.956334  1655 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e578e0Variable Type 7
1561: I0810 04:04:43.956348  1655 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.956362  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.956382  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.956396  1655 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.956435  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.956456  1655 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 04:04:43.956717  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.956750  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.956773  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.956964  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.957451  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.957481  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.957494  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.957607  1655 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 04:04:43.958570  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.958591  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.958642  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.958650  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.959372  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.959393  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.959432  1655 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 04:04:43.959440  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.959764  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.959825  1655 pybind.cc:1827] need skip: 0
1561: I0810 04:04:43.960181  1655 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 04:04:43.960273  1655 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 04:04:43.960284  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.960374  1655 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.960384  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.962824  1655 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 04:04:43.963443  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.963459  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.963464  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.966766  1655 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 04:04:43.966786  1655 scope.cc:202] Create variable feed
1561: I0810 04:04:43.966816  1655 interpreter_util.cc:1169] Creating Variables
1561: I0810 04:04:43.966826  1655 scope.cc:202] Create variable Out
1561: I0810 04:04:43.966835  1655 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x19736ba0 type is 7
1561: I0810 04:04:43.966842  1655 scope.cc:202] Create variable Out@GRAD
1561: I0810 04:04:43.966848  1655 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x19736d20 type is 7
1561: I0810 04:04:43.966853  1655 scope.cc:202] Create variable OutScale
1561: I0810 04:04:43.966856  1655 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x19736670 type is 7
1561: I0810 04:04:43.966861  1655 scope.cc:202] Create variable X
1561: I0810 04:04:43.966866  1655 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19737a60 type is 7
1561: I0810 04:04:43.966869  1655 scope.cc:202] Create variable X@GRAD
1561: I0810 04:04:43.966873  1655 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x19737c80 type is 7
1561: I0810 04:04:43.966878  1655 scope.cc:202] Create variable _generated_var_0
1561: I0810 04:04:43.966881  1655 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x19737ec0 type is 7
1561: I0810 04:04:43.966886  1655 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 04:04:43.966890  1655 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x19738120 type is 7
1561: I0810 04:04:43.966895  1655 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x19736690 type is 9
1561: I0810 04:04:43.966900  1655 scope.cc:202] Create variable fetch
1561: I0810 04:04:43.966904  1655 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x19737ea0 type is 10
1561: I0810 04:04:43.967007  1655 interpreter_util.cc:594] Static build: 0
1561: I0810 04:04:43.967015  1655 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 04:04:43.967020  1655 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 04:04:43.967023  1655 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 04:04:43.967072  1655 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967085  1655 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967140  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967151  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967172  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.967330  1655 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967345  1655 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967361  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.967504  1655 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967516  1655 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967554  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.967592  1655 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967602  1655 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967621  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 04:04:43.967702  1655 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967713  1655 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967730  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 04:04:43.967767  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.967832  1655 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.967844  1655 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 04:04:43.967861  1655 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 04:04:43.967868  1655 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43dcd620Variable Type 7
1561: I0810 04:04:43.967885  1655 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 04:04:43.967900  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.967921  1655 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 04:04:43.967934  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 04:04:43.967976  1655 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 04:04:43.967993  1655 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 04:04:43.968315  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 04:04:43.968348  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 04:04:43.968377  1655 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 04:04:43.969355  1655 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19437660 for it.
1561: I0810 04:04:43.969504  1655 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43b28b60 for it.
1561: I0810 04:04:43.969543  1655 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1944e100 for it.
1561: I0810 04:04:43.970115  1655 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 04:04:43.970150  1655 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.970252  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd4020)  to GradNodeAccumulation (addr: 0x19437660)
1561: I0810 04:04:43.970345  1655 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 04:04:43.970366  1655 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.970474  1655 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x43f97710)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43cd4020)
1561: I0810 04:04:43.970547  1655 backward.cc:442] Run in Backward
1561: I0810 04:04:43.970554  1655 backward.cc:113] Start Backward
1561: I0810 04:04:43.970561  1655 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 04:04:43.970592  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.970623  1655 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x43f97710
1561: I0810 04:04:43.970631  1655 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 04:04:43.970654  1655 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.970695  1655 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 04:04:43.970715  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.970723  1655 backward.cc:335] Node: MeanGradNode addr:0x43f97710, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43cd4020
1561: I0810 04:04:43.970728  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.970753  1655 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd4020
1561: I0810 04:04:43.970760  1655 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 04:04:43.970772  1655 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 04:04:43.970800  1655 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 04:04:43.970830  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:43.970836  1655 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43cd4020, Found pending node: GradNodeAccumulation addr: 0x19437660
1561: I0810 04:04:43.970841  1655 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 04:04:43.970862  1655 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x19437660
1561: I0810 04:04:43.970870  1655 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.970873  1655 accumulation_node.cc:40] Move Tensor ptr: 0x43b23640
1561: I0810 04:04:43.970876  1655 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 04:04:43.970881  1655 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 04:04:44.037513  1655 mmap_allocator.cc:348] PID: 1655, MemoryMapFdSet: set size - 0
1561: I0810 04:04:44.047418  1655 mmap_allocator.cc:348] PID: 1655, MemoryMapFdSet: set size - 0
1561: I0810 04:04:44.101209  1741 thread_data_registry.h:135] Add data {current : 11280, peak : 11280} from thread 12289716731659279983 to 9879652894666900113 , after update, data is {current : 11520, peak : 11520}.
1561: I0810 04:04:44.101223  1741 thread_data_registry.h:135] Add data {current : -1920, peak : 1920} from thread 12289716731659279983 to 11914039533111944516 , after update, data is {current : 0, peak : 1920}.
1561: I0810 04:04:44.101446  1745 thread_data_registry.h:135] Add data {current : 11520, peak : 11520} from thread 9879652894666900113 to 12789917996542635335 , after update, data is {current : 15120, peak : 15120}.
1561: I0810 04:04:44.101486  1744 thread_data_registry.h:135] Add data {current : 15120, peak : 15120} from thread 12789917996542635335 to 7168305081591625432 , after update, data is {current : 921920, peak : 1179720}.
1561: I0810 04:04:44.101683  1746 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 11914039533111944516 to 7168305081591625432 , after update, data is {current : 1843464, peak : 2555920}.
1561: I0810 04:04:44.235311  1655 mmap_allocator.cc:348] PID: 1655, MemoryMapFdSet: set size - 0
1/2 Test #1561: test_fake_quantize_op ................   Passed   10.62 sec
test 2253
    Start 2253: test_fake_quantize_op_static_build

2253: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "FLAGS_new_executor_static_build=true" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_fake_quantize_op"
2253: Test timeout computed to be: 10000000
2253: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
2253: WARNING: Logging before InitGoogleLogging() is written to STDERR
2253: I0810 04:04:45.215333  1790 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
2253: I0810 04:04:46.000222  1790 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=enable_all2all_use_fp16,new_executor_serial_run,print_ir,sync_nccl_allreduce,cache_inference_while_scope,multi_node_sample_use_gpu_table,gpu_allocator_retry_time,cuda_memory_async_pool_realease_threshold,check_kernel_launch,gpugraph_dedup_pull_push_mode,logging_trunc_pir_py_code,op_dir,gpugraph_storage_mode,cusparse_dir,mklml_dir,eager_delete_scope,gpugraph_enable_print_op_debug,curand_dir,logging_pir_py_code_dir,use_pinned_memory,call_stack_level,enable_unused_var_check,fuse_parameter_groups_size,allow_cinn_ops,disable_dyshape_in_train,pinned_memory_as_cpu_backend,new_executor_use_cuda_graph,convert_all_blocks,alloc_fill_value,new_executor_sequential_run,accuracy_check_atol_bf16,selected_gpus,use_cuda_malloc_async_allocator,gpugraph_offload_gather_copy_maxsize,tracer_onednn_ops_on,pir_debug,conv_workspace_size_limit,prim_all,use_cuda_managed_memory,async_trace_count,einsum_opt,accuracy_check_rtol_fp32,pir_broadcast_tree_limit,new_executor_static_build,dist_threadpool_size,use_cinn,dump_chunk_info,prim_check_ops,gpugraph_enable_gpu_direct_access,use_stream_safe_cuda_allocator,fast_eager_deletion_mode,use_virtual_memory_auto_growth,use_auto_growth_v2,gpugraph_enable_hbm_table_collision_stat,pir_apply_shape_optimization_pass,reallocate_gpu_memory_in_mb,enable_cinn_auto_tune,prim_forward,enable_fuse_parallel_matmul_pass,check_nan_inf,graph_load_in_parallel,print_allocator_trace_info,gpugraph_load_node_list_into_hbm,gpugraph_slot_feasign_max_num,enable_api_kernel_fallback,logging_pir_py_code_int_tensor_element_limit,mkl_dir,enable_pir_in_executor_trace_run,cudnn_exhaustive_search,fleet_executor_with_standalone,enable_cinn_accuracy_check,initial_cpu_memory_in_mb,max_inplace_grad_add,check_infer_symbolic,enable_adjust_op_order,nvidia_package_dir,win_cuda_bin_dir,npu_storage_format,cuda_dir,trt_ibuilder_cache,prim_enabled,new_executor_use_local_scope,accuracy_check_atol_fp16,init_allocated_mem,print_sub_graph_dir,accuracy_check_rtol_fp16,enable_record_memory,enable_interpretercore_launch_cinn,paddle_num_threads,enable_cse_in_dy2st,deny_cinn_ops,low_precision_op_list,enable_gpu_memory_usage_log,cudnn_deterministic,cinn_subgraph_graphviz_dir,run_kp_kernel,use_system_allocator,enable_dump_main_program,check_nan_inf_level,gpugraph_enable_segment_merge_grads,save_static_runtime_data,benchmark,query_dest_rank_by_multi_node,fraction_of_cuda_pinned_memory_to_use,graph_get_neighbor_id,enable_gpu_memory_usage_log_mb,gpu_memory_limit_mb,sync_after_alloc,use_auto_growth_pinned_allocator,cublaslt_device_best_config,use_shm_cache,allreduce_record_one_event,enable_graph_multi_node_sampling,manually_trans_conv_filter,gemm_use_half_precision_compute_type,gpugraph_debug_gpu_memory,tensorrt_dir,enable_cinn_compile_cache,static_runtime_data_save_path,get_host_by_name_time,enable_pir_api,dygraph_debug,multiple_of_cupti_buffer_size,allocator_strategy,cusparselt_dir,tracer_profile_fname,free_when_no_cache_hit,graph_metapath_split_opt,jit_engine_type,enable_opt_get_features,auto_growth_chunk_size_in_mb,dataloader_use_file_descriptor,enable_auto_detect_gpu_topo,gpugraph_sparse_table_storage_mode,custom_device_mem_record,ir_inplace_kernel_blacklist,enable_auto_rdma_trans,enable_tracker_all2all,gpugraph_parallel_stream_num,sort_sum_gradient,reader_queue_speed_test_mode,benchmark_nccl,use_fast_math,cuda_malloc_async_pool_memory_throttle_ratio,enable_collect_shape,enable_pir_in_executor,prim_backward,embedding_deterministic,use_autotune,memory_fraction_of_eager_deletion,enable_sparse_inner_gather,cupti_dir,conv2d_disable_cudnn,fuse_parameter_memory_size,accuracy_check_rtol_bf16,enable_fusion_fallback,nccl_blocking_wait,tensor_operants_mode,gpugraph_offload_param_extends,cudnn_exhaustive_search_times,set_to_1d,prim_enable_dynamic,gpugraph_force_device_batch_num_equal,gpugraph_parallel_copyer_split_maxsize,enable_pir_with_pt_in_dy2st,nccl_dir,executor_log_deps_every_microseconds,cublas_dir,add_dependency_for_communication_op,log_memory_stats,cusolver_dir,dynamic_static_unified_comm,apply_pass_to_program,host_trace_level,local_exe_sub_scope_limit,enable_async_trace,enable_blaslt_global_search,cudnn_dir,gpugraph_offload_param_stat,gpugraph_merge_grads_segment_size,pir_subgraph_saving_dir,cinn_compile_thread_num,fraction_of_cpu_memory_to_use,fraction_of_gpu_memory_to_use,tracer_onednn_ops_off,use_xqa_optim,graph_embedding_split_infer_mode,prim_skip_dynamic,free_idle_chunk,initial_gpu_memory_in_mb,new_executor_use_inplace,search_cache_max_number,eager_delete_tensor_gb,gpugraph_hbm_table_load_factor,use_stride_kernel,enable_dependency_builder_debug_info,enable_cublas_tensor_op_math,enable_neighbor_list_use_uva,static_executor_perfstat_filepath,inner_op_parallelism,pir_apply_inplace_pass,all_blocks_convert_trt,cse_max_count,prim_forward_blacklist,cudnn_batchnorm_spatial_persistent,auto_free_cudagraph_allocations_on_launch,lapack_dir,use_mkldnn,graph_neighbor_size_percent,cublaslt_exhaustive_search_times,enable_exit_when_partial_worker,logging_pir_py_code_dump_symbolic_dims,accuracy_check_atol_fp32 
2253: I0810 04:04:46.000347  1790 init.cc:108] After Parse: argc is 2
2253: I0810 04:04:51.226436  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:51.226495  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:51.226678  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:51.226689  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:51.227228  1790 allocator_facade.cc:212] selected allocator strategy:1
2253: I0810 04:04:51.227505  1790 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
2253: I0810 04:04:53.598459  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.598968  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.599534  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.599552  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.599570  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.601826  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.601851  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:53.601949  1790 program_interpreter.cc:243] New Executor is Running.
2253: I0810 04:04:53.601959  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.601965  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.601977  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4464fec0 type is 7
2253: I0810 04:04:53.601989  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.601995  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44c8ee10 type is 7
2253: I0810 04:04:53.601999  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.602003  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4464d450 type is 7
2253: I0810 04:04:53.602007  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.602012  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:53.602017  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.602088  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.602094  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.602098  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.602102  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: W0810 04:04:53.602722  1790 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
2253: I0810 04:04:53.603009  1790 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
2253: W0810 04:04:53.603839  1790 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
2253: I0810 04:04:53.604064  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.604089  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.604216  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.604225  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.604272  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.604292  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.604324  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.604334  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45128c90Variable Type 7
2253: I0810 04:04:53.604358  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.604408  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.604424  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.604470  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.604476  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.604491  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.604496  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44650640Variable Type 7
2253: I0810 04:04:53.604507  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.604521  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.604530  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.604877  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.604921  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.604940  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.605171  1827 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.605314  1828 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.605371  1829 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.605389  1830 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.605474  1831 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.605562  1832 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.606108  1831 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.606107  1830 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.606616  1830 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.606645  1830 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.606673  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4464c9b8) got event_name: TaskCompletion
2253: I0810 04:04:53.606966  1827 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 2173037105002747493 to 11168886607272271118 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.607149  1830 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 1580200262163047400 to 1738218762300064674 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.607353  1832 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 11168886607272271118 to 2770829791301891489 , after update, data is {current : 196608, peak : 196620}.
2253: I0810 04:04:53.705379  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.705413  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.705487  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.705495  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.708156  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.708741  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.709264  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.709278  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.709285  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.711802  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.711921  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.711934  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.711941  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44276310 type is 7
2253: I0810 04:04:53.711951  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.711956  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44c5a390 type is 7
2253: I0810 04:04:53.711961  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.711966  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44273860 type is 7
2253: I0810 04:04:53.711970  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.711979  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.712067  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.712073  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.712078  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.712083  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.712143  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.712162  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.712236  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.712247  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.712292  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.712314  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.712333  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.712342  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b088c0Variable Type 7
2253: I0810 04:04:53.712358  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.712386  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.712404  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.712446  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.712457  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.712473  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.712481  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44276ae0Variable Type 7
2253: I0810 04:04:53.712492  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.712507  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.712522  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.712873  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.712913  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.712935  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.713084  1834 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.713230  1835 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.713266  1836 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.713353  1838 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.713398  1837 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.713451  1839 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.713757  1838 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.713760  1837 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.714200  1838 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.714217  1838 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.714239  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44c59e48) got event_name: TaskCompletion
2253: I0810 04:04:53.714401  1834 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 11168886607272271118 to 17588981528682295231 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.714548  1837 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 10760500565250961709 to 17233454264217551682 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.714776  1839 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 17588981528682295231 to 2770829791301891489 , after update, data is {current : 196608, peak : 393216}.
2253: I0810 04:04:53.714972  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.716543  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.716562  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.716605  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.716614  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.718250  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.718724  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.719089  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.719101  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.719105  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.720984  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.721053  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.721063  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.721068  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b06510 type is 7
2253: I0810 04:04:53.721076  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.721078  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44c56e00 type is 7
2253: I0810 04:04:53.721082  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.721086  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44c578b0 type is 7
2253: I0810 04:04:53.721091  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.721096  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.721161  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.721167  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.721171  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.721174  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.721212  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.721225  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.721266  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.721274  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.721315  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.721324  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.721339  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.721345  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cba050Variable Type 7
2253: I0810 04:04:53.721359  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.721378  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.721390  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.721422  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.721429  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.721446  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.721451  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b06d60Variable Type 7
2253: I0810 04:04:53.721462  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.721474  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.721483  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.721717  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.721747  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.721765  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.721855  1840 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.721920  1841 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.721938  1842 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.721980  1843 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.722007  1844 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.722056  1845 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.722255  1843 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.722270  1844 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.722676  1843 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.722694  1843 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.722716  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44c56898) got event_name: TaskCompletion
2253: I0810 04:04:53.722839  1840 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 17588981528682295231 to 11168886607272271118 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.722985  1844 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 1738218762300064674 to 1580200262163047400 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.723062  1843 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 1580200262163047400 to 2770829791301891489 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:04:53.723181  1845 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 11168886607272271118 to 2770829791301891489 , after update, data is {current : 196608, peak : 393216}.
2253: I0810 04:04:53.725250  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6d4040 for it.
2253: I0810 04:04:53.725494  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.725553  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.726444  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.726522  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.737767  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6d4040 for it.
2253: I0810 04:04:53.737963  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.738006  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:04:53.744274  1790 pir_interpreter.cc:161] PirInterpreter(): 0x442e2460 on Place(gpu:0)
2253: I0810 04:04:53.744330  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.744364  1790 scope.cc:202] Create variable 0x442e24601723262693744309350_inner_var_1
2253: I0810 04:04:53.744376  1790 scope.cc:202] Create variable 0x442e24601723262693744309350_inner_var_2
2253: I0810 04:04:53.744385  1790 scope.cc:202] Create variable 0x442e24601723262693744309350_inner_var_3
2253: I0810 04:04:53.744395  1790 scope.cc:202] Create variable 0x442e24601723262693744309350_inner_var_4
2253: I0810 04:04:53.744405  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:53.744416  1790 scope.cc:202] Create variable 0x442e24601723262693744309350_inner_var_6
2253: I0810 04:04:53.744423  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:53.744908  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:53.744925  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.744931  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: I0810 04:04:53.744979  1790 pir_interpreter.cc:1455] New Executor is Running ...
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x442e0c50
2253: 1 -> 0x442e24601723262693744309350_inner_var_1 -> 0x442e2440
2253: 2 -> 0x442e24601723262693744309350_inner_var_2 -> 0x442e0670
2253: 3 -> 0x442e24601723262693744309350_inner_var_3 -> 0x442e2ab0
2253: 4 -> 0x442e24601723262693744309350_inner_var_4 -> 0x442e2ed0
2253: 5 -> fetch0@fetch -> 0x442e3330
2253: 6 -> 0x442e24601723262693744309350_inner_var_6 -> 0x442e2ef0
2253: 7 -> fetch1@fetch -> 0x442e3aa0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:53.745819  1790 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
2253: I0810 04:04:53.745914  1846 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.745996  1847 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.746021  1848 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.746073  1849 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.746085  1850 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.746152  1851 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.746186  1851 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.746255  1851 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.746294  1851 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442e24601723262693744309350_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_3:[dtype=;place=;dim=;lod={};, 0x442e24601723262693744309350_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.746425  1851 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442e24601723262693744309350_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x442e24601723262693744309350_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.746490  1850 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693744309350_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.746497  1849 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693744309350_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.746537  1850 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.746542  1849 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.746616  1850 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693744309350_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.746928  1849 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693744309350_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693744309350_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.746939  1850 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693744309350_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.746968  1850 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.746985  1850 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693744309350_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.746999  1849 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693744309350_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.747021  1849 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.747169  1849 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693744309350_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.747205  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x442e25d0) got event_name: TaskCompletion
2253: I0810 04:04:53.747232  1790 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.747292  1790 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.749621  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.749840  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.749883  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.752410  1846 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 11168886607272271118 to 17233454264217551682 , after update, data is {current : 196596, peak : 393216}.
2253: I0810 04:04:53.752421  1846 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 11168886607272271118 to 11836897867350493708 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.752578  1849 thread_data_registry.h:135] Add data {current : 196596, peak : 393216} from thread 17233454264217551682 to 17588981528682295231 , after update, data is {current : 196620, peak : 393216}.
2253: I0810 04:04:53.752658  1850 thread_data_registry.h:135] Add data {current : 196620, peak : 393216} from thread 17588981528682295231 to 2770829791301891489 , after update, data is {current : 0, peak : 393216}.
2253: I0810 04:04:53.752777  1851 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 11836897867350493708 to 2770829791301891489 , after update, data is {current : 589836, peak : 786444}.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:04:53.753787  1790 pir_interpreter.cc:161] PirInterpreter(): 0x442e2460 on Place(gpu:0)
2253: I0810 04:04:53.753818  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.753835  1790 scope.cc:202] Create variable 0x442e24601723262693753810348_inner_var_1
2253: I0810 04:04:53.753846  1790 scope.cc:202] Create variable 0x442e24601723262693753810348_inner_var_2
2253: I0810 04:04:53.753854  1790 scope.cc:202] Create variable 0x442e24601723262693753810348_inner_var_3
2253: I0810 04:04:53.753863  1790 scope.cc:202] Create variable 0x442e24601723262693753810348_inner_var_4
2253: I0810 04:04:53.753872  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:53.753883  1790 scope.cc:202] Create variable 0x442e24601723262693753810348_inner_var_6
2253: I0810 04:04:53.753894  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:53.754262  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:53.754277  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.754281  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x442e0ad0
2253: 1 -> 0x442e24601723262693753810348_inner_var_1 -> 0x43cc42a0
2253: 2 -> 0x442e24601723262693753810348_inner_var_2 -> 0x4372cbd0
2253: 3 -> 0x442e24601723262693753810348_inner_var_3 -> 0x442e0c10
2253: 4 -> 0x442e24601723262693753810348_inner_var_4 -> 0x442e47d0
2253: 5 -> fetch0@fetch -> 0x446e5fc0
2253: 6 -> 0x442e24601723262693753810348_inner_var_6 -> 0x442e3a80
2253: 7 -> fetch1@fetch -> 0x4507cd70
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:53.754961  1852 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.755029  1853 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.755057  1854 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.755101  1855 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.755125  1856 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.755167  1857 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.755187  1857 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.755215  1857 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.755244  1857 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442e24601723262693753810348_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_3:[dtype=;place=;dim=;lod={};, 0x442e24601723262693753810348_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.755355  1857 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442e24601723262693753810348_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x442e24601723262693753810348_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.755405  1856 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693753810348_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.755436  1856 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.755421  1855 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693753810348_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.755462  1855 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.755780  1856 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693753810348_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.755816  1856 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693753810348_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.755813  1855 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442e24601723262693753810348_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x442e24601723262693753810348_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.755841  1856 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.755861  1855 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693753810348_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.755882  1855 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.755892  1855 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693753810348_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.755990  1856 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442e24601723262693753810348_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.756024  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x442e25d0) got event_name: TaskCompletion
2253: I0810 04:04:53.756045  1790 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.756112  1790 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.756294  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:19
2253: I0810 04:04:53.756466  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:53.756484  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:20
2253: I0810 04:04:53.756498  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:53.757318  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.757337  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.757382  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.757390  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.758994  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.759459  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.759829  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.759841  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.759846  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.761731  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.761797  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.761807  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.761812  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x444992a0 type is 7
2253: I0810 04:04:53.761819  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.761823  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44495e50 type is 7
2253: I0810 04:04:53.761828  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.761831  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x444968c0 type is 7
2253: I0810 04:04:53.761835  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.761840  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.761911  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.761917  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.761921  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.761924  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.761962  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.761974  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.762023  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.762032  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.762066  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.762074  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.762087  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.762094  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x450eb520Variable Type 7
2253: I0810 04:04:53.762107  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.762126  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.762140  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.762171  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.762178  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.762192  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.762198  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44499c40Variable Type 7
2253: I0810 04:04:53.762209  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.762223  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.762231  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.762451  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.762482  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.762501  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.762652  1858 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.762742  1859 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.762842  1860 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.762848  1861 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.762926  1862 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.762992  1863 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.763222  1862 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.763231  1861 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.763608  1861 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.763628  1861 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.763646  1790 program_interpreter.cc:1308] main_thread_blocker_(0x444959d8) got event_name: TaskCompletion
2253: I0810 04:04:53.763772  1858 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 9497174210020301017 to 14590479405363806404 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.763918  1861 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.763990  1862 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.764093  1863 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:04:53.764241  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.765427  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.765446  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.765489  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.765496  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.767059  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.767539  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.767915  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.767925  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.767931  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.769833  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.769898  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.769908  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.769912  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44a992c0 type is 7
2253: I0810 04:04:53.769919  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.769922  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a95c60 type is 7
2253: I0810 04:04:53.769927  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.769932  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a96760 type is 7
2253: I0810 04:04:53.769935  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.769940  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.770010  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.770016  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.770020  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.770025  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.770058  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.770069  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.770113  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.770121  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.770154  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.770162  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.770177  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.770184  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44c826c0Variable Type 7
2253: I0810 04:04:53.770198  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.770216  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.770228  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.770255  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.770262  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.770277  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.770283  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44a9abe0Variable Type 7
2253: I0810 04:04:53.770294  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.770318  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.770328  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.770534  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.770563  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.770581  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.770656  1864 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.770718  1865 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.770735  1866 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.770783  1867 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.770803  1868 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.770835  1869 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.770998  1868 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.771004  1867 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.771400  1867 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.771417  1867 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.771438  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44a956f8) got event_name: TaskCompletion
2253: I0810 04:04:53.771561  1864 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.771728  1867 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 196608, peak : 196620}.
2253: I0810 04:04:53.771765  1868 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.771884  1869 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:04:53.773545  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.773744  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.773787  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.774138  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.774174  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.777230  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.777251  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.777310  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.777321  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.779212  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.779788  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.780243  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.780258  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.780263  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.782577  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.782653  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.782665  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.782671  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44128240 type is 7
2253: I0810 04:04:53.782680  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.782683  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44643930 type is 7
2253: I0810 04:04:53.782688  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.782692  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x446443b0 type is 7
2253: I0810 04:04:53.782697  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.782702  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.782783  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.782789  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.782794  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.782799  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.782840  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.782855  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.782905  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.782915  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.782956  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.782965  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.782982  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.782989  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43762320Variable Type 7
2253: I0810 04:04:53.783003  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.783023  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.783037  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.783077  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.783084  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.783102  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.783107  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44128ab0Variable Type 7
2253: I0810 04:04:53.783119  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.783135  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.783147  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.783407  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.783442  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.783465  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.783563  1870 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.783627  1871 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.783645  1872 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.783700  1873 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.783725  1874 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.783767  1875 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.783941  1874 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.783963  1873 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.784372  1873 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.784390  1873 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.784413  1790 program_interpreter.cc:1308] main_thread_blocker_(0x446433e8) got event_name: TaskCompletion
2253: I0810 04:04:53.784552  1870 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.784708  1873 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.784780  1874 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 393240, peak : 393240}.
2253: I0810 04:04:53.784888  1875 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:04:53.785063  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.786165  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.786211  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.786224  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.786420  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:53.787542  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.787564  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.787612  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.787622  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.788632  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:53.788663  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:53.788712  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:53.788722  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:53.789145  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.789224  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.789701  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:53.790181  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:53.790203  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:53.790292  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:53.790316  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:53.793740  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.794405  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.794421  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.794427  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.797935  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.797955  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:53.797987  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.797997  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.798002  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cc6420 type is 7
2253: I0810 04:04:53.798009  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:53.798015  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43910990 type is 7
2253: I0810 04:04:53.798022  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.798025  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x450e8ff0 type is 7
2253: I0810 04:04:53.798030  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.798033  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44c7c9e0 type is 7
2253: I0810 04:04:53.798039  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:53.798043  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44c7cc50 type is 7
2253: I0810 04:04:53.798048  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:53.798051  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44c7ce90 type is 7
2253: I0810 04:04:53.798058  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:53.798061  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44c7d0f0 type is 7
2253: I0810 04:04:53.798066  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43cc6400 type is 9
2253: I0810 04:04:53.798074  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:53.798079  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44c7ce70 type is 10
2253: I0810 04:04:53.798179  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.798187  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.798192  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.798197  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.798245  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798259  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798316  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798327  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798386  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798396  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798467  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798477  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798496  1790 interpreter_util.cc:647] Standalone Executor is Used.
2253: I0810 04:04:53.798525  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798534  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798573  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798583  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798611  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.798621  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.798636  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.798645  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x430ecb90Variable Type 7
2253: I0810 04:04:53.798660  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.798679  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.798692  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.798992  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.799039  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:53.799072  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.799175  1876 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.799254  1877 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.799275  1878 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.799328  1879 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.799363  1880 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.799404  1881 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.799901  1881 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:53.799932  1881 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:53.799993  1881 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:53.800032  1881 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:53.800128  1880 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.800475  1880 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.800501  1790 program_interpreter.cc:1308] main_thread_blocker_(0x439111b8) got event_name: TaskCompletion
2253: I0810 04:04:53.800700  1876 thread_data_registry.h:135] Add data {current : -589844, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 589844}.
2253: I0810 04:04:53.800848  1880 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 589848, peak : 589848}.
2253: I0810 04:04:53.801023  1881 thread_data_registry.h:135] Add data {current : 0, peak : 589844} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.803108  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.803314  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.803350  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.803834  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.803865  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.803969  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44f3df90)  to GradNodeAccumulation (addr: 0x1a728870)
2253: I0810 04:04:53.804096  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:53.804114  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.804348  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44f3df90)
2253: I0810 04:04:53.804454  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:53.804464  1790 backward.cc:113] Start Backward
2253: I0810 04:04:53.804481  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:53.804523  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:53.804558  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:53.804576  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:53.804613  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.804699  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:53.804725  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:53.804736  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44f3df90
2253: I0810 04:04:53.804744  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:53.804775  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44f3df90
2253: I0810 04:04:53.804792  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:53.804806  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.804840  1790 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:53.804873  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:53.804881  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44f3df90, Found pending node: GradNodeAccumulation addr: 0x1a728870
2253: I0810 04:04:53.804886  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:53.804901  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a728870
2253: I0810 04:04:53.804910  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:53.804915  1790 accumulation_node.cc:40] Move Tensor ptr: 0x43eac9b0
2253: I0810 04:04:53.804919  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:53.804922  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
2253: Warning:
2253: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
2253:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
2253:   return func(*args, **kwargs)
2253: I0810 04:04:53.890050  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.890069  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.890111  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.890118  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.891705  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.892163  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.892544  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.892556  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.892561  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.894434  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.894500  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.894510  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.894515  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x446b9240 type is 7
2253: I0810 04:04:53.894522  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.894526  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x446b5c90 type is 7
2253: I0810 04:04:53.894529  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.894532  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x446b6790 type is 7
2253: I0810 04:04:53.894536  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.894541  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.894600  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.894606  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.894610  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.894614  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.894650  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.894662  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.894704  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.894712  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.894743  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.894752  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.894765  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.894770  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x440b9df0Variable Type 7
2253: I0810 04:04:53.894784  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.894801  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.894814  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.894840  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.894847  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.894860  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.894866  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x446b9700Variable Type 7
2253: I0810 04:04:53.894877  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.894889  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.894898  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.895131  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.895161  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.895179  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.895279  1882 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.895339  1883 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.895363  1884 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.895392  1885 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.895428  1886 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.895455  1887 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.895659  1886 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.895665  1885 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.895912  1885 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.895931  1885 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.895951  1790 program_interpreter.cc:1308] main_thread_blocker_(0x446b5788) got event_name: TaskCompletion
2253: I0810 04:04:53.896077  1882 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.896222  1885 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.896309  1886 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 786468, peak : 786468}.
2253: I0810 04:04:53.896412  1887 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.898613  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.898636  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.898686  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.898696  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.900602  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.901160  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.901618  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.901631  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.901636  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.903918  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.903992  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.904004  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.904009  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4407ffe0 type is 7
2253: I0810 04:04:53.904017  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.904023  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4511afb0 type is 7
2253: I0810 04:04:53.904029  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.904033  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4407d5f0 type is 7
2253: I0810 04:04:53.904038  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.904044  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.904130  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.904137  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.904142  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.904146  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.904187  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.904201  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.904251  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.904261  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.904309  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.904320  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.904336  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.904343  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44a62600Variable Type 7
2253: I0810 04:04:53.904357  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.904377  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.904392  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.904430  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.904438  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.904455  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.904462  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x440807e0Variable Type 7
2253: I0810 04:04:53.904474  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.904489  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.904501  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.904752  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.904786  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.904807  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.904904  1888 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.904966  1889 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.904985  1890 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.905037  1891 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.905054  1892 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.905097  1893 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.905283  1892 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.905303  1891 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.905689  1891 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.905707  1891 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.905731  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4511aa68) got event_name: TaskCompletion
2253: I0810 04:04:53.905862  1888 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.906004  1891 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 983076, peak : 983076}.
2253: I0810 04:04:53.906076  1892 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 983088, peak : 983088}.
2253: I0810 04:04:53.906172  1893 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.906347  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.907640  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.907662  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.907711  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.907720  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.909634  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.910197  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.910666  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.910681  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.910686  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.913004  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.913079  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.913090  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.913095  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43cab340 type is 7
2253: I0810 04:04:53.913105  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.913110  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e9b760 type is 7
2253: I0810 04:04:53.913115  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.913118  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e9c210 type is 7
2253: I0810 04:04:53.913123  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.913129  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.913215  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.913223  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.913228  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.913234  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.913275  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.913288  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.913347  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.913358  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.913399  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.913409  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.913426  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.913434  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cabd00Variable Type 7
2253: I0810 04:04:53.913448  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.913468  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.913482  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.913522  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.913530  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.913547  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.913553  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43cacbb0Variable Type 7
2253: I0810 04:04:53.913564  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.913580  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.913591  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.913846  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.913883  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.913909  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.914001  1894 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.914064  1895 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.914083  1896 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.914131  1897 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.914148  1898 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.914183  1899 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.914336  1898 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.914343  1897 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.914711  1898 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.914726  1898 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.914745  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43e9b0e8) got event_name: TaskCompletion
2253: I0810 04:04:53.914875  1894 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.915015  1898 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 1672121383278216900 to 985972397889609550 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.915087  1897 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 985972397889609550 to 11836897867350493708 , after update, data is {current : 1179708, peak : 1179708}.
2253: I0810 04:04:53.915199  1899 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.916910  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.917109  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.917153  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.917531  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.917565  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.921130  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.921329  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.921373  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:04:53.924290  1790 pir_interpreter.cc:161] PirInterpreter(): 0x444533d0 on Place(gpu:0)
2253: I0810 04:04:53.924331  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.924352  1790 scope.cc:202] Create variable 0x444533d01723262693924324078_inner_var_1
2253: I0810 04:04:53.924363  1790 scope.cc:202] Create variable 0x444533d01723262693924324078_inner_var_2
2253: I0810 04:04:53.924374  1790 scope.cc:202] Create variable 0x444533d01723262693924324078_inner_var_3
2253: I0810 04:04:53.924382  1790 scope.cc:202] Create variable 0x444533d01723262693924324078_inner_var_4
2253: I0810 04:04:53.924393  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:53.924402  1790 scope.cc:202] Create variable 0x444533d01723262693924324078_inner_var_6
2253: I0810 04:04:53.924412  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:53.924765  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:53.924780  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.924784  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x43db6280
2253: 1 -> 0x444533d01723262693924324078_inner_var_1 -> 0x44c7c480
2253: 2 -> 0x444533d01723262693924324078_inner_var_2 -> 0x44aa4de0
2253: 3 -> 0x444533d01723262693924324078_inner_var_3 -> 0x43f47960
2253: 4 -> 0x444533d01723262693924324078_inner_var_4 -> 0x43cbdf40
2253: 5 -> fetch0@fetch -> 0x44cc4ea0
2253: 6 -> 0x444533d01723262693924324078_inner_var_6 -> 0x43cc6440
2253: 7 -> fetch1@fetch -> 0x44499910
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:53.925482  1900 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.925549  1901 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.925590  1902 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.925647  1904 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.925657  1903 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.925683  1905 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.925702  1905 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.925734  1905 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.925762  1905 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x444533d01723262693924324078_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_3:[dtype=;place=;dim=;lod={};, 0x444533d01723262693924324078_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.925841  1905 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x444533d01723262693924324078_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x444533d01723262693924324078_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.925900  1904 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444533d01723262693924324078_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.925901  1903 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444533d01723262693924324078_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.925931  1904 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.925938  1903 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.925994  1904 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444533d01723262693924324078_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.926311  1903 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444533d01723262693924324078_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444533d01723262693924324078_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.926324  1904 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x444533d01723262693924324078_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.926342  1904 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.926354  1904 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x444533d01723262693924324078_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.926371  1903 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x444533d01723262693924324078_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.926394  1903 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.926543  1903 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x444533d01723262693924324078_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.926579  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x44453540) got event_name: TaskCompletion
2253: I0810 04:04:53.926600  1790 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.926666  1790 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.928576  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.928774  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.928817  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:04:53.931623  1790 pir_interpreter.cc:161] PirInterpreter(): 0x444f3610 on Place(gpu:0)
2253: I0810 04:04:53.931653  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.931672  1790 scope.cc:202] Create variable 0x444f36101723262693931646728_inner_var_1
2253: I0810 04:04:53.931684  1790 scope.cc:202] Create variable 0x444f36101723262693931646728_inner_var_2
2253: I0810 04:04:53.931691  1790 scope.cc:202] Create variable 0x444f36101723262693931646728_inner_var_3
2253: I0810 04:04:53.931702  1790 scope.cc:202] Create variable 0x444f36101723262693931646728_inner_var_4
2253: I0810 04:04:53.931710  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:53.931723  1790 scope.cc:202] Create variable 0x444f36101723262693931646728_inner_var_6
2253: I0810 04:04:53.931732  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:53.932087  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:53.932101  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.932106  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x43764830
2253: 1 -> 0x444f36101723262693931646728_inner_var_1 -> 0x446e7200
2253: 2 -> 0x444f36101723262693931646728_inner_var_2 -> 0x43d86b60
2253: 3 -> 0x444f36101723262693931646728_inner_var_3 -> 0x43f135a0
2253: 4 -> 0x444f36101723262693931646728_inner_var_4 -> 0x444f8420
2253: 5 -> fetch0@fetch -> 0x43b2eaa0
2253: 6 -> 0x444f36101723262693931646728_inner_var_6 -> 0x440b9690
2253: 7 -> fetch1@fetch -> 0x44420370
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:53.932817  1906 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.932941  1908 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.932942  1907 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.933025  1909 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.933094  1910 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.933176  1911 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.933207  1911 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.933236  1911 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.933264  1911 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x444f36101723262693931646728_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_3:[dtype=;place=;dim=;lod={};, 0x444f36101723262693931646728_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.933347  1911 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x444f36101723262693931646728_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x444f36101723262693931646728_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.933405  1910 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444f36101723262693931646728_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.933446  1910 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.933426  1909 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444f36101723262693931646728_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.933477  1909 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.933799  1910 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444f36101723262693931646728_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.933832  1909 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x444f36101723262693931646728_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x444f36101723262693931646728_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.933837  1910 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x444f36101723262693931646728_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.933868  1910 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.933879  1909 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x444f36101723262693931646728_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:53.933898  1909 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.933912  1909 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x444f36101723262693931646728_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:04:53.934015  1910 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x444f36101723262693931646728_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:04:53.934051  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x444f3780) got event_name: TaskCompletion
2253: I0810 04:04:53.934063  1790 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.934100  1790 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:04:53.934250  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:45
2253: I0810 04:04:53.934336  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:53.934350  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:46
2253: I0810 04:04:53.934365  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:53.935171  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.935190  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.935235  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.935241  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.936806  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.937258  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.937654  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.937666  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.937671  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.939504  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.939563  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.939571  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.939576  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4433fc50 type is 7
2253: I0810 04:04:53.939584  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.939587  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4430fb90 type is 7
2253: I0810 04:04:53.939591  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.939595  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x440b81e0 type is 7
2253: I0810 04:04:53.939600  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.939605  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.939663  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.939669  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.939673  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.939677  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.939713  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.939725  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.939769  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.939776  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.939808  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.939817  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.939831  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.939836  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44cf4a70Variable Type 7
2253: I0810 04:04:53.939850  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.939867  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.939879  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.939904  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.939913  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.939925  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.939931  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44cf5ba0Variable Type 7
2253: I0810 04:04:53.939942  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.939954  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.939963  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.940167  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.940197  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.940217  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.940337  1912 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.940479  1914 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.940479  1913 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.940558  1915 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.940641  1916 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.940687  1917 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.940848  1916 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.940850  1915 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.941220  1916 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.941236  1916 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.941254  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4430f788) got event_name: TaskCompletion
2253: I0810 04:04:53.941385  1912 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 13824773680407106994 to 99701420204608342 , after update, data is {current : -393240, peak : 0}.
2253: I0810 04:04:53.941534  1916 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 7708048296032173470 to 14385946922105763111 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.941574  1915 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 14385946922105763111 to 99701420204608342 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.941713  1917 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 13152789332281370610 to 99701420204608342 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:04:53.941856  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.943008  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.943027  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.943078  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.943085  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.944655  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.945109  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.945482  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.945494  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.945500  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.947326  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.947386  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.947396  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.947400  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x444c7040 type is 7
2253: I0810 04:04:53.947407  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.947410  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43916110 type is 7
2253: I0810 04:04:53.947414  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.947418  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x444c4580 type is 7
2253: I0810 04:04:53.947422  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.947428  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.947486  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.947492  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.947499  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.947501  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.947536  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.947547  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.947589  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.947598  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.947629  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.947638  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.947651  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.947657  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e959f0Variable Type 7
2253: I0810 04:04:53.947670  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.947687  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.947700  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.947723  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.947731  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.947744  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.947750  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x444199b0Variable Type 7
2253: I0810 04:04:53.947760  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.947773  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.947782  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.947979  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.948009  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.948025  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.948118  1918 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.948184  1919 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.948205  1920 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.948266  1922 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.948269  1921 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.948334  1923 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.948554  1921 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.948557  1922 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.948833  1922 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.948853  1922 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.948876  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43915ba8) got event_name: TaskCompletion
2253: I0810 04:04:53.949002  1918 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 13152789332281370610 to 13456996948208181472 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.949172  1922 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 10600705262021306540 to 99701420204608342 , after update, data is {current : 196608, peak : 196620}.
2253: I0810 04:04:53.949252  1921 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 13824773680407106994 to 99701420204608342 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:04:53.949370  1923 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 13456996948208181472 to 99701420204608342 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:04:53.951356  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.951557  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.951599  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.951958  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.951992  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.954995  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.955016  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.955067  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.955076  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.956265  1900 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.956275  1900 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : -393240, peak : 196620}.
2253: I0810 04:04:53.956454  1903 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 9497174210020301017 to 99701420204608342 , after update, data is {current : 393216, peak : 393216}.
2253: I0810 04:04:53.956494  1904 thread_data_registry.h:135] Add data {current : 24, peak : 24} from thread 15482172826034771369 to 99701420204608342 , after update, data is {current : 393240, peak : 393240}.
2253: I0810 04:04:53.956641  1905 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:04:53.956817  1906 thread_data_registry.h:135] Add data {current : 393240, peak : 393240} from thread 99701420204608342 to 15785496349805031021 , after update, data is {current : 393264, peak : 393264}.
2253: I0810 04:04:53.956826  1906 thread_data_registry.h:135] Add data {current : -196620, peak : 196620} from thread 99701420204608342 to 11836897867350493708 , after update, data is {current : -393240, peak : 589844}.
2253: I0810 04:04:53.956974  1910 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 4370860029569601088 to 15785496349805031021 , after update, data is {current : 786480, peak : 786480}.
2253: I0810 04:04:53.957054  1909 thread_data_registry.h:135] Add data {current : 786480, peak : 786480} from thread 15785496349805031021 to 11836897867350493708 , after update, data is {current : 1966188, peak : 1966188}.
2253: I0810 04:04:53.957166  1911 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 8141334110365927881 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.958714  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.959292  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.959762  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.959777  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.959782  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.962086  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.962164  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.962175  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.962181  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44aa7470 type is 7
2253: I0810 04:04:53.962189  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.962195  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43e9a6f0 type is 7
2253: I0810 04:04:53.962201  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.962208  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43ecd3d0 type is 7
2253: I0810 04:04:53.962213  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.962219  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.962291  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.962298  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.962311  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.962316  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.962357  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.962370  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.962419  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.962430  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.962467  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.962477  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.962492  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.962499  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x436eda60Variable Type 7
2253: I0810 04:04:53.962515  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.962534  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.962548  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.962579  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.962589  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.962603  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.962610  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4441fc20Variable Type 7
2253: I0810 04:04:53.962622  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.962637  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.962649  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.962893  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.962926  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.962947  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.963038  1924 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.963107  1925 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.963130  1926 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.963165  1927 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.963196  1928 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.963238  1929 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.963392  1928 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.963398  1927 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.963750  1927 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.963765  1927 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.963786  1790 program_interpreter.cc:1308] main_thread_blocker_(0x45116068) got event_name: TaskCompletion
2253: I0810 04:04:53.963917  1924 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 8141334110365927881 to 14824236449615686365 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:04:53.964058  1927 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 2162796, peak : 2162796}.
2253: I0810 04:04:53.964133  1928 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2162808, peak : 2162808}.
2253: I0810 04:04:53.964227  1929 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.964391  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.965049  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.965082  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.965095  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.965224  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:53.966274  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.966295  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.966354  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.966364  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.967149  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:53.967170  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:53.967211  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:53.967218  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:53.967566  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.967630  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:53.968000  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:53.968099  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:53.968111  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:53.968189  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:53.968199  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:53.970677  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.971292  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.971320  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.971326  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.974726  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.974745  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:53.974777  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.974787  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.974792  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x441491f0 type is 7
2253: I0810 04:04:53.974800  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:53.974807  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x43af61c0 type is 7
2253: I0810 04:04:53.974813  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.974817  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43af5b10 type is 7
2253: I0810 04:04:53.974823  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.974828  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x441499c0 type is 7
2253: I0810 04:04:53.974833  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:53.974839  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44149c30 type is 7
2253: I0810 04:04:53.974848  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:53.974853  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44149e70 type is 7
2253: I0810 04:04:53.974859  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:53.974866  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x4414a0d0 type is 7
2253: I0810 04:04:53.974871  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x441491d0 type is 9
2253: I0810 04:04:53.974877  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:53.974882  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44149e50 type is 10
2253: I0810 04:04:53.975001  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.975009  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.975014  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.975018  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.975066  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975080  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975131  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975140  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975183  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975191  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975234  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975244  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975275  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975283  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975330  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975340  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975371  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.975380  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.975399  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.975405  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43f65ac0Variable Type 7
2253: I0810 04:04:53.975421  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.975441  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.975455  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.975742  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.975787  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:53.975818  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.975926  1930 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.975991  1931 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.976007  1932 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.976065  1933 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.976079  1934 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.976132  1935 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.976456  1935 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:53.976482  1935 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:53.976536  1935 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:53.977020  1935 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:53.977118  1934 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.977489  1934 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.977514  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43af69a8) got event_name: TaskCompletion
2253: I0810 04:04:53.977839  1930 thread_data_registry.h:135] Add data {current : -196608, peak : 0} from thread 14824236449615686365 to 1672121383278216900 , after update, data is {current : 0, peak : 196608}.
2253: I0810 04:04:53.977854  1930 thread_data_registry.h:135] Add data {current : -589844, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 589844}.
2253: I0810 04:04:53.978071  1934 thread_data_registry.h:135] Add data {current : 0, peak : 196608} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 2162808, peak : 2162808}.
2253: I0810 04:04:53.978178  1935 thread_data_registry.h:135] Add data {current : 0, peak : 589844} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.979620  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:53.979835  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:53.979875  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:53.980473  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.980509  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.981024  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43eada00)  to GradNodeAccumulation (addr: 0x1a728870)
2253: I0810 04:04:53.981135  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:53.981158  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.981343  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43eada00)
2253: I0810 04:04:53.981423  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:53.981431  1790 backward.cc:113] Start Backward
2253: I0810 04:04:53.981442  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:53.981478  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:53.981508  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:53.981515  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:53.981541  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.981582  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:53.981604  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:53.981613  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43eada00
2253: I0810 04:04:53.981618  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:53.981642  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43eada00
2253: I0810 04:04:53.981650  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:53.981664  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:53.981688  1790 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:53.981724  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:53.981730  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43eada00, Found pending node: GradNodeAccumulation addr: 0x1a728870
2253: I0810 04:04:53.981735  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:53.981751  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a728870
2253: I0810 04:04:53.981758  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:53.981763  1790 accumulation_node.cc:40] Move Tensor ptr: 0x43fa3cd0
2253: I0810 04:04:53.981767  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:53.981772  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:53.984781  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.984803  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.984854  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.984864  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.986721  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.987284  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.987746  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.987761  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.987766  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.990064  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.990132  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.990144  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.990149  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x444e96e0 type is 7
2253: I0810 04:04:53.990156  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.990163  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x444e60f0 type is 7
2253: I0810 04:04:53.990170  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.990175  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x444e6bb0 type is 7
2253: I0810 04:04:53.990180  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.990185  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.990267  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.990273  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.990278  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.990283  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.990331  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.990346  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.990396  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.990406  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.990444  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.990453  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.990470  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.990478  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4432e270Variable Type 7
2253: I0810 04:04:53.990492  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.990512  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.990526  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.990566  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.990576  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.990592  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.990597  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4432dc80Variable Type 7
2253: I0810 04:04:53.990612  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.990628  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.990639  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.990877  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.990911  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.990933  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.991035  1936 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:53.991099  1937 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:53.991123  1938 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:53.991168  1939 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:53.991194  1940 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:53.991232  1941 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:53.991464  1940 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.991465  1939 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:53.991606  1939 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:53.991622  1939 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:53.991647  1790 program_interpreter.cc:1308] main_thread_blocker_(0x444e5b88) got event_name: TaskCompletion
2253: I0810 04:04:53.991782  1936 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:53.991940  1939 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 2192808, peak : 2192808}.
2253: I0810 04:04:53.991978  1940 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2192888, peak : 2192888}.
2253: I0810 04:04:53.992120  1941 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:53.993896  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.993918  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.993968  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:53.993978  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.995831  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.996397  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:53.996829  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.996841  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.996846  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.999051  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:53.999126  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:53.999138  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:53.999143  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b654e0 type is 7
2253: I0810 04:04:53.999152  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:53.999157  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43b62070 type is 7
2253: I0810 04:04:53.999164  1790 scope.cc:202] Create variable X
2253: I0810 04:04:53.999167  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43b62af0 type is 7
2253: I0810 04:04:53.999174  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:53.999181  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:53.999248  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:53.999255  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:53.999261  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:53.999265  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:53.999315  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.999330  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.999379  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.999389  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.999428  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.999436  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.999452  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.999459  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44cb7d80Variable Type 7
2253: I0810 04:04:53.999473  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.999493  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.999507  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.999538  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.999547  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:53.999562  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:53.999568  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44cb0280Variable Type 7
2253: I0810 04:04:53.999581  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:53.999598  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:53.999609  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:53.999842  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:53.999876  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:53.999897  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.000000  1942 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.000065  1943 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.000087  1944 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.000135  1945 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.000156  1946 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.000195  1947 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.000408  1946 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.000422  1945 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.000535  1945 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.000550  1945 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.000573  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43b61b28) got event_name: TaskCompletion
2253: I0810 04:04:54.000702  1942 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.000851  1945 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 30080, peak : 30080}.
2253: I0810 04:04:54.000926  1946 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 2222968, peak : 2222968}.
2253: I0810 04:04:54.001029  1947 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.001200  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.003458  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.003476  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.003522  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.003530  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.005072  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.005539  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.005916  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.005928  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.005934  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.007841  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.007905  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.007915  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.007920  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x442e4c70 type is 7
2253: I0810 04:04:54.007925  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.007930  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43b02dc0 type is 7
2253: I0810 04:04:54.007933  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.007936  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e95880 type is 7
2253: I0810 04:04:54.007942  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.007947  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.008006  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.008013  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.008016  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.008020  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.008052  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.008064  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.008101  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.008111  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.008141  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.008148  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.008162  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.008168  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x446baa10Variable Type 7
2253: I0810 04:04:54.008181  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.008198  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.008209  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.008232  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.008240  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.008253  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.008258  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4506f820Variable Type 7
2253: I0810 04:04:54.008267  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.008280  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.008288  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.008493  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.008522  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.008540  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.008625  1948 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.008690  1949 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.008703  1950 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.008742  1951 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.008767  1952 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.008805  1953 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.008971  1951 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.008987  1952 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.009095  1951 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.009109  1951 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.009130  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44b27698) got event_name: TaskCompletion
2253: I0810 04:04:54.009249  1948 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.009406  1951 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 2252968, peak : 2252968}.
2253: I0810 04:04:54.009480  1952 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2253048, peak : 2253048}.
2253: I0810 04:04:54.009588  1953 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.010872  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.011039  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.011082  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.011443  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.011476  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.013491  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.013639  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.013680  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:04:54.016559  1790 pir_interpreter.cc:161] PirInterpreter(): 0x44cc51d0 on Place(gpu:0)
2253: I0810 04:04:54.016590  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.016610  1790 scope.cc:202] Create variable 0x44cc51d01723262694016583527_inner_var_1
2253: I0810 04:04:54.016621  1790 scope.cc:202] Create variable 0x44cc51d01723262694016583527_inner_var_2
2253: I0810 04:04:54.016633  1790 scope.cc:202] Create variable 0x44cc51d01723262694016583527_inner_var_3
2253: I0810 04:04:54.016642  1790 scope.cc:202] Create variable 0x44cc51d01723262694016583527_inner_var_4
2253: I0810 04:04:54.016654  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.016662  1790 scope.cc:202] Create variable 0x44cc51d01723262694016583527_inner_var_6
2253: I0810 04:04:54.016671  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.016992  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.017005  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.017009  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x436ef6d0
2253: 1 -> 0x44cc51d01723262694016583527_inner_var_1 -> 0x436ef750
2253: 2 -> 0x44cc51d01723262694016583527_inner_var_2 -> 0x444e4c40
2253: 3 -> 0x44cc51d01723262694016583527_inner_var_3 -> 0x4427d080
2253: 4 -> 0x44cc51d01723262694016583527_inner_var_4 -> 0x450e51f0
2253: 5 -> fetch0@fetch -> 0x440b6ce0
2253: 6 -> 0x44cc51d01723262694016583527_inner_var_6 -> 0x43516dc0
2253: 7 -> fetch1@fetch -> 0x444e6ec0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.017691  1954 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.017755  1955 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.017773  1956 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.017818  1957 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.017850  1958 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.017889  1959 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.017906  1959 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.017937  1959 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.017964  1959 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44cc51d01723262694016583527_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44cc51d01723262694016583527_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.018074  1959 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44cc51d01723262694016583527_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x44cc51d01723262694016583527_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.018124  1958 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44cc51d01723262694016583527_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.018134  1957 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44cc51d01723262694016583527_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.018153  1958 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.018168  1957 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.018219  1958 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44cc51d01723262694016583527_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.018277  1957 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44cc51d01723262694016583527_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44cc51d01723262694016583527_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.018287  1958 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44cc51d01723262694016583527_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.018311  1958 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.018321  1958 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44cc51d01723262694016583527_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.018364  1957 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44cc51d01723262694016583527_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.018384  1957 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.018400  1957 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44cc51d01723262694016583527_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.018431  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x44cc5340) got event_name: TaskCompletion
2253: I0810 04:04:54.018455  1790 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.018483  1790 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.019908  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.020064  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.020105  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:04:54.022964  1790 pir_interpreter.cc:161] PirInterpreter(): 0x451198e0 on Place(gpu:0)
2253: I0810 04:04:54.022993  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.023011  1790 scope.cc:202] Create variable 0x451198e01723262694022986478_inner_var_1
2253: I0810 04:04:54.023022  1790 scope.cc:202] Create variable 0x451198e01723262694022986478_inner_var_2
2253: I0810 04:04:54.023030  1790 scope.cc:202] Create variable 0x451198e01723262694022986478_inner_var_3
2253: I0810 04:04:54.023041  1790 scope.cc:202] Create variable 0x451198e01723262694022986478_inner_var_4
2253: I0810 04:04:54.023049  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.023061  1790 scope.cc:202] Create variable 0x451198e01723262694022986478_inner_var_6
2253: I0810 04:04:54.023068  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.023384  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.023398  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.023402  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x44ad0340
2253: 1 -> 0x451198e01723262694022986478_inner_var_1 -> 0x44ad0360
2253: 2 -> 0x451198e01723262694022986478_inner_var_2 -> 0x444f79d0
2253: 3 -> 0x451198e01723262694022986478_inner_var_3 -> 0x44ad04b0
2253: 4 -> 0x451198e01723262694022986478_inner_var_4 -> 0x446ba4b0
2253: 5 -> fetch0@fetch -> 0x4414c5d0
2253: 6 -> 0x451198e01723262694022986478_inner_var_6 -> 0x446ba4d0
2253: 7 -> fetch1@fetch -> 0x43781da0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.024066  1960 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.024163  1961 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.024192  1962 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.024226  1963 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.024255  1964 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.024293  1965 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.024319  1965 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.024350  1965 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.024379  1965 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x451198e01723262694022986478_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_3:[dtype=;place=;dim=;lod={};, 0x451198e01723262694022986478_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.024487  1965 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x451198e01723262694022986478_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x451198e01723262694022986478_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.024549  1963 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451198e01723262694022986478_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.024546  1964 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451198e01723262694022986478_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.024581  1963 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.024587  1964 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.024637  1963 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451198e01723262694022986478_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.024699  1964 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451198e01723262694022986478_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x451198e01723262694022986478_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.024708  1963 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x451198e01723262694022986478_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.024726  1963 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.024737  1963 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x451198e01723262694022986478_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.024762  1964 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x451198e01723262694022986478_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.024782  1964 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.024802  1964 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x451198e01723262694022986478_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.024837  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x45119a50) got event_name: TaskCompletion
2253: I0810 04:04:54.024859  1790 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.024891  1790 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.025036  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:71
2253: I0810 04:04:54.025122  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.025138  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:72
2253: I0810 04:04:54.025156  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.026099  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.026120  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.026171  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.026180  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.028019  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.028581  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.029018  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.029032  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.029037  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.031267  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.031355  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.031368  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.031373  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d296b0 type is 7
2253: I0810 04:04:54.031381  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.031386  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44485200 type is 7
2253: I0810 04:04:54.031394  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.031397  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43b606d0 type is 7
2253: I0810 04:04:54.031404  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.031410  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.031479  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.031486  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.031492  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.031497  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.031538  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.031551  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.031598  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.031608  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.031646  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.031654  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.031670  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.031677  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x442d0150Variable Type 7
2253: I0810 04:04:54.031692  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.031713  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.031725  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.031757  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.031766  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.031782  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.031790  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d55a70Variable Type 7
2253: I0810 04:04:54.031801  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.031816  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.031829  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.032063  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.032097  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.032120  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.032233  1966 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.032323  1967 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.032363  1968 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.032389  1969 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.032430  1970 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.032469  1971 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.032680  1970 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.032680  1969 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.032833  1970 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.032848  1970 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.032871  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44484cb8) got event_name: TaskCompletion
2253: I0810 04:04:54.033003  1966 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 13824773680407106994 to 99701420204608342 , after update, data is {current : -60160, peak : 0}.
2253: I0810 04:04:54.033160  1970 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 7708048296032173470 to 14824236449615686365 , after update, data is {current : -80, peak : 30000}.
2253: I0810 04:04:54.033234  1969 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 14385946922105763111 to 14824236449615686365 , after update, data is {current : 0, peak : 30000}.
2253: I0810 04:04:54.033368  1971 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 13152789332281370610 to 99701420204608342 , after update, data is {current : -30080, peak : 30080}.
2253: I0810 04:04:54.033542  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.034881  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.034904  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.034953  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.034962  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.036276  1954 thread_data_registry.h:135] Add data {current : 0, peak : 30000} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -30080, peak : 30000}.
2253: I0810 04:04:54.036288  1954 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -60160, peak : 30080}.
2253: I0810 04:04:54.036530  1957 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 985972397889609550 to 99701420204608342 , after update, data is {current : 29920, peak : 60000}.
2253: I0810 04:04:54.036608  1958 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 1672121383278216900 to 99701420204608342 , after update, data is {current : 30080, peak : 60000}.
2253: I0810 04:04:54.036720  1959 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : -30080, peak : 30080}.
2253: I0810 04:04:54.036888  1960 thread_data_registry.h:135] Add data {current : 30080, peak : 60000} from thread 99701420204608342 to 15785496349805031021 , after update, data is {current : 30240, peak : 60000}.
2253: I0810 04:04:54.036901  1960 thread_data_registry.h:135] Add data {current : -30080, peak : 30080} from thread 99701420204608342 to 11836897867350493708 , after update, data is {current : -226700, peak : 589844}.
2253: I0810 04:04:54.037073  1963 thread_data_registry.h:135] Add data {current : 30240, peak : 60000} from thread 15785496349805031021 to 11836897867350493708 , after update, data is {current : 2283288, peak : 2283288}.
2253: I0810 04:04:54.037113  1964 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 4370860029569601088 to 11836897867350493708 , after update, data is {current : 2343288, peak : 2343288}.
2253: I0810 04:04:54.037259  1965 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 8141334110365927881 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.038530  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.039109  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.039592  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.039606  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.039613  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.041971  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.042048  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.042059  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.042065  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e983b0 type is 7
2253: I0810 04:04:54.042073  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.042079  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44c81310 type is 7
2253: I0810 04:04:54.042086  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.042093  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43ea88a0 type is 7
2253: I0810 04:04:54.042098  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.042104  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.042179  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.042186  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.042191  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.042196  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.042235  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.042248  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.042296  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.042316  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.042354  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.042364  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.042379  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.042387  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x446ba7f0Variable Type 7
2253: I0810 04:04:54.042402  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.042420  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.042435  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.042466  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.042474  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.042490  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.042496  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x444c7b20Variable Type 7
2253: I0810 04:04:54.042510  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.042524  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.042537  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.042773  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.042809  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.042829  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.042939  1972 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.043022  1973 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.043025  1974 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.043097  1976 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.043108  1975 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.043161  1977 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.043380  1975 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.043403  1976 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.043517  1975 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.043531  1975 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.043555  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4445e198) got event_name: TaskCompletion
2253: I0810 04:04:54.043689  1972 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 8141334110365927881 to 14824236449615686365 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.043854  1975 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 2373288, peak : 2373288}.
2253: I0810 04:04:54.043931  1976 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2373368, peak : 2373368}.
2253: I0810 04:04:54.044039  1977 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.045296  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.045475  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.045517  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.045872  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.045902  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.048331  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.048353  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.048403  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.048413  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.050243  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.050813  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.051254  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.051267  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.051272  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.053535  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.053613  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.053624  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.053630  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44cb3210 type is 7
2253: I0810 04:04:54.053638  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.053643  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44330330 type is 7
2253: I0810 04:04:54.053650  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.053654  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a61010 type is 7
2253: I0810 04:04:54.053660  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.053666  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.053735  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.053741  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.053747  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.053752  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.053791  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.053804  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.053853  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.053862  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.053900  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.053908  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.053925  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.053931  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44c49120Variable Type 7
2253: I0810 04:04:54.053946  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.053965  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.053978  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.054009  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.054018  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.054034  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.054041  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44cb3660Variable Type 7
2253: I0810 04:04:54.054052  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.054068  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.054080  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.054323  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.054358  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.054379  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.054477  1978 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.054544  1979 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.054569  1980 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.054612  1981 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.054638  1982 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.054674  1983 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.054857  1982 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.054860  1981 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.054989  1981 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.055006  1981 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.055024  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4432fe38) got event_name: TaskCompletion
2253: I0810 04:04:54.055148  1978 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.055315  1981 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 30080, peak : 30080}.
2253: I0810 04:04:54.055392  1982 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 2403448, peak : 2403448}.
2253: I0810 04:04:54.055500  1983 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.055661  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.056196  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.056227  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.056239  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.056371  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:54.057356  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.057377  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.057427  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.057437  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.058164  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.058184  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.058223  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.058231  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.058573  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.058636  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.058996  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:54.059092  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:54.059103  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.059180  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.059190  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.061658  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.062265  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.062280  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.062285  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.065644  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.065663  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:54.065694  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.065704  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.065708  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4406e120 type is 7
2253: I0810 04:04:54.065716  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:54.065721  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x450d54b0 type is 7
2253: I0810 04:04:54.065728  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.065732  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x450d4e00 type is 7
2253: I0810 04:04:54.065737  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.065742  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4406e8f0 type is 7
2253: I0810 04:04:54.065747  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:54.065750  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4406eb60 type is 7
2253: I0810 04:04:54.065755  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:54.065759  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4406eda0 type is 7
2253: I0810 04:04:54.065766  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:54.065770  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x4406f000 type is 7
2253: I0810 04:04:54.065775  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4406e100 type is 9
2253: I0810 04:04:54.065781  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:54.065785  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4406ed80 type is 10
2253: I0810 04:04:54.065881  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.065888  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.065893  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.065898  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.065945  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.065959  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066007  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066016  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066054  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066064  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066099  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066109  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066138  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066147  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066185  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066195  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066223  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.066232  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.066248  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.066255  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x436a7d30Variable Type 7
2253: I0810 04:04:54.066270  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.066290  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.066315  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.066599  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.066645  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.066676  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.066777  1984 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.066848  1985 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.066867  1986 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.066911  1987 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.066938  1988 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.066985  1989 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.067339  1989 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.067364  1989 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.067427  1989 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.067466  1989 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.067546  1988 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.067641  1988 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.067670  1790 program_interpreter.cc:1308] main_thread_blocker_(0x450d5c98) got event_name: TaskCompletion
2253: I0810 04:04:54.067823  1984 thread_data_registry.h:135] Add data {current : -90088, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 90088}.
2253: I0810 04:04:54.067975  1988 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2433448, peak : 2433448}.
2253: I0810 04:04:54.068150  1989 thread_data_registry.h:135] Add data {current : 0, peak : 90088} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.069160  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.069345  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.069386  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.069972  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.070006  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.070117  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x4372f540)  to GradNodeAccumulation (addr: 0x1a728870)
2253: I0810 04:04:54.070201  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:54.070220  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.070387  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x4372f540)
2253: I0810 04:04:54.070464  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:54.070472  1790 backward.cc:113] Start Backward
2253: I0810 04:04:54.070482  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:54.070515  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.070544  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:54.070551  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:54.070575  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.070621  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.070642  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.070652  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x4372f540
2253: I0810 04:04:54.070657  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.070680  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x4372f540
2253: I0810 04:04:54.070688  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.070703  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.070729  1790 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.070762  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.070770  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x4372f540, Found pending node: GradNodeAccumulation addr: 0x1a728870
2253: I0810 04:04:54.070775  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.070796  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a728870
2253: I0810 04:04:54.070802  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.070808  1790 accumulation_node.cc:40] Move Tensor ptr: 0x43f755f0
2253: I0810 04:04:54.070813  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.070818  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.082760  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.082778  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.082820  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.082828  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.084321  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.084777  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.085134  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.085145  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.085150  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.086963  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.087030  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.087041  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.087046  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x445f0430 type is 7
2253: I0810 04:04:54.087052  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.087059  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4440fd80 type is 7
2253: I0810 04:04:54.087064  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.087067  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x445ed850 type is 7
2253: I0810 04:04:54.087072  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.087077  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.087132  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.087138  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.087142  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.087146  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.087178  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.087189  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.087229  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.087237  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.087267  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.087275  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.087288  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.087294  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445f0f80Variable Type 7
2253: I0810 04:04:54.087316  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.087332  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.087344  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.087379  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.087388  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.087401  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.087405  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445f1d60Variable Type 7
2253: I0810 04:04:54.087415  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.087428  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.087440  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.087641  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.087668  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.087685  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.087777  1990 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.087831  1991 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.087852  1992 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.087893  1993 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.087917  1994 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.087955  1995 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.088137  1994 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.088148  1993 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.088263  1993 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.088279  1993 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.088307  1790 program_interpreter.cc:1308] main_thread_blocker_(0x445edb08) got event_name: TaskCompletion
2253: I0810 04:04:54.088429  1990 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.088569  1993 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 30080, peak : 30080}.
2253: I0810 04:04:54.088644  1994 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 2463528, peak : 2463528}.
2253: I0810 04:04:54.088742  1995 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.091432  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.091454  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.091498  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.091506  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.093012  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.093468  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.093838  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.093850  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.093855  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.095700  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.095768  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.095777  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.095782  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b71b80 type is 7
2253: I0810 04:04:54.095788  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.095793  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44408a00 type is 7
2253: I0810 04:04:54.095798  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.095800  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cba840 type is 7
2253: I0810 04:04:54.095804  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.095809  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.095868  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.095875  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.095878  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.095882  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.095914  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.095927  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.095965  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.095973  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.096004  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.096011  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.096025  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.096031  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x444e4bd0Variable Type 7
2253: I0810 04:04:54.096045  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.096060  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.096072  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.096096  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.096103  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.096117  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.096122  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44408300Variable Type 7
2253: I0810 04:04:54.096132  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.096145  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.096156  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.096354  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.096383  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.096402  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.096489  1996 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.096549  1997 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.096560  1998 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.096599  1999 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.096629  2000 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.096671  2001 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.096870  1999 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.096871  2000 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.097007  1999 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.097021  1999 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.097043  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44407f48) got event_name: TaskCompletion
2253: I0810 04:04:54.097159  1996 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.097313  1999 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 2493528, peak : 2493528}.
2253: I0810 04:04:54.097388  2000 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2493608, peak : 2493608}.
2253: I0810 04:04:54.097489  2001 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.097647  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.098677  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.098695  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.098737  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.098745  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.100248  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.100711  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.101076  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.101087  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.101094  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.102950  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.103015  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.103025  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.103030  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x442d0820 type is 7
2253: I0810 04:04:54.103036  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.103039  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43d15a90 type is 7
2253: I0810 04:04:54.103044  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.103047  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4448a2c0 type is 7
2253: I0810 04:04:54.103051  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.103056  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.103112  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.103118  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.103122  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.103127  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.103158  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.103169  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.103207  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.103215  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.103245  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.103253  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.103267  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.103273  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44073030Variable Type 7
2253: I0810 04:04:54.103286  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.103309  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.103322  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.103346  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.103354  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.103367  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.103374  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44072c00Variable Type 7
2253: I0810 04:04:54.103384  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.103396  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.103406  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.103595  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.103624  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.103642  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.103729  2002 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.103785  2003 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.103803  2004 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.103840  2005 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.103864  2006 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.103905  2007 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.104085  2006 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.104090  2005 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.104223  2005 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.104238  2005 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.104256  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43d15528) got event_name: TaskCompletion
2253: I0810 04:04:54.104377  2002 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.104528  2005 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 30080, peak : 30080}.
2253: I0810 04:04:54.104606  2006 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 2523688, peak : 2523688}.
2253: I0810 04:04:54.104704  2007 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.105870  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.106027  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.106068  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.106428  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.106459  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.108448  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.108597  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.108637  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:04:54.111447  1790 pir_interpreter.cc:161] PirInterpreter(): 0x43f40b50 on Place(gpu:0)
2253: I0810 04:04:54.111477  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.111496  1790 scope.cc:202] Create variable 0x43f40b501723262694111471050_inner_var_1
2253: I0810 04:04:54.111507  1790 scope.cc:202] Create variable 0x43f40b501723262694111471050_inner_var_2
2253: I0810 04:04:54.111516  1790 scope.cc:202] Create variable 0x43f40b501723262694111471050_inner_var_3
2253: I0810 04:04:54.111526  1790 scope.cc:202] Create variable 0x43f40b501723262694111471050_inner_var_4
2253: I0810 04:04:54.111537  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.111549  1790 scope.cc:202] Create variable 0x43f40b501723262694111471050_inner_var_6
2253: I0810 04:04:54.111559  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.111872  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.111886  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.111889  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x450a4ca0
2253: 1 -> 0x43f40b501723262694111471050_inner_var_1 -> 0x44b2c820
2253: 2 -> 0x43f40b501723262694111471050_inner_var_2 -> 0x440b4570
2253: 3 -> 0x43f40b501723262694111471050_inner_var_3 -> 0x445f35a0
2253: 4 -> 0x43f40b501723262694111471050_inner_var_4 -> 0x4440d5f0
2253: 5 -> fetch0@fetch -> 0x4406fa50
2253: 6 -> 0x43f40b501723262694111471050_inner_var_6 -> 0x4440d610
2253: 7 -> fetch1@fetch -> 0x44267160
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.112552  2008 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.112629  2009 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.112644  2010 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.112690  2011 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.112718  2012 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.112763  2013 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.112784  2013 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.112813  2013 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.112843  2013 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43f40b501723262694111471050_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43f40b501723262694111471050_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.112959  2013 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43f40b501723262694111471050_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x43f40b501723262694111471050_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.113013  2012 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f40b501723262694111471050_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.113019  2011 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f40b501723262694111471050_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.113044  2012 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.113049  2011 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.113122  2012 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f40b501723262694111471050_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.113148  2011 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f40b501723262694111471050_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x43f40b501723262694111471050_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.113157  2012 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43f40b501723262694111471050_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.113174  2012 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.113197  2012 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43f40b501723262694111471050_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.113212  2011 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43f40b501723262694111471050_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.113232  2011 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.113245  2011 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43f40b501723262694111471050_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.113276  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x43f40cc0) got event_name: TaskCompletion
2253: I0810 04:04:54.113306  1790 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.113335  1790 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.114727  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.114883  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.114924  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:04:54.117687  1790 pir_interpreter.cc:161] PirInterpreter(): 0x44264760 on Place(gpu:0)
2253: I0810 04:04:54.117717  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.117734  1790 scope.cc:202] Create variable 0x442647601723262694117710093_inner_var_1
2253: I0810 04:04:54.117744  1790 scope.cc:202] Create variable 0x442647601723262694117710093_inner_var_2
2253: I0810 04:04:54.117756  1790 scope.cc:202] Create variable 0x442647601723262694117710093_inner_var_3
2253: I0810 04:04:54.117767  1790 scope.cc:202] Create variable 0x442647601723262694117710093_inner_var_4
2253: I0810 04:04:54.117776  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.117787  1790 scope.cc:202] Create variable 0x442647601723262694117710093_inner_var_6
2253: I0810 04:04:54.117797  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.118103  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.118116  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.118120  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x44264700
2253: 1 -> 0x442647601723262694117710093_inner_var_1 -> 0x44264740
2253: 2 -> 0x442647601723262694117710093_inner_var_2 -> 0x44cb1fb0
2253: 3 -> 0x442647601723262694117710093_inner_var_3 -> 0x4353b970
2253: 4 -> 0x442647601723262694117710093_inner_var_4 -> 0x4353bd40
2253: 5 -> fetch0@fetch -> 0x44332790
2253: 6 -> 0x442647601723262694117710093_inner_var_6 -> 0x4353bd60
2253: 7 -> fetch1@fetch -> 0x44cb1700
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.118799  2014 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.118878  2015 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.118911  2016 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.118935  2017 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.118968  2018 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.118999  2019 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.119016  2019 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.119036  2019 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.119061  2019 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442647601723262694117710093_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_3:[dtype=;place=;dim=;lod={};, 0x442647601723262694117710093_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.119169  2019 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442647601723262694117710093_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x442647601723262694117710093_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.119217  2018 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442647601723262694117710093_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.119222  2017 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442647601723262694117710093_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.119242  2018 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.119244  2017 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.119309  2017 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442647601723262694117710093_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.119383  2018 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442647601723262694117710093_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x442647601723262694117710093_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.119387  2017 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442647601723262694117710093_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.119413  2017 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.119423  2017 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442647601723262694117710093_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:04:54.119431  2018 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442647601723262694117710093_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.119448  2018 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.119482  2018 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442647601723262694117710093_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:04:54.119514  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x442648d0) got event_name: TaskCompletion
2253: I0810 04:04:54.119534  1790 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.119562  1790 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.119706  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:97
2253: I0810 04:04:54.119786  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.119801  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:98
2253: I0810 04:04:54.119819  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.120760  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.120781  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.120832  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.120842  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.122217  2008 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : -60160, peak : 0}.
2253: I0810 04:04:54.122226  2008 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : -60160, peak : 0}.
2253: I0810 04:04:54.122498  2011 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 9497174210020301017 to 99701420204608342 , after update, data is {current : -60000, peak : 160}.
2253: I0810 04:04:54.122573  2012 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 15482172826034771369 to 99701420204608342 , after update, data is {current : 0, peak : 60000}.
2253: I0810 04:04:54.122684  2013 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -30080, peak : 30080}.
2253: I0810 04:04:54.122850  2014 thread_data_registry.h:135] Add data {current : 0, peak : 60000} from thread 99701420204608342 to 15785496349805031021 , after update, data is {current : 160, peak : 60000}.
2253: I0810 04:04:54.122862  2014 thread_data_registry.h:135] Add data {current : -30080, peak : 30080} from thread 99701420204608342 to 11836897867350493708 , after update, data is {current : -226700, peak : 589844}.
2253: I0810 04:04:54.123018  2018 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 4370860029569601088 to 15785496349805031021 , after update, data is {current : 60160, peak : 60160}.
2253: I0810 04:04:54.123088  2017 thread_data_registry.h:135] Add data {current : 60160, peak : 60160} from thread 15785496349805031021 to 11836897867350493708 , after update, data is {current : 2583848, peak : 2583848}.
2253: I0810 04:04:54.123195  2019 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 8141334110365927881 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.124326  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.124897  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.125370  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.125385  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.125391  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.127719  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.127797  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.127810  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.127815  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44486e60 type is 7
2253: I0810 04:04:54.127825  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.127828  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x437270c0 type is 7
2253: I0810 04:04:54.127835  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.127841  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44264720 type is 7
2253: I0810 04:04:54.127846  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.127852  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.127925  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.127931  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.127938  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.127944  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.127985  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.127997  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.128046  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.128057  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.128094  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.128103  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.128119  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.128126  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44b277b0Variable Type 7
2253: I0810 04:04:54.128141  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.128161  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.128175  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.128207  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.128216  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.128232  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.128238  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43d76640Variable Type 7
2253: I0810 04:04:54.128250  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.128266  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.128278  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.128525  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.128561  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.128583  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.128688  2020 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.128755  2021 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.128778  2022 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.128825  2023 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.128851  2024 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.128896  2025 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.129076  2024 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.129079  2023 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.129220  2023 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.129236  2023 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.129258  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43af6988) got event_name: TaskCompletion
2253: I0810 04:04:54.129397  2020 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 8141334110365927881 to 14824236449615686365 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.129550  2023 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 2613848, peak : 2613848}.
2253: I0810 04:04:54.129626  2024 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2613928, peak : 2613928}.
2253: I0810 04:04:54.129729  2025 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.129909  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.131242  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.131263  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.131321  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.131332  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.133165  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.133739  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.134197  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.134212  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.134217  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.136524  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.136603  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.136615  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.136619  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x436a32e0 type is 7
2253: I0810 04:04:54.136627  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.136633  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x450d3760 type is 7
2253: I0810 04:04:54.136641  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.136644  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x450d4220 type is 7
2253: I0810 04:04:54.136649  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.136655  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.136729  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.136735  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.136739  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.136746  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.136786  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.136799  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.136847  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.136857  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.136894  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.136904  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.136920  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.136929  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43c989a0Variable Type 7
2253: I0810 04:04:54.136942  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.136963  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.136977  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.137008  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.137017  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.137033  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.137041  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b70210Variable Type 7
2253: I0810 04:04:54.137053  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.137068  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.137081  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.137326  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.137360  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.137383  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.137485  2026 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.137560  2027 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.137586  2028 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.137626  2029 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.137655  2030 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.137692  2031 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.137878  2030 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.137879  2029 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.138013  2029 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.138029  2029 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.138051  1790 program_interpreter.cc:1308] main_thread_blocker_(0x442d51b8) got event_name: TaskCompletion
2253: I0810 04:04:54.138181  2026 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.138336  2029 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 30080, peak : 30080}.
2253: I0810 04:04:54.138407  2030 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 2644008, peak : 2644008}.
2253: I0810 04:04:54.138511  2031 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.139740  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.139906  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.139948  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.140308  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.140340  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.142827  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.142849  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.142899  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.142910  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.144747  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.145318  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.145749  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.145763  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.145768  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.148026  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.148101  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.148113  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.148118  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4353dab0 type is 7
2253: I0810 04:04:54.148129  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.148133  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43538e70 type is 7
2253: I0810 04:04:54.148138  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.148142  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x435398b0 type is 7
2253: I0810 04:04:54.148147  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.148152  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.148223  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.148229  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.148236  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.148239  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.148279  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.148293  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.148350  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.148361  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.148399  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.148409  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.148425  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.148432  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4440bdd0Variable Type 7
2253: I0810 04:04:54.148447  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.148466  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.148480  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.148511  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.148520  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.148536  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.148542  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4353e320Variable Type 7
2253: I0810 04:04:54.148553  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.148569  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.148581  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.148818  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.148849  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.148871  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.148970  2032 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.149044  2033 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.149065  2034 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.149104  2035 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.149133  2036 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.149176  2037 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.149366  2036 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.149374  2035 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.149514  2035 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.149530  2035 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.149554  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43538928) got event_name: TaskCompletion
2253: I0810 04:04:54.149683  2032 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:04:54.149827  2035 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 2674008, peak : 2674008}.
2253: I0810 04:04:54.149899  2036 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 2674088, peak : 2674088}.
2253: I0810 04:04:54.150018  2037 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.150190  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.150727  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.150759  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.150771  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.150892  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:54.151881  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.151902  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.151952  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.151960  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.152725  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.152745  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.152786  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.152793  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.153116  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.153177  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.153561  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:54.153657  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:54.153667  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.153746  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.153756  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.156200  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.156821  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.156837  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.156842  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.160220  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.160239  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:54.160270  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.160279  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.160284  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44c28180 type is 7
2253: I0810 04:04:54.160291  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:54.160297  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44a43720 type is 7
2253: I0810 04:04:54.160311  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.160315  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a43070 type is 7
2253: I0810 04:04:54.160320  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.160324  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44c28950 type is 7
2253: I0810 04:04:54.160329  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:54.160333  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44c28bc0 type is 7
2253: I0810 04:04:54.160339  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:54.160344  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44c28e00 type is 7
2253: I0810 04:04:54.160351  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:54.160358  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44c29060 type is 7
2253: I0810 04:04:54.160363  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44c28160 type is 9
2253: I0810 04:04:54.160369  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:54.160373  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44c28de0 type is 10
2253: I0810 04:04:54.160490  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.160497  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.160504  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.160508  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.160557  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160569  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160620  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160630  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160673  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160683  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160724  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160733  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160763  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160773  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160820  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160828  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160859  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.160868  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.160884  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.160892  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e7bbe0Variable Type 7
2253: I0810 04:04:54.160905  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.160925  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.160939  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.161235  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.161274  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.161312  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.161420  2038 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.161490  2039 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.161521  2040 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.161556  2041 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.161594  2042 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.161630  2043 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.161978  2043 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.162001  2043 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.162058  2043 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.162101  2043 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.162181  2042 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.162272  2042 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.162297  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44a43f08) got event_name: TaskCompletion
2253: I0810 04:04:54.162472  2038 thread_data_registry.h:135] Add data {current : -90088, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 90088}.
2253: I0810 04:04:54.162629  2042 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 2704088, peak : 2704088}.
2253: I0810 04:04:54.162802  2043 thread_data_registry.h:135] Add data {current : 0, peak : 90088} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:04:54.163827  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a728870 for it.
2253: I0810 04:04:54.164000  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6eb1b0 for it.
2253: I0810 04:04:54.164039  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4591dc50 for it.
2253: I0810 04:04:54.166339  1852 thread_data_registry.h:135] Add data {current : 2704088, peak : 2704088} from thread 11836897867350493708 to 1580200262163047400 , after update, data is {current : 2704112, peak : 2704112}.
2253: I0810 04:04:54.166350  1852 thread_data_registry.h:135] Add data {current : -196620, peak : 589844} from thread 11836897867350493708 to 11168886607272271118 , after update, data is {current : 0, peak : 589844}.
2253: I0810 04:04:54.166518  1855 thread_data_registry.h:135] Add data {current : 2704112, peak : 2704112} from thread 1580200262163047400 to 1738218762300064674 , after update, data is {current : 3097328, peak : 3097328}.
2253: I0810 04:04:54.166558  1856 thread_data_registry.h:135] Add data {current : 3097328, peak : 3097328} from thread 1738218762300064674 to 2770829791301891489 , after update, data is {current : 513560, peak : 3097328}.
2253: I0810 04:04:54.166719  1857 thread_data_registry.h:135] Add data {current : 0, peak : 589844} from thread 11168886607272271118 to 2770829791301891489 , after update, data is {current : 1872864, peak : 2555920}.
2253: I0810 04:04:54.168485  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.168519  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.168679  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44f3df90)  to GradNodeAccumulation (addr: 0x1a728870)
2253: I0810 04:04:54.168917  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:54.168937  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.169104  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44f3df90)
2253: I0810 04:04:54.169173  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:54.169180  1790 backward.cc:113] Start Backward
2253: I0810 04:04:54.169188  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:54.169215  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.169238  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:54.169245  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:54.169268  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.169324  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.169344  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.169351  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44f3df90
2253: I0810 04:04:54.169356  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.169376  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44f3df90
2253: I0810 04:04:54.169382  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.169394  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.169431  1790 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.169459  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.169466  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44f3df90, Found pending node: GradNodeAccumulation addr: 0x1a728870
2253: I0810 04:04:54.169471  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.169487  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a728870
2253: I0810 04:04:54.169493  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.169497  1790 accumulation_node.cc:40] Move Tensor ptr: 0x4441ed00
2253: I0810 04:04:54.169500  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.169503  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.171352  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.171373  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.171424  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.171433  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.173267  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.173835  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.174340  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.174355  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.174360  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.176724  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.176801  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.176813  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.176820  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43d74790 type is 7
2253: I0810 04:04:54.176827  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.176833  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4448a110 type is 7
2253: I0810 04:04:54.176841  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.176844  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e7ca80 type is 7
2253: I0810 04:04:54.176851  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.176856  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.176932  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.176939  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.176945  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.176951  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.176991  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.177004  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.177054  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.177064  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.177102  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.177112  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.177129  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.177136  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x435390b0Variable Type 7
2253: I0810 04:04:54.177150  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.177171  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.177186  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.177217  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.177225  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.177242  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.177248  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x376b660Variable Type 7
2253: I0810 04:04:54.177260  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.177275  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.177289  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.177542  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.177578  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.177600  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.177703  2044 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.177780  2045 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.177806  2046 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.177852  2047 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.177883  2048 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.177927  2049 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.178164  2048 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.178170  2047 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.178295  2048 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.178316  2048 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.178337  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43b73b68) got event_name: TaskCompletion
2253: I0810 04:04:54.178471  2044 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 11168886607272271118 to 11836897867350493708 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.178622  2048 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 17588981528682295231 to 17233454264217551682 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.178699  2047 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 17233454264217551682 to 2770829791301891489 , after update, data is {current : 515480, peak : 3097328}.
2253: I0810 04:04:54.178830  2049 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 11836897867350493708 to 2770829791301891489 , after update, data is {current : 1814664, peak : 2555920}.
2253: I0810 04:04:54.180475  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.180498  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.180548  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.180557  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.182413  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.182971  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.183441  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.183455  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.183462  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.185739  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.185819  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.185830  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.185837  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a52a720 type is 7
2253: I0810 04:04:54.185846  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.185853  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x450d3fd0 type is 7
2253: I0810 04:04:54.185858  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.185863  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a9b780 type is 7
2253: I0810 04:04:54.185868  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.185873  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.185947  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.185954  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.185961  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.185966  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.186007  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.186020  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.186069  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.186077  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.186115  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.186125  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.186141  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.186147  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44072be0Variable Type 7
2253: I0810 04:04:54.186161  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.186182  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.186194  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.186225  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.186233  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.186249  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.186256  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44072060Variable Type 7
2253: I0810 04:04:54.186267  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.186283  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.186296  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.186545  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.186580  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.186601  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.186708  2050 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.186772  2051 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.186794  2052 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.186831  2053 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.186870  2054 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.186910  2055 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.187078  2054 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.187085  2053 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.187203  2053 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.187217  2053 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.187237  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44677f28) got event_name: TaskCompletion
2253: I0810 04:04:54.187376  2050 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 11836897867350493708 to 11168886607272271118 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.187526  2053 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 1580200262163047400 to 1738218762300064674 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.187600  2054 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 1738218762300064674 to 2770829791301891489 , after update, data is {current : 517400, peak : 3097328}.
2253: I0810 04:04:54.187705  2055 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 11168886607272271118 to 2770829791301891489 , after update, data is {current : 1814664, peak : 2555920}.
2253: I0810 04:04:54.187870  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.189121  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.189141  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.189191  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.189200  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.191051  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.191623  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.192080  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.192094  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.192098  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.194401  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.194478  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.194490  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.194495  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4377f620 type is 7
2253: I0810 04:04:54.194505  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.194509  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x436a4590 type is 7
2253: I0810 04:04:54.194515  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.194519  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43e988b0 type is 7
2253: I0810 04:04:54.194525  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.194530  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.194604  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.194612  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.194617  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.194622  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.194661  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.194674  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.194723  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.194732  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.194770  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.194779  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.194797  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.194803  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x450e7460Variable Type 7
2253: I0810 04:04:54.194818  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.194837  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.194851  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.194881  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.194890  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.194906  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.194913  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4377f820Variable Type 7
2253: I0810 04:04:54.194924  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.194940  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.194953  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.195189  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.195223  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.195245  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.195340  2056 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.195425  2057 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.195436  2058 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.195475  2059 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.195500  2060 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.195541  2061 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.195736  2060 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.195744  2059 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.195838  2060 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.195851  2060 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.195870  1790 program_interpreter.cc:1308] main_thread_blocker_(0x444f6458) got event_name: TaskCompletion
2253: I0810 04:04:54.195997  2056 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 11168886607272271118 to 11836897867350493708 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.196143  2060 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 17588981528682295231 to 17233454264217551682 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.196218  2059 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 17233454264217551682 to 2770829791301891489 , after update, data is {current : 515480, peak : 3097328}.
2253: I0810 04:04:54.196369  2061 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 11836897867350493708 to 2770829791301891489 , after update, data is {current : 1814664, peak : 2555920}.
2253: I0810 04:04:54.197494  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.197642  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.197683  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.198033  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.198063  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.199891  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.200033  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.200073  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:04:54.203734  1790 pir_interpreter.cc:161] PirInterpreter(): 0x440c2620 on Place(gpu:0)
2253: I0810 04:04:54.203760  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.203778  1790 scope.cc:202] Create variable 0x440c26201723262694203754656_inner_var_1
2253: I0810 04:04:54.203786  1790 scope.cc:202] Create variable 0x440c26201723262694203754656_inner_var_2
2253: I0810 04:04:54.203792  1790 scope.cc:202] Create variable 0x440c26201723262694203754656_inner_var_3
2253: I0810 04:04:54.203800  1790 scope.cc:202] Create variable 0x440c26201723262694203754656_inner_var_4
2253: I0810 04:04:54.203809  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.203816  1790 scope.cc:202] Create variable 0x440c26201723262694203754656_inner_var_6
2253: I0810 04:04:54.203822  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.204082  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.204092  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.204097  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x44a99280
2253: 1 -> 0x440c26201723262694203754656_inner_var_1 -> 0x436fd2f0
2253: 2 -> 0x440c26201723262694203754656_inner_var_2 -> 0x43b62ad0
2253: 3 -> 0x440c26201723262694203754656_inner_var_3 -> 0x43e9c120
2253: 4 -> 0x440c26201723262694203754656_inner_var_4 -> 0x29334b0
2253: 5 -> fetch0@fetch -> 0x3592e70
2253: 6 -> 0x440c26201723262694203754656_inner_var_6 -> 0x35cc5c0
2253: 7 -> fetch1@fetch -> 0x4407d5d0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.204660  2062 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.204715  2063 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.204730  2064 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.204766  2065 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.204792  2066 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.204823  2067 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.204841  2067 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.204867  2067 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.204895  2067 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x440c26201723262694203754656_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_3:[dtype=;place=;dim=;lod={};, 0x440c26201723262694203754656_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.204984  2067 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x440c26201723262694203754656_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x440c26201723262694203754656_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.205036  2065 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x440c26201723262694203754656_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.205063  2065 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.205046  2066 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x440c26201723262694203754656_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.205086  2066 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.205111  2065 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x440c26201723262694203754656_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.205158  2066 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x440c26201723262694203754656_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x440c26201723262694203754656_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.205168  2065 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x440c26201723262694203754656_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.205184  2065 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.205194  2065 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x440c26201723262694203754656_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.205212  2066 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x440c26201723262694203754656_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.205231  2066 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.205248  2066 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x440c26201723262694203754656_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.205279  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x440c2790) got event_name: TaskCompletion
2253: I0810 04:04:54.205304  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.205327  1790 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.206560  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.206709  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.206750  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:04:54.209527  1790 pir_interpreter.cc:161] PirInterpreter(): 0x1a73d140 on Place(gpu:0)
2253: I0810 04:04:54.209556  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.209575  1790 scope.cc:202] Create variable 0x1a73d1401723262694209549892_inner_var_1
2253: I0810 04:04:54.209586  1790 scope.cc:202] Create variable 0x1a73d1401723262694209549892_inner_var_2
2253: I0810 04:04:54.209596  1790 scope.cc:202] Create variable 0x1a73d1401723262694209549892_inner_var_3
2253: I0810 04:04:54.209604  1790 scope.cc:202] Create variable 0x1a73d1401723262694209549892_inner_var_4
2253: I0810 04:04:54.209615  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.209628  1790 scope.cc:202] Create variable 0x1a73d1401723262694209549892_inner_var_6
2253: I0810 04:04:54.209636  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.209944  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.209957  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.209961  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x44b279f0
2253: 1 -> 0x1a73d1401723262694209549892_inner_var_1 -> 0x43cc3070
2253: 2 -> 0x1a73d1401723262694209549892_inner_var_2 -> 0x43cc45e0
2253: 3 -> 0x1a73d1401723262694209549892_inner_var_3 -> 0x43f71da0
2253: 4 -> 0x1a73d1401723262694209549892_inner_var_4 -> 0x446e64a0
2253: 5 -> fetch0@fetch -> 0x451395e0
2253: 6 -> 0x1a73d1401723262694209549892_inner_var_6 -> 0x4427e680
2253: 7 -> fetch1@fetch -> 0x450695a0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.210647  2068 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.210727  2069 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.210757  2070 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.210786  2071 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.210814  2072 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.210857  2073 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.210875  2073 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.210896  2073 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.210919  2073 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a73d1401723262694209549892_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1a73d1401723262694209549892_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.211012  2073 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a73d1401723262694209549892_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x1a73d1401723262694209549892_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.211058  2072 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a73d1401723262694209549892_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.211063  2071 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a73d1401723262694209549892_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.211087  2071 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.211087  2072 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.211144  2071 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a73d1401723262694209549892_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.211179  2072 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a73d1401723262694209549892_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x1a73d1401723262694209549892_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.211189  2071 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a73d1401723262694209549892_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.211205  2071 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.211215  2071 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a73d1401723262694209549892_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.211228  2072 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a73d1401723262694209549892_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.211244  2072 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.211256  2072 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a73d1401723262694209549892_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.211283  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x1a73d2b0) got event_name: TaskCompletion
2253: I0810 04:04:54.211310  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.211335  1790 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.211477  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:123
2253: I0810 04:04:54.211550  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.211566  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:124
2253: I0810 04:04:54.211585  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.212515  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.212535  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.212586  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.212595  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.214442  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.214998  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.215457  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.215472  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.215478  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.217777  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.217855  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.217867  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.217875  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4369c000 type is 7
2253: I0810 04:04:54.217885  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.217890  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44332cd0 type is 7
2253: I0810 04:04:54.217896  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.217903  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44484c20 type is 7
2253: I0810 04:04:54.217911  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.217916  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.217988  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.217995  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.218000  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.218007  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.218048  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.218061  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.218111  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.218122  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.218159  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.218169  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.218186  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.218194  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44c4a7e0Variable Type 7
2253: I0810 04:04:54.218207  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.218228  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.218242  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.218273  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.218282  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.218307  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.218314  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45950750Variable Type 7
2253: I0810 04:04:54.218326  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.218343  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.218356  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.218600  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.218636  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.218658  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.218770  2074 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.218859  2075 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.218889  2076 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.218920  2077 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.218952  2078 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.218992  2079 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.219162  2077 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.219164  2078 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.219255  2078 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.219269  2078 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.219290  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4353ec18) got event_name: TaskCompletion
2253: I0810 04:04:54.219419  2074 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 99701420204608342 to 9497174210020301017 , after update, data is {current : -3840, peak : 0}.
2253: I0810 04:04:54.219563  2078 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4370860029569601088 to 15785496349805031021 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.219636  2077 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 15785496349805031021 to 1672121383278216900 , after update, data is {current : 2160, peak : 2160}.
2253: I0810 04:04:54.219748  2079 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 8141334110365927881 to 9497174210020301017 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:04:54.219908  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.221225  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.221246  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.221295  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.221313  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.223134  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.223706  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.224153  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.224167  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.224172  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.226480  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.226557  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.226569  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.226575  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44454650 type is 7
2253: I0810 04:04:54.226585  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.226589  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x451455d0 type is 7
2253: I0810 04:04:54.226594  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.226598  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43efffa0 type is 7
2253: I0810 04:04:54.226605  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.226610  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.226684  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.226691  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.226696  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.226701  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.226742  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.226755  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.226804  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.226814  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.226850  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.226859  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.226876  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.226882  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43eaeb70Variable Type 7
2253: I0810 04:04:54.226897  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.226917  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.226930  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.226962  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.226970  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.226987  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.226994  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4353f2d0Variable Type 7
2253: I0810 04:04:54.227005  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.227021  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.227033  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.227272  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.227315  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.227339  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.227428  2080 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.227499  2081 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.227520  2082 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.227555  2083 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.227584  2084 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.227622  2085 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.227773  2084 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.227779  2083 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.227875  2084 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.227890  2084 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.227909  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4406bd38) got event_name: TaskCompletion
2253: I0810 04:04:54.228039  2080 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 8141334110365927881 to 9497174210020301017 , after update, data is {current : -3840, peak : 1920}.
2253: I0810 04:04:54.228186  2084 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 3532399860737347736 to 99701420204608342 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.228260  2083 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 99701420204608342 to 1672121383278216900 , after update, data is {current : 4080, peak : 4080}.
2253: I0810 04:04:54.228375  2085 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 10485228443072753046 to 9497174210020301017 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:04:54.229492  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.229640  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.229682  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.230034  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.230064  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.232335  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.232357  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.232409  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.232419  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.234220  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.234797  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.235237  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.235251  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.235256  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.237494  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.237571  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.237583  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.237589  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43f609f0 type is 7
2253: I0810 04:04:54.237600  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.237604  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44264200 type is 7
2253: I0810 04:04:54.237610  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.237617  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45133e10 type is 7
2253: I0810 04:04:54.237623  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.237629  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.237702  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.237709  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.237716  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.237722  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.237761  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.237774  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.237824  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.237834  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.237872  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.237882  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.237900  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.237906  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x430efc70Variable Type 7
2253: I0810 04:04:54.237921  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.237941  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.237955  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.237986  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.237995  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.238013  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.238019  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x430f0030Variable Type 7
2253: I0810 04:04:54.238031  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.238046  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.238059  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.238296  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.238341  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.238363  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.238453  2086 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.238521  2087 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.238543  2088 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.238577  2089 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.238617  2090 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.238654  2091 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.238803  2090 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.238823  2089 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.238926  2090 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.238947  2090 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.238971  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44263e88) got event_name: TaskCompletion
2253: I0810 04:04:54.239099  2086 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 10485228443072753046 to 9497174210020301017 , after update, data is {current : -3840, peak : 1920}.
2253: I0810 04:04:54.239248  2090 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4370860029569601088 to 15785496349805031021 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.239328  2089 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 15785496349805031021 to 1672121383278216900 , after update, data is {current : 6000, peak : 6000}.
2253: I0810 04:04:54.239444  2091 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 8141334110365927881 to 9497174210020301017 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:04:54.239609  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.240106  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.240136  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.240149  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.240265  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:54.241297  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.241328  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.241380  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.241390  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.242141  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.242161  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.242201  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.242209  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.242566  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.242631  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.243011  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:54.243106  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:54.243116  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.243194  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.243203  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.244321  2068 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 9497174210020301017 to 1672121383278216900 , after update, data is {current : 4080, peak : 6000}.
2253: I0810 04:04:54.244330  2068 thread_data_registry.h:135] Add data {current : -1920, peak : 1920} from thread 9497174210020301017 to 14590479405363806404 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.244482  2072 thread_data_registry.h:135] Add data {current : 4080, peak : 6000} from thread 1672121383278216900 to 985972397889609550 , after update, data is {current : 7680, peak : 7680}.
2253: I0810 04:04:54.244549  2071 thread_data_registry.h:135] Add data {current : 7680, peak : 7680} from thread 985972397889609550 to 11836897867350493708 , after update, data is {current : 5760, peak : 7680}.
2253: I0810 04:04:54.244654  2073 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:04:54.247062  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.247757  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.247774  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.247779  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.251331  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.251350  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:54.251382  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.251392  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.251397  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x436fe700 type is 7
2253: I0810 04:04:54.251405  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:54.251410  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44cf5400 type is 7
2253: I0810 04:04:54.251416  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.251420  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43ea8860 type is 7
2253: I0810 04:04:54.251425  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.251428  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44281260 type is 7
2253: I0810 04:04:54.251433  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:54.251437  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x43ea9f20 type is 7
2253: I0810 04:04:54.251442  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:54.251446  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x436ef950 type is 7
2253: I0810 04:04:54.251452  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:54.251456  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x43ea9ff0 type is 7
2253: I0810 04:04:54.251461  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4440d970 type is 9
2253: I0810 04:04:54.251467  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:54.251472  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x436ef930 type is 10
2253: I0810 04:04:54.251576  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.251585  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.251590  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.251595  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.251642  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251655  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251704  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251714  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251752  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251762  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251798  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251808  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251837  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251847  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251883  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251892  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.251921  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.251930  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.251945  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.251952  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x446b4930Variable Type 7
2253: I0810 04:04:54.251967  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.251987  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.252002  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.252295  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.252339  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.252368  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.252470  2092 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.252559  2093 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.252565  2094 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.252640  2095 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.252676  2097 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.252696  2096 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.252987  2097 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.253010  2097 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.253067  2097 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.253105  2097 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.253196  2096 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.253278  2096 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.253312  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43f63738) got event_name: TaskCompletion
2253: I0810 04:04:54.253484  2092 thread_data_registry.h:135] Add data {current : -5528, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 5528}.
2253: I0810 04:04:54.253650  2096 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 7560, peak : 7680}.
2253: I0810 04:04:54.253808  2097 thread_data_registry.h:135] Add data {current : 0, peak : 5528} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.254809  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.254972  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.255012  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.255604  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.255638  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.255746  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43eada00)  to GradNodeAccumulation (addr: 0x450a3000)
2253: I0810 04:04:54.255834  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:54.255854  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.255983  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43eada00)
2253: I0810 04:04:54.256057  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:54.256065  1790 backward.cc:113] Start Backward
2253: I0810 04:04:54.256073  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:54.256108  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.256136  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:54.256145  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:54.256170  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.256212  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.256235  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.256243  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43eada00
2253: I0810 04:04:54.256248  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.256273  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43eada00
2253: I0810 04:04:54.256280  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.256294  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.256350  1790 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.256383  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.256390  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43eada00, Found pending node: GradNodeAccumulation addr: 0x450a3000
2253: I0810 04:04:54.256397  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.256418  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x450a3000
2253: I0810 04:04:54.256425  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.256430  1790 accumulation_node.cc:40] Move Tensor ptr: 0x44c7dbb0
2253: I0810 04:04:54.256434  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.256440  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.258735  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.258754  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.258796  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.258805  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.260298  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.260764  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.261137  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.261149  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.261154  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.263015  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.263082  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.263090  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.263096  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44064bb0 type is 7
2253: I0810 04:04:54.263103  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.263110  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44b2e100 type is 7
2253: I0810 04:04:54.263115  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.263118  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x440b77f0 type is 7
2253: I0810 04:04:54.263123  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.263128  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.263187  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.263195  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.263198  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.263201  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.263235  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.263247  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.263286  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.263294  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.263334  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.263341  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.263357  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.263363  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44311fc0Variable Type 7
2253: I0810 04:04:54.263377  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.263393  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.263406  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.263429  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.263437  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.263450  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.263456  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x436aa6f0Variable Type 7
2253: I0810 04:04:54.263466  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.263479  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.263489  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.263682  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.263711  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.263729  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.263823  2098 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.263882  2099 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.263900  2100 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.263940  2101 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.263968  2102 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.264009  2103 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.264190  2101 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.264195  2102 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.264293  2101 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.264315  2101 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.264335  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4414aea8) got event_name: TaskCompletion
2253: I0810 04:04:54.264457  2098 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.264596  2101 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.264672  2102 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 9480, peak : 9480}.
2253: I0810 04:04:54.264775  2103 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.266353  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.266376  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.266427  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.266435  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.268252  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.268816  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.269253  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.269268  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.269272  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.271518  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.271595  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.271607  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.271613  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44c4bb90 type is 7
2253: I0810 04:04:54.271621  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.271627  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4429f7d0 type is 7
2253: I0810 04:04:54.271632  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.271636  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4369aed0 type is 7
2253: I0810 04:04:54.271641  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.271647  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.271719  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.271725  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.271730  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.271735  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.271775  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.271787  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.271834  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.271844  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.271881  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.271890  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.271905  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.271912  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x436f3890Variable Type 7
2253: I0810 04:04:54.271926  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.271946  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.271960  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.271992  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.272001  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.272017  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.272022  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4506be40Variable Type 7
2253: I0810 04:04:54.272037  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.272051  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.272063  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.272310  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.272346  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.272367  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.272467  2104 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.272541  2105 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.272562  2106 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.272603  2107 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.272639  2108 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.272681  2109 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.272854  2108 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.272864  2107 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.272960  2107 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.272977  2107 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.272998  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4429f288) got event_name: TaskCompletion
2253: I0810 04:04:54.273124  2104 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.273273  2107 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 11280, peak : 11280}.
2253: I0810 04:04:54.273353  2108 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 11400, peak : 11400}.
2253: I0810 04:04:54.273461  2109 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.273643  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.274888  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.274909  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.274960  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.274968  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.276804  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.277371  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.277814  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.277827  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.277832  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.280086  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.280164  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.280174  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.280180  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43e79ad0 type is 7
2253: I0810 04:04:54.280191  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.280195  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45058fe0 type is 7
2253: I0810 04:04:54.280200  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.280205  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45059a90 type is 7
2253: I0810 04:04:54.280211  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.280218  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.280292  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.280298  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.280318  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.280325  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.280366  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.280380  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.280427  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.280437  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.280473  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.280483  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.280500  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.280508  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e7a340Variable Type 7
2253: I0810 04:04:54.280522  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.280542  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.280556  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.280588  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.280596  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.280613  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.280622  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e7b1f0Variable Type 7
2253: I0810 04:04:54.280633  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.280648  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.280661  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.280898  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.280933  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.280956  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.281054  2110 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.281121  2111 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.281140  2112 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.281186  2113 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.281219  2114 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.281260  2115 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.281446  2114 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.281447  2113 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.281566  2113 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.281582  2113 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.281603  1790 program_interpreter.cc:1308] main_thread_blocker_(0x45058ae8) got event_name: TaskCompletion
2253: I0810 04:04:54.281731  2110 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.281873  2113 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.281944  2114 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 13320, peak : 13320}.
2253: I0810 04:04:54.282066  2115 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.283181  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.283349  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.283390  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.283740  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.283771  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.286267  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.286443  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.286478  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:04:54.289031  1790 pir_interpreter.cc:161] PirInterpreter(): 0x450e5220 on Place(gpu:0)
2253: I0810 04:04:54.289057  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.289072  1790 scope.cc:202] Create variable 0x450e52201723262694289050775_inner_var_1
2253: I0810 04:04:54.289081  1790 scope.cc:202] Create variable 0x450e52201723262694289050775_inner_var_2
2253: I0810 04:04:54.289088  1790 scope.cc:202] Create variable 0x450e52201723262694289050775_inner_var_3
2253: I0810 04:04:54.289096  1790 scope.cc:202] Create variable 0x450e52201723262694289050775_inner_var_4
2253: I0810 04:04:54.289103  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.289111  1790 scope.cc:202] Create variable 0x450e52201723262694289050775_inner_var_6
2253: I0810 04:04:54.289117  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.289383  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.289395  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.289399  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x43912470
2253: 1 -> 0x450e52201723262694289050775_inner_var_1 -> 0x445ed7c0
2253: 2 -> 0x450e52201723262694289050775_inner_var_2 -> 0x43e977d0
2253: 3 -> 0x450e52201723262694289050775_inner_var_3 -> 0x44c8cb60
2253: 4 -> 0x450e52201723262694289050775_inner_var_4 -> 0x43765530
2253: 5 -> fetch0@fetch -> 0x4353c180
2253: 6 -> 0x450e52201723262694289050775_inner_var_6 -> 0x4359dc60
2253: 7 -> fetch1@fetch -> 0x1a6f8a10
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.289942  2116 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.289999  2117 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.290017  2118 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.290066  2119 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.290082  2120 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.290133  2121 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.290155  2121 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.290189  2121 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.290220  2121 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x450e52201723262694289050775_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_3:[dtype=;place=;dim=;lod={};, 0x450e52201723262694289050775_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.290339  2121 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x450e52201723262694289050775_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x450e52201723262694289050775_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.290393  2120 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x450e52201723262694289050775_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.290402  2119 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x450e52201723262694289050775_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.290426  2120 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.290434  2119 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.290479  2120 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x450e52201723262694289050775_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.290513  2119 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x450e52201723262694289050775_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x450e52201723262694289050775_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.290517  2120 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x450e52201723262694289050775_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.290542  2120 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.290552  2120 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x450e52201723262694289050775_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.290553  2119 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x450e52201723262694289050775_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.290572  2119 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.290586  2119 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x450e52201723262694289050775_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.290616  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x450e5390) got event_name: TaskCompletion
2253: I0810 04:04:54.290637  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.290659  1790 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.291877  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.292034  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.292075  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:04:54.294818  1790 pir_interpreter.cc:161] PirInterpreter(): 0x430ec660 on Place(gpu:0)
2253: I0810 04:04:54.294847  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.294865  1790 scope.cc:202] Create variable 0x430ec6601723262694294841244_inner_var_1
2253: I0810 04:04:54.294876  1790 scope.cc:202] Create variable 0x430ec6601723262694294841244_inner_var_2
2253: I0810 04:04:54.294886  1790 scope.cc:202] Create variable 0x430ec6601723262694294841244_inner_var_3
2253: I0810 04:04:54.294894  1790 scope.cc:202] Create variable 0x430ec6601723262694294841244_inner_var_4
2253: I0810 04:04:54.294905  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.294916  1790 scope.cc:202] Create variable 0x430ec6601723262694294841244_inner_var_6
2253: I0810 04:04:54.294926  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.295225  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.295239  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.295243  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x444c7120
2253: 1 -> 0x430ec6601723262694294841244_inner_var_1 -> 0x43cc33b0
2253: 2 -> 0x430ec6601723262694294841244_inner_var_2 -> 0x43da1040
2253: 3 -> 0x430ec6601723262694294841244_inner_var_3 -> 0x43c9e480
2253: 4 -> 0x430ec6601723262694294841244_inner_var_4 -> 0x43912630
2253: 5 -> fetch0@fetch -> 0x43f60b60
2253: 6 -> 0x430ec6601723262694294841244_inner_var_6 -> 0x43ece840
2253: 7 -> fetch1@fetch -> 0x44b27890
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.295920  2122 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.296007  2123 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.296034  2124 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.296070  2125 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.296108  2126 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.296152  2127 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.296173  2127 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.296205  2127 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.296236  2127 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x430ec6601723262694294841244_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_3:[dtype=;place=;dim=;lod={};, 0x430ec6601723262694294841244_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.296344  2127 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x430ec6601723262694294841244_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x430ec6601723262694294841244_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.296392  2126 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x430ec6601723262694294841244_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.296415  2126 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.296401  2125 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x430ec6601723262694294841244_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.296429  2125 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.296478  2126 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x430ec6601723262694294841244_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.296511  2125 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x430ec6601723262694294841244_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x430ec6601723262694294841244_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.296522  2126 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x430ec6601723262694294841244_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.296538  2126 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.296536  2125 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x430ec6601723262694294841244_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.296552  2125 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.296548  2126 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x430ec6601723262694294841244_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.296562  2125 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x430ec6601723262694294841244_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:04:54.296592  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x430ec7d0) got event_name: TaskCompletion
2253: I0810 04:04:54.296613  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.296638  1790 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.296775  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:149
2253: I0810 04:04:54.296846  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.296861  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:150
2253: I0810 04:04:54.296880  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.297801  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.297822  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.297873  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.297881  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.299721  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.300271  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.300743  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.300758  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.300765  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.303064  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.303143  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.303154  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.303160  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x444e5d40 type is 7
2253: I0810 04:04:54.303170  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.303174  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x445edd00 type is 7
2253: I0810 04:04:54.303180  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.303187  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43ecf680 type is 7
2253: I0810 04:04:54.303194  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.303200  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.303272  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.303279  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.303284  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.303289  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.303340  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.303354  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.303403  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.303414  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.303452  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.303463  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.303480  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.303488  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43764cd0Variable Type 7
2253: I0810 04:04:54.303503  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.303524  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.303539  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.303570  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.303580  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.303596  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.303603  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43764c30Variable Type 7
2253: I0810 04:04:54.303615  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.303630  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.303643  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.303887  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.303923  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.303946  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.304064  2128 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.304150  2129 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.304181  2130 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.304215  2131 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.304246  2132 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.304291  2133 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.304472  2132 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.304478  2131 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.304586  2132 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.304603  2132 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.304626  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43f02948) got event_name: TaskCompletion
2253: I0810 04:04:54.304754  2128 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 13824773680407106994 to 99701420204608342 , after update, data is {current : -3840, peak : 0}.
2253: I0810 04:04:54.304903  2132 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 7708048296032173470 to 14385946922105763111 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.304920  2131 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 14385946922105763111 to 99701420204608342 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.305058  2133 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 13152789332281370610 to 99701420204608342 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:04:54.305233  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.306567  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.306588  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.306638  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.306648  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.308459  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.309016  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.309473  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.309489  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.309494  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.311805  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.311882  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.311893  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.311899  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44453710 type is 7
2253: I0810 04:04:54.311909  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.311913  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43ed1480 type is 7
2253: I0810 04:04:54.311918  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.311923  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x445f21b0 type is 7
2253: I0810 04:04:54.311928  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.311933  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.312005  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.312011  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.312017  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.312022  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.312062  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.312074  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.312121  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.312132  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.312168  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.312177  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.312193  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.312201  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4429dc20Variable Type 7
2253: I0810 04:04:54.312214  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.312234  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.312248  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.312279  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.312287  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.312316  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.312323  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44c2b030Variable Type 7
2253: I0810 04:04:54.312335  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.312352  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.312366  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.312604  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.312638  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.312660  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.312759  2134 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.312832  2135 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.312850  2136 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.312896  2137 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.312923  2138 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.312966  2139 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.313130  2138 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.313139  2137 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.313241  2137 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.313256  2137 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.313279  1790 program_interpreter.cc:1308] main_thread_blocker_(0x45138d38) got event_name: TaskCompletion
2253: I0810 04:04:54.313413  2134 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 13152789332281370610 to 13456996948208181472 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.313558  2137 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 13824773680407106994 to 99701420204608342 , after update, data is {current : 1800, peak : 1920}.
2253: I0810 04:04:54.313630  2138 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 10600705262021306540 to 99701420204608342 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:04:54.313732  2139 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 13456996948208181472 to 99701420204608342 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:04:54.314846  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.314994  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.315037  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.315397  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.315429  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.317710  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.317734  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.317783  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.317793  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.319603  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.320153  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.320596  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.320611  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.320616  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.322755  2116 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.322767  2116 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : -3840, peak : 1920}.
2253: I0810 04:04:54.322933  2119 thread_data_registry.h:135] Add data {current : 240, peak : 240} from thread 9497174210020301017 to 99701420204608342 , after update, data is {current : 240, peak : 1920}.
2253: I0810 04:04:54.323002  2120 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 15482172826034771369 to 99701420204608342 , after update, data is {current : 3840, peak : 3840}.
2253: I0810 04:04:54.323114  2121 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:04:54.323293  2122 thread_data_registry.h:135] Add data {current : 3840, peak : 3840} from thread 99701420204608342 to 15785496349805031021 , after update, data is {current : 4080, peak : 4080}.
2253: I0810 04:04:54.323312  2122 thread_data_registry.h:135] Add data {current : -1920, peak : 1920} from thread 99701420204608342 to 11836897867350493708 , after update, data is {current : -3840, peak : 5528}.
2253: I0810 04:04:54.323485  2125 thread_data_registry.h:135] Add data {current : 4080, peak : 4080} from thread 15785496349805031021 to 11836897867350493708 , after update, data is {current : 17400, peak : 17400}.
2253: I0810 04:04:54.323562  2126 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 4370860029569601088 to 11836897867350493708 , after update, data is {current : 21000, peak : 21000}.
2253: I0810 04:04:54.323675  2127 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 8141334110365927881 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.324559  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.324637  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.324648  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.324654  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x436f04b0 type is 7
2253: I0810 04:04:54.324664  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.324668  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43c90050 type is 7
2253: I0810 04:04:54.324676  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.324679  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43cac8e0 type is 7
2253: I0810 04:04:54.324684  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.324689  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.324765  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.324772  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.324777  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.324784  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.324824  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.324837  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.324887  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.324898  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.324934  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.324944  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.324959  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.324967  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44689ba0Variable Type 7
2253: I0810 04:04:54.324982  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.325002  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.325017  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.325049  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.325058  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.325073  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.325080  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43b02bf0Variable Type 7
2253: I0810 04:04:54.325093  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.325109  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.325120  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.325373  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.325408  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.325429  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.325527  2140 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.325601  2141 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.325634  2142 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.325665  2143 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.325706  2144 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.325745  2145 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.325932  2144 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.325935  2143 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.326037  2143 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.326052  2143 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.326074  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43f63738) got event_name: TaskCompletion
2253: I0810 04:04:54.326205  2140 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 8141334110365927881 to 14824236449615686365 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:04:54.326361  2144 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 21120, peak : 21120}.
2253: I0810 04:04:54.326435  2143 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 22920, peak : 22920}.
2253: I0810 04:04:54.326555  2145 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.326746  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.327271  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.327311  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.327324  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.327441  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:54.328403  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.328424  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.328473  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.328483  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.329196  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.329216  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.329254  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.329262  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.329603  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.329668  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.330036  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:54.330129  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:54.330139  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.330217  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.330226  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.332749  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.333425  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.333442  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.333447  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.336907  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.336926  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:54.336958  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.336968  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.336972  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45069c60 type is 7
2253: I0810 04:04:54.336980  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:54.336987  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44685640 type is 7
2253: I0810 04:04:54.336992  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.336997  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4426ad20 type is 7
2253: I0810 04:04:54.337002  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.337005  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4506a300 type is 7
2253: I0810 04:04:54.337010  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:54.337014  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4506a570 type is 7
2253: I0810 04:04:54.337019  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:54.337023  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4506a7b0 type is 7
2253: I0810 04:04:54.337029  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:54.337033  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x4506aa10 type is 7
2253: I0810 04:04:54.337038  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45069c40 type is 9
2253: I0810 04:04:54.337044  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:54.337049  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4506a790 type is 10
2253: I0810 04:04:54.337150  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.337157  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.337163  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.337169  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.337217  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337230  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337280  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337289  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337337  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337347  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337383  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337392  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337421  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337430  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337467  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337477  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337507  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.337515  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.337531  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.337538  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44cb65b0Variable Type 7
2253: I0810 04:04:54.337553  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.337574  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.337587  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.337869  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.337900  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.337930  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.338032  2146 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.338105  2147 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.338120  2148 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.338173  2149 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.338200  2150 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.338253  2151 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.338644  2151 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.338680  2151 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.338755  2151 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.338804  2151 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.338888  2150 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.338953  2150 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.338975  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4426a8c8) got event_name: TaskCompletion
2253: I0810 04:04:54.339133  2146 thread_data_registry.h:135] Add data {current : -5528, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 5528}.
2253: I0810 04:04:54.339284  2150 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 24720, peak : 24720}.
2253: I0810 04:04:54.339491  2151 thread_data_registry.h:135] Add data {current : 0, peak : 5528} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.340440  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.340603  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.340643  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.341213  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.341248  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.341362  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x4372f540)  to GradNodeAccumulation (addr: 0x450a3000)
2253: I0810 04:04:54.341447  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:54.341465  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.341580  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x4372f540)
2253: I0810 04:04:54.341653  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:54.341660  1790 backward.cc:113] Start Backward
2253: I0810 04:04:54.341670  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:54.341701  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.341727  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:54.341735  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:54.341759  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.341802  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.341823  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.341831  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x4372f540
2253: I0810 04:04:54.341836  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.341861  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x4372f540
2253: I0810 04:04:54.341868  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.341882  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.341917  1790 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.341948  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.341954  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x4372f540, Found pending node: GradNodeAccumulation addr: 0x450a3000
2253: I0810 04:04:54.341961  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.341984  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x450a3000
2253: I0810 04:04:54.341990  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.341995  1790 accumulation_node.cc:40] Move Tensor ptr: 0x4359bf10
2253: I0810 04:04:54.342000  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.342005  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.343703  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.343724  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.343775  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.343784  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.345638  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.346202  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.346658  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.346673  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.346678  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.348942  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.349020  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.349032  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.349037  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4424a680 type is 7
2253: I0810 04:04:54.349047  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.349051  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44409b60 type is 7
2253: I0810 04:04:54.349057  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.349061  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4440a660 type is 7
2253: I0810 04:04:54.349067  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.349074  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.349144  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.349150  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.349156  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.349161  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.349201  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.349215  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.349262  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.349272  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.349318  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.349328  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.349345  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.349352  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x446d5ac0Variable Type 7
2253: I0810 04:04:54.349367  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.349386  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.349400  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.349431  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.349440  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.349457  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.349463  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4424bef0Variable Type 7
2253: I0810 04:04:54.349475  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.349493  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.349504  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.349737  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.349771  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.349793  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.349892  2152 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.349951  2153 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.349967  2154 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.350014  2155 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.350045  2156 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.350085  2157 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.350265  2156 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.350275  2155 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.350380  2155 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.350396  2155 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.350418  1790 program_interpreter.cc:1308] main_thread_blocker_(0x444095f8) got event_name: TaskCompletion
2253: I0810 04:04:54.350551  2152 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.350693  2155 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 26520, peak : 26520}.
2253: I0810 04:04:54.350765  2156 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 26580, peak : 26580}.
2253: I0810 04:04:54.350863  2157 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.352465  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.352488  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.352537  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.352547  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.354362  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.354910  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.355351  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.355366  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.355371  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.357585  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.357662  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.357673  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.357679  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43698170 type is 7
2253: I0810 04:04:54.357690  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.357694  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a420f0 type is 7
2253: I0810 04:04:54.357699  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.357703  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a427f0 type is 7
2253: I0810 04:04:54.357708  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.357717  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.357784  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.357791  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.357797  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.357802  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.357842  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.357854  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.357901  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.357911  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.357949  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.357957  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.357973  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.357980  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43698c40Variable Type 7
2253: I0810 04:04:54.357995  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.358014  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.358028  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.358058  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.358067  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.358083  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.358090  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44248cf0Variable Type 7
2253: I0810 04:04:54.358103  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.358117  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.358130  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.358386  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.358422  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.358443  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.358536  2158 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.358593  2159 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.358625  2160 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.358659  2161 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.358704  2162 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.358736  2163 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.358911  2162 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.358912  2161 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.359025  2161 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.359040  2161 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.359058  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44a41ba8) got event_name: TaskCompletion
2253: I0810 04:04:54.359184  2158 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.359340  2162 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 1672121383278216900 to 985972397889609550 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:04:54.359378  2161 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 985972397889609550 to 11836897867350493708 , after update, data is {current : 28440, peak : 28440}.
2253: I0810 04:04:54.359513  2163 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.359676  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.360926  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.360949  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.360996  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.361006  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.363729  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.364188  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.364605  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.364617  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.364624  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.366554  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.366618  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.366628  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.366632  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44cb16e0 type is 7
2253: I0810 04:04:54.366639  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.366645  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44499260 type is 7
2253: I0810 04:04:54.366650  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.366653  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a5f080 type is 7
2253: I0810 04:04:54.366657  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.366662  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.366725  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.366731  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.366735  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.366739  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.366771  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.366782  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.366822  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.366830  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.366860  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.366868  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.366881  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.366887  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x648bd50Variable Type 7
2253: I0810 04:04:54.366899  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.366915  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.366927  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.366950  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.366957  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.366972  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.366978  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451396c0Variable Type 7
2253: I0810 04:04:54.366988  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.367002  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.367012  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.367201  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.367229  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.367247  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.367347  2164 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.367403  2165 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.367439  2166 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.367498  2167 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.367530  2169 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.367550  2168 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.367741  2168 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.367751  2167 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.367859  2167 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.367877  2167 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.367897  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43f63738) got event_name: TaskCompletion
2253: I0810 04:04:54.368013  2164 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.368165  2167 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 30240, peak : 30240}.
2253: I0810 04:04:54.368237  2168 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 30300, peak : 30300}.
2253: I0810 04:04:54.368346  2169 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.369441  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.369597  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.369638  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.369985  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.370015  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.371848  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.371989  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.372030  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:04:54.374825  1790 pir_interpreter.cc:161] PirInterpreter(): 0x44276f40 on Place(gpu:0)
2253: I0810 04:04:54.374854  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.374872  1790 scope.cc:202] Create variable 0x44276f401723262694374847103_inner_var_1
2253: I0810 04:04:54.374883  1790 scope.cc:202] Create variable 0x44276f401723262694374847103_inner_var_2
2253: I0810 04:04:54.374893  1790 scope.cc:202] Create variable 0x44276f401723262694374847103_inner_var_3
2253: I0810 04:04:54.374902  1790 scope.cc:202] Create variable 0x44276f401723262694374847103_inner_var_4
2253: I0810 04:04:54.374912  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.374922  1790 scope.cc:202] Create variable 0x44276f401723262694374847103_inner_var_6
2253: I0810 04:04:54.374930  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.375238  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.375252  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.375257  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x446b6950
2253: 1 -> 0x44276f401723262694374847103_inner_var_1 -> 0x45144760
2253: 2 -> 0x44276f401723262694374847103_inner_var_2 -> 0x43695630
2253: 3 -> 0x44276f401723262694374847103_inner_var_3 -> 0x450e5f70
2253: 4 -> 0x44276f401723262694374847103_inner_var_4 -> 0x44641e90
2253: 5 -> fetch0@fetch -> 0x436f0e10
2253: 6 -> 0x44276f401723262694374847103_inner_var_6 -> 0x43693d70
2253: 7 -> fetch1@fetch -> 0x43c87cd0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.375936  2170 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.376003  2171 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.376025  2172 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.376067  2173 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.376099  2174 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.376143  2175 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.376163  2175 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.376195  2175 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.376224  2175 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44276f401723262694374847103_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44276f401723262694374847103_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.376343  2175 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44276f401723262694374847103_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x44276f401723262694374847103_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.376401  2173 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44276f401723262694374847103_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.376402  2174 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44276f401723262694374847103_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.376435  2173 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.376441  2174 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.376492  2173 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44276f401723262694374847103_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.376535  2173 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44276f401723262694374847103_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.376531  2174 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44276f401723262694374847103_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x44276f401723262694374847103_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.376557  2173 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.376567  2173 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44276f401723262694374847103_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.376574  2174 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44276f401723262694374847103_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.376595  2174 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.376611  2174 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44276f401723262694374847103_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.376647  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x442770b0) got event_name: TaskCompletion
2253: I0810 04:04:54.376672  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.376698  1790 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.377980  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.378139  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.378180  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:04:54.380928  1790 pir_interpreter.cc:161] PirInterpreter(): 0x442d1a00 on Place(gpu:0)
2253: I0810 04:04:54.380957  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.380975  1790 scope.cc:202] Create variable 0x442d1a001723262694380950665_inner_var_1
2253: I0810 04:04:54.380985  1790 scope.cc:202] Create variable 0x442d1a001723262694380950665_inner_var_2
2253: I0810 04:04:54.380996  1790 scope.cc:202] Create variable 0x442d1a001723262694380950665_inner_var_3
2253: I0810 04:04:54.381007  1790 scope.cc:202] Create variable 0x442d1a001723262694380950665_inner_var_4
2253: I0810 04:04:54.381016  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.381027  1790 scope.cc:202] Create variable 0x442d1a001723262694380950665_inner_var_6
2253: I0810 04:04:54.381036  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.381345  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.381361  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.381364  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x442d1f20
2253: 1 -> 0x442d1a001723262694380950665_inner_var_1 -> 0x1a6eb3e0
2253: 2 -> 0x442d1a001723262694380950665_inner_var_2 -> 0x436edd10
2253: 3 -> 0x442d1a001723262694380950665_inner_var_3 -> 0x4414c200
2253: 4 -> 0x442d1a001723262694380950665_inner_var_4 -> 0x43ecf510
2253: 5 -> fetch0@fetch -> 0x43ececc0
2253: 6 -> 0x442d1a001723262694380950665_inner_var_6 -> 0x4369b110
2253: 7 -> fetch1@fetch -> 0x43f03010
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.382032  2176 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.382119  2177 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.382145  2178 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.382184  2179 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.382208  2180 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.382272  2181 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.382289  2181 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.382314  2181 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.382339  2181 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442d1a001723262694380950665_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_3:[dtype=;place=;dim=;lod={};, 0x442d1a001723262694380950665_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.382433  2181 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x442d1a001723262694380950665_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x442d1a001723262694380950665_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.382484  2180 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442d1a001723262694380950665_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.382490  2179 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442d1a001723262694380950665_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.382512  2180 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.382519  2179 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.382577  2180 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442d1a001723262694380950665_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.382608  2179 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x442d1a001723262694380950665_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x442d1a001723262694380950665_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.382612  2180 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442d1a001723262694380950665_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.382633  2180 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.382647  2180 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442d1a001723262694380950665_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.382653  2179 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x442d1a001723262694380950665_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.382673  2179 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.382686  2179 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x442d1a001723262694380950665_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.382715  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x442d1b70) got event_name: TaskCompletion
2253: I0810 04:04:54.382736  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.382761  1790 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.382902  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:175
2253: I0810 04:04:54.382972  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.382987  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:176
2253: I0810 04:04:54.383005  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.383944  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.383965  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.384013  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.384023  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.385855  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.386415  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.386857  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.386870  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.386876  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.389124  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.389204  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.389216  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.389221  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4359acd0 type is 7
2253: I0810 04:04:54.389231  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.389235  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44d10590 type is 7
2253: I0810 04:04:54.389240  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.389245  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43d13860 type is 7
2253: I0810 04:04:54.389250  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.389258  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.389336  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.389344  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.389351  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.389356  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.389396  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.389410  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.389459  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.389469  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.389506  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.389516  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.389532  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.389539  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43f468d0Variable Type 7
2253: I0810 04:04:54.389554  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.389573  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.389587  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.389619  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.389627  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.389643  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.389649  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4359b2a0Variable Type 7
2253: I0810 04:04:54.389663  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.389678  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.389690  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.389964  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.390002  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.390023  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.390146  2182 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.390233  2183 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.390267  2184 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.390295  2185 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.390337  2186 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.390388  2187 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.390588  2185 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.390588  2186 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.390699  2186 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.390720  2186 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.390748  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44d10208) got event_name: TaskCompletion
2253: I0810 04:04:54.390875  2182 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 13824773680407106994 to 99701420204608342 , after update, data is {current : -3720, peak : 0}.
2253: I0810 04:04:54.391037  2186 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 7708048296032173470 to 14824236449615686365 , after update, data is {current : -60, peak : 1800}.
2253: I0810 04:04:54.391110  2185 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 14385946922105763111 to 14824236449615686365 , after update, data is {current : 0, peak : 1800}.
2253: I0810 04:04:54.391233  2187 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 13152789332281370610 to 99701420204608342 , after update, data is {current : -1860, peak : 1860}.
2253: I0810 04:04:54.391418  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.392740  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.392762  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.392812  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.392820  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.394666  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.395232  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.395684  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.395699  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.395704  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.397969  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.398048  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.398059  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.398064  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44d12ce0 type is 7
2253: I0810 04:04:54.398072  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.398078  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4357a8d0 type is 7
2253: I0810 04:04:54.398085  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.398089  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4357b390 type is 7
2253: I0810 04:04:54.398094  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.398100  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.398170  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.398177  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.398181  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.398186  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.398226  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.398239  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.398288  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.398298  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.398346  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.398355  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.398372  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.398380  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44d13660Variable Type 7
2253: I0810 04:04:54.398394  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.398414  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.398428  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.398459  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.398468  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.398484  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.398490  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44d144f0Variable Type 7
2253: I0810 04:04:54.398504  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.398519  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.398530  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.398766  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.398801  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.398823  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.398923  2188 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.399041  2189 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.399070  2190 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.399113  2191 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.399147  2192 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.399194  2193 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.399372  2192 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.399379  2191 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.399485  2191 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.399505  2191 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.399531  1790 program_interpreter.cc:1308] main_thread_blocker_(0x4357a368) got event_name: TaskCompletion
2253: I0810 04:04:54.399662  2188 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 13152789332281370610 to 13456996948208181472 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.399812  2191 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 13824773680407106994 to 14824236449615686365 , after update, data is {current : 1800, peak : 1800}.
2253: I0810 04:04:54.399847  2192 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 10600705262021306540 to 14824236449615686365 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:04:54.399986  2193 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 13456996948208181472 to 99701420204608342 , after update, data is {current : -1860, peak : 1860}.
2253: I0810 04:04:54.401105  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.401262  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.401312  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.401836  2170 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.401846  2170 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -3720, peak : 1860}.
2253: I0810 04:04:54.402040  2174 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 1672121383278216900 to 99701420204608342 , after update, data is {current : 120, peak : 1860}.
2253: I0810 04:04:54.402110  2173 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 985972397889609550 to 99701420204608342 , after update, data is {current : 3720, peak : 3720}.
2253: I0810 04:04:54.402231  2175 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : -1860, peak : 1860}.
2253: I0810 04:04:54.402420  2176 thread_data_registry.h:135] Add data {current : 3720, peak : 3720} from thread 99701420204608342 to 15785496349805031021 , after update, data is {current : 3840, peak : 3840}.
2253: I0810 04:04:54.402429  2176 thread_data_registry.h:135] Add data {current : -1860, peak : 1860} from thread 99701420204608342 to 11836897867350493708 , after update, data is {current : -3780, peak : 5528}.
2253: I0810 04:04:54.402604  2179 thread_data_registry.h:135] Add data {current : 3840, peak : 3840} from thread 15785496349805031021 to 11836897867350493708 , after update, data is {current : 34140, peak : 34140}.
2253: I0810 04:04:54.402678  2180 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 4370860029569601088 to 11836897867350493708 , after update, data is {current : 37740, peak : 37740}.
2253: I0810 04:04:54.402797  2181 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 8141334110365927881 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.403316  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.403352  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.405905  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.405928  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.405978  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.405987  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.407829  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.408398  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.408859  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.408874  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.408878  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.411182  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.411260  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.411273  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.411278  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x445f4170 type is 7
2253: I0810 04:04:54.411288  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.411293  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44312790 type is 7
2253: I0810 04:04:54.411326  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.411334  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4433fef0 type is 7
2253: I0810 04:04:54.411341  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.411347  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.411422  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.411428  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.411435  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.411440  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.411480  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.411494  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.411542  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.411552  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.411589  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.411598  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.411615  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.411623  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44b27790Variable Type 7
2253: I0810 04:04:54.411636  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.411656  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.411671  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.411701  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.411710  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.411726  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.411734  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44641da0Variable Type 7
2253: I0810 04:04:54.411746  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.411761  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.411774  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.412007  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.412041  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.412062  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.412164  2194 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.412241  2195 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.412262  2196 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.412321  2197 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.412357  2198 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.412400  2199 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.412575  2198 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.412585  2197 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.412683  2197 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.412703  2197 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.412730  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43f63738) got event_name: TaskCompletion
2253: I0810 04:04:54.412858  2194 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 8141334110365927881 to 14824236449615686365 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.413005  2197 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 39540, peak : 39540}.
2253: I0810 04:04:54.413074  2198 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 39600, peak : 39600}.
2253: I0810 04:04:54.413184  2199 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.413372  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.413882  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.413911  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.413924  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.414040  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:54.415009  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.415030  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.415081  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.415091  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.415817  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.415836  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.415876  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.415885  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.416210  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.416273  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.416652  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:54.416749  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:54.416759  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.416838  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.416848  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.419340  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.419965  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.419979  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.419984  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.423408  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.423426  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:54.423457  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.423467  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.423472  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44b0dc50 type is 7
2253: I0810 04:04:54.423480  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:54.423487  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44acc850 type is 7
2253: I0810 04:04:54.423494  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.423498  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44acc1a0 type is 7
2253: I0810 04:04:54.423503  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.423507  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44b0e420 type is 7
2253: I0810 04:04:54.423512  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:54.423517  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44b0e690 type is 7
2253: I0810 04:04:54.423522  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:54.423528  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44b0e8d0 type is 7
2253: I0810 04:04:54.423534  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:54.423538  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44b0eb30 type is 7
2253: I0810 04:04:54.423543  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44b0dc30 type is 9
2253: I0810 04:04:54.423549  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:54.423553  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44b0e8b0 type is 10
2253: I0810 04:04:54.423651  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.423658  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.423663  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.423669  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.423717  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423730  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423780  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423790  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423828  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423837  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423874  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423884  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423913  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423923  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423961  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.423970  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.424000  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.424010  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.424026  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.424033  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e874d0Variable Type 7
2253: I0810 04:04:54.424047  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.424068  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.424082  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.424397  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.424430  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.424461  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.424566  2200 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.424638  2201 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.424661  2202 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.424701  2203 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.424727  2204 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.424772  2205 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.425077  2205 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.425101  2205 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.425158  2205 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.425196  2205 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.425283  2204 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.425369  2204 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.425395  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44acd038) got event_name: TaskCompletion
2253: I0810 04:04:54.425561  2200 thread_data_registry.h:135] Add data {current : -5468, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 5468}.
2253: I0810 04:04:54.425707  2204 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 41400, peak : 41400}.
2253: I0810 04:04:54.425884  2205 thread_data_registry.h:135] Add data {current : 0, peak : 5468} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.426860  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.427023  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.427062  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.427659  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.427695  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.427807  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44f3df90)  to GradNodeAccumulation (addr: 0x450a3000)
2253: I0810 04:04:54.427891  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:54.427909  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.428025  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44f3df90)
2253: I0810 04:04:54.428097  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:54.428105  1790 backward.cc:113] Start Backward
2253: I0810 04:04:54.428113  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:54.428146  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.428170  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:54.428179  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:54.428201  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.428243  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.428262  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.428270  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44f3df90
2253: I0810 04:04:54.428277  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.428310  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44f3df90
2253: I0810 04:04:54.428318  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.428332  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.428360  1790 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.428392  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.428400  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44f3df90, Found pending node: GradNodeAccumulation addr: 0x450a3000
2253: I0810 04:04:54.428406  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.428428  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x450a3000
2253: I0810 04:04:54.428436  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.428442  1790 accumulation_node.cc:40] Move Tensor ptr: 0x444f34e0
2253: I0810 04:04:54.428444  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.428448  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.430740  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.430758  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.430799  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.430807  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.432287  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.432752  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.433111  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.433123  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.433128  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.434953  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.435021  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.435031  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.435035  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43ad73e0 type is 7
2253: I0810 04:04:54.435042  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.435050  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x43ad3db0 type is 7
2253: I0810 04:04:54.435053  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.435057  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43ad48b0 type is 7
2253: I0810 04:04:54.435062  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.435067  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.435127  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.435132  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.435137  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.435139  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.435171  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.435182  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.435221  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.435230  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.435261  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.435268  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.435282  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.435288  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43ad7e90Variable Type 7
2253: I0810 04:04:54.435309  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.435326  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.435339  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.435374  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.435380  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.435395  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.435401  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43ad8c70Variable Type 7
2253: I0810 04:04:54.435411  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.435424  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.435434  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.435639  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.435667  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.435684  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.435772  2206 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.435835  2207 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.435863  2208 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.435899  2209 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.435928  2210 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.435967  2211 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.436146  2210 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.436154  2209 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.436249  2209 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.436264  2209 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.436285  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43ad3848) got event_name: TaskCompletion
2253: I0810 04:04:54.436415  2206 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.436555  2209 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 43200, peak : 43200}.
2253: I0810 04:04:54.436627  2210 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 43260, peak : 43260}.
2253: I0810 04:04:54.436728  2211 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.438277  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.438308  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.438357  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.438367  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.441149  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.441676  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.442060  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.442072  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.442078  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.443974  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.444041  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.444051  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.444056  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43f62f70 type is 7
2253: I0810 04:04:54.444061  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.444068  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x440b6450 type is 7
2253: I0810 04:04:54.444072  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.444077  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x442cf760 type is 7
2253: I0810 04:04:54.444080  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.444085  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.444144  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.444150  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.444154  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.444157  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.444190  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.444201  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.444240  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.444249  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.444284  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.444293  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.444314  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.444321  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x442e15c0Variable Type 7
2253: I0810 04:04:54.444335  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.444352  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.444365  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.444391  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.444397  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.444412  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.444418  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x442595c0Variable Type 7
2253: I0810 04:04:54.444429  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.444442  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.444453  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.444641  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.444669  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.444686  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.444772  2212 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.444837  2213 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.444859  2214 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.444898  2215 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.444929  2216 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.444964  2217 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.445132  2216 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.445135  2215 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.445243  2215 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.445258  2215 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.445278  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43f63738) got event_name: TaskCompletion
2253: I0810 04:04:54.445399  2212 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.445544  2215 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 985972397889609550 to 1672121383278216900 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:04:54.445585  2216 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 1672121383278216900 to 11836897867350493708 , after update, data is {current : 45120, peak : 45120}.
2253: I0810 04:04:54.445719  2217 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.445883  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.446913  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.446931  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.446974  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.446981  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.448494  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.448951  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.449332  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.449344  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.449349  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.451234  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.451309  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.451319  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.451324  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44a3dc40 type is 7
2253: I0810 04:04:54.451330  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.451334  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44c7eb40 type is 7
2253: I0810 04:04:54.451339  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.451342  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44d163b0 type is 7
2253: I0810 04:04:54.451346  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.451350  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.451409  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.451414  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.451418  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.451422  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.451454  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.451467  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.451505  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.451514  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.451543  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.451552  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.451565  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.451572  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4505c540Variable Type 7
2253: I0810 04:04:54.451586  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.451602  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.451613  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.451639  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.451646  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.451661  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.451668  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451155a0Variable Type 7
2253: I0810 04:04:54.451678  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.451689  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.451699  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.451890  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.451918  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.451936  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.452023  2218 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.452081  2219 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.452102  2220 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.452140  2221 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.452167  2222 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.452211  2223 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.452378  2222 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.452386  2221 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.452482  2221 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.452497  2221 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.452515  1790 program_interpreter.cc:1308] main_thread_blocker_(0x450a3858) got event_name: TaskCompletion
2253: I0810 04:04:54.452636  2218 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.452780  2221 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 46920, peak : 46920}.
2253: I0810 04:04:54.452823  2222 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 46980, peak : 46980}.
2253: I0810 04:04:54.452957  2223 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.454036  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.454195  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.454234  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.454592  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.454623  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.456444  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.456585  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.456626  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:04:54.459403  1790 pir_interpreter.cc:161] PirInterpreter(): 0x43f72b40 on Place(gpu:0)
2253: I0810 04:04:54.459432  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.459451  1790 scope.cc:202] Create variable 0x43f72b401723262694459425603_inner_var_1
2253: I0810 04:04:54.459462  1790 scope.cc:202] Create variable 0x43f72b401723262694459425603_inner_var_2
2253: I0810 04:04:54.459471  1790 scope.cc:202] Create variable 0x43f72b401723262694459425603_inner_var_3
2253: I0810 04:04:54.459481  1790 scope.cc:202] Create variable 0x43f72b401723262694459425603_inner_var_4
2253: I0810 04:04:54.459491  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.459503  1790 scope.cc:202] Create variable 0x43f72b401723262694459425603_inner_var_6
2253: I0810 04:04:54.459510  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.459811  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.459825  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.459829  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x446e7470
2253: 1 -> 0x43f72b401723262694459425603_inner_var_1 -> 0x446e74f0
2253: 2 -> 0x43f72b401723262694459425603_inner_var_2 -> 0x44c7fb40
2253: 3 -> 0x43f72b401723262694459425603_inner_var_3 -> 0x44310f10
2253: 4 -> 0x43f72b401723262694459425603_inner_var_4 -> 0x44675290
2253: 5 -> fetch0@fetch -> 0x43597c80
2253: 6 -> 0x43f72b401723262694459425603_inner_var_6 -> 0x43597c40
2253: 7 -> fetch1@fetch -> 0x44407dd0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.460493  2224 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.460558  2225 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.460580  2226 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.460638  2227 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.460687  2228 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.460741  2229 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.460763  2229 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.460791  2229 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.460819  2229 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43f72b401723262694459425603_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_3:[dtype=;place=;dim=;lod={};, 0x43f72b401723262694459425603_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.460920  2229 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x43f72b401723262694459425603_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x43f72b401723262694459425603_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.460978  2228 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f72b401723262694459425603_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.460978  2227 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f72b401723262694459425603_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.461009  2228 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.461015  2227 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.461066  2228 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f72b401723262694459425603_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.461102  2227 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x43f72b401723262694459425603_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x43f72b401723262694459425603_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.461112  2228 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43f72b401723262694459425603_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.461128  2228 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.461130  2227 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x43f72b401723262694459425603_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.461138  2228 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43f72b401723262694459425603_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.461146  2227 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.461158  2227 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x43f72b401723262694459425603_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.461186  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x43f72cb0) got event_name: TaskCompletion
2253: I0810 04:04:54.461208  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.461232  1790 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.462515  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.462662  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.462704  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:04:54.465459  1790 pir_interpreter.cc:161] PirInterpreter(): 0x44a41520 on Place(gpu:0)
2253: I0810 04:04:54.465489  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.465508  1790 scope.cc:202] Create variable 0x44a415201723262694465483098_inner_var_1
2253: I0810 04:04:54.465519  1790 scope.cc:202] Create variable 0x44a415201723262694465483098_inner_var_2
2253: I0810 04:04:54.465530  1790 scope.cc:202] Create variable 0x44a415201723262694465483098_inner_var_3
2253: I0810 04:04:54.465541  1790 scope.cc:202] Create variable 0x44a415201723262694465483098_inner_var_4
2253: I0810 04:04:54.465551  1790 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:04:54.465562  1790 scope.cc:202] Create variable 0x44a415201723262694465483098_inner_var_6
2253: I0810 04:04:54.465571  1790 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:04:54.465873  1790 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:04:54.465885  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.465889  1790 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x450a37f0
2253: 1 -> 0x44a415201723262694465483098_inner_var_1 -> 0x450a3890
2253: 2 -> 0x44a415201723262694465483098_inner_var_2 -> 0x4441b900
2253: 3 -> 0x44a415201723262694465483098_inner_var_3 -> 0x43e9a910
2253: 4 -> 0x44a415201723262694465483098_inner_var_4 -> 0x44342a10
2253: 5 -> fetch0@fetch -> 0x4433e850
2253: 6 -> 0x44a415201723262694465483098_inner_var_6 -> 0x4433e810
2253: 7 -> fetch1@fetch -> 0x436a9a10
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:04:54.466559  2230 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.466794  2231 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.466821  2232 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.466854  2233 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.466879  2234 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.466934  2235 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.466951  2235 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.466969  2235 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.466990  2235 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44a415201723262694465483098_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44a415201723262694465483098_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.467070  2235 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44a415201723262694465483098_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x44a415201723262694465483098_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.467116  2234 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a415201723262694465483098_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.467124  2233 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a415201723262694465483098_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.467147  2234 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.467152  2233 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.467204  2234 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a415201723262694465483098_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.467236  2234 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44a415201723262694465483098_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.467234  2233 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a415201723262694465483098_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x44a415201723262694465483098_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.467257  2234 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.467272  2234 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44a415201723262694465483098_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:04:54.467288  2233 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44a415201723262694465483098_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:04:54.467314  2233 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.467329  2233 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44a415201723262694465483098_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:04:54.467365  1790 pir_interpreter.cc:1766] main_thread_blocker_(0x44a41690) got event_name: TaskCompletion
2253: I0810 04:04:54.467387  1790 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.467412  1790 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:04:54.467552  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:201
2253: I0810 04:04:54.467619  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.467635  1790 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:202
2253: I0810 04:04:54.467653  1790 pir.cc:2451] Start compare shape and data.
2253: I0810 04:04:54.468585  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.468604  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.468655  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.468664  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.470499  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.471053  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.471493  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.471508  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.471513  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.473731  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.473810  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.473821  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.473826  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44247ee0 type is 7
2253: I0810 04:04:54.473837  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.473841  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a54af0 type is 7
2253: I0810 04:04:54.473846  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.473850  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a55560 type is 7
2253: I0810 04:04:54.473855  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.473860  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.473932  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.473939  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.473944  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.473948  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.473989  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.474001  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.474050  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.474061  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.474098  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.474108  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.474124  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.474131  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x443f9230Variable Type 7
2253: I0810 04:04:54.474146  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.474166  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.474180  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.474211  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.474220  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.474236  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.474242  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44063030Variable Type 7
2253: I0810 04:04:54.474254  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.474269  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.474283  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.474545  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.474581  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.474601  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.474716  2236 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.474959  2237 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.475005  2238 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.475024  2239 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.475055  2240 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.475103  2241 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.475296  2240 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.475309  2239 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.475402  2240 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.475415  2240 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.475436  1790 program_interpreter.cc:1308] main_thread_blocker_(0x44a54498) got event_name: TaskCompletion
2253: I0810 04:04:54.475560  2236 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 13824773680407106994 to 99701420204608342 , after update, data is {current : -3720, peak : 0}.
2253: I0810 04:04:54.475713  2240 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 7708048296032173470 to 14824236449615686365 , after update, data is {current : -60, peak : 1800}.
2253: I0810 04:04:54.475806  2239 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 14385946922105763111 to 14824236449615686365 , after update, data is {current : 0, peak : 1800}.
2253: I0810 04:04:54.475935  2241 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 13152789332281370610 to 99701420204608342 , after update, data is {current : -1860, peak : 1860}.
2253: I0810 04:04:54.476096  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.477017  2224 thread_data_registry.h:135] Add data {current : 0, peak : 1800} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -1860, peak : 1800}.
2253: I0810 04:04:54.477027  2224 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14824236449615686365 to 99701420204608342 , after update, data is {current : -3720, peak : 1860}.
2253: I0810 04:04:54.477283  2227 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 985972397889609550 to 99701420204608342 , after update, data is {current : 1740, peak : 3600}.
2253: I0810 04:04:54.477360  2228 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 1672121383278216900 to 99701420204608342 , after update, data is {current : 1860, peak : 3600}.
2253: I0810 04:04:54.477468  2229 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 14590479405363806404 to 99701420204608342 , after update, data is {current : -1860, peak : 1860}.
2253: I0810 04:04:54.477623  2230 thread_data_registry.h:135] Add data {current : 1860, peak : 3600} from thread 99701420204608342 to 15785496349805031021 , after update, data is {current : 1980, peak : 3600}.
2253: I0810 04:04:54.477635  2230 thread_data_registry.h:135] Add data {current : -1860, peak : 1860} from thread 99701420204608342 to 11836897867350493708 , after update, data is {current : -3780, peak : 5528}.
2253: I0810 04:04:54.477802  2233 thread_data_registry.h:135] Add data {current : 1980, peak : 3600} from thread 15785496349805031021 to 11836897867350493708 , after update, data is {current : 48960, peak : 48960}.
2253: I0810 04:04:54.477877  2234 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 4370860029569601088 to 11836897867350493708 , after update, data is {current : 52560, peak : 52560}.
2253: I0810 04:04:54.477973  2235 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 8141334110365927881 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.479214  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.479238  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.479290  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.479307  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.481159  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.481748  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.482220  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.482234  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.482240  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.484617  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.484695  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.484709  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.484714  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43b2a3c0 type is 7
2253: I0810 04:04:54.484722  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.484728  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x442e6320 type is 7
2253: I0810 04:04:54.484735  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.484740  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43f12100 type is 7
2253: I0810 04:04:54.484745  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.484751  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.484827  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.484834  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.484839  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.484845  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.484885  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.484898  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.484947  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.484957  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.484995  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.485005  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.485021  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.485029  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4371fc20Variable Type 7
2253: I0810 04:04:54.485044  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.485064  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.485080  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.485110  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.485119  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.485136  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.485143  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43f91c00Variable Type 7
2253: I0810 04:04:54.485155  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.485172  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.485183  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.485422  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.485457  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.485481  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.485579  2242 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.485649  2243 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.485670  2244 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.485714  2245 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.485745  2246 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.485790  2247 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.486011  2245 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.486011  2246 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.486132  2245 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.486150  2245 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.486172  1790 program_interpreter.cc:1308] main_thread_blocker_(0x43f63738) got event_name: TaskCompletion
2253: I0810 04:04:54.486306  2242 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 8141334110365927881 to 14824236449615686365 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.486455  2245 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 11836897867350493708 , after update, data is {current : 54360, peak : 54360}.
2253: I0810 04:04:54.486528  2246 thread_data_registry.h:135] Add data {current : 60, peak : 60} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 54420, peak : 54420}.
2253: I0810 04:04:54.486635  2247 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.487776  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.487934  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.487977  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.488337  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.488368  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.490674  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.490696  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.490748  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.490758  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.492592  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.493147  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.493598  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.493613  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.493618  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.495898  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.495975  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.495987  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.495993  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43ad9310 type is 7
2253: I0810 04:04:54.496007  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.496012  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a3ea20 type is 7
2253: I0810 04:04:54.496017  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.496021  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x440ea6b0 type is 7
2253: I0810 04:04:54.496026  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4464fea0 type is 9
2253: I0810 04:04:54.496038  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x446504b0 type is 10
2253: I0810 04:04:54.496106  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.496114  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.496119  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.496122  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.496163  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.496176  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.496224  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.496234  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.496273  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.496282  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.496308  1790 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.496316  1790 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44d14d60Variable Type 7
2253: I0810 04:04:54.496332  1790 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.496352  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.496366  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.496399  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.496408  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.496424  1790 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.496431  1790 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44c3a5b0Variable Type 7
2253: I0810 04:04:54.496444  1790 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.496460  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.496472  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.496709  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.496742  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.496764  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.496866  2248 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.496940  2249 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.496946  2250 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.496999  2251 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.497051  2253 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.497239  2250 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.497241  2251 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.497328  2252 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.497361  2250 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.497377  2250 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:04:54.497400  1790 program_interpreter.cc:1308] main_thread_blocker_(0x440ea1c8) got event_name: TaskCompletion
2253: I0810 04:04:54.497529  2248 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 14824236449615686365 to 14590479405363806404 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:04:54.497677  2250 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9497174210020301017 to 985972397889609550 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:04:54.497714  2251 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 985972397889609550 to 11836897867350493708 , after update, data is {current : 56280, peak : 56280}.
2253: I0810 04:04:54.497855  2253 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 14590479405363806404 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.498023  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.498548  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.498579  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.498590  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.498710  1790 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:04:54.499684  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.499706  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.499754  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.499764  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.500499  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.500517  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.500556  1790 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:04:54.500566  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.500892  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.500953  1790 pybind.cc:1827] need skip: 0
2253: I0810 04:04:54.501324  1790 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:04:54.501421  1790 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:04:54.501431  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.501510  1790 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.501520  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.503980  1790 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:04:54.504650  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.504666  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.504671  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.508123  1790 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:04:54.508142  1790 scope.cc:202] Create variable feed
2253: I0810 04:04:54.508174  1790 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:04:54.508183  1790 scope.cc:202] Create variable Out
2253: I0810 04:04:54.508188  1790 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44233610 type is 7
2253: I0810 04:04:54.508195  1790 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:04:54.508199  1790 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x443ec1d0 type is 7
2253: I0810 04:04:54.508204  1790 scope.cc:202] Create variable OutScale
2253: I0810 04:04:54.508208  1790 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x443ebb20 type is 7
2253: I0810 04:04:54.508213  1790 scope.cc:202] Create variable X
2253: I0810 04:04:54.508219  1790 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44233de0 type is 7
2253: I0810 04:04:54.508225  1790 scope.cc:202] Create variable X@GRAD
2253: I0810 04:04:54.508231  1790 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44234050 type is 7
2253: I0810 04:04:54.508237  1790 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:04:54.508240  1790 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44234290 type is 7
2253: I0810 04:04:54.508246  1790 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:04:54.508250  1790 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x442344f0 type is 7
2253: I0810 04:04:54.508255  1790 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x442335f0 type is 9
2253: I0810 04:04:54.508261  1790 scope.cc:202] Create variable fetch
2253: I0810 04:04:54.508265  1790 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44234270 type is 10
2253: I0810 04:04:54.508394  1790 interpreter_util.cc:594] Static build: 1
2253: I0810 04:04:54.508401  1790 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:04:54.508407  1790 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:04:54.508412  1790 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:04:54.508461  1790 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508476  1790 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508530  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508539  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508581  1790 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508591  1790 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508632  1790 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508641  1790 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508671  1790 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508680  1790 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508728  1790 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508736  1790 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508767  1790 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.508776  1790 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:04:54.508792  1790 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:04:54.508800  1790 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x43e67490Variable Type 7
2253: I0810 04:04:54.508816  1790 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:04:54.508836  1790 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:04:54.508849  1790 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:04:54.509159  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:04:54.509203  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:04:54.509234  1790 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:04:54.509343  2254 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:04:54.509416  2255 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:04:54.509440  2256 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:04:54.509485  2257 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:04:54.509510  2258 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:04:54.509552  2259 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:04:54.509843  2259 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.509866  2259 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:04:54.509922  2259 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:04:54.509959  2259 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.510040  2258 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:04:54.510115  2258 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:04:54.510139  1790 program_interpreter.cc:1308] main_thread_blocker_(0x443ec9b8) got event_name: TaskCompletion
2253: I0810 04:04:54.510308  2254 thread_data_registry.h:135] Add data {current : -5468, peak : 0} from thread 14590479405363806404 to 14824236449615686365 , after update, data is {current : 0, peak : 5468}.
2253: I0810 04:04:54.510458  2258 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 15482172826034771369 to 11836897867350493708 , after update, data is {current : 58080, peak : 58080}.
2253: I0810 04:04:54.510627  2259 thread_data_registry.h:135] Add data {current : 0, peak : 5468} from thread 14824236449615686365 to 11836897867350493708 , after update, data is {current : -1920, peak : 5528}.
2253: I0810 04:04:54.511600  1790 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x450a3000 for it.
2253: I0810 04:04:54.511756  1790 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x43d743e0 for it.
2253: I0810 04:04:54.511795  1790 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x43db0d40 for it.
2253: I0810 04:04:54.512401  1790 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:04:54.512439  1790 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.512554  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43eada00)  to GradNodeAccumulation (addr: 0x450a3000)
2253: I0810 04:04:54.512643  1790 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:04:54.512663  1790 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.512778  1790 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4429e840)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x43eada00)
2253: I0810 04:04:54.512854  1790 backward.cc:442] Run in Backward
2253: I0810 04:04:54.512862  1790 backward.cc:113] Start Backward
2253: I0810 04:04:54.512871  1790 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:04:54.512905  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.512931  1790 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4429e840
2253: I0810 04:04:54.512939  1790 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:04:54.512962  1790 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.513007  1790 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:04:54.513029  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.513037  1790 backward.cc:335] Node: MeanGradNode addr:0x4429e840, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x43eada00
2253: I0810 04:04:54.513043  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.513067  1790 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43eada00
2253: I0810 04:04:54.513075  1790 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:04:54.513088  1790 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:04:54.513118  1790 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:04:54.513147  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.513154  1790 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x43eada00, Found pending node: GradNodeAccumulation addr: 0x450a3000
2253: I0810 04:04:54.513160  1790 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:04:54.513181  1790 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x450a3000
2253: I0810 04:04:54.513188  1790 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.513195  1790 accumulation_node.cc:40] Move Tensor ptr: 0x4427c580
2253: I0810 04:04:54.513199  1790 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:04:54.513206  1790 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:04:54.579612  1790 mmap_allocator.cc:348] PID: 1790, MemoryMapFdSet: set size - 0
2253: I0810 04:04:54.589242  1790 mmap_allocator.cc:348] PID: 1790, MemoryMapFdSet: set size - 0
2253: I0810 04:04:54.650244  2062 thread_data_registry.h:135] Add data {current : 58080, peak : 58080} from thread 11836897867350493708 to 1738218762300064674 , after update, data is {current : 61680, peak : 61680}.
2253: I0810 04:04:54.650275  2062 thread_data_registry.h:135] Add data {current : -1920, peak : 5528} from thread 11836897867350493708 to 11168886607272271118 , after update, data is {current : 0, peak : 5528}.
2253: I0810 04:04:54.650558  2066 thread_data_registry.h:135] Add data {current : 61680, peak : 61680} from thread 1738218762300064674 to 1580200262163047400 , after update, data is {current : 61920, peak : 61920}.
2253: I0810 04:04:54.650641  2065 thread_data_registry.h:135] Add data {current : 61920, peak : 61920} from thread 1580200262163047400 to 2770829791301891489 , after update, data is {current : 528680, peak : 3097328}.
2253: I0810 04:04:54.650782  2067 thread_data_registry.h:135] Add data {current : 0, peak : 5528} from thread 11168886607272271118 to 2770829791301891489 , after update, data is {current : 1843464, peak : 2555920}.
2253: I0810 04:04:54.781231  1790 mmap_allocator.cc:348] PID: 1790, MemoryMapFdSet: set size - 0
2/2 Test #2253: test_fake_quantize_op_static_build ...   Passed   10.54 sec

The following tests passed:
	test_fake_quantize_op
	test_fake_quantize_op_static_build

100% tests passed, 0 tests failed out of 2

Total Test time (real) =  21.34 sec
