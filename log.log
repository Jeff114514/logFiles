UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1561
    Start 1561: test_fake_quantize_op

1561: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_fake_quantize_op"
1561: Test timeout computed to be: 10000000
1561: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1561: WARNING: Logging before InitGoogleLogging() is written to STDERR
1561: I0810 03:59:37.087277  1133 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1561: I0810 03:59:37.872100  1133 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=cuda_memory_async_pool_realease_threshold,use_mkldnn,npu_storage_format,enable_opt_get_features,check_nan_inf,dist_threadpool_size,query_dest_rank_by_multi_node,pinned_memory_as_cpu_backend,prim_forward_blacklist,mkl_dir,max_inplace_grad_add,curand_dir,inner_op_parallelism,graph_get_neighbor_id,use_xqa_optim,gpugraph_sparse_table_storage_mode,executor_log_deps_every_microseconds,use_virtual_memory_auto_growth,reallocate_gpu_memory_in_mb,enable_unused_var_check,pir_broadcast_tree_limit,host_trace_level,initial_gpu_memory_in_mb,cudnn_dir,tracer_onednn_ops_on,benchmark,op_dir,paddle_num_threads,gpugraph_dedup_pull_push_mode,enable_pir_in_executor_trace_run,cusolver_dir,cublaslt_exhaustive_search_times,nccl_dir,log_memory_stats,add_dependency_for_communication_op,graph_neighbor_size_percent,tracer_onednn_ops_off,prim_forward,trt_ibuilder_cache,gpugraph_parallel_copyer_split_maxsize,accuracy_check_rtol_bf16,gpugraph_merge_grads_segment_size,enable_pir_api,enable_async_trace,init_allocated_mem,memory_fraction_of_eager_deletion,gemm_use_half_precision_compute_type,prim_skip_dynamic,fleet_executor_with_standalone,enable_interpretercore_launch_cinn,gpugraph_slot_feasign_max_num,allreduce_record_one_event,pir_apply_inplace_pass,enable_fusion_fallback,gpugraph_storage_mode,gpugraph_enable_print_op_debug,cupti_dir,prim_enabled,enable_blaslt_global_search,low_precision_op_list,ir_inplace_kernel_blacklist,print_sub_graph_dir,accuracy_check_rtol_fp16,gpugraph_offload_param_extends,allocator_strategy,pir_debug,convert_all_blocks,gpugraph_offload_param_stat,use_auto_growth_v2,cudnn_batchnorm_spatial_persistent,prim_check_ops,apply_pass_to_program,use_fast_math,deny_cinn_ops,run_kp_kernel,new_executor_use_local_scope,enable_cinn_auto_tune,print_allocator_trace_info,graph_load_in_parallel,gpugraph_offload_gather_copy_maxsize,enable_neighbor_list_use_uva,dataloader_use_file_descriptor,async_trace_count,use_shm_cache,enable_cublas_tensor_op_math,pir_apply_shape_optimization_pass,cublas_dir,accuracy_check_atol_bf16,gpugraph_parallel_stream_num,embedding_deterministic,multiple_of_cupti_buffer_size,cusparse_dir,sync_nccl_allreduce,static_executor_perfstat_filepath,logging_pir_py_code_dump_symbolic_dims,fuse_parameter_groups_size,tracer_profile_fname,gpugraph_load_node_list_into_hbm,benchmark_nccl,enable_collect_shape,enable_fuse_parallel_matmul_pass,cuda_dir,enable_graph_multi_node_sampling,new_executor_use_inplace,enable_api_kernel_fallback,enable_sparse_inner_gather,prim_backward,sort_sum_gradient,jit_engine_type,eager_delete_tensor_gb,graph_embedding_split_infer_mode,cache_inference_while_scope,cuda_malloc_async_pool_memory_throttle_ratio,reader_queue_speed_test_mode,print_ir,use_cinn,allow_cinn_ops,set_to_1d,cublaslt_device_best_config,enable_gpu_memory_usage_log_mb,tensorrt_dir,multi_node_sample_use_gpu_table,fast_eager_deletion_mode,use_auto_growth_pinned_allocator,search_cache_max_number,enable_cse_in_dy2st,gpugraph_enable_segment_merge_grads,fraction_of_gpu_memory_to_use,logging_pir_py_code_dir,enable_gpu_memory_usage_log,new_executor_static_build,accuracy_check_atol_fp32,einsum_opt,enable_cinn_accuracy_check,check_nan_inf_level,cinn_subgraph_graphviz_dir,dynamic_static_unified_comm,new_executor_use_cuda_graph,all_blocks_convert_trt,gpu_memory_limit_mb,mklml_dir,dump_chunk_info,cinn_compile_thread_num,accuracy_check_atol_fp16,cudnn_exhaustive_search,gpugraph_enable_gpu_direct_access,cudnn_exhaustive_search_times,enable_exit_when_partial_worker,auto_growth_chunk_size_in_mb,logging_pir_py_code_int_tensor_element_limit,auto_free_cudagraph_allocations_on_launch,free_idle_chunk,use_cuda_malloc_async_allocator,custom_device_mem_record,free_when_no_cache_hit,nccl_blocking_wait,disable_dyshape_in_train,conv2d_disable_cudnn,static_runtime_data_save_path,enable_tracker_all2all,conv_workspace_size_limit,alloc_fill_value,lapack_dir,enable_auto_detect_gpu_topo,get_host_by_name_time,use_pinned_memory,local_exe_sub_scope_limit,call_stack_level,use_autotune,use_cuda_managed_memory,save_static_runtime_data,use_system_allocator,use_stride_kernel,enable_pir_in_executor,fuse_parameter_memory_size,enable_record_memory,win_cuda_bin_dir,selected_gpus,enable_auto_rdma_trans,check_infer_symbolic,gpugraph_hbm_table_load_factor,use_stream_safe_cuda_allocator,graph_metapath_split_opt,eager_delete_scope,accuracy_check_rtol_fp32,enable_cinn_compile_cache,fraction_of_cuda_pinned_memory_to_use,pir_subgraph_saving_dir,enable_dependency_builder_debug_info,gpugraph_enable_hbm_table_collision_stat,fraction_of_cpu_memory_to_use,gpu_allocator_retry_time,sync_after_alloc,enable_all2all_use_fp16,cse_max_count,initial_cpu_memory_in_mb,prim_all,enable_pir_with_pt_in_dy2st,tensor_operants_mode,gpugraph_force_device_batch_num_equal,logging_trunc_pir_py_code,nvidia_package_dir,cusparselt_dir,gpugraph_debug_gpu_memory,enable_dump_main_program,manually_trans_conv_filter,cudnn_deterministic,enable_adjust_op_order,new_executor_serial_run,dygraph_debug,prim_enable_dynamic,check_kernel_launch,new_executor_sequential_run 
1561: I0810 03:59:37.872210  1133 init.cc:108] After Parse: argc is 2
1561: I0810 03:59:45.846174  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:45.846235  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:45.846423  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:45.846436  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:45.846989  1133 allocator_facade.cc:212] selected allocator strategy:1
1561: I0810 03:59:45.847270  1133 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1561: I0810 03:59:48.234627  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.235116  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.235641  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.235659  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.235677  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.237820  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.237843  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.237939  1133 program_interpreter.cc:243] New Executor is Running.
1561: I0810 03:59:48.237948  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.237954  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.237965  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44cc21b0 type is 7
1561: I0810 03:59:48.237979  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.237982  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44cc2110 type is 7
1561: I0810 03:59:48.237987  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.237990  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44cc2bd0 type is 7
1561: I0810 03:59:48.237993  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.237998  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.238001  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.238070  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.238076  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.238080  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.238085  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: W0810 03:59:48.238693  1133 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1561: I0810 03:59:48.238936  1133 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1561: W0810 03:59:48.239871  1133 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1561: I0810 03:59:48.240059  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.240082  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.240238  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.240247  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.240267  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.240521  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.240545  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.240566  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.240576  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45141080Variable Type 7
1561: I0810 03:59:48.240595  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.240619  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.240648  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.240669  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.241047  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.241101  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.241171  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.241181  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.241197  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.241204  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44cc4080Variable Type 7
1561: I0810 03:59:48.241217  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.241230  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.241250  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.241263  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.241318  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.241349  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.241829  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.241865  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.241884  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.339900  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.339937  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.340014  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.340023  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.342798  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.343396  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.343919  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.343933  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.343940  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.346413  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.346529  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.346544  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.346552  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4517e850 type is 7
1561: I0810 03:59:48.346561  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.346567  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4517d9a0 type is 7
1561: I0810 03:59:48.346572  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.346577  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4517e420 type is 7
1561: I0810 03:59:48.346582  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.346587  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.346673  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.346679  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.346684  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.346688  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.346751  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.346769  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.346849  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.346861  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.346880  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.347080  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.347095  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.347112  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.347121  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45186e20Variable Type 7
1561: I0810 03:59:48.347138  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.347160  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.347185  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.347204  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.347498  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.347530  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.347589  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.347600  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.347620  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.347626  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4517ec10Variable Type 7
1561: I0810 03:59:48.347642  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.347657  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.347676  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.347693  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.347740  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.347769  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.348104  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.348145  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.348167  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.348444  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.350332  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.350355  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.350407  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.350416  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.352370  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.352950  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.353415  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.353430  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.353435  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.355716  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.355793  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.355804  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.355810  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x451797a0 type is 7
1561: I0810 03:59:48.355820  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.355824  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x451788c0 type is 7
1561: I0810 03:59:48.355829  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.355832  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45179370 type is 7
1561: I0810 03:59:48.355837  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.355844  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.355932  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.355939  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.355944  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.355948  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.355991  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.356004  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.356065  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.356074  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.356094  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.356227  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.356240  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.356258  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.356266  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45146480Variable Type 7
1561: I0810 03:59:48.356281  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.356297  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.356328  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.356343  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.356539  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.356560  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.356611  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.356621  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.356639  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.356647  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451462c0Variable Type 7
1561: I0810 03:59:48.356662  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.356675  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.356694  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.356709  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.356748  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.356770  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.357081  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.357120  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.357141  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.359354  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.359549  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a660980 for it.
1561: I0810 03:59:48.359606  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.360450  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.360512  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.370440  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.370608  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.370653  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a660980 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 03:59:48.376190  1133 pir_interpreter.cc:161] PirInterpreter(): 0x4528f190 on Place(gpu:0)
1561: I0810 03:59:48.376232  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.376264  1133 scope.cc:202] Create variable 0x4528f1901723262388376217391_inner_var_1
1561: I0810 03:59:48.376276  1133 scope.cc:202] Create variable 0x4528f1901723262388376217391_inner_var_2
1561: I0810 03:59:48.376289  1133 scope.cc:202] Create variable 0x4528f1901723262388376217391_inner_var_3
1561: I0810 03:59:48.376298  1133 scope.cc:202] Create variable 0x4528f1901723262388376217391_inner_var_4
1561: I0810 03:59:48.376317  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.376327  1133 scope.cc:202] Create variable 0x4528f1901723262388376217391_inner_var_6
1561: I0810 03:59:48.376338  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.376775  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.376791  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.376796  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: I0810 03:59:48.376844  1133 pir_interpreter.cc:1455] New Executor is Running ...
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x4528d950
1561: 1 -> 0x4528f1901723262388376217391_inner_var_1 -> 0x4528f170
1561: 2 -> 0x4528f1901723262388376217391_inner_var_2 -> 0x4528d420
1561: 3 -> 0x4528f1901723262388376217391_inner_var_3 -> 0x4528c7f0
1561: 4 -> 0x4528f1901723262388376217391_inner_var_4 -> 0x4528fba0
1561: 5 -> fetch0@fetch -> 0x45290000
1561: 6 -> 0x4528f1901723262388376217391_inner_var_6 -> 0x4528fbc0
1561: 7 -> fetch1@fetch -> 0x45290700
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.377641  1133 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1561: I0810 03:59:48.377866  1171 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.377993  1172 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.378086  1174 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.378090  1173 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.378181  1175 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.378238  1176 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.378316  1176 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.378414  1176 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.378477  1176 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4528f1901723262388376217391_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4528f1901723262388376217391_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.378655  1176 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4528f1901723262388376217391_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x4528f1901723262388376217391_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.378748  1175 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4528f1901723262388376217391_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.378752  1174 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4528f1901723262388376217391_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.378806  1175 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.378806  1174 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.378923  1174 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4528f1901723262388376217391_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.379230  1175 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4528f1901723262388376217391_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4528f1901723262388376217391_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.379243  1174 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4528f1901723262388376217391_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.379264  1175 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4528f1901723262388376217391_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.379274  1174 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.379289  1175 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.379326  1174 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4528f1901723262388376217391_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.379447  1175 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4528f1901723262388376217391_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.379519  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x4528f300) got event_name: TaskCompletion
1561: I0810 03:59:48.379563  1133 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.379658  1133 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.383234  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a660980 for it.
1561: I0810 03:59:48.383502  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.383554  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.386637  1171 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 11087063223774793996 to 18063684737095990605 , after update, data is {current : -196596, peak : 24}.
1561: I0810 03:59:48.386657  1171 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 11087063223774793996 to 6151130021515389890 , after update, data is {current : 0, peak : 196620}.
1561: I0810 03:59:48.386828  1175 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 4571571410515315331 to 18063684737095990605 , after update, data is {current : 196620, peak : 393216}.
1561: I0810 03:59:48.386904  1174 thread_data_registry.h:135] Add data {current : 196620, peak : 393216} from thread 18063684737095990605 to 6743992051131779078 , after update, data is {current : 393240, peak : 393240}.
1561: I0810 03:59:48.387058  1176 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 6151130021515389890 to 6743992051131779078 , after update, data is {current : 589836, peak : 786444}.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 03:59:48.388236  1133 pir_interpreter.cc:161] PirInterpreter(): 0x45301520 on Place(gpu:0)
1561: I0810 03:59:48.388273  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.388295  1133 scope.cc:202] Create variable 0x453015201723262388388263501_inner_var_1
1561: I0810 03:59:48.388337  1133 scope.cc:202] Create variable 0x453015201723262388388263501_inner_var_2
1561: I0810 03:59:48.388347  1133 scope.cc:202] Create variable 0x453015201723262388388263501_inner_var_3
1561: I0810 03:59:48.388356  1133 scope.cc:202] Create variable 0x453015201723262388388263501_inner_var_4
1561: I0810 03:59:48.388367  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.388379  1133 scope.cc:202] Create variable 0x453015201723262388388263501_inner_var_6
1561: I0810 03:59:48.388389  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.388797  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.388811  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.388816  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x452654a0
1561: 1 -> 0x453015201723262388388263501_inner_var_1 -> 0x44cc1a20
1561: 2 -> 0x453015201723262388388263501_inner_var_2 -> 0x45301a60
1561: 3 -> 0x453015201723262388388263501_inner_var_3 -> 0x45264d10
1561: 4 -> 0x453015201723262388388263501_inner_var_4 -> 0x4528ffe0
1561: 5 -> fetch0@fetch -> 0x452906e0
1561: 6 -> 0x453015201723262388388263501_inner_var_6 -> 0x4528d910
1561: 7 -> fetch1@fetch -> 0x45290a30
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.389578  1177 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.389662  1178 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.389709  1179 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.389725  1180 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.389779  1181 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.389806  1182 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.389838  1182 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.389871  1182 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.389902  1182 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x453015201723262388388263501_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_3:[dtype=;place=;dim=;lod={};, 0x453015201723262388388263501_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.389999  1182 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x453015201723262388388263501_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x453015201723262388388263501_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.390082  1181 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x453015201723262388388263501_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.390086  1179 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x453015201723262388388263501_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.390129  1181 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.390133  1179 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.390494  1181 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x453015201723262388388263501_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.390529  1179 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x453015201723262388388263501_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x453015201723262388388263501_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.390535  1181 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x453015201723262388388263501_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.390558  1181 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.390587  1179 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x453015201723262388388263501_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.390609  1179 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.390622  1179 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x453015201723262388388263501_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.390717  1181 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x453015201723262388388263501_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.390754  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x45301690) got event_name: TaskCompletion
1561: I0810 03:59:48.390777  1133 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.390846  1133 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.391054  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:19
1561: I0810 03:59:48.391265  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.391285  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:20
1561: I0810 03:59:48.391309  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.392426  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.392448  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.392508  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.392517  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.394590  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.395157  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.395634  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.395650  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.395655  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.397940  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.398015  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.398026  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.398032  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45318a00 type is 7
1561: I0810 03:59:48.398044  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.398048  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45317b60 type is 7
1561: I0810 03:59:48.398054  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.398058  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x453185d0 type is 7
1561: I0810 03:59:48.398065  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.398072  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.398144  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.398150  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.398156  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.398161  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.398216  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.398234  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.398312  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.398324  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.398344  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.398469  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.398483  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.398500  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.398509  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45321370Variable Type 7
1561: I0810 03:59:48.398526  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.398546  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.398568  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.398584  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.398792  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.398818  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.398869  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.398880  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.398896  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.398905  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4531cc00Variable Type 7
1561: I0810 03:59:48.398919  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.398934  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.398953  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.398968  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.399009  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.399027  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.399315  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.399356  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.399377  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.399596  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.400668  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.400709  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.400722  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.400923  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.402034  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.402057  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.402105  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.402115  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.403134  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.403162  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.403208  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.403214  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.403616  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.403699  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.404160  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.404580  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.404603  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.404690  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.404706  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.407224  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.407861  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.407877  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.407882  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.411334  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.411351  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.411381  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.411391  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.411396  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x451b3e50 type is 7
1561: I0810 03:59:48.411404  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.411410  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x451b3d30 type is 7
1561: I0810 03:59:48.411417  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.411420  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x451b3680 type is 7
1561: I0810 03:59:48.411427  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.411430  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x451b4a60 type is 7
1561: I0810 03:59:48.411437  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.411441  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x451b4cd0 type is 7
1561: I0810 03:59:48.411448  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.411451  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x451b4f10 type is 7
1561: I0810 03:59:48.411458  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.411461  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x451b5170 type is 7
1561: I0810 03:59:48.411468  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x451b36a0 type is 9
1561: I0810 03:59:48.411473  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.411479  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x451b4ef0 type is 10
1561: I0810 03:59:48.411590  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.411597  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.411604  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.411610  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.411660  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.411674  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.411728  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.411738  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.411757  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.411902  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.411916  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.411933  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.412360  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.412377  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.412451  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.412482  1133 interpreter_util.cc:647] Standalone Executor is Used.
1561: I0810 03:59:48.412509  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.412519  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.412539  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.412626  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.412637  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.412654  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.412693  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.412768  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.412779  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.412797  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.412806  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x453fa370Variable Type 7
1561: I0810 03:59:48.412822  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.412838  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.412858  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.412873  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.413062  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.413081  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.413401  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.413439  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.413472  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.415802  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.415983  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.416018  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a660980 for it.
1561: I0810 03:59:48.416538  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.416574  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.416669  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44ca88e0)  to GradNodeAccumulation (addr: 0x1a6420d0)
1561: I0810 03:59:48.416790  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.416807  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.417012  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x44c99680)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44ca88e0)
1561: I0810 03:59:48.417102  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.417112  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.417129  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.417169  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.417201  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x44c99680
1561: I0810 03:59:48.417220  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.417258  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.417346  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.417372  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.417383  1133 backward.cc:335] Node: MeanGradNode addr:0x44c99680, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44ca88e0
1561: I0810 03:59:48.417392  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.417424  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44ca88e0
1561: I0810 03:59:48.417443  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.417456  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.417490  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.417516  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.417524  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44ca88e0, Found pending node: GradNodeAccumulation addr: 0x1a6420d0
1561: I0810 03:59:48.417529  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.417546  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a6420d0
1561: I0810 03:59:48.417553  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.417559  1133 accumulation_node.cc:40] Move Tensor ptr: 0x44c98340
1561: I0810 03:59:48.417562  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.417567  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1561: Warning:
1561: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1561:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1561:   return func(*args, **kwargs)
1561: I0810 03:59:48.504169  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.504189  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.504232  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.504240  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.505818  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.506273  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.506662  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.506675  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.506681  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.508541  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.508598  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.508608  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.508612  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a9caa40 type is 7
1561: I0810 03:59:48.508620  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.508622  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1a9c9b50 type is 7
1561: I0810 03:59:48.508627  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.508630  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x1a9ca610 type is 7
1561: I0810 03:59:48.508635  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.508639  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.508713  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.508720  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.508724  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.508728  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.508764  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.508775  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.508826  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.508834  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.508850  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.508942  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.508953  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.508968  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.508975  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9d2a60Variable Type 7
1561: I0810 03:59:48.508991  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.509006  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.509022  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.509035  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.509222  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.509248  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.509284  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.509292  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.509315  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.509321  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9c9df0Variable Type 7
1561: I0810 03:59:48.509333  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.509346  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.509361  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.509373  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.509406  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.509424  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.509641  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.509670  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.509688  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.512758  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.512776  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.512820  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.512828  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.514376  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.514832  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.515192  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.515203  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.515208  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.517005  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.517063  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.517073  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.517077  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4535e6c0 type is 7
1561: I0810 03:59:48.517084  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.517087  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44cb1ad0 type is 7
1561: I0810 03:59:48.517092  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.517095  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x451b1250 type is 7
1561: I0810 03:59:48.517100  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.517104  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.517163  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.517169  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.517174  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.517179  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.517210  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.517222  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.517266  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.517275  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.517290  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.517386  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.517397  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.517411  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.517417  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4535ee50Variable Type 7
1561: I0810 03:59:48.517431  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.517444  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.517462  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.517474  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.517659  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.517678  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.517716  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.517725  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.517740  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.517747  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x453560d0Variable Type 7
1561: I0810 03:59:48.517758  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.517771  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.517786  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.517798  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.517832  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.517848  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.518054  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.518082  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.518100  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.518251  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.519274  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.519294  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.519340  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.519348  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.520874  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.521334  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.521692  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.521703  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.521708  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.523509  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.523562  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.523571  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.523576  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x453580c0 type is 7
1561: I0810 03:59:48.523582  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.523586  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x453571a0 type is 7
1561: I0810 03:59:48.523590  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.523594  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45357c90 type is 7
1561: I0810 03:59:48.523599  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.523604  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.523665  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.523671  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.523675  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.523679  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.523711  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.523722  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.523766  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.523773  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.523788  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.523874  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.523885  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.523898  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.523905  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451b6440Variable Type 7
1561: I0810 03:59:48.523918  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.523932  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.523949  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.523962  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.524138  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.524156  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.524192  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.524200  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.524215  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.524221  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9d7630Variable Type 7
1561: I0810 03:59:48.524235  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.524246  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.524262  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.524273  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.524312  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.524329  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.524531  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.524559  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.524575  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.526217  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.526412  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a660980 for it.
1561: I0810 03:59:48.526456  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.526822  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.526854  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.529385  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.529565  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.529608  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a660980 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 03:59:48.532533  1133 pir_interpreter.cc:161] PirInterpreter(): 0x4531e320 on Place(gpu:0)
1561: I0810 03:59:48.532564  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.532584  1133 scope.cc:202] Create variable 0x4531e3201723262388532556997_inner_var_1
1561: I0810 03:59:48.532596  1133 scope.cc:202] Create variable 0x4531e3201723262388532556997_inner_var_2
1561: I0810 03:59:48.532608  1133 scope.cc:202] Create variable 0x4531e3201723262388532556997_inner_var_3
1561: I0810 03:59:48.532616  1133 scope.cc:202] Create variable 0x4531e3201723262388532556997_inner_var_4
1561: I0810 03:59:48.532626  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.532636  1133 scope.cc:202] Create variable 0x4531e3201723262388532556997_inner_var_6
1561: I0810 03:59:48.532645  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.533000  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.533015  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.533020  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x4531fdf0
1561: 1 -> 0x4531e3201723262388532556997_inner_var_1 -> 0x4531fe70
1561: 2 -> 0x4531e3201723262388532556997_inner_var_2 -> 0x45358330
1561: 3 -> 0x4531e3201723262388532556997_inner_var_3 -> 0x45359f20
1561: 4 -> 0x4531e3201723262388532556997_inner_var_4 -> 0x453555c0
1561: 5 -> fetch0@fetch -> 0x1a9d8d00
1561: 6 -> 0x4531e3201723262388532556997_inner_var_6 -> 0x453555e0
1561: 7 -> fetch1@fetch -> 0x1a9cfb70
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.533818  1183 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.533954  1184 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.533979  1185 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.534037  1186 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.534122  1187 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.534158  1188 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.534212  1188 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.534250  1188 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.534286  1188 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4531e3201723262388532556997_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4531e3201723262388532556997_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.534415  1188 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4531e3201723262388532556997_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x4531e3201723262388532556997_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.534482  1186 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4531e3201723262388532556997_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.534478  1187 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4531e3201723262388532556997_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.534507  1186 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.534510  1187 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.534564  1186 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4531e3201723262388532556997_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.534878  1187 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4531e3201723262388532556997_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4531e3201723262388532556997_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.534888  1186 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4531e3201723262388532556997_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.534904  1186 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.534907  1187 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4531e3201723262388532556997_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.534914  1186 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4531e3201723262388532556997_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.534926  1187 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.535077  1187 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4531e3201723262388532556997_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.535110  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x4531e490) got event_name: TaskCompletion
1561: I0810 03:59:48.535132  1133 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.535194  1133 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.537906  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a660980 for it.
1561: I0810 03:59:48.538102  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.538151  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: I0810 03:59:48.541224  1133 pir_interpreter.cc:161] PirInterpreter(): 0x4534c2d0 on Place(gpu:0)
1561: I0810 03:59:48.541256  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.541276  1133 scope.cc:202] Create variable 0x4534c2d01723262388541248349_inner_var_1
1561: I0810 03:59:48.541288  1133 scope.cc:202] Create variable 0x4534c2d01723262388541248349_inner_var_2
1561: I0810 03:59:48.541307  1133 scope.cc:202] Create variable 0x4534c2d01723262388541248349_inner_var_3
1561: I0810 03:59:48.541319  1133 scope.cc:202] Create variable 0x4534c2d01723262388541248349_inner_var_4
1561: I0810 03:59:48.541332  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.541343  1133 scope.cc:202] Create variable 0x4534c2d01723262388541248349_inner_var_6
1561: I0810 03:59:48.541353  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.541705  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.541723  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.541726  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x1a9d8750
1561: 1 -> 0x4534c2d01723262388541248349_inner_var_1 -> 0x45323d70
1561: 2 -> 0x4534c2d01723262388541248349_inner_var_2 -> 0x45323530
1561: 3 -> 0x4534c2d01723262388541248349_inner_var_3 -> 0x45356650
1561: 4 -> 0x4534c2d01723262388541248349_inner_var_4 -> 0x1a9aff10
1561: 5 -> fetch0@fetch -> 0x4531d320
1561: 6 -> 0x4534c2d01723262388541248349_inner_var_6 -> 0x1a9d80c0
1561: 7 -> fetch1@fetch -> 0x4531da20
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.542482  1189 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.542654  1191 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.542680  1190 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.542701  1192 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.542815  1193 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.542824  1194 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.542863  1194 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.542896  1194 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.542928  1194 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4534c2d01723262388541248349_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4534c2d01723262388541248349_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.543026  1194 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4534c2d01723262388541248349_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x4534c2d01723262388541248349_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.543083  1193 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4534c2d01723262388541248349_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.543093  1192 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4534c2d01723262388541248349_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.543114  1193 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.543126  1192 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.543179  1193 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4534c2d01723262388541248349_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.543493  1192 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4534c2d01723262388541248349_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4534c2d01723262388541248349_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.543504  1193 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4534c2d01723262388541248349_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.543520  1193 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.543524  1192 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4534c2d01723262388541248349_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.543534  1193 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4534c2d01723262388541248349_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
1561: I0810 03:59:48.543540  1192 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.543701  1192 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4534c2d01723262388541248349_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
1561: I0810 03:59:48.543733  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x4534c440) got event_name: TaskCompletion
1561: I0810 03:59:48.543754  1133 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.543802  1133 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.543948  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:45
1561: I0810 03:59:48.544029  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.544044  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:46
1561: I0810 03:59:48.544057  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.544924  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.544942  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.544987  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.544996  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.546567  1183 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 16032460314951642159 to 5273543327658301049 , after update, data is {current : -393240, peak : 0}.
1561: I0810 03:59:48.546579  1183 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 16032460314951642159 to 5273543327658301049 , after update, data is {current : -393240, peak : 0}.
1561: I0810 03:59:48.546727  1187 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 851839650703684232 to 5273543327658301049 , after update, data is {current : -24, peak : 393216}.
1561: I0810 03:59:48.546794  1186 thread_data_registry.h:135] Add data {current : 24, peak : 24} from thread 17260883039236997028 to 5273543327658301049 , after update, data is {current : 0, peak : 393216}.
1561: I0810 03:59:48.546938  1188 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 3547362242347984968 to 5273543327658301049 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 03:59:48.547109  1189 thread_data_registry.h:135] Add data {current : 0, peak : 393216} from thread 5273543327658301049 to 15570368069496115662 , after update, data is {current : 393216, peak : 393216}.
1561: I0810 03:59:48.547117  1189 thread_data_registry.h:135] Add data {current : -196620, peak : 196620} from thread 5273543327658301049 to 10083915897714757693 , after update, data is {current : 0, peak : 196620}.
1561: I0810 03:59:48.547247  1192 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 15570368069496115662 to 6151130021515389890 , after update, data is {current : 196596, peak : 393216}.
1561: I0810 03:59:48.547326  1193 thread_data_registry.h:135] Add data {current : 24, peak : 24} from thread 2444487992483424474 to 6151130021515389890 , after update, data is {current : 196620, peak : 393216}.
1561: I0810 03:59:48.547420  1194 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 10083915897714757693 to 6151130021515389890 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 03:59:48.548375  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.548844  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.549264  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.549276  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.549281  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.551184  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.551242  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.551252  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.551256  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x451bac50 type is 7
1561: I0810 03:59:48.551263  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.551266  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1a9d3180 type is 7
1561: I0810 03:59:48.551270  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.551273  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4531f650 type is 7
1561: I0810 03:59:48.551276  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.551281  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.551355  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.551362  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.551365  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.551368  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.551409  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.551419  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.551469  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.551477  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.551492  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.551594  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.551604  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.551618  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.551625  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45293490Variable Type 7
1561: I0810 03:59:48.551638  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.551653  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.551671  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.551683  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.551874  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.551899  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.551941  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.551949  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.551965  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.551971  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44c9be30Variable Type 7
1561: I0810 03:59:48.551983  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.551996  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.552012  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.552024  1133 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.552058  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.552078  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.552313  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.552343  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.552362  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.552534  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.553138  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.553167  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.553179  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.553311  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.554157  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.554175  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.554215  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.554224  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.554852  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.554869  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.554903  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.554909  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.555204  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.555259  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.555601  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.555691  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.555701  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.555763  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.555771  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.557817  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.558365  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.558379  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.558383  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.561081  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.561098  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.561122  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.561131  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.561134  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45333530 type is 7
1561: I0810 03:59:48.561141  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.561144  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x45317070 type is 7
1561: I0810 03:59:48.561148  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.561151  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x453169c0 type is 7
1561: I0810 03:59:48.561156  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.561158  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x453339b0 type is 7
1561: I0810 03:59:48.561162  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.561165  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45333b80 type is 7
1561: I0810 03:59:48.561170  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.561173  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45333d70 type is 7
1561: I0810 03:59:48.561177  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.561180  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45333f80 type is 7
1561: I0810 03:59:48.561184  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45333510 type is 9
1561: I0810 03:59:48.561189  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.561192  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45333d50 type is 10
1561: I0810 03:59:48.561285  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.561291  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.561295  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.561304  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.561344  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561355  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561399  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561408  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561424  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.561537  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561547  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561560  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.561724  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561735  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561769  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.561805  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561813  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561829  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.561892  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561902  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.561916  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.562389  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.562466  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.562476  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.562494  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.562500  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451a97a0Variable Type 7
1561: I0810 03:59:48.562515  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.562528  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.562547  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.562561  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.562783  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.562798  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.563354  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.563387  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.563412  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.564980  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.565143  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.565186  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.565807  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.565847  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.566252  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44240e60)  to GradNodeAccumulation (addr: 0x4534aa10)
1561: I0810 03:59:48.566365  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.566390  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.566560  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x44c99680)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44240e60)
1561: I0810 03:59:48.566643  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.566651  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.566659  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.566695  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.566723  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x44c99680
1561: I0810 03:59:48.566731  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.566757  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.566800  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.566824  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.566833  1133 backward.cc:335] Node: MeanGradNode addr:0x44c99680, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44240e60
1561: I0810 03:59:48.566838  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.566864  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44240e60
1561: I0810 03:59:48.566870  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.566884  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.566907  1133 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.566939  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.566946  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44240e60, Found pending node: GradNodeAccumulation addr: 0x4534aa10
1561: I0810 03:59:48.566951  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.566967  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4534aa10
1561: I0810 03:59:48.566973  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.566977  1133 accumulation_node.cc:40] Move Tensor ptr: 0x451b54d0
1561: I0810 03:59:48.566982  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.566987  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.569980  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.570003  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.570053  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.570062  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.571906  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.572482  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.572921  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.572934  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.572939  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.575165  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.575232  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.575242  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.575248  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4547ca30 type is 7
1561: I0810 03:59:48.575258  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.575261  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4547c320 type is 7
1561: I0810 03:59:48.575266  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.575273  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4547cde0 type is 7
1561: I0810 03:59:48.575277  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.575284  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.575362  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.575369  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.575373  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.575378  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.575418  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.575431  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.575487  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.575497  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.575515  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.575704  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.575717  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.575734  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.575742  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45485ff0Variable Type 7
1561: I0810 03:59:48.575758  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.575774  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.575795  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.575810  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.575887  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.575908  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.575960  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.575970  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.575987  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.575994  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45481a30Variable Type 7
1561: I0810 03:59:48.576009  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.576023  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.576041  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.576056  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.576092  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.576112  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.576385  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.576419  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.576442  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.578236  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.578259  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.578317  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.578327  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.580149  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.580718  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.581146  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.581161  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.581166  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.583411  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.583485  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.583495  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.583501  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45457300 type is 7
1561: I0810 03:59:48.583510  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.583515  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45456450 type is 7
1561: I0810 03:59:48.583520  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.583527  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45456ed0 type is 7
1561: I0810 03:59:48.583532  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.583537  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.583606  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.583613  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.583617  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.583622  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.583662  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.583674  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.583729  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.583739  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.583756  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.583878  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.583891  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.583909  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.583916  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4545b520Variable Type 7
1561: I0810 03:59:48.583931  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.583947  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.583968  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.583983  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.584057  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.584079  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.584126  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.584136  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.584153  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.584160  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4545b250Variable Type 7
1561: I0810 03:59:48.584173  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.584187  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.584205  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.584219  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.584256  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.584276  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.584549  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.584590  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.584611  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.584805  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.587009  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.587029  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.587073  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.587081  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.588573  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.589030  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.589411  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.589423  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.589427  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.591244  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.591315  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.591325  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.591331  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45298240 type is 7
1561: I0810 03:59:48.591336  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.591338  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45487700 type is 7
1561: I0810 03:59:48.591342  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.591346  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45356000 type is 7
1561: I0810 03:59:48.591351  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.591354  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.591415  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.591421  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.591425  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.591428  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.591460  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.591471  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.591514  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.591522  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.591537  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.591637  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.591648  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.591662  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.591668  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4530c520Variable Type 7
1561: I0810 03:59:48.591681  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.591694  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.591710  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.591722  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.591786  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.591804  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.591843  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.591852  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.591866  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.591872  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9d5360Variable Type 7
1561: I0810 03:59:48.591883  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.591894  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.591909  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.591920  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.591953  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.591969  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.592185  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.592216  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.592233  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.593418  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.593564  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.593605  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.593969  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.593999  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.595957  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.596100  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.596143  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 03:59:48.598989  1133 pir_interpreter.cc:161] PirInterpreter(): 0x44c97f00 on Place(gpu:0)
1561: I0810 03:59:48.599020  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.599038  1133 scope.cc:202] Create variable 0x44c97f001723262388599012723_inner_var_1
1561: I0810 03:59:48.599049  1133 scope.cc:202] Create variable 0x44c97f001723262388599012723_inner_var_2
1561: I0810 03:59:48.599059  1133 scope.cc:202] Create variable 0x44c97f001723262388599012723_inner_var_3
1561: I0810 03:59:48.599071  1133 scope.cc:202] Create variable 0x44c97f001723262388599012723_inner_var_4
1561: I0810 03:59:48.599082  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.599093  1133 scope.cc:202] Create variable 0x44c97f001723262388599012723_inner_var_6
1561: I0810 03:59:48.599103  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.599417  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.599432  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.599435  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x452929a0
1561: 1 -> 0x44c97f001723262388599012723_inner_var_1 -> 0x452929e0
1561: 2 -> 0x44c97f001723262388599012723_inner_var_2 -> 0x4534a3a0
1561: 3 -> 0x44c97f001723262388599012723_inner_var_3 -> 0x1a9d1050
1561: 4 -> 0x44c97f001723262388599012723_inner_var_4 -> 0x45330730
1561: 5 -> fetch0@fetch -> 0x4535dcc0
1561: 6 -> 0x44c97f001723262388599012723_inner_var_6 -> 0x45330750
1561: 7 -> fetch1@fetch -> 0x44ca08b0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.600111  1195 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.600178  1196 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.600204  1197 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.600245  1198 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.600270  1199 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.600320  1200 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.600363  1200 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.600399  1200 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.600431  1200 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44c97f001723262388599012723_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44c97f001723262388599012723_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.600574  1200 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44c97f001723262388599012723_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x44c97f001723262388599012723_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.600638  1198 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44c97f001723262388599012723_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.600642  1199 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44c97f001723262388599012723_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.600677  1198 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.600682  1199 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.600777  1198 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44c97f001723262388599012723_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.600816  1199 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44c97f001723262388599012723_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x44c97f001723262388599012723_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.600829  1198 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44c97f001723262388599012723_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.600850  1198 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.600847  1199 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44c97f001723262388599012723_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.600867  1199 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.600876  1199 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44c97f001723262388599012723_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.600875  1198 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44c97f001723262388599012723_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.600920  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x44c98070) got event_name: TaskCompletion
1561: I0810 03:59:48.600945  1133 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.600980  1133 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.602394  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.602556  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.602598  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 03:59:48.605388  1133 pir_interpreter.cc:161] PirInterpreter(): 0x1a9c78f0 on Place(gpu:0)
1561: I0810 03:59:48.605419  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.605437  1133 scope.cc:202] Create variable 0x1a9c78f01723262388605412902_inner_var_1
1561: I0810 03:59:48.605448  1133 scope.cc:202] Create variable 0x1a9c78f01723262388605412902_inner_var_2
1561: I0810 03:59:48.605460  1133 scope.cc:202] Create variable 0x1a9c78f01723262388605412902_inner_var_3
1561: I0810 03:59:48.605471  1133 scope.cc:202] Create variable 0x1a9c78f01723262388605412902_inner_var_4
1561: I0810 03:59:48.605482  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.605494  1133 scope.cc:202] Create variable 0x1a9c78f01723262388605412902_inner_var_6
1561: I0810 03:59:48.605504  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.605804  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.605819  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.605823  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x1a9c8c50
1561: 1 -> 0x1a9c78f01723262388605412902_inner_var_1 -> 0x44c9ebd0
1561: 2 -> 0x1a9c78f01723262388605412902_inner_var_2 -> 0x453fc730
1561: 3 -> 0x1a9c78f01723262388605412902_inner_var_3 -> 0x62d2290
1561: 4 -> 0x1a9c78f01723262388605412902_inner_var_4 -> 0x453f98f0
1561: 5 -> fetch0@fetch -> 0x453f9d60
1561: 6 -> 0x1a9c78f01723262388605412902_inner_var_6 -> 0x453f9910
1561: 7 -> fetch1@fetch -> 0x4535c1d0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.606499  1201 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.606570  1202 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.606603  1203 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.606638  1204 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.606660  1205 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.606704  1206 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.606731  1206 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.606755  1206 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.606784  1206 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a9c78f01723262388605412902_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1a9c78f01723262388605412902_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.606889  1206 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a9c78f01723262388605412902_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x1a9c78f01723262388605412902_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.606942  1205 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9c78f01723262388605412902_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.606945  1204 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9c78f01723262388605412902_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.606972  1205 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.606978  1204 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.607036  1205 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9c78f01723262388605412902_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.607090  1204 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9c78f01723262388605412902_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x1a9c78f01723262388605412902_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.607100  1205 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9c78f01723262388605412902_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.607116  1205 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.607116  1204 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9c78f01723262388605412902_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.607127  1205 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9c78f01723262388605412902_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.607136  1204 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.607169  1204 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9c78f01723262388605412902_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.607201  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x1a9c7a60) got event_name: TaskCompletion
1561: I0810 03:59:48.607224  1133 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.607256  1133 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.607409  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:71
1561: I0810 03:59:48.607489  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.607506  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:72
1561: I0810 03:59:48.607523  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.608474  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.608495  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.608546  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.608554  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.610371  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.610921  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.611363  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.611378  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.611383  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.613580  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.613656  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.613667  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.613672  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a9ae850 type is 7
1561: I0810 03:59:48.613682  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.613687  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45456240 type is 7
1561: I0810 03:59:48.613691  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.613695  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x1a9adac0 type is 7
1561: I0810 03:59:48.613703  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.613708  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.613781  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.613788  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.613792  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.613797  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.613837  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.613849  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.613904  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.613914  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.613931  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.614059  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.614073  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.614089  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.614097  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45339c50Variable Type 7
1561: I0810 03:59:48.614112  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.614128  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.614148  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.614163  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.614246  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.614269  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.614323  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.614334  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.614351  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.614358  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9adc90Variable Type 7
1561: I0810 03:59:48.614372  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.614387  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.614405  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.614419  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.614457  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.614477  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.614737  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.614771  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.614794  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.614987  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.615505  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.615538  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.615551  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.615679  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.616672  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.616693  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.616742  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.616751  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.617492  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.617512  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.617552  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.617560  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.617899  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.617964  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.618343  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.618439  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.618449  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.618527  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.618536  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.620450  1195 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 10083915897714757693 to 5273543327658301049 , after update, data is {current : 29920, peak : 60000}.
1561: I0810 03:59:48.620463  1195 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 10083915897714757693 to 12645738160726870451 , after update, data is {current : 0, peak : 30080}.
1561: I0810 03:59:48.620683  1198 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 16032460314951642159 to 5273543327658301049 , after update, data is {current : 89920, peak : 89920}.
1561: I0810 03:59:48.620759  1199 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 12154384437526056481 to 5273543327658301049 , after update, data is {current : 90080, peak : 90080}.
1561: I0810 03:59:48.620879  1200 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 12645738160726870451 to 6151130021515389890 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 03:59:48.621054  1201 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 17260883039236997028 to 5273543327658301049 , after update, data is {current : 60000, peak : 90080}.
1561: I0810 03:59:48.621063  1201 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 17260883039236997028 to 6151130021515389890 , after update, data is {current : -226700, peak : 196620}.
1561: I0810 03:59:48.621234  1204 thread_data_registry.h:135] Add data {current : 60000, peak : 90080} from thread 5273543327658301049 to 13849610542794429082 , after update, data is {current : 60160, peak : 90080}.
1561: I0810 03:59:48.621317  1205 thread_data_registry.h:135] Add data {current : 60160, peak : 90080} from thread 13849610542794429082 to 6151130021515389890 , after update, data is {current : 256780, peak : 393216}.
1561: I0810 03:59:48.621423  1206 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 5166932111831906457 to 6151130021515389890 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 03:59:48.622702  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.623378  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.623394  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.623399  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.626816  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.626837  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.626865  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.626875  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.626880  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4534c050 type is 7
1561: I0810 03:59:48.626889  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.626893  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x6368930 type is 7
1561: I0810 03:59:48.626899  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.626905  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1a9af8b0 type is 7
1561: I0810 03:59:48.626910  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.626914  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x451b1950 type is 7
1561: I0810 03:59:48.626919  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.626924  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x451b1b70 type is 7
1561: I0810 03:59:48.626928  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.626932  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x451b1db0 type is 7
1561: I0810 03:59:48.626937  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.626941  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x451b2010 type is 7
1561: I0810 03:59:48.626946  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45456d20 type is 9
1561: I0810 03:59:48.626955  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.626960  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x451b1d90 type is 10
1561: I0810 03:59:48.627064  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.627071  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.627076  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.627080  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.627128  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627141  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627193  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627203  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627221  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.627384  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627398  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627414  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.627609  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627624  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627660  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.627699  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627710  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627728  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.627810  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627821  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.627838  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.627875  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.627940  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.627951  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.627969  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.627976  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4534ea30Variable Type 7
1561: I0810 03:59:48.627993  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.628010  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.628029  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.628044  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.628114  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.628131  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.628466  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.628500  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.628530  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.629611  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.629762  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.629803  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.630386  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.630422  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.630527  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x441352e0)  to GradNodeAccumulation (addr: 0x4534aa10)
1561: I0810 03:59:48.630614  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.630633  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.630785  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x44c99680)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x441352e0)
1561: I0810 03:59:48.630863  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.630870  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.630877  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.630908  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.630935  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x44c99680
1561: I0810 03:59:48.630944  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.630966  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.631014  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.631038  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.631047  1133 backward.cc:335] Node: MeanGradNode addr:0x44c99680, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x441352e0
1561: I0810 03:59:48.631052  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.631075  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x441352e0
1561: I0810 03:59:48.631083  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.631095  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.631124  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.631153  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.631160  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x441352e0, Found pending node: GradNodeAccumulation addr: 0x4534aa10
1561: I0810 03:59:48.631165  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.631186  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4534aa10
1561: I0810 03:59:48.631193  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.631197  1133 accumulation_node.cc:40] Move Tensor ptr: 0x1a9d8810
1561: I0810 03:59:48.631201  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.631206  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.643154  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.643175  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.643220  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.643229  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.644963  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.645447  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.645889  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.645901  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.645905  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.647802  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.647869  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.647878  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.647883  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4518ff50 type is 7
1561: I0810 03:59:48.647890  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.647894  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4518f020 type is 7
1561: I0810 03:59:48.647899  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.647903  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4518fb20 type is 7
1561: I0810 03:59:48.647908  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.647912  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.647986  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.647993  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.647997  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.648000  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.648036  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.648048  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.648095  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.648104  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.648119  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.648232  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.648243  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.648259  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.648265  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4518cb50Variable Type 7
1561: I0810 03:59:48.648280  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.648294  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.648324  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.648336  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.648407  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.648427  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.648468  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.648476  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.648491  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.648497  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45474440Variable Type 7
1561: I0810 03:59:48.648512  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.648524  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.648540  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.648551  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.648582  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.648602  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.648852  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.648890  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.648907  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.650692  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.650714  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.650764  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.650774  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.652623  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.653178  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.653625  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.653638  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.653643  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.655843  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.655917  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.655928  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.655934  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a918530 type is 7
1561: I0810 03:59:48.655942  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.655947  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1a917680 type is 7
1561: I0810 03:59:48.655956  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.655959  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x1a918100 type is 7
1561: I0810 03:59:48.655964  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.655969  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.656045  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.656052  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.656059  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.656064  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.656105  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.656118  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.656172  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.656180  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.656198  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.656333  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.656347  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.656364  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.656371  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451a4200Variable Type 7
1561: I0810 03:59:48.656387  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.656404  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.656424  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.656440  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.656508  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.656529  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.656579  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.656589  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.656607  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.656615  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9188a0Variable Type 7
1561: I0810 03:59:48.656628  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.656642  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.656661  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.656674  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.656710  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.656730  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.656984  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.657024  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.657045  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.657244  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.658505  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.658526  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.658576  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.658586  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.660421  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.660984  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.661434  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.661448  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.661453  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.663683  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.663756  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.663766  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.663772  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4552d2d0 type is 7
1561: I0810 03:59:48.663780  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.663786  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4552c3f0 type is 7
1561: I0810 03:59:48.663792  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.663796  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4552cea0 type is 7
1561: I0810 03:59:48.663801  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.663807  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.663878  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.663887  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.663892  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.663899  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.663939  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.663952  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.664007  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.664017  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.664036  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.664155  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.664167  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.664186  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.664192  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x455358f0Variable Type 7
1561: I0810 03:59:48.664208  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.664224  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.664245  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.664260  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.664330  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.664353  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.664402  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.664410  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.664428  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.664435  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45531430Variable Type 7
1561: I0810 03:59:48.664450  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.664464  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.664484  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.664497  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.664532  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.664554  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.664820  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.664857  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.664880  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.666144  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.666297  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.666352  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.666733  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.666764  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.668746  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.668891  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.668932  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 03:59:48.672989  1133 pir_interpreter.cc:161] PirInterpreter(): 0x454d5550 on Place(gpu:0)
1561: I0810 03:59:48.673019  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.673038  1133 scope.cc:202] Create variable 0x454d55501723262388673012877_inner_var_1
1561: I0810 03:59:48.673050  1133 scope.cc:202] Create variable 0x454d55501723262388673012877_inner_var_2
1561: I0810 03:59:48.673060  1133 scope.cc:202] Create variable 0x454d55501723262388673012877_inner_var_3
1561: I0810 03:59:48.673069  1133 scope.cc:202] Create variable 0x454d55501723262388673012877_inner_var_4
1561: I0810 03:59:48.673080  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.673090  1133 scope.cc:202] Create variable 0x454d55501723262388673012877_inner_var_6
1561: I0810 03:59:48.673100  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.673432  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.673447  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.673451  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x45193650
1561: 1 -> 0x454d55501723262388673012877_inner_var_1 -> 0x4535c740
1561: 2 -> 0x454d55501723262388673012877_inner_var_2 -> 0x45325a60
1561: 3 -> 0x454d55501723262388673012877_inner_var_3 -> 0x453f9d40
1561: 4 -> 0x454d55501723262388673012877_inner_var_4 -> 0x451b94c0
1561: 5 -> fetch0@fetch -> 0x45474ef0
1561: 6 -> 0x454d55501723262388673012877_inner_var_6 -> 0x45363490
1561: 7 -> fetch1@fetch -> 0x44c9aeb0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.674136  1207 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.674228  1208 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.674254  1209 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.674291  1210 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.674356  1211 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.674393  1212 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.674412  1212 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.674438  1212 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.674465  1212 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x454d55501723262388673012877_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_3:[dtype=;place=;dim=;lod={};, 0x454d55501723262388673012877_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.674561  1212 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x454d55501723262388673012877_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x454d55501723262388673012877_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.674612  1211 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454d55501723262388673012877_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.674640  1211 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.674623  1210 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454d55501723262388673012877_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.674657  1210 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.674701  1211 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454d55501723262388673012877_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.674758  1210 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454d55501723262388673012877_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454d55501723262388673012877_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.674768  1211 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x454d55501723262388673012877_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.674786  1211 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.674788  1210 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x454d55501723262388673012877_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.674798  1211 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x454d55501723262388673012877_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.674804  1210 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.674836  1210 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x454d55501723262388673012877_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.674867  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x454d56c0) got event_name: TaskCompletion
1561: I0810 03:59:48.674890  1133 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.674921  1133 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.676378  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.676534  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.676576  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: I0810 03:59:48.679386  1133 pir_interpreter.cc:161] PirInterpreter(): 0x45488360 on Place(gpu:0)
1561: I0810 03:59:48.679416  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.679435  1133 scope.cc:202] Create variable 0x454883601723262388679410313_inner_var_1
1561: I0810 03:59:48.679445  1133 scope.cc:202] Create variable 0x454883601723262388679410313_inner_var_2
1561: I0810 03:59:48.679456  1133 scope.cc:202] Create variable 0x454883601723262388679410313_inner_var_3
1561: I0810 03:59:48.679464  1133 scope.cc:202] Create variable 0x454883601723262388679410313_inner_var_4
1561: I0810 03:59:48.679473  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.679486  1133 scope.cc:202] Create variable 0x454883601723262388679410313_inner_var_6
1561: I0810 03:59:48.679495  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.679803  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.679817  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.679821  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x4531e280
1561: 1 -> 0x454883601723262388679410313_inner_var_1 -> 0x45361f70
1561: 2 -> 0x454883601723262388679410313_inner_var_2 -> 0x44c9cf20
1561: 3 -> 0x454883601723262388679410313_inner_var_3 -> 0x45362030
1561: 4 -> 0x454883601723262388679410313_inner_var_4 -> 0x4534eca0
1561: 5 -> fetch0@fetch -> 0x44ca06f0
1561: 6 -> 0x454883601723262388679410313_inner_var_6 -> 0x1a9cd3a0
1561: 7 -> fetch1@fetch -> 0x1a9d5ab0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.680500  1213 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.680606  1214 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.680640  1215 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.680670  1216 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.680706  1217 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.680753  1218 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.680770  1218 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.680789  1218 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.680814  1218 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x454883601723262388679410313_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_3:[dtype=;place=;dim=;lod={};, 0x454883601723262388679410313_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.680903  1218 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x454883601723262388679410313_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x454883601723262388679410313_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.680950  1217 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454883601723262388679410313_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.680969  1217 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.680968  1216 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454883601723262388679410313_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.681010  1216 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.681020  1217 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454883601723262388679410313_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.681044  1217 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x454883601723262388679410313_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.681061  1217 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.681071  1217 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x454883601723262388679410313_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
1561: I0810 03:59:48.681099  1216 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454883601723262388679410313_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x454883601723262388679410313_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.681128  1216 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x454883601723262388679410313_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.681147  1216 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.681171  1216 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x454883601723262388679410313_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
1561: I0810 03:59:48.681203  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x454884d0) got event_name: TaskCompletion
1561: I0810 03:59:48.681224  1133 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.681252  1133 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.681411  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:97
1561: I0810 03:59:48.681499  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.681516  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:98
1561: I0810 03:59:48.681533  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.682471  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.682490  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.682541  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.682550  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.684417  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.684976  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.685431  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.685444  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.685449  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.687696  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.687772  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.687783  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.687789  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a90db00 type is 7
1561: I0810 03:59:48.687798  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.687803  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x454590b0 type is 7
1561: I0810 03:59:48.687808  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.687812  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45458ed0 type is 7
1561: I0810 03:59:48.687819  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.687825  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.687899  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.687907  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.687913  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.687919  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.687959  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.687973  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.688027  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.688037  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.688055  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.688186  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.688199  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.688217  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.688225  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4548ae00Variable Type 7
1561: I0810 03:59:48.688241  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.688257  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.688278  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.688293  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.688376  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.688398  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.688448  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.688458  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.688477  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.688483  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451889f0Variable Type 7
1561: I0810 03:59:48.688498  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.688513  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.688532  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.688547  1133 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.688583  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.688606  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.688876  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.688915  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.688936  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.689133  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.689656  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.689688  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.689702  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.689841  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.690851  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.690872  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.690922  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.690932  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.691692  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.691712  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.691752  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.691761  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.692119  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.692186  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.692579  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.692678  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.692688  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.692766  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.692775  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.695257  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.695878  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.695894  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.695899  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.699254  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.699273  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.699312  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.699323  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.699328  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45572990 type is 7
1561: I0810 03:59:48.699335  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.699342  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x1a904d00 type is 7
1561: I0810 03:59:48.699348  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.699352  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1a904650 type is 7
1561: I0810 03:59:48.699357  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.699362  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45572d90 type is 7
1561: I0810 03:59:48.699368  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.699371  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45572f60 type is 7
1561: I0810 03:59:48.699378  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.699383  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45573150 type is 7
1561: I0810 03:59:48.699390  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.699394  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45573360 type is 7
1561: I0810 03:59:48.699399  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45572970 type is 9
1561: I0810 03:59:48.699405  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.699409  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45573130 type is 10
1561: I0810 03:59:48.699519  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.699527  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.699532  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.699537  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.699586  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.699599  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.699656  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.699666  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.699684  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.699836  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.699849  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.699865  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.700059  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.700073  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.700114  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.700155  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.700165  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.700183  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.700264  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.700276  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.700292  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.700340  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.700407  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.700419  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.700436  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.700444  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4556e850Variable Type 7
1561: I0810 03:59:48.700461  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.700479  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.700498  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.700513  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.700578  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.700596  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.700915  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.700948  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.700980  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.702090  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.702250  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.702291  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.702893  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.702929  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.703027  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44ca88e0)  to GradNodeAccumulation (addr: 0x4534aa10)
1561: I0810 03:59:48.703116  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.703136  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.703291  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x45327060)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44ca88e0)
1561: I0810 03:59:48.703382  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.703390  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.703399  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.703434  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.703459  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x45327060
1561: I0810 03:59:48.703469  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.703493  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.703541  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.703564  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.703572  1133 backward.cc:335] Node: MeanGradNode addr:0x45327060, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44ca88e0
1561: I0810 03:59:48.703578  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.703601  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44ca88e0
1561: I0810 03:59:48.703610  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.703624  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.703651  1133 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.703680  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.703687  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44ca88e0, Found pending node: GradNodeAccumulation addr: 0x4534aa10
1561: I0810 03:59:48.703692  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.703716  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4534aa10
1561: I0810 03:59:48.703722  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.703728  1133 accumulation_node.cc:40] Move Tensor ptr: 0x1a9d8810
1561: I0810 03:59:48.703732  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.703737  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.705567  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.705586  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.705628  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.705636  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.706449  1207 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 5166932111831906457 to 15570368069496115662 , after update, data is {current : 29920, peak : 60000}.
1561: I0810 03:59:48.706466  1207 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 5166932111831906457 to 10083915897714757693 , after update, data is {current : 0, peak : 30080}.
1561: I0810 03:59:48.706612  1210 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 16032460314951642159 to 15570368069496115662 , after update, data is {current : 89920, peak : 89920}.
1561: I0810 03:59:48.706683  1211 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 12154384437526056481 to 15570368069496115662 , after update, data is {current : 90080, peak : 90080}.
1561: I0810 03:59:48.706791  1212 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 12645738160726870451 to 10083915897714757693 , after update, data is {current : 30080, peak : 30080}.
1561: I0810 03:59:48.706935  1213 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 17260883039236997028 to 15570368069496115662 , after update, data is {current : 60000, peak : 90080}.
1561: I0810 03:59:48.706943  1213 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 17260883039236997028 to 10083915897714757693 , after update, data is {current : 0, peak : 30080}.
1561: I0810 03:59:48.707089  1216 thread_data_registry.h:135] Add data {current : 60000, peak : 90080} from thread 15570368069496115662 to 6151130021515389890 , after update, data is {current : 316780, peak : 393216}.
1561: I0810 03:59:48.707165  1217 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 2444487992483424474 to 6151130021515389890 , after update, data is {current : 316940, peak : 393216}.
1561: I0810 03:59:48.707262  1218 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 10083915897714757693 to 6151130021515389890 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 03:59:48.708833  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.709296  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.709692  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.709704  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.709708  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.711587  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.711652  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.711661  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.711666  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a905230 type is 7
1561: I0810 03:59:48.711673  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.711679  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45194aa0 type is 7
1561: I0810 03:59:48.711683  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.711687  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x453f7690 type is 7
1561: I0810 03:59:48.711692  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.711696  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.711760  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.711766  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.711771  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.711776  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.711809  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.711820  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.711865  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.711874  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.711889  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.712028  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.712038  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.712054  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.712059  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9b5b80Variable Type 7
1561: I0810 03:59:48.712072  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.712086  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.712103  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.712116  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.712158  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.712177  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.712219  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.712229  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.712242  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.712249  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45319350Variable Type 7
1561: I0810 03:59:48.712262  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.712273  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.712287  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.712316  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.712348  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.712366  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.712576  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.712605  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.712622  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.714237  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.714260  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.714321  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.714332  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.716172  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.716743  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.717185  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.717198  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.717203  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.719463  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.719540  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.719552  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.719558  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4534e290 type is 7
1561: I0810 03:59:48.719566  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.719571  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x453fdf10 type is 7
1561: I0810 03:59:48.719576  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.719580  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x451a5ab0 type is 7
1561: I0810 03:59:48.719585  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.719591  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.719664  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.719671  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.719676  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.719681  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.719722  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.719735  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.719789  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.719798  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.719815  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.719933  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.719944  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.719961  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.719969  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45470710Variable Type 7
1561: I0810 03:59:48.719985  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.720002  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.720023  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.720037  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.720084  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.720106  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.720155  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.720163  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.720182  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.720189  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4544f240Variable Type 7
1561: I0810 03:59:48.720204  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.720218  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.720237  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.720250  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.720285  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.720316  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.720568  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.720602  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.720623  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.720819  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.722077  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.722100  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.722149  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.722158  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.723991  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.724568  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.725023  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.725035  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.725040  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.727293  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.727381  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.727392  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.727398  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a915b50 type is 7
1561: I0810 03:59:48.727406  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.727414  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45306e40 type is 7
1561: I0810 03:59:48.727420  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.727424  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x1a915740 type is 7
1561: I0810 03:59:48.727430  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.727435  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.727514  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.727520  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.727524  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.727530  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.727571  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.727584  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.727638  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.727648  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.727666  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.727783  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.727794  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.727813  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.727820  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4546adf0Variable Type 7
1561: I0810 03:59:48.727836  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.727854  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.727874  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.727890  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.727938  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.727962  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.728008  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.728018  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.728037  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.728044  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451a1c80Variable Type 7
1561: I0810 03:59:48.728057  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.728071  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.728091  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.728103  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.728138  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.728159  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.728425  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.728461  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.728483  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.729672  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.729822  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.729866  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.730247  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.730281  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.732152  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.732296  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.732348  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 03:59:48.735313  1133 pir_interpreter.cc:161] PirInterpreter(): 0x1a915d50 on Place(gpu:0)
1561: I0810 03:59:48.735347  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.735368  1133 scope.cc:202] Create variable 0x1a915d501723262388735339766_inner_var_1
1561: I0810 03:59:48.735378  1133 scope.cc:202] Create variable 0x1a915d501723262388735339766_inner_var_2
1561: I0810 03:59:48.735388  1133 scope.cc:202] Create variable 0x1a915d501723262388735339766_inner_var_3
1561: I0810 03:59:48.735400  1133 scope.cc:202] Create variable 0x1a915d501723262388735339766_inner_var_4
1561: I0810 03:59:48.735412  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.735423  1133 scope.cc:202] Create variable 0x1a915d501723262388735339766_inner_var_6
1561: I0810 03:59:48.735432  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.735749  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.735762  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.735766  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x1a9c3750
1561: 1 -> 0x1a915d501723262388735339766_inner_var_1 -> 0x454842a0
1561: 2 -> 0x1a915d501723262388735339766_inner_var_2 -> 0x1a9c3730
1561: 3 -> 0x1a915d501723262388735339766_inner_var_3 -> 0x45484280
1561: 4 -> 0x1a915d501723262388735339766_inner_var_4 -> 0x45484710
1561: 5 -> fetch0@fetch -> 0x1a912d60
1561: 6 -> 0x1a915d501723262388735339766_inner_var_6 -> 0x45484730
1561: 7 -> fetch1@fetch -> 0x45537380
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.736469  1219 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.736548  1220 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.736582  1221 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.736624  1222 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.736654  1223 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.736696  1224 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.736719  1224 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.736748  1224 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.736778  1224 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a915d501723262388735339766_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1a915d501723262388735339766_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.736902  1224 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a915d501723262388735339766_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x1a915d501723262388735339766_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.736951  1223 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a915d501723262388735339766_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.736958  1222 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a915d501723262388735339766_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.736979  1223 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.736984  1222 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.737047  1223 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a915d501723262388735339766_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.737087  1222 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a915d501723262388735339766_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a915d501723262388735339766_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.737089  1223 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a915d501723262388735339766_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.737118  1223 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.737129  1223 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a915d501723262388735339766_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.737149  1222 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a915d501723262388735339766_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.737169  1222 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.737177  1222 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a915d501723262388735339766_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.737208  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x1a915ec0) got event_name: TaskCompletion
1561: I0810 03:59:48.737231  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.737258  1133 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.738591  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.738754  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.738794  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 03:59:48.741619  1133 pir_interpreter.cc:161] PirInterpreter(): 0x454521d0 on Place(gpu:0)
1561: I0810 03:59:48.741649  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.741668  1133 scope.cc:202] Create variable 0x454521d01723262388741643198_inner_var_1
1561: I0810 03:59:48.741679  1133 scope.cc:202] Create variable 0x454521d01723262388741643198_inner_var_2
1561: I0810 03:59:48.741689  1133 scope.cc:202] Create variable 0x454521d01723262388741643198_inner_var_3
1561: I0810 03:59:48.741701  1133 scope.cc:202] Create variable 0x454521d01723262388741643198_inner_var_4
1561: I0810 03:59:48.741710  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.741722  1133 scope.cc:202] Create variable 0x454521d01723262388741643198_inner_var_6
1561: I0810 03:59:48.741732  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.742038  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.742053  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.742058  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x1a8fe5b0
1561: 1 -> 0x454521d01723262388741643198_inner_var_1 -> 0x4546ba60
1561: 2 -> 0x454521d01723262388741643198_inner_var_2 -> 0x1a9b2980
1561: 3 -> 0x454521d01723262388741643198_inner_var_3 -> 0x4546b100
1561: 4 -> 0x454521d01723262388741643198_inner_var_4 -> 0x454695f0
1561: 5 -> fetch0@fetch -> 0x1a9b2c20
1561: 6 -> 0x454521d01723262388741643198_inner_var_6 -> 0x45452b00
1561: 7 -> fetch1@fetch -> 0x4552bac0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.742746  1225 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.742839  1226 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.742880  1227 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.742904  1228 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.742944  1229 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.742982  1230 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.743000  1230 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.743021  1230 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.743043  1230 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x454521d01723262388741643198_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_3:[dtype=;place=;dim=;lod={};, 0x454521d01723262388741643198_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.743147  1230 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x454521d01723262388741643198_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x454521d01723262388741643198_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.743191  1229 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454521d01723262388741643198_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.743214  1229 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.743206  1228 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454521d01723262388741643198_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.743233  1228 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.743263  1229 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454521d01723262388741643198_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.743312  1228 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x454521d01723262388741643198_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x454521d01723262388741643198_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.743323  1229 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x454521d01723262388741643198_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.743340  1229 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.743350  1229 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x454521d01723262388741643198_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.743359  1228 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x454521d01723262388741643198_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.743376  1228 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.743386  1228 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x454521d01723262388741643198_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.743418  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x45452340) got event_name: TaskCompletion
1561: I0810 03:59:48.743444  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.743469  1133 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.743610  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:123
1561: I0810 03:59:48.743687  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.743702  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:124
1561: I0810 03:59:48.743719  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.744942  1219 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 10083915897714757693 to 5273543327658301049 , after update, data is {current : 1680, peak : 3600}.
1561: I0810 03:59:48.744958  1219 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 10083915897714757693 to 12645738160726870451 , after update, data is {current : 0, peak : 1920}.
1561: I0810 03:59:48.745311  1223 thread_data_registry.h:135] Add data {current : 240, peak : 240} from thread 12154384437526056481 to 5273543327658301049 , after update, data is {current : 1920, peak : 3600}.
1561: I0810 03:59:48.745379  1222 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 16032460314951642159 to 5273543327658301049 , after update, data is {current : 5520, peak : 5520}.
1561: I0810 03:59:48.745518  1224 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 12645738160726870451 to 6151130021515389890 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 03:59:48.745688  1225 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 17260883039236997028 to 5273543327658301049 , after update, data is {current : 3600, peak : 5520}.
1561: I0810 03:59:48.745697  1225 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 17260883039236997028 to 6151130021515389890 , after update, data is {current : -198540, peak : 196620}.
1561: I0810 03:59:48.745858  1228 thread_data_registry.h:135] Add data {current : 3600, peak : 5520} from thread 5273543327658301049 to 13849610542794429082 , after update, data is {current : 3840, peak : 5520}.
1561: I0810 03:59:48.745931  1229 thread_data_registry.h:135] Add data {current : 3840, peak : 5520} from thread 13849610542794429082 to 6151130021515389890 , after update, data is {current : 320780, peak : 393216}.
1561: I0810 03:59:48.746047  1230 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 5166932111831906457 to 6151130021515389890 , after update, data is {current : -196620, peak : 196620}.
1561: I0810 03:59:48.746634  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.746657  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.746712  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.746721  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.748637  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.749202  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.749686  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.749701  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.749706  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.752019  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.752103  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.752115  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.752120  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4531d030 type is 7
1561: I0810 03:59:48.752130  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.752135  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1a9c3710 type is 7
1561: I0810 03:59:48.752139  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.752144  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x451a31e0 type is 7
1561: I0810 03:59:48.752151  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.752158  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.752238  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.752244  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.752249  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.752255  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.752298  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.752324  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.752384  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.752394  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.752413  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.752543  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.752555  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.752574  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.752583  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45472860Variable Type 7
1561: I0810 03:59:48.752599  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.752615  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.752636  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.752652  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.752703  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.752725  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.752775  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.752784  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.752802  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.752810  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45141fb0Variable Type 7
1561: I0810 03:59:48.752823  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.752838  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.752856  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.752871  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.752907  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.752926  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.753191  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.753227  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.753248  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.753453  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.753969  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.754001  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.754014  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.754133  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.755131  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.755152  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.755203  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.755211  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.755951  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.755971  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.756011  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.756021  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.756373  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.756440  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.756817  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.756912  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.756922  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.757000  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.757009  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.759521  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.760156  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.760170  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.760176  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.763546  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.763566  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.763595  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.763604  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.763609  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45442830 type is 7
1561: I0810 03:59:48.763617  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.763623  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x45442dd0 type is 7
1561: I0810 03:59:48.763630  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.763634  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45442720 type is 7
1561: I0810 03:59:48.763639  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.763643  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45443ab0 type is 7
1561: I0810 03:59:48.763648  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.763653  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45443d20 type is 7
1561: I0810 03:59:48.763659  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.763664  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45443f60 type is 7
1561: I0810 03:59:48.763670  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.763674  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x454441c0 type is 7
1561: I0810 03:59:48.763679  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4545ae50 type is 9
1561: I0810 03:59:48.763685  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.763692  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45443f40 type is 10
1561: I0810 03:59:48.763798  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.763805  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.763811  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.763818  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.763865  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.763878  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.763934  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.763944  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.763962  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.764107  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764122  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764137  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.764310  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764324  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764364  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.764405  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764415  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764434  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.764518  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764529  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764545  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.764582  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.764647  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.764658  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.764676  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.764683  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a90cfc0Variable Type 7
1561: I0810 03:59:48.764700  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.764717  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.764736  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.764752  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.764793  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.764811  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.765122  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.765153  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.765183  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.766211  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.766374  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.766417  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.766997  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.767033  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.767132  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44240e60)  to GradNodeAccumulation (addr: 0x4534aa10)
1561: I0810 03:59:48.767220  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.767239  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.767370  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x45327060)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44240e60)
1561: I0810 03:59:48.767449  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.767457  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.767467  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.767501  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.767527  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x45327060
1561: I0810 03:59:48.767535  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.767560  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.767604  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.767627  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.767634  1133 backward.cc:335] Node: MeanGradNode addr:0x45327060, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44240e60
1561: I0810 03:59:48.767640  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.767666  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44240e60
1561: I0810 03:59:48.767674  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.767688  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.767715  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.767745  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.767750  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44240e60, Found pending node: GradNodeAccumulation addr: 0x4534aa10
1561: I0810 03:59:48.767757  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.767778  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4534aa10
1561: I0810 03:59:48.767786  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.767791  1133 accumulation_node.cc:40] Move Tensor ptr: 0x45573e50
1561: I0810 03:59:48.767796  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.767802  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.770164  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.770184  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.770226  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.770233  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.771731  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.772183  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.772550  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.772562  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.772567  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.774369  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.774435  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.774446  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.774451  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4540fed0 type is 7
1561: I0810 03:59:48.774456  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.774462  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4540efe0 type is 7
1561: I0810 03:59:48.774467  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.774471  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4540faa0 type is 7
1561: I0810 03:59:48.774477  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.774482  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.774541  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.774547  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.774551  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.774555  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.774588  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.774600  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.774643  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.774652  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.774667  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.774761  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.774771  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.774785  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.774791  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a8f2b00Variable Type 7
1561: I0810 03:59:48.774804  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.774818  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.774835  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.774847  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.774888  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.774906  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.774945  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.774953  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.774967  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.774973  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4540f280Variable Type 7
1561: I0810 03:59:48.774986  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.774998  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.775013  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.775025  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.775054  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.775070  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.775280  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.775317  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.775336  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.776894  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.776916  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.776966  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.776975  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.778800  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.779363  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.779795  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.779808  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.779814  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.781983  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.782058  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.782070  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.782076  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45433a90 type is 7
1561: I0810 03:59:48.782083  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.782090  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45432be0 type is 7
1561: I0810 03:59:48.782096  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.782101  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45433660 type is 7
1561: I0810 03:59:48.782107  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.782114  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.782186  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.782192  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.782197  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.782200  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.782240  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.782253  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.782316  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.782327  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.782346  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.782461  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.782474  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.782490  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.782497  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45551e40Variable Type 7
1561: I0810 03:59:48.782513  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.782529  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.782550  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.782565  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.782610  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.782631  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.782680  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.782688  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.782706  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.782712  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4554a0e0Variable Type 7
1561: I0810 03:59:48.782727  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.782740  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.782759  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.782773  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.782807  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.782827  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.783083  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.783118  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.783138  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.783347  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.785710  1177 thread_data_registry.h:135] Add data {current : 320780, peak : 393216} from thread 6151130021515389890 to 18063684737095990605 , after update, data is {current : 320804, peak : 393216}.
1561: I0810 03:59:48.785732  1177 thread_data_registry.h:135] Add data {current : -196620, peak : 196620} from thread 6151130021515389890 to 6307369485653213174 , after update, data is {current : 0, peak : 196620}.
1561: I0810 03:59:48.785920  1179 thread_data_registry.h:135] Add data {current : 320804, peak : 393216} from thread 18063684737095990605 to 8731122713088139093 , after update, data is {current : 714020, peak : 714020}.
1561: I0810 03:59:48.785997  1181 thread_data_registry.h:135] Add data {current : 714020, peak : 714020} from thread 8731122713088139093 to 6743992051131779078 , after update, data is {current : 910640, peak : 983100}.
1561: I0810 03:59:48.786132  1182 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 6307369485653213174 to 6743992051131779078 , after update, data is {current : 1821864, peak : 2555920}.
1561: I0810 03:59:48.789067  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.789088  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.789134  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.789142  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.790684  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.791141  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.791558  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.791570  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.791575  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.793474  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.793541  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.793551  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.793556  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4552c930 type is 7
1561: I0810 03:59:48.793562  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.793567  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45291a10 type is 7
1561: I0810 03:59:48.793573  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.793576  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45295620 type is 7
1561: I0810 03:59:48.793582  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.793586  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.793654  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.793660  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.793665  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.793669  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.793704  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.793715  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.793759  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.793767  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.793782  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.793879  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.793888  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.793903  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.793910  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x453fc2e0Variable Type 7
1561: I0810 03:59:48.793922  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.793936  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.793953  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.793965  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.794005  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.794025  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.794064  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.794075  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.794090  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.794095  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4554a1f0Variable Type 7
1561: I0810 03:59:48.794107  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.794118  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.794134  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.794145  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.794176  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.794193  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.794453  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.794488  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.794507  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.795593  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.795740  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.795781  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.796141  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.796173  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.797999  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.798146  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.798185  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 03:59:48.801002  1133 pir_interpreter.cc:161] PirInterpreter(): 0x451a7b70 on Place(gpu:0)
1561: I0810 03:59:48.801033  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.801051  1133 scope.cc:202] Create variable 0x451a7b701723262388801025819_inner_var_1
1561: I0810 03:59:48.801062  1133 scope.cc:202] Create variable 0x451a7b701723262388801025819_inner_var_2
1561: I0810 03:59:48.801072  1133 scope.cc:202] Create variable 0x451a7b701723262388801025819_inner_var_3
1561: I0810 03:59:48.801082  1133 scope.cc:202] Create variable 0x451a7b701723262388801025819_inner_var_4
1561: I0810 03:59:48.801093  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.801105  1133 scope.cc:202] Create variable 0x451a7b701723262388801025819_inner_var_6
1561: I0810 03:59:48.801115  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.801427  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.801442  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.801446  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x451b7960
1561: 1 -> 0x451a7b701723262388801025819_inner_var_1 -> 0x45143800
1561: 2 -> 0x451a7b701723262388801025819_inner_var_2 -> 0x44335520
1561: 3 -> 0x451a7b701723262388801025819_inner_var_3 -> 0x44c7f690
1561: 4 -> 0x451a7b701723262388801025819_inner_var_4 -> 0x45323cd0
1561: 5 -> fetch0@fetch -> 0x4552b390
1561: 6 -> 0x451a7b701723262388801025819_inner_var_6 -> 0x4534ee70
1561: 7 -> fetch1@fetch -> 0x45364950
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.802124  1231 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.802217  1232 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.802255  1233 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.802330  1235 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.802345  1234 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.802381  1236 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.802402  1236 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.802426  1236 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.802453  1236 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x451a7b701723262388801025819_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_3:[dtype=;place=;dim=;lod={};, 0x451a7b701723262388801025819_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.802560  1236 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x451a7b701723262388801025819_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x451a7b701723262388801025819_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.802609  1235 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451a7b701723262388801025819_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.802634  1235 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.802615  1234 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451a7b701723262388801025819_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.802649  1234 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.802687  1235 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451a7b701723262388801025819_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.802726  1234 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x451a7b701723262388801025819_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x451a7b701723262388801025819_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.802736  1235 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x451a7b701723262388801025819_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.802752  1235 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.802762  1235 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x451a7b701723262388801025819_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.802772  1234 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x451a7b701723262388801025819_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.802790  1234 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.802801  1234 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x451a7b701723262388801025819_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.802836  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x451a7ce0) got event_name: TaskCompletion
1561: I0810 03:59:48.802862  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.802888  1133 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.804196  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.804368  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.804410  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: I0810 03:59:48.807288  1133 pir_interpreter.cc:161] PirInterpreter(): 0x4535d630 on Place(gpu:0)
1561: I0810 03:59:48.807328  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.807348  1133 scope.cc:202] Create variable 0x4535d6301723262388807322458_inner_var_1
1561: I0810 03:59:48.807358  1133 scope.cc:202] Create variable 0x4535d6301723262388807322458_inner_var_2
1561: I0810 03:59:48.807370  1133 scope.cc:202] Create variable 0x4535d6301723262388807322458_inner_var_3
1561: I0810 03:59:48.807379  1133 scope.cc:202] Create variable 0x4535d6301723262388807322458_inner_var_4
1561: I0810 03:59:48.807389  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.807399  1133 scope.cc:202] Create variable 0x4535d6301723262388807322458_inner_var_6
1561: I0810 03:59:48.807410  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.807713  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.807726  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.807731  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x45190930
1561: 1 -> 0x4535d6301723262388807322458_inner_var_1 -> 0x45190130
1561: 2 -> 0x4535d6301723262388807322458_inner_var_2 -> 0x4552cc10
1561: 3 -> 0x4535d6301723262388807322458_inner_var_3 -> 0x45190250
1561: 4 -> 0x4535d6301723262388807322458_inner_var_4 -> 0x44c894c0
1561: 5 -> fetch0@fetch -> 0x44cbc590
1561: 6 -> 0x4535d6301723262388807322458_inner_var_6 -> 0x44c894e0
1561: 7 -> fetch1@fetch -> 0x4554bdc0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.808408  1237 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.808501  1238 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.808530  1239 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.808566  1240 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.808599  1241 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.808647  1242 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.808665  1242 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.808684  1242 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.808707  1242 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4535d6301723262388807322458_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4535d6301723262388807322458_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.808815  1242 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4535d6301723262388807322458_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x4535d6301723262388807322458_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.808871  1240 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388807322458_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.808869  1241 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388807322458_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.808894  1240 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.808902  1241 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.808948  1240 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388807322458_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.808986  1241 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388807322458_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388807322458_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.808996  1240 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388807322458_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.809012  1240 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.809021  1240 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388807322458_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
1561: I0810 03:59:48.809041  1241 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388807322458_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.809059  1241 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.809072  1241 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388807322458_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.809105  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x4535d7a0) got event_name: TaskCompletion
1561: I0810 03:59:48.809129  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.809155  1133 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.809293  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:149
1561: I0810 03:59:48.809378  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.809396  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:150
1561: I0810 03:59:48.809412  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.810369  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.810391  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.810443  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.810452  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.812281  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.812851  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.813311  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.813326  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.813331  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.815574  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.815652  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.815665  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.815670  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x452962b0 type is 7
1561: I0810 03:59:48.815680  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.815685  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1a906b90 type is 7
1561: I0810 03:59:48.815692  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.815699  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45295ed0 type is 7
1561: I0810 03:59:48.815704  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.815711  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.815789  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.815796  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.815801  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.815807  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.815848  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.815861  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.815917  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.815928  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.815946  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.816074  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.816087  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.816103  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.816111  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44c94740Variable Type 7
1561: I0810 03:59:48.816126  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.816143  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.816164  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.816180  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.816231  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.816253  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.816314  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.816325  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.816344  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.816352  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4540bc10Variable Type 7
1561: I0810 03:59:48.816366  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.816381  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.816401  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.816414  1133 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.816453  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.816474  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.816751  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.816797  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.816818  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.817010  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.817512  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.817544  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.817557  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.817680  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.818653  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.818676  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.818727  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.818735  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.819481  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.819502  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.819542  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.819550  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.819881  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.819944  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.820322  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.820418  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.820430  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.820506  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.820515  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.822337  1231 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 6307369485653213174 to 16032460314951642159 , after update, data is {current : -3840, peak : 0}.
1561: I0810 03:59:48.822347  1231 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 6307369485653213174 to 16032460314951642159 , after update, data is {current : -3840, peak : 0}.
1561: I0810 03:59:48.822588  1234 thread_data_registry.h:135] Add data {current : 240, peak : 240} from thread 18063684737095990605 to 16032460314951642159 , after update, data is {current : -3600, peak : 240}.
1561: I0810 03:59:48.822666  1235 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 4571571410515315331 to 16032460314951642159 , after update, data is {current : 0, peak : 3600}.
1561: I0810 03:59:48.822798  1236 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 6151130021515389890 to 16032460314951642159 , after update, data is {current : -1920, peak : 1920}.
1561: I0810 03:59:48.822973  1237 thread_data_registry.h:135] Add data {current : 0, peak : 3600} from thread 16032460314951642159 to 851839650703684232 , after update, data is {current : 3600, peak : 3600}.
1561: I0810 03:59:48.822981  1237 thread_data_registry.h:135] Add data {current : -1920, peak : 1920} from thread 16032460314951642159 to 3547362242347984968 , after update, data is {current : 0, peak : 1920}.
1561: I0810 03:59:48.823141  1241 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 851839650703684232 to 17260883039236997028 , after update, data is {current : 3840, peak : 3840}.
1561: I0810 03:59:48.823212  1240 thread_data_registry.h:135] Add data {current : 3840, peak : 3840} from thread 17260883039236997028 to 6743992051131779078 , after update, data is {current : 914480, peak : 983100}.
1561: I0810 03:59:48.823334  1242 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 3547362242347984968 to 6743992051131779078 , after update, data is {current : 1829064, peak : 2555920}.
1561: I0810 03:59:48.824857  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.825551  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.825568  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.825574  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.829061  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.829082  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.829110  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.829120  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.829125  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44ca0890 type is 7
1561: I0810 03:59:48.829133  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.829139  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4531e2a0 type is 7
1561: I0810 03:59:48.829145  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.829149  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44c897e0 type is 7
1561: I0810 03:59:48.829154  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.829159  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447994e0 type is 7
1561: I0810 03:59:48.829164  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.829169  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x451815b0 type is 7
1561: I0810 03:59:48.829175  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.829182  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4540d030 type is 7
1561: I0810 03:59:48.829187  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.829191  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45436490 type is 7
1561: I0810 03:59:48.829197  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45573340 type is 9
1561: I0810 03:59:48.829202  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.829207  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45355720 type is 10
1561: I0810 03:59:48.829344  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.829351  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.829358  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.829363  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.829411  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829425  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829479  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829489  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829507  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.829650  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829664  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829680  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.829825  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829838  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829874  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.829912  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829923  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.829942  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.830022  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.830034  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.830050  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.830088  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.830152  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.830163  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.830181  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.830188  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45181f30Variable Type 7
1561: I0810 03:59:48.830206  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.830222  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.830242  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.830257  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.830415  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.830435  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.830758  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.830792  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.830824  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.831852  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.832005  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.832046  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.832639  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.832675  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.832772  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x441352e0)  to GradNodeAccumulation (addr: 0x4534aa10)
1561: I0810 03:59:48.832856  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.832875  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.832988  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x45327060)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x441352e0)
1561: I0810 03:59:48.833062  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.833070  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.833077  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.833107  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.833132  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x45327060
1561: I0810 03:59:48.833140  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.833164  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.833209  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.833230  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.833237  1133 backward.cc:335] Node: MeanGradNode addr:0x45327060, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x441352e0
1561: I0810 03:59:48.833243  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.833271  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x441352e0
1561: I0810 03:59:48.833277  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.833292  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.833333  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.833364  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.833369  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x441352e0, Found pending node: GradNodeAccumulation addr: 0x4534aa10
1561: I0810 03:59:48.833375  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.833397  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4534aa10
1561: I0810 03:59:48.833405  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.833410  1133 accumulation_node.cc:40] Move Tensor ptr: 0x45297e50
1561: I0810 03:59:48.833413  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.833418  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.835130  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.835153  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.835203  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.835212  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.837052  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.837628  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.838086  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.838100  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.838105  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.840397  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.840474  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.840485  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.840492  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4543a120 type is 7
1561: I0810 03:59:48.840498  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.840505  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4530cb10 type is 7
1561: I0810 03:59:48.840512  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.840515  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44c8aaa0 type is 7
1561: I0810 03:59:48.840521  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.840528  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.840607  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.840615  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.840621  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.840626  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.840667  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.840680  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.840734  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.840744  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.840761  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.840909  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.840921  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.840940  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.840948  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45474570Variable Type 7
1561: I0810 03:59:48.840963  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.840981  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.841001  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.841017  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.841063  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.841085  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.841136  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.841146  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.841163  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.841171  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45451800Variable Type 7
1561: I0810 03:59:48.841185  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.841199  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.841218  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.841233  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.841267  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.841288  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.841557  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.841594  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.841615  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.843227  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.843250  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.843310  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.843320  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.845126  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.845690  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.846132  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.846145  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.846150  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.848371  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.848448  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.848459  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.848464  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a9c9160 type is 7
1561: I0810 03:59:48.848474  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.848479  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44cafce0 type is 7
1561: I0810 03:59:48.848486  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.848490  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44cb0760 type is 7
1561: I0810 03:59:48.848495  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.848501  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.848577  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.848584  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.848589  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.848593  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.848635  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.848649  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.848704  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.848713  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.848732  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.848855  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.848868  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.848886  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.848893  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4404e0d0Variable Type 7
1561: I0810 03:59:48.848909  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.848927  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.848948  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.848963  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.849009  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.849031  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.849079  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.849089  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.849108  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.849115  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4518d480Variable Type 7
1561: I0810 03:59:48.849129  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.849143  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.849161  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.849175  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.849210  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.849231  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.849493  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.849527  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.849550  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.849736  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.850963  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.850986  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.851034  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.851044  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.852859  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.853433  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.853888  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.853901  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.853906  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.856165  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.856241  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.856252  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.856258  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45400800 type is 7
1561: I0810 03:59:48.856267  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.856273  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45362b70 type is 7
1561: I0810 03:59:48.856279  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.856284  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x453628a0 type is 7
1561: I0810 03:59:48.856289  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.856295  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.856384  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.856392  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.856398  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.856403  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.856443  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.856457  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.856510  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.856520  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.856537  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.856665  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.856679  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.856698  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.856705  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45567e50Variable Type 7
1561: I0810 03:59:48.856720  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.856736  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.856757  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.856772  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.856819  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.856840  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.856889  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.856899  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.856917  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.856925  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45400430Variable Type 7
1561: I0810 03:59:48.856938  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.856952  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.856971  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.856985  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.857020  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.857041  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.857290  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.857337  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.857358  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.858472  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.858618  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.858659  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.859014  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.859045  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.860868  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.861011  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.861052  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 03:59:48.864933  1133 pir_interpreter.cc:161] PirInterpreter(): 0x4535d630 on Place(gpu:0)
1561: I0810 03:59:48.864964  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.864981  1133 scope.cc:202] Create variable 0x4535d6301723262388864956896_inner_var_1
1561: I0810 03:59:48.864992  1133 scope.cc:202] Create variable 0x4535d6301723262388864956896_inner_var_2
1561: I0810 03:59:48.865001  1133 scope.cc:202] Create variable 0x4535d6301723262388864956896_inner_var_3
1561: I0810 03:59:48.865010  1133 scope.cc:202] Create variable 0x4535d6301723262388864956896_inner_var_4
1561: I0810 03:59:48.865018  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.865027  1133 scope.cc:202] Create variable 0x4535d6301723262388864956896_inner_var_6
1561: I0810 03:59:48.865036  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.865353  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.865367  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.865371  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x44cb99e0
1561: 1 -> 0x4535d6301723262388864956896_inner_var_1 -> 0x44ca5ca0
1561: 2 -> 0x4535d6301723262388864956896_inner_var_2 -> 0x44ca86b0
1561: 3 -> 0x4535d6301723262388864956896_inner_var_3 -> 0x4542ba70
1561: 4 -> 0x4535d6301723262388864956896_inner_var_4 -> 0x454569d0
1561: 5 -> fetch0@fetch -> 0x4552c910
1561: 6 -> 0x4535d6301723262388864956896_inner_var_6 -> 0x45468b80
1561: 7 -> fetch1@fetch -> 0x45442ae0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.866044  1243 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.866127  1244 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.866149  1245 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.866183  1246 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.866220  1247 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.866256  1248 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.866278  1248 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.866314  1248 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.866345  1248 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4535d6301723262388864956896_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4535d6301723262388864956896_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.866452  1248 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4535d6301723262388864956896_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x4535d6301723262388864956896_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.866510  1246 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388864956896_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.866508  1247 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388864956896_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.866539  1246 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.866545  1247 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.866600  1246 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388864956896_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.866638  1247 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4535d6301723262388864956896_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4535d6301723262388864956896_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.866649  1246 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388864956896_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.866667  1246 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.866665  1247 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388864956896_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.866681  1247 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.866678  1246 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388864956896_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.866694  1247 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4535d6301723262388864956896_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.866724  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x4535d7a0) got event_name: TaskCompletion
1561: I0810 03:59:48.866745  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.866768  1133 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.868053  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.868202  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.868243  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 03:59:48.871013  1133 pir_interpreter.cc:161] PirInterpreter(): 0x1a8f1100 on Place(gpu:0)
1561: I0810 03:59:48.871042  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.871060  1133 scope.cc:202] Create variable 0x1a8f11001723262388871036485_inner_var_1
1561: I0810 03:59:48.871071  1133 scope.cc:202] Create variable 0x1a8f11001723262388871036485_inner_var_2
1561: I0810 03:59:48.871081  1133 scope.cc:202] Create variable 0x1a8f11001723262388871036485_inner_var_3
1561: I0810 03:59:48.871089  1133 scope.cc:202] Create variable 0x1a8f11001723262388871036485_inner_var_4
1561: I0810 03:59:48.871100  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.871110  1133 scope.cc:202] Create variable 0x1a8f11001723262388871036485_inner_var_6
1561: I0810 03:59:48.871119  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.871430  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.871445  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.871449  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x1a684860
1561: 1 -> 0x1a8f11001723262388871036485_inner_var_1 -> 0x45567df0
1561: 2 -> 0x1a8f11001723262388871036485_inner_var_2 -> 0x1a509c20
1561: 3 -> 0x1a8f11001723262388871036485_inner_var_3 -> 0x4530ce40
1561: 4 -> 0x1a8f11001723262388871036485_inner_var_4 -> 0x1a9b0230
1561: 5 -> fetch0@fetch -> 0x451794d0
1561: 6 -> 0x1a8f11001723262388871036485_inner_var_6 -> 0x453250a0
1561: 7 -> fetch1@fetch -> 0x45410d40
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.872123  1249 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.872205  1250 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.872237  1251 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.872268  1252 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.872304  1253 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.872350  1254 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.872370  1254 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.872388  1254 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.872409  1254 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a8f11001723262388871036485_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1a8f11001723262388871036485_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.872493  1254 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a8f11001723262388871036485_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x1a8f11001723262388871036485_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.872538  1253 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a8f11001723262388871036485_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.872540  1252 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a8f11001723262388871036485_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.872560  1253 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.872565  1252 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.872611  1253 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a8f11001723262388871036485_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.872644  1252 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a8f11001723262388871036485_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a8f11001723262388871036485_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.872653  1253 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a8f11001723262388871036485_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.872669  1253 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.872665  1252 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a8f11001723262388871036485_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.872680  1252 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.872677  1253 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a8f11001723262388871036485_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.872691  1252 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a8f11001723262388871036485_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.872718  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x1a8f1270) got event_name: TaskCompletion
1561: I0810 03:59:48.872740  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.872763  1133 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.872897  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:175
1561: I0810 03:59:48.872963  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.872978  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:176
1561: I0810 03:59:48.872995  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.873925  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.873945  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.873996  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.874006  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.875844  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.876405  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.876860  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.876875  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.876880  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.879173  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.879248  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.879259  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.879264  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1a9cf610 type is 7
1561: I0810 03:59:48.879276  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.879280  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x455371d0 type is 7
1561: I0810 03:59:48.879285  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.879289  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45319120 type is 7
1561: I0810 03:59:48.879295  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.879313  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.879390  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.879397  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.879402  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.879407  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.879448  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.879462  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.879518  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.879527  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.879545  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.879674  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.879688  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.879705  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.879712  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4517f150Variable Type 7
1561: I0810 03:59:48.879729  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.879745  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.879766  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.879782  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.879829  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.879851  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.879900  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.879910  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.879927  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.879935  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4556a1c0Variable Type 7
1561: I0810 03:59:48.879949  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.879963  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.879981  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.879995  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.880031  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.880051  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.880335  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.880373  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.880395  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.880584  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.881063  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.881093  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.881105  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.881222  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.882202  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.882225  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.882274  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.882284  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.883023  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.883042  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.883081  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.883090  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.883424  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.883491  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.883855  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.883947  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.883957  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.884033  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.884043  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.886530  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.887159  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.887176  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.887180  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.890542  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.890561  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.890591  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.890600  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.890605  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44c8de30 type is 7
1561: I0810 03:59:48.890612  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.890619  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4554b490 type is 7
1561: I0810 03:59:48.890626  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.890630  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4554ade0 type is 7
1561: I0810 03:59:48.890635  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.890640  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44c8e2b0 type is 7
1561: I0810 03:59:48.890645  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.890650  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44c8e480 type is 7
1561: I0810 03:59:48.890655  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.890658  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44c8e670 type is 7
1561: I0810 03:59:48.890664  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.890668  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44c8e880 type is 7
1561: I0810 03:59:48.890673  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44c8de10 type is 9
1561: I0810 03:59:48.890679  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.890683  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44c8e650 type is 10
1561: I0810 03:59:48.890791  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.890798  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.890805  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.890810  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.890859  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.890873  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.890928  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.890937  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.890955  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.891106  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891119  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891136  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.891278  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891291  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891338  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.891377  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891388  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891407  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.891489  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891499  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891516  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.891553  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.891616  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.891628  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.891645  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.891654  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45451390Variable Type 7
1561: I0810 03:59:48.891670  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.891686  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.891706  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.891721  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.891762  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.891779  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.892105  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.892136  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.892174  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.893168  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.893329  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.893373  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.893950  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.893986  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.894088  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44ca88e0)  to GradNodeAccumulation (addr: 0x4534aa10)
1561: I0810 03:59:48.894170  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.894191  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.894315  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x45327060)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44ca88e0)
1561: I0810 03:59:48.894392  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.894398  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.894407  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.894440  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.894464  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x45327060
1561: I0810 03:59:48.894472  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.894495  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.894536  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.894557  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.894565  1133 backward.cc:335] Node: MeanGradNode addr:0x45327060, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44ca88e0
1561: I0810 03:59:48.894570  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.894595  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44ca88e0
1561: I0810 03:59:48.894603  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.894616  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.894645  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.894675  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.894681  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44ca88e0, Found pending node: GradNodeAccumulation addr: 0x4534aa10
1561: I0810 03:59:48.894687  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.894709  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4534aa10
1561: I0810 03:59:48.894716  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.894721  1133 accumulation_node.cc:40] Move Tensor ptr: 0x45297e50
1561: I0810 03:59:48.894726  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.894731  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.897037  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.897056  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.897099  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.897106  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.897989  1243 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 3547362242347984968 to 16032460314951642159 , after update, data is {current : 1740, peak : 3600}.
1561: I0810 03:59:48.898005  1243 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 3547362242347984968 to 12645738160726870451 , after update, data is {current : 0, peak : 1860}.
1561: I0810 03:59:48.898151  1247 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 8731122713088139093 to 16032460314951642159 , after update, data is {current : 5340, peak : 5340}.
1561: I0810 03:59:48.898223  1246 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 7386319254308557504 to 16032460314951642159 , after update, data is {current : 5460, peak : 5460}.
1561: I0810 03:59:48.898356  1248 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 6307369485653213174 to 12645738160726870451 , after update, data is {current : 1860, peak : 1860}.
1561: I0810 03:59:48.898505  1249 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 18063684737095990605 to 16032460314951642159 , after update, data is {current : 3600, peak : 5460}.
1561: I0810 03:59:48.898514  1249 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 18063684737095990605 to 12645738160726870451 , after update, data is {current : 0, peak : 1860}.
1561: I0810 03:59:48.898658  1252 thread_data_registry.h:135] Add data {current : 3600, peak : 5460} from thread 16032460314951642159 to 12154384437526056481 , after update, data is {current : 3720, peak : 5460}.
1561: I0810 03:59:48.898728  1253 thread_data_registry.h:135] Add data {current : 3720, peak : 5460} from thread 12154384437526056481 to 6743992051131779078 , after update, data is {current : 918200, peak : 983100}.
1561: I0810 03:59:48.898821  1254 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 12645738160726870451 to 6743992051131779078 , after update, data is {current : 1838064, peak : 2555920}.
1561: I0810 03:59:48.900337  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.900799  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.901185  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.901196  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.901201  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.903111  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.903175  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.903184  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.903189  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x451bade0 type is 7
1561: I0810 03:59:48.903195  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.903199  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45191300 type is 7
1561: I0810 03:59:48.903203  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.903208  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4545b230 type is 7
1561: I0810 03:59:48.903211  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.903218  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.903283  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.903290  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.903295  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.903308  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.903342  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.903354  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.903398  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.903407  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.903421  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.903525  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.903537  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.903550  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.903556  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4544f380Variable Type 7
1561: I0810 03:59:48.903570  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.903584  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.903600  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.903613  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.903654  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.903672  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.903713  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.903721  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.903736  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.903741  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451b3600Variable Type 7
1561: I0810 03:59:48.903752  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.903761  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.903774  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.903784  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.903812  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.903826  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.904031  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.904057  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.904071  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.905652  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.905674  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.905723  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.905733  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.907662  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.908233  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.908685  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.908700  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.908705  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.910943  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.911021  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.911032  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.911037  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x454d34d0 type is 7
1561: I0810 03:59:48.911048  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.911052  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4540b430 type is 7
1561: I0810 03:59:48.911057  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.911062  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4535fcd0 type is 7
1561: I0810 03:59:48.911072  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.911077  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.911151  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.911157  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.911163  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.911170  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.911211  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.911223  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.911278  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.911288  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.911314  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.911439  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.911453  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.911470  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.911478  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9c7d80Variable Type 7
1561: I0810 03:59:48.911494  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.911510  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.911530  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.911546  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.911593  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.911614  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.911662  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.911672  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.911689  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.911697  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4547b740Variable Type 7
1561: I0810 03:59:48.911712  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.911726  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.911744  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.911758  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.911794  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.911814  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.912063  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.912096  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.912117  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.912321  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.913566  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.913587  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.913637  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.913646  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.915463  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.916025  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.916487  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.916502  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.916507  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.918763  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.918838  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.918848  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.918854  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45567bb0 type is 7
1561: I0810 03:59:48.918864  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.918869  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4547aff0 type is 7
1561: I0810 03:59:48.918874  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.918879  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x455677f0 type is 7
1561: I0810 03:59:48.918884  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.918889  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.918963  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.918970  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.918977  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.918983  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.919025  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.919039  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.919092  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.919102  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.919121  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.919241  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.919253  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.919271  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.919278  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4519ec80Variable Type 7
1561: I0810 03:59:48.919294  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.919322  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.919343  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.919359  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.919405  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.919427  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.919476  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.919484  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.919502  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.919509  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45336370Variable Type 7
1561: I0810 03:59:48.919523  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.919538  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.919556  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.919570  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.919605  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.919625  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.919873  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.919907  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.919929  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.921053  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.921198  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.921240  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.921600  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.921633  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.923449  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.923591  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.923632  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 03:59:48.926409  1133 pir_interpreter.cc:161] PirInterpreter(): 0x45488db0 on Place(gpu:0)
1561: I0810 03:59:48.926438  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.926458  1133 scope.cc:202] Create variable 0x45488db01723262388926432458_inner_var_1
1561: I0810 03:59:48.926469  1133 scope.cc:202] Create variable 0x45488db01723262388926432458_inner_var_2
1561: I0810 03:59:48.926478  1133 scope.cc:202] Create variable 0x45488db01723262388926432458_inner_var_3
1561: I0810 03:59:48.926489  1133 scope.cc:202] Create variable 0x45488db01723262388926432458_inner_var_4
1561: I0810 03:59:48.926498  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.926509  1133 scope.cc:202] Create variable 0x45488db01723262388926432458_inner_var_6
1561: I0810 03:59:48.926519  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.926816  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.926831  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.926834  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x1a9ceb20
1561: 1 -> 0x45488db01723262388926432458_inner_var_1 -> 0x455342d0
1561: 2 -> 0x45488db01723262388926432458_inner_var_2 -> 0x4535b0d0
1561: 3 -> 0x45488db01723262388926432458_inner_var_3 -> 0x45442cf0
1561: 4 -> 0x45488db01723262388926432458_inner_var_4 -> 0x454892d0
1561: 5 -> fetch0@fetch -> 0x45533800
1561: 6 -> 0x45488db01723262388926432458_inner_var_6 -> 0x455337c0
1561: 7 -> fetch1@fetch -> 0x45533fd0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.927489  1255 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.927564  1256 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.927592  1257 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.927625  1258 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.927659  1259 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.927693  1260 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.927713  1260 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.927738  1260 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.927765  1260 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x45488db01723262388926432458_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_3:[dtype=;place=;dim=;lod={};, 0x45488db01723262388926432458_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.927866  1260 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x45488db01723262388926432458_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x45488db01723262388926432458_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.927920  1259 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x45488db01723262388926432458_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.927925  1258 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x45488db01723262388926432458_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.927950  1259 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.927963  1258 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.928017  1259 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x45488db01723262388926432458_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.928059  1259 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x45488db01723262388926432458_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.928054  1258 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x45488db01723262388926432458_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x45488db01723262388926432458_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.928081  1259 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.928094  1259 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x45488db01723262388926432458_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.928110  1258 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x45488db01723262388926432458_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.928134  1258 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.928149  1258 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x45488db01723262388926432458_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.928191  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x45488f20) got event_name: TaskCompletion
1561: I0810 03:59:48.928217  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.928239  1133 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.929517  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.929670  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.929713  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: IR before lowering = {
1561:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
1561:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
1561:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
1561:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
1561: }
1561: 
1561: IR after lowering = {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: I0810 03:59:48.932502  1133 pir_interpreter.cc:161] PirInterpreter(): 0x1a9bc710 on Place(gpu:0)
1561: I0810 03:59:48.932533  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.932551  1133 scope.cc:202] Create variable 0x1a9bc7101723262388932526063_inner_var_1
1561: I0810 03:59:48.932562  1133 scope.cc:202] Create variable 0x1a9bc7101723262388932526063_inner_var_2
1561: I0810 03:59:48.932574  1133 scope.cc:202] Create variable 0x1a9bc7101723262388932526063_inner_var_3
1561: I0810 03:59:48.932581  1133 scope.cc:202] Create variable 0x1a9bc7101723262388932526063_inner_var_4
1561: I0810 03:59:48.932592  1133 scope.cc:202] Create variable fetch0@fetch
1561: I0810 03:59:48.932605  1133 scope.cc:202] Create variable 0x1a9bc7101723262388932526063_inner_var_6
1561: I0810 03:59:48.932615  1133 scope.cc:202] Create variable fetch1@fetch
1561: I0810 03:59:48.932915  1133 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1561: I0810 03:59:48.932929  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.932932  1133 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1561: ======================== The network executed by pir interpreter ========================
1561: {
1561:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
1561:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
1561:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
1561:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
1561:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
1561: }
1561: 
1561: ======================== The instruction executed by pir interpreter ========================
1561: {outputs} =  instruction_name[idx] ({inputs})
1561: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1561: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
1561: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1561: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1561: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
1561: 5: ( 7 )  = pd_op.fetch ( 6 ) 
1561: ---------------------------var_id -> var_name -> variable*---------------------------
1561: 0 -> X -> 0x1a9bd580
1561: 1 -> 0x1a9bc7101723262388932526063_inner_var_1 -> 0x1a9bd5e0
1561: 2 -> 0x1a9bc7101723262388932526063_inner_var_2 -> 0x1a9ccc30
1561: 3 -> 0x1a9bc7101723262388932526063_inner_var_3 -> 0x44ccaac0
1561: 4 -> 0x1a9bc7101723262388932526063_inner_var_4 -> 0x1a9bcda0
1561: 5 -> fetch0@fetch -> 0x4519e530
1561: 6 -> 0x1a9bc7101723262388932526063_inner_var_6 -> 0x1a9bcdc0
1561: 7 -> fetch1@fetch -> 0x4552e7e0
1561: 
1561: 
1561: ======================= The dependency of all instruction ========================
1561: id -> down_stream_id
1561: 0 -> 1 
1561: 1 -> 2 4 
1561: 2 -> 3 
1561: 4 -> 5 
1561: 
1561: 
1561: ======================== pir interpreter trace order ========================
1561: 
1561: Leaf nodes: 0[pd_op.shadow_feed]->
1561: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
1561: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
1561: 2 downstreams: 3[pd_op.fetch]->
1561: 3 downstreams: 
1561: 4 downstreams: 5[pd_op.fetch]->
1561: 5 downstreams: 
1561: I0810 03:59:48.933612  1261 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1561: I0810 03:59:48.933687  1262 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1561: I0810 03:59:48.933720  1263 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1561: I0810 03:59:48.933750  1264 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1561: I0810 03:59:48.933776  1265 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1561: I0810 03:59:48.933816  1266 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1561: I0810 03:59:48.933835  1266 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.933852  1266 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.933874  1266 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a9bc7101723262388932526063_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1a9bc7101723262388932526063_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.933954  1266 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1561: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x1a9bc7101723262388932526063_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x1a9bc7101723262388932526063_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.933997  1265 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9bc7101723262388932526063_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.934015  1265 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.934010  1264 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9bc7101723262388932526063_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.934048  1264 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.934062  1265 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9bc7101723262388932526063_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.934114  1264 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1561: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1a9bc7101723262388932526063_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x1a9bc7101723262388932526063_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.934123  1265 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9bc7101723262388932526063_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.934139  1265 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.934145  1264 pir_interpreter.cc:1876] 
1561: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9bc7101723262388932526063_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1561: I0810 03:59:48.934147  1265 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9bc7101723262388932526063_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
1561: I0810 03:59:48.934166  1264 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.934180  1264 pir_interpreter.cc:1916] 
1561: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1561: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1a9bc7101723262388932526063_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
1561: I0810 03:59:48.934211  1133 pir_interpreter.cc:1766] main_thread_blocker_(0x1a9bc880) got event_name: TaskCompletion
1561: I0810 03:59:48.934232  1133 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.934255  1133 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
1561: I0810 03:59:48.934396  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:201
1561: I0810 03:59:48.934463  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.934478  1133 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:202
1561: I0810 03:59:48.934496  1133 pir.cc:2451] Start compare shape and data.
1561: I0810 03:59:48.935425  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.935446  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.935497  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.935508  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.936570  1255 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 12645738160726870451 to 851839650703684232 , after update, data is {current : 1740, peak : 3600}.
1561: I0810 03:59:48.936579  1255 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 12645738160726870451 to 18063684737095990605 , after update, data is {current : -3720, peak : 0}.
1561: I0810 03:59:48.936844  1258 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 7386319254308557504 to 851839650703684232 , after update, data is {current : 1860, peak : 3600}.
1561: I0810 03:59:48.936918  1259 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 8731122713088139093 to 851839650703684232 , after update, data is {current : 5460, peak : 5460}.
1561: I0810 03:59:48.937026  1260 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 6307369485653213174 to 18063684737095990605 , after update, data is {current : -1860, peak : 1860}.
1561: I0810 03:59:48.937173  1261 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 18063684737095990605 to 851839650703684232 , after update, data is {current : 3600, peak : 5460}.
1561: I0810 03:59:48.937181  1261 thread_data_registry.h:135] Add data {current : -1860, peak : 1860} from thread 18063684737095990605 to 3547362242347984968 , after update, data is {current : 0, peak : 1860}.
1561: I0810 03:59:48.937338  1264 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 17260883039236997028 to 851839650703684232 , after update, data is {current : 3720, peak : 5460}.
1561: I0810 03:59:48.937409  1265 thread_data_registry.h:135] Add data {current : 3720, peak : 5460} from thread 851839650703684232 to 6743992051131779078 , after update, data is {current : 923780, peak : 983100}.
1561: I0810 03:59:48.937505  1266 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 3547362242347984968 to 6743992051131779078 , after update, data is {current : 1843524, peak : 2555920}.
1561: I0810 03:59:48.939038  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.939611  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.940078  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.940093  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.940097  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.942430  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.942505  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.942515  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.942521  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4554a0a0 type is 7
1561: I0810 03:59:48.942533  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.942538  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x45321b60 type is 7
1561: I0810 03:59:48.942543  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.942548  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x454d3a40 type is 7
1561: I0810 03:59:48.942552  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44ca9740 type is 9
1561: I0810 03:59:48.942559  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44cc3470 type is 10
1561: I0810 03:59:48.942636  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.942643  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.942649  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.942654  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.942695  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.942709  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.942764  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.942775  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.942791  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.942924  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.942936  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.942955  1133 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.942962  1133 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1a9b6eb0Variable Type 7
1561: I0810 03:59:48.942978  1133 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.942996  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.943015  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.943032  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.943079  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.943102  1133 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.943150  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.943161  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.943178  1133 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.943185  1133 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x451b6f20Variable Type 7
1561: I0810 03:59:48.943199  1133 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.943213  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.943231  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.943245  1133 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.943281  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.943316  1133 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
1561: I0810 03:59:48.943576  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.943611  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.943632  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.943827  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.944334  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.944363  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.944376  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.944489  1133 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1561: I0810 03:59:48.945454  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.945475  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.945525  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.945534  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.946254  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.946272  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.946321  1133 op_desc.cc:1111] CompileTime infer shape on mean
1561: I0810 03:59:48.946328  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.946655  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.946718  1133 pybind.cc:1827] need skip: 0
1561: I0810 03:59:48.947077  1133 op_desc.cc:1111] CompileTime infer shape on fill_constant
1561: I0810 03:59:48.947170  1133 op_desc.cc:1111] CompileTime infer shape on mean_grad
1561: I0810 03:59:48.947180  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.947257  1133 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.947266  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.949757  1133 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1561: I0810 03:59:48.950395  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.950412  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.950416  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.953775  1133 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1561: I0810 03:59:48.953794  1133 scope.cc:202] Create variable feed
1561: I0810 03:59:48.953823  1133 interpreter_util.cc:1169] Creating Variables
1561: I0810 03:59:48.953832  1133 scope.cc:202] Create variable Out
1561: I0810 03:59:48.953837  1133 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4546e5e0 type is 7
1561: I0810 03:59:48.953845  1133 scope.cc:202] Create variable Out@GRAD
1561: I0810 03:59:48.953851  1133 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4546e760 type is 7
1561: I0810 03:59:48.953858  1133 scope.cc:202] Create variable OutScale
1561: I0810 03:59:48.953862  1133 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4519c830 type is 7
1561: I0810 03:59:48.953868  1133 scope.cc:202] Create variable X
1561: I0810 03:59:48.953872  1133 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4546f4a0 type is 7
1561: I0810 03:59:48.953878  1133 scope.cc:202] Create variable X@GRAD
1561: I0810 03:59:48.953882  1133 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4546f710 type is 7
1561: I0810 03:59:48.953887  1133 scope.cc:202] Create variable _generated_var_0
1561: I0810 03:59:48.953892  1133 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4546f950 type is 7
1561: I0810 03:59:48.953897  1133 scope.cc:202] Create variable _generated_var_0@GRAD
1561: I0810 03:59:48.953902  1133 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45531810 type is 7
1561: I0810 03:59:48.953909  1133 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4519c850 type is 9
1561: I0810 03:59:48.953917  1133 scope.cc:202] Create variable fetch
1561: I0810 03:59:48.953920  1133 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4546f930 type is 10
1561: I0810 03:59:48.954026  1133 interpreter_util.cc:594] Static build: 0
1561: I0810 03:59:48.954033  1133 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1561: I0810 03:59:48.954039  1133 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1561: I0810 03:59:48.954044  1133 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1561: I0810 03:59:48.954092  1133 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954105  1133 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954159  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954169  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954185  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.954344  1133 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954357  1133 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954375  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.954517  1133 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954530  1133 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954564  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.954602  1133 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954612  1133 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954630  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1561: I0810 03:59:48.954711  1133 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954722  1133 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954739  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
1561: I0810 03:59:48.954777  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.954839  1133 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.954850  1133 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1561: I0810 03:59:48.954867  1133 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1561: I0810 03:59:48.954875  1133 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x454147f0Variable Type 7
1561: I0810 03:59:48.954892  1133 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1561: I0810 03:59:48.954910  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.954928  1133 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1561: I0810 03:59:48.954943  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
1561: I0810 03:59:48.954984  1133 data_transfer.cc:232] Run memcpy_d2h done.
1561: I0810 03:59:48.955001  1133 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1561: I0810 03:59:48.955315  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
1561: I0810 03:59:48.955348  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1561: I0810 03:59:48.955379  1133 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1561: I0810 03:59:48.956380  1133 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4534aa10 for it.
1561: I0810 03:59:48.956527  1133 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a6420d0 for it.
1561: I0810 03:59:48.956568  1133 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x1a6a3220 for it.
1561: I0810 03:59:48.957136  1133 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
1561: I0810 03:59:48.957170  1133 dygraph_functions.cc:27517] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.957270  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44240e60)  to GradNodeAccumulation (addr: 0x4534aa10)
1561: I0810 03:59:48.957366  1133 dygraph_functions.cc:51780] Running AD API: mean
1561: I0810 03:59:48.957386  1133 dygraph_functions.cc:51837] { Input: [ 
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.957499  1133 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x45327060)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44240e60)
1561: I0810 03:59:48.957572  1133 backward.cc:442] Run in Backward
1561: I0810 03:59:48.957579  1133 backward.cc:113] Start Backward
1561: I0810 03:59:48.957587  1133 backward.cc:197] Fill grad input tensor 0 with 1.0
1561: I0810 03:59:48.957616  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.957640  1133 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x45327060
1561: I0810 03:59:48.957648  1133 nodes.cc:25338] Running AD API GRAD: mean_grad
1561: I0810 03:59:48.957671  1133 nodes.cc:25394] { Input: [ 
1561: ( grad_out , [[ Not specified tensor log level ]]),  
1561: ( x , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.957713  1133 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1561: I0810 03:59:48.957732  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.957741  1133 backward.cc:335] Node: MeanGradNode addr:0x45327060, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44240e60
1561: I0810 03:59:48.957746  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.957770  1133 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44240e60
1561: I0810 03:59:48.957777  1133 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
1561: I0810 03:59:48.957791  1133 nodes.cc:12289] { Input: [ 
1561: ( out_grad , [[ Not specified tensor log level ]]), ]} 
1561: I0810 03:59:48.957819  1133 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
1561: I0810 03:59:48.957849  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:48.957855  1133 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44240e60, Found pending node: GradNodeAccumulation addr: 0x4534aa10
1561: I0810 03:59:48.957860  1133 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1561: I0810 03:59:48.957883  1133 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4534aa10
1561: I0810 03:59:48.957890  1133 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.957896  1133 accumulation_node.cc:40] Move Tensor ptr: 0x4554bb60
1561: I0810 03:59:48.957901  1133 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1561: I0810 03:59:48.957906  1133 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1561: I0810 03:59:49.014513  1133 mmap_allocator.cc:348] PID: 1133, MemoryMapFdSet: set size - 0
1561: I0810 03:59:49.024227  1133 mmap_allocator.cc:348] PID: 1133, MemoryMapFdSet: set size - 0
1561: I0810 03:59:49.202425  1133 mmap_allocator.cc:348] PID: 1133, MemoryMapFdSet: set size - 0
1/2 Test #1561: test_fake_quantize_op ................   Passed   13.07 sec
test 2253
    Start 2253: test_fake_quantize_op_static_build

2253: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "FLAGS_new_executor_static_build=true" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_fake_quantize_op"
2253: Test timeout computed to be: 10000000
2253: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
2253: WARNING: Logging before InitGoogleLogging() is written to STDERR
2253: I0810 03:59:50.157210  1268 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
2253: I0810 03:59:50.935680  1268 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=selected_gpus,enable_dump_main_program,enable_gpu_memory_usage_log_mb,enable_fuse_parallel_matmul_pass,manually_trans_conv_filter,cudnn_batchnorm_spatial_persistent,low_precision_op_list,sync_nccl_allreduce,gpugraph_enable_segment_merge_grads,check_infer_symbolic,enable_dependency_builder_debug_info,use_auto_growth_v2,cudnn_exhaustive_search,search_cache_max_number,new_executor_use_cuda_graph,static_runtime_data_save_path,enable_blaslt_global_search,use_shm_cache,einsum_opt,cudnn_dir,cublaslt_exhaustive_search_times,static_executor_perfstat_filepath,use_pinned_memory,cuda_dir,tracer_onednn_ops_on,enable_gpu_memory_usage_log,prim_check_ops,accuracy_check_rtol_bf16,new_executor_use_local_scope,enable_fusion_fallback,enable_cinn_accuracy_check,use_cinn,enable_opt_get_features,gpugraph_enable_gpu_direct_access,auto_growth_chunk_size_in_mb,gpugraph_offload_param_extends,executor_log_deps_every_microseconds,get_host_by_name_time,pir_apply_inplace_pass,graph_metapath_split_opt,dynamic_static_unified_comm,cudnn_exhaustive_search_times,prim_enable_dynamic,fast_eager_deletion_mode,use_autotune,enable_cublas_tensor_op_math,enable_all2all_use_fp16,gpugraph_parallel_stream_num,gpugraph_dedup_pull_push_mode,use_stream_safe_cuda_allocator,async_trace_count,enable_pir_with_pt_in_dy2st,cudnn_deterministic,paddle_num_threads,cusolver_dir,check_kernel_launch,cublaslt_device_best_config,enable_cinn_compile_cache,sort_sum_gradient,accuracy_check_atol_bf16,enable_graph_multi_node_sampling,max_inplace_grad_add,prim_forward_blacklist,local_exe_sub_scope_limit,reallocate_gpu_memory_in_mb,gpugraph_force_device_batch_num_equal,cublas_dir,run_kp_kernel,sync_after_alloc,set_to_1d,conv_workspace_size_limit,gpugraph_storage_mode,apply_pass_to_program,enable_exit_when_partial_worker,check_nan_inf_level,check_nan_inf,enable_cse_in_dy2st,accuracy_check_atol_fp16,deny_cinn_ops,tracer_onednn_ops_off,print_sub_graph_dir,enable_record_memory,save_static_runtime_data,gpu_allocator_retry_time,logging_pir_py_code_dir,init_allocated_mem,fraction_of_cuda_pinned_memory_to_use,pir_broadcast_tree_limit,tracer_profile_fname,fraction_of_cpu_memory_to_use,enable_pir_in_executor_trace_run,allow_cinn_ops,prim_all,prim_skip_dynamic,pir_debug,enable_api_kernel_fallback,allreduce_record_one_event,npu_storage_format,gpugraph_sparse_table_storage_mode,accuracy_check_rtol_fp16,use_stride_kernel,logging_pir_py_code_int_tensor_element_limit,pir_subgraph_saving_dir,use_virtual_memory_auto_growth,use_system_allocator,enable_cinn_auto_tune,benchmark,mklml_dir,graph_get_neighbor_id,disable_dyshape_in_train,prim_enabled,trt_ibuilder_cache,enable_interpretercore_launch_cinn,graph_neighbor_size_percent,embedding_deterministic,cuda_malloc_async_pool_memory_throttle_ratio,cusparse_dir,gpugraph_enable_hbm_table_collision_stat,alloc_fill_value,enable_adjust_op_order,accuracy_check_rtol_fp32,cuda_memory_async_pool_realease_threshold,gpu_memory_limit_mb,reader_queue_speed_test_mode,curand_dir,use_auto_growth_pinned_allocator,cinn_subgraph_graphviz_dir,multi_node_sample_use_gpu_table,benchmark_nccl,nccl_dir,gpugraph_enable_print_op_debug,enable_collect_shape,tensorrt_dir,new_executor_use_inplace,gpugraph_offload_param_stat,new_executor_static_build,op_dir,gpugraph_debug_gpu_memory,eager_delete_scope,enable_auto_detect_gpu_topo,accuracy_check_atol_fp32,conv2d_disable_cudnn,dataloader_use_file_descriptor,enable_pir_in_executor,win_cuda_bin_dir,pinned_memory_as_cpu_backend,use_fast_math,gpugraph_offload_gather_copy_maxsize,use_mkldnn,logging_trunc_pir_py_code,new_executor_sequential_run,cse_max_count,all_blocks_convert_trt,add_dependency_for_communication_op,gemm_use_half_precision_compute_type,enable_sparse_inner_gather,initial_cpu_memory_in_mb,enable_tracker_all2all,host_trace_level,nccl_blocking_wait,prim_forward,use_xqa_optim,use_cuda_malloc_async_allocator,fraction_of_gpu_memory_to_use,prim_backward,gpugraph_slot_feasign_max_num,fleet_executor_with_standalone,cupti_dir,logging_pir_py_code_dump_symbolic_dims,inner_op_parallelism,graph_embedding_split_infer_mode,cusparselt_dir,cinn_compile_thread_num,custom_device_mem_record,enable_async_trace,initial_gpu_memory_in_mb,log_memory_stats,graph_load_in_parallel,jit_engine_type,nvidia_package_dir,mkl_dir,allocator_strategy,print_allocator_trace_info,gpugraph_parallel_copyer_split_maxsize,cache_inference_while_scope,enable_pir_api,lapack_dir,memory_fraction_of_eager_deletion,print_ir,use_cuda_managed_memory,eager_delete_tensor_gb,convert_all_blocks,tensor_operants_mode,free_when_no_cache_hit,new_executor_serial_run,query_dest_rank_by_multi_node,multiple_of_cupti_buffer_size,dump_chunk_info,enable_unused_var_check,gpugraph_load_node_list_into_hbm,call_stack_level,dist_threadpool_size,auto_free_cudagraph_allocations_on_launch,pir_apply_shape_optimization_pass,fuse_parameter_memory_size,enable_auto_rdma_trans,gpugraph_hbm_table_load_factor,dygraph_debug,ir_inplace_kernel_blacklist,gpugraph_merge_grads_segment_size,enable_neighbor_list_use_uva,free_idle_chunk,fuse_parameter_groups_size 
2253: I0810 03:59:50.935794  1268 init.cc:108] After Parse: argc is 2
2253: I0810 03:59:57.948150  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 03:59:57.948212  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 03:59:57.948401  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 03:59:57.948413  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 03:59:57.949081  1268 allocator_facade.cc:212] selected allocator strategy:1
2253: I0810 03:59:57.949365  1268 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
2253: I0810 04:00:00.359997  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.360502  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.361021  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.361039  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.361056  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.363322  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.363346  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:00.363441  1268 program_interpreter.cc:243] New Executor is Running.
2253: I0810 04:00:00.363451  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.363456  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.363467  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44181c40 type is 7
2253: I0810 04:00:00.363481  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.363487  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4417e550 type is 7
2253: I0810 04:00:00.363492  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.363494  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4417f010 type is 7
2253: I0810 04:00:00.363498  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.363503  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:00.363507  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.363571  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.363577  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.363581  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.363584  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: W0810 04:00:00.364197  1268 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
2253: I0810 04:00:00.364513  1268 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
2253: W0810 04:00:00.365504  1268 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
2253: I0810 04:00:00.365738  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.365763  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.365892  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.365901  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.365953  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.365976  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.365996  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.366006  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445f0430Variable Type 7
2253: I0810 04:00:00.366029  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.366077  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.366096  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.366147  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.366156  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.366169  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.366176  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44182620Variable Type 7
2253: I0810 04:00:00.366185  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.366199  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.366212  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.366688  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.366730  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.366750  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.367031  1305 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.367276  1306 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.367326  1307 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.367357  1308 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.367449  1309 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.367544  1310 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.368017  1309 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.368018  1308 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.368530  1308 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.368556  1308 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.368587  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4417f2c8) got event_name: TaskCompletion
2253: I0810 04:00:00.368773  1305 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 9875440051227790845 to 17189945363590869653 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.368954  1308 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 7266018504506563179 to 4387486040692420614 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:00:00.369127  1310 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 17189945363590869653 to 3258848792123612270 , after update, data is {current : 196608, peak : 196620}.
2253: I0810 04:00:00.480692  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.480727  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.480803  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.480813  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.483609  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.484184  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.484716  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.484732  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.484738  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.487258  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.487388  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.487402  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.487409  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44172600 type is 7
2253: I0810 04:00:00.487421  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.487425  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4416f190 type is 7
2253: I0810 04:00:00.487432  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.487437  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4416fc10 type is 7
2253: I0810 04:00:00.487443  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.487452  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.487533  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.487540  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.487545  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.487550  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.487612  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.487630  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.487701  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.487715  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.487756  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.487767  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.487787  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.487794  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44602eb0Variable Type 7
2253: I0810 04:00:00.487812  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.487840  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.487855  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.487890  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.487901  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.487918  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.487926  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44172e70Variable Type 7
2253: I0810 04:00:00.487937  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.487952  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.487967  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.488307  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.488351  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.488373  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.488519  1312 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.488665  1313 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.488740  1314 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.488785  1315 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.488833  1316 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.488912  1317 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.489246  1316 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.489254  1315 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.489674  1316 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.489696  1316 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.489720  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4416ec48) got event_name: TaskCompletion
2253: I0810 04:00:00.489893  1312 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 17189945363590869653 to 4825685957987445629 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.490048  1315 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 11590346935734899628 to 15215870038455397554 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:00:00.490268  1317 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 4825685957987445629 to 3258848792123612270 , after update, data is {current : 196608, peak : 393216}.
2253: I0810 04:00:00.490499  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.492419  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.492441  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.492494  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.492504  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.494486  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.495056  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.495544  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.495559  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.495564  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.497912  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.497989  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.498001  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.498008  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x445fc690 type is 7
2253: I0810 04:00:00.498018  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.498021  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x445f9140 type is 7
2253: I0810 04:00:00.498028  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.498031  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x445f9bf0 type is 7
2253: I0810 04:00:00.498036  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.498045  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.498116  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.498123  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.498129  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.498133  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.498178  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.498193  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.498243  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.498253  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.498291  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.498324  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.498343  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.498351  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4460e200Variable Type 7
2253: I0810 04:00:00.498366  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.498390  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.498405  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.498438  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.498446  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.498463  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.498471  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44611540Variable Type 7
2253: I0810 04:00:00.498483  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.498499  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.498512  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.498773  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.498809  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.498831  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.498937  1318 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.499011  1319 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.499030  1320 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.499078  1321 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.499111  1322 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.499163  1323 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.499374  1322 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.499385  1321 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.499646  1321 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.499666  1321 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.499688  1268 program_interpreter.cc:1308] main_thread_blocker_(0x445f8bf8) got event_name: TaskCompletion
2253: I0810 04:00:00.499819  1318 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 4825685957987445629 to 17189945363590869653 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.499972  1321 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 7266018504506563179 to 4387486040692420614 , after update, data is {current : 196620, peak : 196620}.
2253: I0810 04:00:00.500046  1322 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 4387486040692420614 to 3258848792123612270 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:00:00.500152  1323 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 17189945363590869653 to 3258848792123612270 , after update, data is {current : 196608, peak : 393216}.
2253: I0810 04:00:00.502341  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.502545  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192a84a0 for it.
2253: I0810 04:00:00.502601  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.503409  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.503473  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.513546  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.513718  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.513760  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192a84a0 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:00:00.519527  1268 pir_interpreter.cc:161] PirInterpreter(): 0x44716360 on Place(gpu:0)
2253: I0810 04:00:00.519568  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.519600  1268 scope.cc:202] Create variable 0x447163601723262400519554115_inner_var_1
2253: I0810 04:00:00.519611  1268 scope.cc:202] Create variable 0x447163601723262400519554115_inner_var_2
2253: I0810 04:00:00.519623  1268 scope.cc:202] Create variable 0x447163601723262400519554115_inner_var_3
2253: I0810 04:00:00.519634  1268 scope.cc:202] Create variable 0x447163601723262400519554115_inner_var_4
2253: I0810 04:00:00.519641  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.519652  1268 scope.cc:202] Create variable 0x447163601723262400519554115_inner_var_6
2253: I0810 04:00:00.519661  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.520104  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.520119  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.520126  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: I0810 04:00:00.520174  1268 pir_interpreter.cc:1455] New Executor is Running ...
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x44716320
2253: 1 -> 0x447163601723262400519554115_inner_var_1 -> 0x44716340
2253: 2 -> 0x447163601723262400519554115_inner_var_2 -> 0x447145f0
2253: 3 -> 0x447163601723262400519554115_inner_var_3 -> 0x44715a70
2253: 4 -> 0x447163601723262400519554115_inner_var_4 -> 0x44716db0
2253: 5 -> fetch0@fetch -> 0x44717220
2253: 6 -> 0x447163601723262400519554115_inner_var_6 -> 0x44716dd0
2253: 7 -> fetch1@fetch -> 0x44717990
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.520965  1268 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
2253: I0810 04:00:00.521061  1324 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.521143  1325 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.521154  1326 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.521203  1327 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.521229  1328 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.521277  1329 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.521312  1329 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.521395  1329 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.521430  1329 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x447163601723262400519554115_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_3:[dtype=;place=;dim=;lod={};, 0x447163601723262400519554115_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.521549  1329 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x447163601723262400519554115_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x447163601723262400519554115_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.521608  1328 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447163601723262400519554115_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.521607  1327 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447163601723262400519554115_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.521651  1328 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.521652  1327 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.521721  1328 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447163601723262400519554115_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.522029  1327 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447163601723262400519554115_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447163601723262400519554115_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.522038  1328 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x447163601723262400519554115_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.522065  1328 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.522078  1327 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x447163601723262400519554115_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.522085  1328 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x447163601723262400519554115_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.522097  1327 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.522239  1327 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x447163601723262400519554115_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.522274  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x447164d0) got event_name: TaskCompletion
2253: I0810 04:00:00.522310  1268 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.522387  1268 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.525418  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192a84a0 for it.
2253: I0810 04:00:00.525609  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.525653  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.528209  1324 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 17189945363590869653 to 15215870038455397554 , after update, data is {current : 196596, peak : 393216}.
2253: I0810 04:00:00.528220  1324 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 17189945363590869653 to 3894914143258603765 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.528369  1327 thread_data_registry.h:135] Add data {current : 196596, peak : 393216} from thread 15215870038455397554 to 4825685957987445629 , after update, data is {current : 196620, peak : 393216}.
2253: I0810 04:00:00.528439  1328 thread_data_registry.h:135] Add data {current : 196620, peak : 393216} from thread 4825685957987445629 to 3258848792123612270 , after update, data is {current : 0, peak : 393216}.
2253: I0810 04:00:00.528553  1329 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 3894914143258603765 to 3258848792123612270 , after update, data is {current : 589836, peak : 786444}.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:00:00.529552  1268 pir_interpreter.cc:161] PirInterpreter(): 0x4414d520 on Place(gpu:0)
2253: I0810 04:00:00.529582  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.529601  1268 scope.cc:202] Create variable 0x4414d5201723262400529576459_inner_var_1
2253: I0810 04:00:00.529613  1268 scope.cc:202] Create variable 0x4414d5201723262400529576459_inner_var_2
2253: I0810 04:00:00.529623  1268 scope.cc:202] Create variable 0x4414d5201723262400529576459_inner_var_3
2253: I0810 04:00:00.529631  1268 scope.cc:202] Create variable 0x4414d5201723262400529576459_inner_var_4
2253: I0810 04:00:00.529642  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.529654  1268 scope.cc:202] Create variable 0x4414d5201723262400529576459_inner_var_6
2253: I0810 04:00:00.529664  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.530010  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.530026  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.530030  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x446efaf0
2253: 1 -> 0x4414d5201723262400529576459_inner_var_1 -> 0x446ebc40
2253: 2 -> 0x4414d5201723262400529576459_inner_var_2 -> 0x447149a0
2253: 3 -> 0x4414d5201723262400529576459_inner_var_3 -> 0x4414b110
2253: 4 -> 0x4414d5201723262400529576459_inner_var_4 -> 0x44604a40
2253: 5 -> fetch0@fetch -> 0x44716300
2253: 6 -> 0x4414d5201723262400529576459_inner_var_6 -> 0x446150e0
2253: 7 -> fetch1@fetch -> 0x447eab60
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.530720  1330 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.530786  1331 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.530805  1332 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.530849  1333 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.530879  1334 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.530926  1335 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.530944  1335 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.530972  1335 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.530998  1335 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4414d5201723262400529576459_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4414d5201723262400529576459_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.531090  1335 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4414d5201723262400529576459_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x4414d5201723262400529576459_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.531140  1334 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4414d5201723262400529576459_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.531147  1333 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4414d5201723262400529576459_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.531167  1334 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.531172  1333 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.531215  1334 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4414d5201723262400529576459_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.531388  1333 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4414d5201723262400529576459_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4414d5201723262400529576459_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.531396  1334 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4414d5201723262400529576459_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.531414  1334 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.531424  1334 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4414d5201723262400529576459_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.531435  1333 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4414d5201723262400529576459_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.531451  1333 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.531592  1333 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4414d5201723262400529576459_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.531625  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x4414d690) got event_name: TaskCompletion
2253: I0810 04:00:00.531644  1268 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.531708  1268 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.531889  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:19
2253: I0810 04:00:00.532030  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.532047  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:20
2253: I0810 04:00:00.532061  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.532897  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.532915  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.532958  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.532966  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.534547  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.534997  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.535367  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.535378  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.535383  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.537232  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.537294  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.537312  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.537319  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x447a1d90 type is 7
2253: I0810 04:00:00.537328  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.537333  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4479e940 type is 7
2253: I0810 04:00:00.537336  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.537339  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4479f3b0 type is 7
2253: I0810 04:00:00.537344  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.537348  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.537402  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.537408  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.537412  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.537416  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.537453  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.537465  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.537508  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.537519  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.537550  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.537559  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.537572  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.537578  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447ab600Variable Type 7
2253: I0810 04:00:00.537592  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.537609  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.537621  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.537648  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.537657  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.537668  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.537674  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447a2730Variable Type 7
2253: I0810 04:00:00.537684  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.537698  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.537708  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.537900  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.537931  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.537948  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.538112  1336 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.538203  1337 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.538332  1339 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.538333  1338 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.538424  1340 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.538484  1341 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.538664  1340 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.538687  1338 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.539070  1338 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.539089  1338 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.539111  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4479e3f8) got event_name: TaskCompletion
2253: I0810 04:00:00.539230  1336 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 9470489340628506630 to 4431466935759173892 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.539383  1338 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -12, peak : 196608}.
2253: I0810 04:00:00.539455  1340 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 0, peak : 196608}.
2253: I0810 04:00:00.539559  1341 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:00:00.539717  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.540619  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.540659  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.540673  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.540849  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:00.541769  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.541787  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.541829  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.541837  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.542660  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.542685  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.542727  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.542734  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.543092  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.543162  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.543540  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:00.543920  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:00.543937  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.544009  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.544023  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.546073  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.546581  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.546594  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.546602  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.549387  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.549403  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:00.549429  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.549437  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.549441  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448b2320 type is 7
2253: I0810 04:00:00.549448  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:00.549453  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x448aaa50 type is 7
2253: I0810 04:00:00.549456  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.549460  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448aa3a0 type is 7
2253: I0810 04:00:00.549464  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.549468  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x448b2af0 type is 7
2253: I0810 04:00:00.549472  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:00.549475  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x448b2d60 type is 7
2253: I0810 04:00:00.549479  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:00.549484  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x448b2fa0 type is 7
2253: I0810 04:00:00.549489  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:00.549491  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x448b3200 type is 7
2253: I0810 04:00:00.549496  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x448b2300 type is 9
2253: I0810 04:00:00.549501  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:00.549504  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x448b2f80 type is 10
2253: I0810 04:00:00.549583  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.549590  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.549597  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.549599  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.549641  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549654  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549692  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549700  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549746  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549755  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549813  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549822  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549835  1268 interpreter_util.cc:647] Standalone Executor is Used.
2253: I0810 04:00:00.549862  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549870  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549902  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549909  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.549933  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.549942  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.549954  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.549961  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448bf670Variable Type 7
2253: I0810 04:00:00.549975  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.549991  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.550004  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.550236  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.550266  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.550293  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.550400  1342 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.550457  1343 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.550482  1344 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.550505  1345 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.550536  1346 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.550571  1347 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.551087  1347 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.551120  1347 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.551172  1347 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.551210  1347 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.551332  1346 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.551704  1346 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.551731  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448ab238) got event_name: TaskCompletion
2253: I0810 04:00:00.551977  1342 thread_data_registry.h:135] Add data {current : -589844, peak : 0} from thread 4431466935759173892 to 13016180095601220208 , after update, data is {current : 0, peak : 589844}.
2253: I0810 04:00:00.552132  1346 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 196608, peak : 196608}.
2253: I0810 04:00:00.552318  1347 thread_data_registry.h:135] Add data {current : 0, peak : 589844} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.554729  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.554900  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.554935  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192a84a0 for it.
2253: I0810 04:00:00.555449  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.555481  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.555581  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x447ab100)  to GradNodeAccumulation (addr: 0x19291330)
2253: I0810 04:00:00.555689  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:00.555707  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.555914  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x447ab100)
2253: I0810 04:00:00.556005  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:00.556015  1268 backward.cc:113] Start Backward
2253: I0810 04:00:00.556030  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:00.556067  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.556100  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:00.556113  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:00.556149  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.556222  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.556247  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.556257  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x447ab100
2253: I0810 04:00:00.556265  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.556310  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x447ab100
2253: I0810 04:00:00.556324  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.556337  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.556366  1268 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.556398  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.556406  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x447ab100, Found pending node: GradNodeAccumulation addr: 0x19291330
2253: I0810 04:00:00.556411  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.556427  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x19291330
2253: I0810 04:00:00.556435  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.556440  1268 accumulation_node.cc:40] Move Tensor ptr: 0x4414b720
2253: I0810 04:00:00.556444  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.556448  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
2253: Warning:
2253: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
2253:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
2253:   return func(*args, **kwargs)
2253: I0810 04:00:00.644806  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.644830  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.644884  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.644892  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.646745  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.647208  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.647634  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.647647  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.647651  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.649588  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.649655  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.649667  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.649672  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448d7e70 type is 7
2253: I0810 04:00:00.649680  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.649684  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448d4900 type is 7
2253: I0810 04:00:00.649689  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.649693  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x448d53c0 type is 7
2253: I0810 04:00:00.649698  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.649703  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.649775  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.649782  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.649785  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.649789  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.649839  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.649852  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.649904  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.649914  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.649947  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.649955  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.649971  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.649978  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448d8b80Variable Type 7
2253: I0810 04:00:00.649992  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.650015  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.650028  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.650063  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.650070  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.650084  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.650090  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448d8590Variable Type 7
2253: I0810 04:00:00.650100  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.650113  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.650125  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.650413  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.650458  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.650476  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.650578  1348 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.650660  1349 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.650717  1350 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.650769  1351 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.650816  1352 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.650868  1353 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.651031  1352 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.651031  1351 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.651432  1351 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.651449  1351 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.651472  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448d4398) got event_name: TaskCompletion
2253: I0810 04:00:00.651633  1348 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.651793  1351 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 393216, peak : 393216}.
2253: I0810 04:00:00.651868  1352 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 393228, peak : 393228}.
2253: I0810 04:00:00.651976  1353 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.655565  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.655586  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.655632  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.655640  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.657220  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.657688  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.658066  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.658079  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.658083  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.659952  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.660017  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.660027  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.660032  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x447dc010 type is 7
2253: I0810 04:00:00.660041  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.660044  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4482a3e0 type is 7
2253: I0810 04:00:00.660048  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.660051  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x448c6a90 type is 7
2253: I0810 04:00:00.660055  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.660060  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.660120  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.660126  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.660130  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.660133  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.660171  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.660182  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.660223  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.660231  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.660262  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.660270  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.660283  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.660290  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4fae2d0Variable Type 7
2253: I0810 04:00:00.660310  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.660328  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.660341  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.660367  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.660374  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.660387  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.660392  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4fae110Variable Type 7
2253: I0810 04:00:00.660403  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.660416  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.660426  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.660635  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.660665  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.660683  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.660761  1354 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.660822  1355 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.660840  1356 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.660881  1357 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.660900  1358 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.660944  1359 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.661105  1357 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.661113  1358 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.661499  1357 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.661512  1357 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.661531  1268 program_interpreter.cc:1308] main_thread_blocker_(0x447d9488) got event_name: TaskCompletion
2253: I0810 04:00:00.661646  1354 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 4431466935759173892 to 13016180095601220208 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.661784  1357 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 589836, peak : 589836}.
2253: I0810 04:00:00.661859  1358 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 589848, peak : 589848}.
2253: I0810 04:00:00.661950  1359 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.662086  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.663161  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.663180  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.663220  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.663228  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.664763  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.665221  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.665597  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.665611  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.665614  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.667445  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.667502  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.667512  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.667516  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x447c3510 type is 7
2253: I0810 04:00:00.667526  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.667528  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x447bacd0 type is 7
2253: I0810 04:00:00.667533  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.667536  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447bb810 type is 7
2253: I0810 04:00:00.667541  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.667544  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.667603  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.667610  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.667613  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.667618  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.667650  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.667660  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.667701  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.667709  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.667739  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.667747  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.667760  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.667766  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447be4e0Variable Type 7
2253: I0810 04:00:00.667778  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.667794  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.667806  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.667832  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.667840  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.667852  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.667858  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447c1ae0Variable Type 7
2253: I0810 04:00:00.667867  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.667881  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.667891  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.668084  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.668112  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.668130  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.668205  1360 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.668259  1361 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.668272  1362 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.668313  1363 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.668335  1364 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.668371  1365 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.668517  1364 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.668522  1363 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.668766  1363 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.668780  1363 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.668799  1268 program_interpreter.cc:1308] main_thread_blocker_(0x447ba798) got event_name: TaskCompletion
2253: I0810 04:00:00.668912  1360 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.669049  1363 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 786456, peak : 786456}.
2253: I0810 04:00:00.669126  1364 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 786468, peak : 786468}.
2253: I0810 04:00:00.669214  1365 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.670922  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.671115  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192a84a0 for it.
2253: I0810 04:00:00.671160  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.671602  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.671641  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.674252  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.674444  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.674487  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192a84a0 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:00:00.677603  1268 pir_interpreter.cc:161] PirInterpreter(): 0x4481ca80 on Place(gpu:0)
2253: I0810 04:00:00.677634  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.677657  1268 scope.cc:202] Create variable 0x4481ca801723262400677626742_inner_var_1
2253: I0810 04:00:00.677670  1268 scope.cc:202] Create variable 0x4481ca801723262400677626742_inner_var_2
2253: I0810 04:00:00.677680  1268 scope.cc:202] Create variable 0x4481ca801723262400677626742_inner_var_3
2253: I0810 04:00:00.677690  1268 scope.cc:202] Create variable 0x4481ca801723262400677626742_inner_var_4
2253: I0810 04:00:00.677700  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.677712  1268 scope.cc:202] Create variable 0x4481ca801723262400677626742_inner_var_6
2253: I0810 04:00:00.677722  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.678092  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.678108  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.678112  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x448f1370
2253: 1 -> 0x4481ca801723262400677626742_inner_var_1 -> 0x4415b060
2253: 2 -> 0x4481ca801723262400677626742_inner_var_2 -> 0x4481d280
2253: 3 -> 0x4481ca801723262400677626742_inner_var_3 -> 0x447be360
2253: 4 -> 0x4481ca801723262400677626742_inner_var_4 -> 0x447c5320
2253: 5 -> fetch0@fetch -> 0x4481c360
2253: 6 -> 0x4481ca801723262400677626742_inner_var_6 -> 0x447c5340
2253: 7 -> fetch1@fetch -> 0x447ba6b0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.678812  1366 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.678874  1367 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.678889  1368 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.678933  1369 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.678953  1370 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.678999  1371 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.679018  1371 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.679045  1371 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.679072  1371 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4481ca801723262400677626742_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4481ca801723262400677626742_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.679158  1371 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4481ca801723262400677626742_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x4481ca801723262400677626742_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.679208  1370 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4481ca801723262400677626742_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.679212  1369 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4481ca801723262400677626742_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.679240  1370 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.679242  1369 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.679572  1370 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4481ca801723262400677626742_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.679603  1370 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4481ca801723262400677626742_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.679602  1369 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4481ca801723262400677626742_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x4481ca801723262400677626742_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.679625  1370 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.679634  1369 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4481ca801723262400677626742_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.679652  1369 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.679661  1369 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4481ca801723262400677626742_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.679769  1370 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4481ca801723262400677626742_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.679800  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x4481cbf0) got event_name: TaskCompletion
2253: I0810 04:00:00.679822  1268 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.679874  1268 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.681993  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192a84a0 for it.
2253: I0810 04:00:00.682193  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.682235  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> builtin.tensor<3x4x64x64xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>, builtin.tensor<3xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3x4x64x64xf32>) -> builtin.tensor<3x4x64x64xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<3xf32>) -> builtin.tensor<3xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: I0810 04:00:00.685030  1268 pir_interpreter.cc:161] PirInterpreter(): 0x447c43a0 on Place(gpu:0)
2253: I0810 04:00:00.685060  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.685079  1268 scope.cc:202] Create variable 0x447c43a01723262400685053855_inner_var_1
2253: I0810 04:00:00.685091  1268 scope.cc:202] Create variable 0x447c43a01723262400685053855_inner_var_2
2253: I0810 04:00:00.685101  1268 scope.cc:202] Create variable 0x447c43a01723262400685053855_inner_var_3
2253: I0810 04:00:00.685110  1268 scope.cc:202] Create variable 0x447c43a01723262400685053855_inner_var_4
2253: I0810 04:00:00.685122  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.685133  1268 scope.cc:202] Create variable 0x447c43a01723262400685053855_inner_var_6
2253: I0810 04:00:00.685142  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.685503  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.685521  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.685525  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[3,4,64,64],stop_gradient:[true]} : () -> undefined_tensor<3x4x64x64xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<3x4x64x64xf32>) -> gpu_tensor<3x4x64x64xf32>, gpu_tensor<3xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3x4x64x64xf32>) -> cpu_tensor<3x4x64x64xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<3xf32>) -> cpu_tensor<3xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x447ccfe0
2253: 1 -> 0x447c43a01723262400685053855_inner_var_1 -> 0x447cd000
2253: 2 -> 0x447c43a01723262400685053855_inner_var_2 -> 0x448a8f30
2253: 3 -> 0x447c43a01723262400685053855_inner_var_3 -> 0x448a3f50
2253: 4 -> 0x447c43a01723262400685053855_inner_var_4 -> 0x448d0560
2253: 5 -> fetch0@fetch -> 0x441620f0
2253: 6 -> 0x447c43a01723262400685053855_inner_var_6 -> 0x4471f370
2253: 7 -> fetch1@fetch -> 0x44162820
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.686216  1372 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.686345  1373 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.686367  1374 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.686445  1375 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.686489  1376 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.686527  1377 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.686565  1377 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.686595  1377 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.686625  1377 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x447c43a01723262400685053855_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_3:[dtype=;place=;dim=;lod={};, 0x447c43a01723262400685053855_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.686702  1377 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x447c43a01723262400685053855_inner_var_1:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};, 0x447c43a01723262400685053855_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.686751  1376 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447c43a01723262400685053855_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.686775  1376 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.686759  1375 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447c43a01723262400685053855_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.686789  1375 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.686839  1376 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447c43a01723262400685053855_inner_var_3:[dtype=float;place=Place(gpu:0);dim=3;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.687144  1375 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x447c43a01723262400685053855_inner_var_2:[dtype=float;place=Place(gpu:0);dim=3, 4, 64, 64;lod={};]}, outputs:{0x447c43a01723262400685053855_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.687151  1376 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x447c43a01723262400685053855_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.687168  1376 tensor_utils.cc:57] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.687179  1375 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x447c43a01723262400685053855_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.687180  1376 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x447c43a01723262400685053855_inner_var_6:[dtype=float;place=Place(cpu);dim=3;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=3;lod={};]}.
2253: I0810 04:00:00.687201  1375 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.687350  1375 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x447c43a01723262400685053855_inner_var_4:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=3, 4, 64, 64;lod={};]}.
2253: I0810 04:00:00.687381  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x447c4510) got event_name: TaskCompletion
2253: I0810 04:00:00.687398  1268 tensor_util.cc:48] TensorCopy 3, 4, 64, 64 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.687439  1268 tensor_util.cc:48] TensorCopy 3 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.687583  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:45
2253: I0810 04:00:00.687664  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.687680  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:46
2253: I0810 04:00:00.687693  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.688513  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.688532  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.688576  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.688585  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.689930  1366 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 4431466935759173892 to 7993959110900736729 , after update, data is {current : 196596, peak : 393216}.
2253: I0810 04:00:00.689939  1366 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 4431466935759173892 to 6015713031042148541 , after update, data is {current : -393240, peak : 0}.
2253: I0810 04:00:00.690080  1370 thread_data_registry.h:135] Add data {current : 393216, peak : 393216} from thread 4982686142408154 to 7993959110900736729 , after update, data is {current : 589812, peak : 589812}.
2253: I0810 04:00:00.690147  1369 thread_data_registry.h:135] Add data {current : 24, peak : 24} from thread 9470489340628506630 to 7993959110900736729 , after update, data is {current : 589836, peak : 589836}.
2253: I0810 04:00:00.690253  1371 thread_data_registry.h:135] Add data {current : 196620, peak : 196620} from thread 13016180095601220208 to 6015713031042148541 , after update, data is {current : -196620, peak : 196620}.
2253: I0810 04:00:00.690418  1372 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 6015713031042148541 to 7993959110900736729 , after update, data is {current : 393216, peak : 589836}.
2253: I0810 04:00:00.690428  1372 thread_data_registry.h:135] Add data {current : -196620, peak : 196620} from thread 6015713031042148541 to 10788832235836042612 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.690554  1375 thread_data_registry.h:135] Add data {current : 393216, peak : 589836} from thread 7993959110900736729 to 11386166155001416730 , after update, data is {current : 393240, peak : 589836}.
2253: I0810 04:00:00.690623  1376 thread_data_registry.h:135] Add data {current : 393240, peak : 589836} from thread 11386166155001416730 to 3894914143258603765 , after update, data is {current : 1179708, peak : 1179708}.
2253: I0810 04:00:00.690714  1377 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 10788832235836042612 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.691619  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.692077  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.692456  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.692469  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.692473  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.694335  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.694391  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.694401  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.694406  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x447204a0 type is 7
2253: I0810 04:00:00.694415  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.694418  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448bb1d0 type is 7
2253: I0810 04:00:00.694423  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.694427  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447c9340 type is 7
2253: I0810 04:00:00.694430  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.694434  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.694494  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.694499  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.694502  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.694506  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.694541  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.694552  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.694591  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.694599  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.694630  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.694638  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.694653  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.694658  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448231f0Variable Type 7
2253: I0810 04:00:00.694669  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.694686  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.694698  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.694725  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.694732  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.694744  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.694751  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44720980Variable Type 7
2253: I0810 04:00:00.694761  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.694773  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.694783  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.694979  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.695008  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.695025  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.695108  1378 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.695168  1379 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.695180  1380 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.695215  1381 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.695236  1382 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.695271  1383 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.695436  1381 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.695436  1382 tensor_utils.cc:57] TensorCopy 3 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.695825  1381 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.695840  1381 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.695860  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448e6658) got event_name: TaskCompletion
2253: I0810 04:00:00.695971  1378 thread_data_registry.h:135] Add data {current : -196620, peak : 0} from thread 10788832235836042612 to 13016180095601220208 , after update, data is {current : 0, peak : 196620}.
2253: I0810 04:00:00.696102  1381 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 1376316, peak : 1376316}.
2253: I0810 04:00:00.696172  1382 thread_data_registry.h:135] Add data {current : 12, peak : 12} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1376328, peak : 1376328}.
2253: I0810 04:00:00.696260  1383 thread_data_registry.h:135] Add data {current : 0, peak : 196620} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.696406  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.696964  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.696995  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.697005  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.697124  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:00.697974  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.697993  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.698035  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.698041  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.698695  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.698714  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.698747  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.698755  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.699048  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.699105  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.699437  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:00.699528  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:00.699537  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.699602  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.699611  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.701607  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.702126  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.702139  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.702143  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.704885  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.704901  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:00.704926  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.704934  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.704938  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4479c960 type is 7
2253: I0810 04:00:00.704944  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:00.704947  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44791e50 type is 7
2253: I0810 04:00:00.704952  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.704954  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44791b00 type is 7
2253: I0810 04:00:00.704959  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.704962  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4479d130 type is 7
2253: I0810 04:00:00.704967  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:00.704969  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4479d3a0 type is 7
2253: I0810 04:00:00.704973  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:00.704977  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4479d5e0 type is 7
2253: I0810 04:00:00.704980  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:00.704983  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x4479d840 type is 7
2253: I0810 04:00:00.704988  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4479c940 type is 9
2253: I0810 04:00:00.704991  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:00.704995  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4479d5c0 type is 10
2253: I0810 04:00:00.705075  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.705081  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.705085  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.705088  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.705127  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705138  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705178  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705186  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705217  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705224  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705255  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705262  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705287  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705294  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705333  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705341  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705365  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.705372  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.705385  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.705391  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4487bf80Variable Type 7
2253: I0810 04:00:00.705402  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.705420  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.705430  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.705659  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.705687  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.705711  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.705807  1384 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.705860  1385 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.705886  1386 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.705909  1387 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.705945  1388 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.705979  1389 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.706373  1389 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.706403  1389 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.706457  1389 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.706948  1389 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.707049  1388 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.707417  1388 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.707443  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44795888) got event_name: TaskCompletion
2253: I0810 04:00:00.707793  1384 thread_data_registry.h:135] Add data {current : -196608, peak : 0} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : 1179720, peak : 1376328}.
2253: I0810 04:00:00.707813  1384 thread_data_registry.h:135] Add data {current : -589844, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 589844}.
2253: I0810 04:00:00.707959  1388 thread_data_registry.h:135] Add data {current : 196608, peak : 196608} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 1376328, peak : 1376328}.
2253: I0810 04:00:00.708137  1389 thread_data_registry.h:135] Add data {current : 0, peak : 589844} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.709973  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.710179  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.710222  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.710821  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.710862  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.711380  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x449e4c90)  to GradNodeAccumulation (addr: 0x4481c510)
2253: I0810 04:00:00.711488  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:00.711511  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.711694  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x449e4c90)
2253: I0810 04:00:00.711777  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:00.711784  1268 backward.cc:113] Start Backward
2253: I0810 04:00:00.711794  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:00.711831  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.711860  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:00.711869  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:00.711895  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.711938  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=49152, vec_size=4, block_size=256, grid_size=48, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.711962  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.711970  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x449e4c90
2253: I0810 04:00:00.711977  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.712002  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x449e4c90
2253: I0810 04:00:00.712009  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.712023  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.712047  1268 tensor_utils.cc:57] TensorCopy 3, 4, 64, 64 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.712080  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.712087  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x449e4c90, Found pending node: GradNodeAccumulation addr: 0x4481c510
2253: I0810 04:00:00.712092  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.712107  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4481c510
2253: I0810 04:00:00.712114  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.712119  1268 accumulation_node.cc:40] Move Tensor ptr: 0x44175250
2253: I0810 04:00:00.712122  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.712127  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.715009  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.715029  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.715070  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.715078  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.716576  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.717031  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.717397  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.717410  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.717414  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.719205  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.719264  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.719273  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.719277  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x1960fd90 type is 7
2253: I0810 04:00:00.719283  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.719290  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x1960c6f0 type is 7
2253: I0810 04:00:00.719295  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.719297  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x1960d1b0 type is 7
2253: I0810 04:00:00.719311  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.719319  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.719375  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.719381  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.719385  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.719388  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.719422  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.719434  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.719471  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.719480  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.719511  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.719518  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.719530  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.719537  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19610aa0Variable Type 7
2253: I0810 04:00:00.719548  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.719565  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.719578  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.719604  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.719610  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.719623  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.719630  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x196104b0Variable Type 7
2253: I0810 04:00:00.719638  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.719651  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.719661  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.719851  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.719877  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.719894  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.719977  1390 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.720045  1391 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.720062  1392 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.720116  1393 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.720122  1394 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.720166  1395 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.720386  1394 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.720414  1393 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.720542  1393 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.720559  1393 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.720579  1268 program_interpreter.cc:1308] main_thread_blocker_(0x1960d468) got event_name: TaskCompletion
2253: I0810 04:00:00.720695  1390 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 4431466935759173892 to 13016180095601220208 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:00:00.720840  1393 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 1406328, peak : 1406328}.
2253: I0810 04:00:00.720909  1394 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1406408, peak : 1406408}.
2253: I0810 04:00:00.721012  1395 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.722672  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.722695  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.722746  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.722755  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.724581  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.725136  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.725567  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.725582  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.725587  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.727850  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.727923  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.727934  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.727943  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4489a2a0 type is 7
2253: I0810 04:00:00.727950  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.727957  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44896e30 type is 7
2253: I0810 04:00:00.727962  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.727967  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x448978b0 type is 7
2253: I0810 04:00:00.727972  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.727977  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.728049  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.728056  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.728060  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.728065  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.728104  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.728117  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.728166  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.728176  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.728212  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.728221  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.728237  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.728245  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19543950Variable Type 7
2253: I0810 04:00:00.728258  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.728278  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.728292  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.728332  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.728343  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.728358  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.728365  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4489aad0Variable Type 7
2253: I0810 04:00:00.728376  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.728392  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.728404  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.728633  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.728667  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.728689  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.728780  1396 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.728849  1397 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.728874  1398 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.728909  1399 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.728935  1400 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.728971  1401 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.729111  1400 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.729116  1399 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.729230  1399 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.729243  1399 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.729264  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448968e8) got event_name: TaskCompletion
2253: I0810 04:00:00.729398  1396 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:00:00.729532  1399 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 1436408, peak : 1436408}.
2253: I0810 04:00:00.729600  1400 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 1436488, peak : 1436488}.
2253: I0810 04:00:00.729696  1401 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.729842  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.732066  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.732087  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.732131  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.732139  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.733641  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.734094  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.734472  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.734485  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.734489  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.736337  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.736400  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.736410  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.736415  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x445f5820 type is 7
2253: I0810 04:00:00.736424  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.736428  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44838c00 type is 7
2253: I0810 04:00:00.736433  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.736435  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4414c6c0 type is 7
2253: I0810 04:00:00.736439  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.736444  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.736502  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.736508  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.736512  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.736515  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.736548  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.736559  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.736598  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.736604  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.736634  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.736641  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.736654  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.736661  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44837670Variable Type 7
2253: I0810 04:00:00.736672  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.736688  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.736701  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.736725  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.736732  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.736747  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.736752  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x441619e0Variable Type 7
2253: I0810 04:00:00.736761  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.736773  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.736784  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.736971  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.736999  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.737017  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.737107  1402 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.737164  1403 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.737182  1404 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.737241  1405 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.737247  1406 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.737298  1407 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.737509  1406 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.737545  1405 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.737694  1405 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.737712  1405 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.737735  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448386e8) got event_name: TaskCompletion
2253: I0810 04:00:00.737854  1402 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 4431466935759173892 to 13016180095601220208 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:00:00.738001  1405 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 1466488, peak : 1466488}.
2253: I0810 04:00:00.738075  1406 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1466568, peak : 1466568}.
2253: I0810 04:00:00.738176  1407 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.739368  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.739537  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.739579  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.739935  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.739966  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.741916  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.742066  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.742108  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:00:00.744935  1268 pir_interpreter.cc:161] PirInterpreter(): 0x448f0ae0 on Place(gpu:0)
2253: I0810 04:00:00.744964  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.744985  1268 scope.cc:202] Create variable 0x448f0ae01723262400744958485_inner_var_1
2253: I0810 04:00:00.744997  1268 scope.cc:202] Create variable 0x448f0ae01723262400744958485_inner_var_2
2253: I0810 04:00:00.745007  1268 scope.cc:202] Create variable 0x448f0ae01723262400744958485_inner_var_3
2253: I0810 04:00:00.745018  1268 scope.cc:202] Create variable 0x448f0ae01723262400744958485_inner_var_4
2253: I0810 04:00:00.745028  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.745039  1268 scope.cc:202] Create variable 0x448f0ae01723262400744958485_inner_var_6
2253: I0810 04:00:00.745049  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.745373  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.745389  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.745393  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x448aa010
2253: 1 -> 0x448f0ae01723262400744958485_inner_var_1 -> 0x448aa050
2253: 2 -> 0x448f0ae01723262400744958485_inner_var_2 -> 0x448de8f0
2253: 3 -> 0x448f0ae01723262400744958485_inner_var_3 -> 0x445f5a60
2253: 4 -> 0x448f0ae01723262400744958485_inner_var_4 -> 0x4418a420
2253: 5 -> fetch0@fetch -> 0x447216f0
2253: 6 -> 0x448f0ae01723262400744958485_inner_var_6 -> 0x4418a440
2253: 7 -> fetch1@fetch -> 0x447ce210
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.746047  1408 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.746112  1409 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.746132  1410 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.746172  1411 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.746202  1412 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.746237  1413 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.746258  1413 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.746284  1413 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.746316  1413 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448f0ae01723262400744958485_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_3:[dtype=;place=;dim=;lod={};, 0x448f0ae01723262400744958485_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.746410  1413 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448f0ae01723262400744958485_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x448f0ae01723262400744958485_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.746464  1411 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448f0ae01723262400744958485_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.746471  1412 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448f0ae01723262400744958485_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.746498  1411 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.746508  1412 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.746577  1411 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448f0ae01723262400744958485_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.746613  1412 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448f0ae01723262400744958485_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x448f0ae01723262400744958485_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.746618  1411 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448f0ae01723262400744958485_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.746645  1411 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.746663  1412 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448f0ae01723262400744958485_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.746665  1411 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448f0ae01723262400744958485_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.746685  1412 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.746698  1412 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448f0ae01723262400744958485_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.746726  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x448f0c50) got event_name: TaskCompletion
2253: I0810 04:00:00.746747  1268 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.746775  1268 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.748169  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.748340  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.748384  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:00:00.751132  1268 pir_interpreter.cc:161] PirInterpreter(): 0x448dec40 on Place(gpu:0)
2253: I0810 04:00:00.751161  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.751179  1268 scope.cc:202] Create variable 0x448dec401723262400751155403_inner_var_1
2253: I0810 04:00:00.751191  1268 scope.cc:202] Create variable 0x448dec401723262400751155403_inner_var_2
2253: I0810 04:00:00.751202  1268 scope.cc:202] Create variable 0x448dec401723262400751155403_inner_var_3
2253: I0810 04:00:00.751212  1268 scope.cc:202] Create variable 0x448dec401723262400751155403_inner_var_4
2253: I0810 04:00:00.751222  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.751235  1268 scope.cc:202] Create variable 0x448dec401723262400751155403_inner_var_6
2253: I0810 04:00:00.751243  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.751569  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.751585  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.751590  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x4416a980
2253: 1 -> 0x448dec401723262400751155403_inner_var_1 -> 0x448dec20
2253: 2 -> 0x448dec401723262400751155403_inner_var_2 -> 0x44880b00
2253: 3 -> 0x448dec401723262400751155403_inner_var_3 -> 0x1960a670
2253: 4 -> 0x448dec401723262400751155403_inner_var_4 -> 0x4416c700
2253: 5 -> fetch0@fetch -> 0x44837930
2253: 6 -> 0x448dec401723262400751155403_inner_var_6 -> 0x4416c720
2253: 7 -> fetch1@fetch -> 0x448c0060
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.752243  1414 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.752331  1415 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.752363  1416 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.752390  1417 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.752420  1418 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.752458  1419 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.752476  1419 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.752506  1419 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.752533  1419 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448dec401723262400751155403_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_3:[dtype=;place=;dim=;lod={};, 0x448dec401723262400751155403_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.752631  1419 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448dec401723262400751155403_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x448dec401723262400751155403_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.752681  1418 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448dec401723262400751155403_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.752705  1418 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.752704  1417 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448dec401723262400751155403_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.752745  1417 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.752754  1418 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448dec401723262400751155403_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.752782  1418 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448dec401723262400751155403_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.752799  1418 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.752811  1418 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448dec401723262400751155403_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.752842  1417 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448dec401723262400751155403_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448dec401723262400751155403_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.752871  1417 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448dec401723262400751155403_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.752888  1417 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.752907  1417 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448dec401723262400751155403_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.752936  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x448dedb0) got event_name: TaskCompletion
2253: I0810 04:00:00.752957  1268 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.752985  1268 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.753126  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:71
2253: I0810 04:00:00.753211  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.753227  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:72
2253: I0810 04:00:00.753244  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.754174  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.754196  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.754247  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.754256  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.756060  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.756616  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.757050  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.757066  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.757071  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.759297  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.759379  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.759392  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.759400  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448c8740 type is 7
2253: I0810 04:00:00.759408  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.759413  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x447b75d0 type is 7
2253: I0810 04:00:00.759419  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.759423  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x1953e690 type is 7
2253: I0810 04:00:00.759428  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.759433  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.759505  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.759512  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.759517  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.759521  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.759562  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.759575  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.759626  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.759635  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.759673  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.759683  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.759699  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.759706  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447e1010Variable Type 7
2253: I0810 04:00:00.759721  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.759740  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.759754  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.759786  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.759795  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.759811  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.759817  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447df6e0Variable Type 7
2253: I0810 04:00:00.759829  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.759845  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.759856  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.760093  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.760130  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.760151  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.760288  1420 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.760445  1421 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.760461  1422 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.760531  1423 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.760629  1424 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.760656  1425 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.760826  1424 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.760831  1423 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.760973  1424 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.760988  1424 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.761008  1268 program_interpreter.cc:1308] main_thread_blocker_(0x447b7088) got event_name: TaskCompletion
2253: I0810 04:00:00.761133  1420 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 11889672084016139656 to 6015713031042148541 , after update, data is {current : -60160, peak : 0}.
2253: I0810 04:00:00.761286  1424 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 5971630607618707325 to 14056846822129258120 , after update, data is {current : 30080, peak : 30080}.
2253: I0810 04:00:00.761365  1423 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 14056846822129258120 to 7993959110900736729 , after update, data is {current : 90080, peak : 90080}.
2253: I0810 04:00:00.761477  1425 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 11721675564733120910 to 6015713031042148541 , after update, data is {current : -30080, peak : 30080}.
2253: I0810 04:00:00.761629  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.762156  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.762187  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.762200  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.762336  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:00.763327  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.763350  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.763398  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.763408  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.764124  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.764144  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.764182  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.764191  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.764528  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.764593  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.764959  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:00.765058  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:00.765069  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.765146  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.765157  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.767062  1408 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 13016180095601220208 to 7993959110900736729 , after update, data is {current : 60000, peak : 90080}.
2253: I0810 04:00:00.767072  1408 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 13016180095601220208 to 6015713031042148541 , after update, data is {current : -60160, peak : 30080}.
2253: I0810 04:00:00.767289  1412 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 753228128760470270 to 7993959110900736729 , after update, data is {current : 60160, peak : 90080}.
2253: I0810 04:00:00.767365  1411 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 4976018710619039040 to 7993959110900736729 , after update, data is {current : 120160, peak : 120160}.
2253: I0810 04:00:00.767472  1413 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 4431466935759173892 to 6015713031042148541 , after update, data is {current : -30080, peak : 30080}.
2253: I0810 04:00:00.767621  1414 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 6015713031042148541 to 7993959110900736729 , after update, data is {current : 90080, peak : 120160}.
2253: I0810 04:00:00.767630  1414 thread_data_registry.h:135] Add data {current : -30080, peak : 30080} from thread 6015713031042148541 to 10788832235836042612 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:00:00.767784  1417 thread_data_registry.h:135] Add data {current : 90080, peak : 120160} from thread 7993959110900736729 to 11386166155001416730 , after update, data is {current : 90240, peak : 120160}.
2253: I0810 04:00:00.767861  1418 thread_data_registry.h:135] Add data {current : 90240, peak : 120160} from thread 11386166155001416730 to 3894914143258603765 , after update, data is {current : 1556808, peak : 1556808}.
2253: I0810 04:00:00.767958  1419 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 10788832235836042612 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.769228  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.769898  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.769915  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.769920  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.773396  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.773415  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:00.773445  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.773455  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.773460  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448a50a0 type is 7
2253: I0810 04:00:00.773470  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:00.773474  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x447d7370 type is 7
2253: I0810 04:00:00.773479  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.773485  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4414f010 type is 7
2253: I0810 04:00:00.773490  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.773494  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19606c70 type is 7
2253: I0810 04:00:00.773499  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:00.773502  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x19606ee0 type is 7
2253: I0810 04:00:00.773509  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:00.773511  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x19607120 type is 7
2253: I0810 04:00:00.773517  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:00.773521  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x19607380 type is 7
2253: I0810 04:00:00.773526  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x448a5080 type is 9
2253: I0810 04:00:00.773531  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:00.773535  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x19607100 type is 10
2253: I0810 04:00:00.773636  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.773644  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.773648  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.773653  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.773701  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773713  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773763  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773773  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773811  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773821  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773856  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773865  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773895  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773903  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773941  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773950  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.773980  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.773989  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.774004  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.774011  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448c2bd0Variable Type 7
2253: I0810 04:00:00.774025  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.774045  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.774060  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.774358  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.774389  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.774418  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.774509  1426 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.774572  1427 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.774605  1428 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.774631  1429 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.774660  1430 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.774698  1431 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.775004  1431 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.775027  1431 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.775087  1431 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.775125  1431 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.775195  1430 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.775285  1430 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.775314  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4482f558) got event_name: TaskCompletion
2253: I0810 04:00:00.775482  1426 thread_data_registry.h:135] Add data {current : -90088, peak : 0} from thread 10788832235836042612 to 13016180095601220208 , after update, data is {current : 0, peak : 90088}.
2253: I0810 04:00:00.775632  1430 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1586808, peak : 1586808}.
2253: I0810 04:00:00.775810  1431 thread_data_registry.h:135] Add data {current : 0, peak : 90088} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.776834  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.776997  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.777040  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.777621  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.777657  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.777766  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44721dc0)  to GradNodeAccumulation (addr: 0x4481c510)
2253: I0810 04:00:00.777858  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:00.777877  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.778028  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44721dc0)
2253: I0810 04:00:00.778103  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:00.778110  1268 backward.cc:113] Start Backward
2253: I0810 04:00:00.778118  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:00.778152  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.778178  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:00.778187  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:00.778211  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.778256  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.778276  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.778285  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44721dc0
2253: I0810 04:00:00.778290  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.778323  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44721dc0
2253: I0810 04:00:00.778331  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.778345  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.778374  1268 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.778405  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.778412  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44721dc0, Found pending node: GradNodeAccumulation addr: 0x4481c510
2253: I0810 04:00:00.778417  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.778438  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4481c510
2253: I0810 04:00:00.778446  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.778450  1268 accumulation_node.cc:40] Move Tensor ptr: 0x447b7ea0
2253: I0810 04:00:00.778455  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.778458  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.789841  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.789861  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.789901  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.789909  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.791399  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.791853  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.792213  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.792227  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.792229  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.794050  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.794113  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.794123  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.794127  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4478ca80 type is 7
2253: I0810 04:00:00.794133  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.794138  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x447a5e40 type is 7
2253: I0810 04:00:00.794143  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.794147  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447a6900 type is 7
2253: I0810 04:00:00.794150  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.794155  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.794211  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.794217  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.794221  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.794224  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.794257  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.794268  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.794314  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.794323  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.794353  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.794361  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.794374  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.794380  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4478d730Variable Type 7
2253: I0810 04:00:00.794392  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.794409  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.794420  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.794445  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.794452  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.794464  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.794471  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4478e5c0Variable Type 7
2253: I0810 04:00:00.794481  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.794494  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.794504  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.794692  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.794718  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.794736  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.794822  1432 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.794888  1433 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.794900  1434 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.794930  1435 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.794976  1436 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.794999  1437 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.795235  1436 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.795240  1435 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.795400  1435 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.795420  1435 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.795442  1268 program_interpreter.cc:1308] main_thread_blocker_(0x447a58d8) got event_name: TaskCompletion
2253: I0810 04:00:00.795563  1432 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:00:00.795708  1435 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 1616808, peak : 1616808}.
2253: I0810 04:00:00.795761  1436 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 1616888, peak : 1616888}.
2253: I0810 04:00:00.795899  1437 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.797573  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.797597  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.797646  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.797657  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.799468  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.800025  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.800457  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.800472  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.800477  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.802680  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.802757  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.802769  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.802778  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4484c880 type is 7
2253: I0810 04:00:00.802785  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.802791  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44849410 type is 7
2253: I0810 04:00:00.802796  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.802800  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44849e90 type is 7
2253: I0810 04:00:00.802805  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.802810  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.802876  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.802883  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.802887  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.802891  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.802932  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.802943  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.802994  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.803002  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.803040  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.803048  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.803064  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.803072  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1954e750Variable Type 7
2253: I0810 04:00:00.803086  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.803105  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.803119  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.803150  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.803159  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.803175  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.803182  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4484cf50Variable Type 7
2253: I0810 04:00:00.803193  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.803208  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.803221  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.803460  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.803495  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.803519  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.803611  1438 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.803687  1439 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.803715  1440 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.803750  1441 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.803783  1442 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.803824  1443 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.804003  1442 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.804009  1441 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.804136  1441 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.804152  1441 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.804172  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44848ec8) got event_name: TaskCompletion
2253: I0810 04:00:00.804296  1438 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 4431466935759173892 to 13016180095601220208 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:00:00.804455  1441 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 1646888, peak : 1646888}.
2253: I0810 04:00:00.804539  1442 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1646968, peak : 1646968}.
2253: I0810 04:00:00.804646  1443 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.804818  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.806051  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.806074  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.806123  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.806133  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.807962  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.808540  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.808976  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.808991  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.808996  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.811218  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.811292  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.811314  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.811321  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448f6fc0 type is 7
2253: I0810 04:00:00.811329  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.811336  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448f3a70 type is 7
2253: I0810 04:00:00.811340  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.811344  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x448f4520 type is 7
2253: I0810 04:00:00.811348  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.811354  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.811421  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.811429  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.811434  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.811437  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.811477  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.811491  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.811539  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.811548  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.811585  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.811594  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.811610  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.811618  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448ff5e0Variable Type 7
2253: I0810 04:00:00.811632  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.811652  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.811666  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.811697  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.811705  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.811722  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.811728  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448f8830Variable Type 7
2253: I0810 04:00:00.811739  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.811754  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.811767  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.811998  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.812031  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.812053  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.812153  1444 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.812220  1445 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.812242  1446 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.812278  1447 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.812309  1448 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.812354  1449 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.812523  1447 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.812530  1448 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.812666  1447 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.812688  1447 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.812711  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448f34e8) got event_name: TaskCompletion
2253: I0810 04:00:00.812839  1444 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 30080}.
2253: I0810 04:00:00.812985  1447 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 1676968, peak : 1676968}.
2253: I0810 04:00:00.813064  1448 thread_data_registry.h:135] Add data {current : 80, peak : 80} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 1677048, peak : 1677048}.
2253: I0810 04:00:00.813169  1449 thread_data_registry.h:135] Add data {current : 0, peak : 30080} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.814361  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.814523  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.814565  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.814916  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.814949  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.816905  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.817049  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.817090  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:00:00.820456  1268 pir_interpreter.cc:161] PirInterpreter(): 0x19614040 on Place(gpu:0)
2253: I0810 04:00:00.820480  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.820497  1268 scope.cc:202] Create variable 0x196140401723262400820475951_inner_var_1
2253: I0810 04:00:00.820506  1268 scope.cc:202] Create variable 0x196140401723262400820475951_inner_var_2
2253: I0810 04:00:00.820515  1268 scope.cc:202] Create variable 0x196140401723262400820475951_inner_var_3
2253: I0810 04:00:00.820523  1268 scope.cc:202] Create variable 0x196140401723262400820475951_inner_var_4
2253: I0810 04:00:00.820529  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.820538  1268 scope.cc:202] Create variable 0x196140401723262400820475951_inner_var_6
2253: I0810 04:00:00.820546  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.820798  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.820811  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.820813  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x4482e030
2253: 1 -> 0x196140401723262400820475951_inner_var_1 -> 0x1955d530
2253: 2 -> 0x196140401723262400820475951_inner_var_2 -> 0x447927b0
2253: 3 -> 0x196140401723262400820475951_inner_var_3 -> 0x19530850
2253: 4 -> 0x196140401723262400820475951_inner_var_4 -> 0x447c8870
2253: 5 -> fetch0@fetch -> 0x44162800
2253: 6 -> 0x196140401723262400820475951_inner_var_6 -> 0x448a50c0
2253: 7 -> fetch1@fetch -> 0x446ecc20
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.821352  1450 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.821411  1451 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.821424  1452 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.821460  1453 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.821487  1454 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.821518  1455 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.821538  1455 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.821566  1455 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.821591  1455 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x196140401723262400820475951_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_3:[dtype=;place=;dim=;lod={};, 0x196140401723262400820475951_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.821679  1455 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x196140401723262400820475951_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x196140401723262400820475951_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.821725  1454 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196140401723262400820475951_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.821728  1453 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196140401723262400820475951_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.821754  1454 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.821759  1453 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.821831  1454 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196140401723262400820475951_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.821867  1453 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x196140401723262400820475951_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x196140401723262400820475951_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.821877  1454 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x196140401723262400820475951_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.821892  1454 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.821892  1453 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x196140401723262400820475951_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.821906  1453 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.821908  1454 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x196140401723262400820475951_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.821914  1453 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x196140401723262400820475951_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.821938  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x196141b0) got event_name: TaskCompletion
2253: I0810 04:00:00.821957  1268 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.821980  1268 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.823295  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.823467  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.823509  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> builtin.tensor<15x20x5x5xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>, builtin.tensor<20xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15x20x5x5xf32>) -> builtin.tensor<15x20x5x5xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<20xf32>) -> builtin.tensor<20xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: I0810 04:00:00.826251  1268 pir_interpreter.cc:161] PirInterpreter(): 0x448e4370 on Place(gpu:0)
2253: I0810 04:00:00.826278  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.826297  1268 scope.cc:202] Create variable 0x448e43701723262400826272960_inner_var_1
2253: I0810 04:00:00.826316  1268 scope.cc:202] Create variable 0x448e43701723262400826272960_inner_var_2
2253: I0810 04:00:00.826326  1268 scope.cc:202] Create variable 0x448e43701723262400826272960_inner_var_3
2253: I0810 04:00:00.826337  1268 scope.cc:202] Create variable 0x448e43701723262400826272960_inner_var_4
2253: I0810 04:00:00.826349  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.826360  1268 scope.cc:202] Create variable 0x448e43701723262400826272960_inner_var_6
2253: I0810 04:00:00.826370  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.826683  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.826699  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.826702  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[15,20,5,5],stop_gradient:[true]} : () -> undefined_tensor<15x20x5x5xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<15x20x5x5xf32>) -> gpu_tensor<15x20x5x5xf32>, gpu_tensor<20xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15x20x5x5xf32>) -> cpu_tensor<15x20x5x5xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<20xf32>) -> cpu_tensor<20xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x448cfe10
2253: 1 -> 0x448e43701723262400826272960_inner_var_1 -> 0x196083e0
2253: 2 -> 0x448e43701723262400826272960_inner_var_2 -> 0x448387f0
2253: 3 -> 0x448e43701723262400826272960_inner_var_3 -> 0x19608440
2253: 4 -> 0x448e43701723262400826272960_inner_var_4 -> 0x1961e800
2253: 5 -> fetch0@fetch -> 0x4466a4d0
2253: 6 -> 0x448e43701723262400826272960_inner_var_6 -> 0x448bfda0
2253: 7 -> fetch1@fetch -> 0x195f49c0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.827360  1456 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.827440  1457 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.827466  1458 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.827498  1459 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.827522  1460 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.827562  1461 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.827579  1461 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.827596  1461 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.827617  1461 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448e43701723262400826272960_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_3:[dtype=;place=;dim=;lod={};, 0x448e43701723262400826272960_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.827715  1461 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448e43701723262400826272960_inner_var_1:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};, 0x448e43701723262400826272960_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.827760  1460 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448e43701723262400826272960_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.827762  1459 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448e43701723262400826272960_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.827783  1460 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.827787  1459 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.827840  1460 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448e43701723262400826272960_inner_var_3:[dtype=float;place=Place(gpu:0);dim=20;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.827916  1459 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448e43701723262400826272960_inner_var_2:[dtype=float;place=Place(gpu:0);dim=15, 20, 5, 5;lod={};]}, outputs:{0x448e43701723262400826272960_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.827926  1460 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448e43701723262400826272960_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.827941  1460 tensor_utils.cc:57] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.827944  1459 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448e43701723262400826272960_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.827957  1459 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.827955  1460 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448e43701723262400826272960_inner_var_6:[dtype=float;place=Place(cpu);dim=20;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=20;lod={};]}.
2253: I0810 04:00:00.827991  1459 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448e43701723262400826272960_inner_var_4:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=15, 20, 5, 5;lod={};]}.
2253: I0810 04:00:00.828018  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x448e44e0) got event_name: TaskCompletion
2253: I0810 04:00:00.828042  1268 tensor_util.cc:48] TensorCopy 15, 20, 5, 5 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.828068  1268 tensor_util.cc:48] TensorCopy 20 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.828210  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:97
2253: I0810 04:00:00.828290  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.828316  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:98
2253: I0810 04:00:00.828336  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.829252  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.829272  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.829330  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.829341  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.831171  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.831735  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.832176  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.832191  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.832195  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.834465  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.834540  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.834553  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.834565  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448441d0 type is 7
2253: I0810 04:00:00.834573  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.834582  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x447a4150 type is 7
2253: I0810 04:00:00.834589  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.834592  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447a3f70 type is 7
2253: I0810 04:00:00.834597  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.834602  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.834671  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.834678  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.834683  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.834687  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.834729  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.834743  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.834793  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.834805  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.834841  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.834851  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.834867  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.834874  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448f8090Variable Type 7
2253: I0810 04:00:00.834888  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.834908  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.834921  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.834954  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.834962  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.834976  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.834983  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19559610Variable Type 7
2253: I0810 04:00:00.834995  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.835011  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.835022  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.835263  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.835309  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.835332  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.835438  1462 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.835527  1463 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.835558  1464 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.835583  1465 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.835616  1466 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.835652  1467 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.835811  1466 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.835830  1465 tensor_utils.cc:57] TensorCopy 20 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.835968  1466 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.835983  1466 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.836002  1268 program_interpreter.cc:1308] main_thread_blocker_(0x1955adc8) got event_name: TaskCompletion
2253: I0810 04:00:00.836131  1462 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 11889672084016139656 to 6015713031042148541 , after update, data is {current : -60160, peak : 0}.
2253: I0810 04:00:00.836278  1466 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 5971630607618707325 to 14056846822129258120 , after update, data is {current : 30080, peak : 30080}.
2253: I0810 04:00:00.836356  1465 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 14056846822129258120 to 7993959110900736729 , after update, data is {current : 90080, peak : 90080}.
2253: I0810 04:00:00.836475  1467 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 11721675564733120910 to 6015713031042148541 , after update, data is {current : -30080, peak : 30080}.
2253: I0810 04:00:00.836642  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.837145  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.837178  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.837191  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.837322  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:00.838352  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.838375  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.838428  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.838438  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.839193  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.839215  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.839253  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.839262  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.839617  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.839684  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.840058  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:00.840157  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:00.840166  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.840245  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.840255  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.842717  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.843340  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.843358  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.843361  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.846743  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.846764  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:00.846794  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.846804  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.846809  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x449f35d0 type is 7
2253: I0810 04:00:00.846819  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:00.846823  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44861900 type is 7
2253: I0810 04:00:00.846828  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.846835  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44861250 type is 7
2253: I0810 04:00:00.846840  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.846844  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x449f3da0 type is 7
2253: I0810 04:00:00.846849  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:00.846853  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x449f4010 type is 7
2253: I0810 04:00:00.846858  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:00.846863  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x449f4250 type is 7
2253: I0810 04:00:00.846868  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:00.846871  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x449f44b0 type is 7
2253: I0810 04:00:00.846876  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x449f35b0 type is 9
2253: I0810 04:00:00.846881  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:00.846887  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x449f4230 type is 10
2253: I0810 04:00:00.846985  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.846993  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.846997  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.847002  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.847052  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847066  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847116  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847126  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847164  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847173  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847210  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847220  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847249  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847258  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847297  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847316  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847345  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.847354  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.847370  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.847378  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44a147f0Variable Type 7
2253: I0810 04:00:00.847393  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.847412  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.847426  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.847723  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.847755  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.847785  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.847906  1468 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.847993  1469 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.847994  1470 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.848031  1471 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.848057  1472 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.848098  1473 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.848479  1473 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.848517  1473 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.848582  1473 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.848646  1473 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.848729  1472 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.848853  1472 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.848876  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44860ce8) got event_name: TaskCompletion
2253: I0810 04:00:00.849031  1468 thread_data_registry.h:135] Add data {current : -90088, peak : 0} from thread 11721675564733120910 to 6015713031042148541 , after update, data is {current : -120168, peak : 30080}.
2253: I0810 04:00:00.849195  1472 thread_data_registry.h:135] Add data {current : 30000, peak : 30000} from thread 2467189415505742546 to 7993959110900736729 , after update, data is {current : 120080, peak : 120080}.
2253: I0810 04:00:00.849373  1473 thread_data_registry.h:135] Add data {current : 90088, peak : 90088} from thread 14591741820773456119 to 6015713031042148541 , after update, data is {current : -30080, peak : 90088}.
2253: I0810 04:00:00.850382  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.850554  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.850595  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.851190  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.851228  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.851351  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x445f2ae0)  to GradNodeAccumulation (addr: 0x4481c510)
2253: I0810 04:00:00.851444  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:00.851466  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.851626  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x445f2ae0)
2253: I0810 04:00:00.851703  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:00.851711  1268 backward.cc:113] Start Backward
2253: I0810 04:00:00.851720  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:00.851754  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.851779  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:00.851788  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:00.851814  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.851861  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=7500, vec_size=4, block_size=64, grid_size=30, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.851884  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.851893  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x445f2ae0
2253: I0810 04:00:00.851902  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.851929  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x445f2ae0
2253: I0810 04:00:00.851938  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.851951  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.851981  1268 tensor_utils.cc:57] TensorCopy 15, 20, 5, 5 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.852012  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.852020  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x445f2ae0, Found pending node: GradNodeAccumulation addr: 0x4481c510
2253: I0810 04:00:00.852025  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.852046  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4481c510
2253: I0810 04:00:00.852054  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.852059  1268 accumulation_node.cc:40] Move Tensor ptr: 0x44835300
2253: I0810 04:00:00.852063  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.852068  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.853965  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.853989  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.854039  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.854049  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.855063  1450 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 4431466935759173892 to 7993959110900736729 , after update, data is {current : 90000, peak : 120080}.
2253: I0810 04:00:00.855082  1450 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 4431466935759173892 to 6015713031042148541 , after update, data is {current : -60160, peak : 90088}.
2253: I0810 04:00:00.855262  1453 thread_data_registry.h:135] Add data {current : 160, peak : 160} from thread 9470489340628506630 to 7993959110900736729 , after update, data is {current : 90160, peak : 120080}.
2253: I0810 04:00:00.855345  1454 thread_data_registry.h:135] Add data {current : 60000, peak : 60000} from thread 4982686142408154 to 7993959110900736729 , after update, data is {current : 150160, peak : 150160}.
2253: I0810 04:00:00.855471  1455 thread_data_registry.h:135] Add data {current : 30080, peak : 30080} from thread 13016180095601220208 to 6015713031042148541 , after update, data is {current : -30080, peak : 90088}.
2253: I0810 04:00:00.855675  1456 thread_data_registry.h:135] Add data {current : -30080, peak : 0} from thread 6015713031042148541 to 7993959110900736729 , after update, data is {current : 120080, peak : 150160}.
2253: I0810 04:00:00.855686  1456 thread_data_registry.h:135] Add data {current : -30080, peak : 90088} from thread 6015713031042148541 to 10788832235836042612 , after update, data is {current : 0, peak : 90088}.
2253: I0810 04:00:00.855849  1459 thread_data_registry.h:135] Add data {current : 120080, peak : 150160} from thread 7993959110900736729 to 11386166155001416730 , after update, data is {current : 120240, peak : 150160}.
2253: I0810 04:00:00.855924  1460 thread_data_registry.h:135] Add data {current : 120240, peak : 150160} from thread 11386166155001416730 to 3894914143258603765 , after update, data is {current : 1797288, peak : 1797288}.
2253: I0810 04:00:00.856035  1461 thread_data_registry.h:135] Add data {current : 0, peak : 90088} from thread 10788832235836042612 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.858107  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.858700  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.859194  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.859210  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.859215  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.861580  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.861660  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.861673  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.861690  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4489b6c0 type is 7
2253: I0810 04:00:00.861698  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.861704  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x441620d0 type is 7
2253: I0810 04:00:00.861709  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.861714  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44736690 type is 7
2253: I0810 04:00:00.861718  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.861724  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.861810  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.861817  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.861822  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.861826  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.861868  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.861882  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.861934  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.861944  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.861982  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.861992  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.862008  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.862016  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4486b4e0Variable Type 7
2253: I0810 04:00:00.862030  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.862051  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.862064  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.862097  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.862105  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.862121  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.862128  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44845790Variable Type 7
2253: I0810 04:00:00.862140  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.862155  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.862166  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.862419  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.862455  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.862478  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.862586  1474 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.862672  1475 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.862741  1476 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.862798  1477 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.862807  1479 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.862857  1478 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.863093  1478 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.863093  1477 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.863225  1477 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.863245  1477 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.863269  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44879cb8) got event_name: TaskCompletion
2253: I0810 04:00:00.863416  1474 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 10788832235836042612 to 13016180095601220208 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.863579  1477 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 1799088, peak : 1799088}.
2253: I0810 04:00:00.863653  1478 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1799208, peak : 1799208}.
2253: I0810 04:00:00.863770  1479 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.865478  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.865502  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.865554  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.865563  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.867415  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.867975  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.868429  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.868445  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.868450  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.870714  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.870795  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.870808  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.870815  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4485ab80 type is 7
2253: I0810 04:00:00.870823  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.870828  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x447d3710 type is 7
2253: I0810 04:00:00.870834  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.870838  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44841490 type is 7
2253: I0810 04:00:00.870843  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.870849  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.870920  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.870927  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.870931  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.870935  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.870975  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.870988  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.871038  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.871048  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.871085  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.871094  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.871110  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.871117  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44847e50Variable Type 7
2253: I0810 04:00:00.871131  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.871151  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.871165  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.871196  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.871204  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.871219  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.871227  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44848de0Variable Type 7
2253: I0810 04:00:00.871238  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.871253  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.871265  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.871512  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.871548  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.871570  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.871673  1480 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.871748  1481 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.871767  1482 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.871814  1483 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.871838  1484 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.871877  1485 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.872087  1483 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.872097  1484 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.872192  1483 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.872210  1483 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.872233  1268 program_interpreter.cc:1308] main_thread_blocker_(0x447d3248) got event_name: TaskCompletion
2253: I0810 04:00:00.872373  1480 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.872527  1483 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 1801008, peak : 1801008}.
2253: I0810 04:00:00.872603  1484 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 1801128, peak : 1801128}.
2253: I0810 04:00:00.872717  1485 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.872898  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.874167  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.874191  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.874240  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.874249  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.876124  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.876691  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.877142  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.877156  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.877161  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.879428  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.879508  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.879519  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.879524  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44920290 type is 7
2253: I0810 04:00:00.879534  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.879539  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4485cb20 type is 7
2253: I0810 04:00:00.879544  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.879550  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4485d610 type is 7
2253: I0810 04:00:00.879555  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.879561  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.879630  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.879637  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.879642  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.879647  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.879685  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.879698  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.879745  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.879755  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.879792  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.879801  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.879817  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.879824  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19534e50Variable Type 7
2253: I0810 04:00:00.879838  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.879858  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.879873  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.879902  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.879911  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.879927  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.879935  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4484f7d0Variable Type 7
2253: I0810 04:00:00.879945  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.879961  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.879973  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.880208  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.880241  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.880262  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.880380  1486 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.880458  1487 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.880530  1488 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.880546  1490 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.880589  1491 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.880793  1490 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.880805  1488 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.880923  1488 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.880940  1488 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.880964  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4485c598) got event_name: TaskCompletion
2253: I0810 04:00:00.881095  1486 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 4431466935759173892 to 13016180095601220208 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.881337  1489 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.881462  1490 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 4982686142408154 to 4976018710619039040 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:00:00.881546  1488 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 1803048, peak : 1803048}.
2253: I0810 04:00:00.881675  1491 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.882804  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.882962  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.883004  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.883381  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.883414  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.885247  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.885416  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.885459  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:00:00.888403  1268 pir_interpreter.cc:161] PirInterpreter(): 0x448671d0 on Place(gpu:0)
2253: I0810 04:00:00.888435  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.888456  1268 scope.cc:202] Create variable 0x448671d01723262400888427684_inner_var_1
2253: I0810 04:00:00.888468  1268 scope.cc:202] Create variable 0x448671d01723262400888427684_inner_var_2
2253: I0810 04:00:00.888478  1268 scope.cc:202] Create variable 0x448671d01723262400888427684_inner_var_3
2253: I0810 04:00:00.888489  1268 scope.cc:202] Create variable 0x448671d01723262400888427684_inner_var_4
2253: I0810 04:00:00.888501  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.888512  1268 scope.cc:202] Create variable 0x448671d01723262400888427684_inner_var_6
2253: I0810 04:00:00.888522  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.888839  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.888854  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.888857  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x449e08f0
2253: 1 -> 0x448671d01723262400888427684_inner_var_1 -> 0x449e0910
2253: 2 -> 0x448671d01723262400888427684_inner_var_2 -> 0x19532850
2253: 3 -> 0x448671d01723262400888427684_inner_var_3 -> 0x448f8a60
2253: 4 -> 0x448671d01723262400888427684_inner_var_4 -> 0x195f6ff0
2253: 5 -> fetch0@fetch -> 0x44867dd0
2253: 6 -> 0x448671d01723262400888427684_inner_var_6 -> 0x195f7010
2253: 7 -> fetch1@fetch -> 0x4484d700
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.889611  1493 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.889632  1494 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.889674  1495 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.889698  1496 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.889750  1497 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.889781  1497 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.889811  1497 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.889835  1497 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448671d01723262400888427684_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_3:[dtype=;place=;dim=;lod={};, 0x448671d01723262400888427684_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.889938  1497 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448671d01723262400888427684_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x448671d01723262400888427684_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.889988  1496 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448671d01723262400888427684_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.889995  1495 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448671d01723262400888427684_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.890017  1496 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.890041  1495 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.890098  1496 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448671d01723262400888427684_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.890134  1495 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448671d01723262400888427684_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448671d01723262400888427684_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.890143  1496 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448671d01723262400888427684_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.890161  1496 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.890165  1495 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448671d01723262400888427684_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.890172  1496 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448671d01723262400888427684_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.890187  1495 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.890202  1495 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448671d01723262400888427684_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.890231  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x44867340) got event_name: TaskCompletion
2253: I0810 04:00:00.890255  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.890282  1268 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.890331  1492 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.891590  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.891752  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.891795  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:00:00.894564  1268 pir_interpreter.cc:161] PirInterpreter(): 0x448fc430 on Place(gpu:0)
2253: I0810 04:00:00.894593  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.894613  1268 scope.cc:202] Create variable 0x448fc4301723262400894587631_inner_var_1
2253: I0810 04:00:00.894624  1268 scope.cc:202] Create variable 0x448fc4301723262400894587631_inner_var_2
2253: I0810 04:00:00.894635  1268 scope.cc:202] Create variable 0x448fc4301723262400894587631_inner_var_3
2253: I0810 04:00:00.894647  1268 scope.cc:202] Create variable 0x448fc4301723262400894587631_inner_var_4
2253: I0810 04:00:00.894658  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.894670  1268 scope.cc:202] Create variable 0x448fc4301723262400894587631_inner_var_6
2253: I0810 04:00:00.894680  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.894986  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.895001  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.895005  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x448fdfa0
2253: 1 -> 0x448fc4301723262400894587631_inner_var_1 -> 0x4478f400
2253: 2 -> 0x448fc4301723262400894587631_inner_var_2 -> 0x449df310
2253: 3 -> 0x448fc4301723262400894587631_inner_var_3 -> 0x448f9480
2253: 4 -> 0x448fc4301723262400894587631_inner_var_4 -> 0x19553390
2253: 5 -> fetch0@fetch -> 0x448fce90
2253: 6 -> 0x448fc4301723262400894587631_inner_var_6 -> 0x448fca80
2253: 7 -> fetch1@fetch -> 0x4485f750
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.895781  1499 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.895820  1500 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.895843  1501 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.895874  1502 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.895912  1503 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.895929  1503 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.895948  1503 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.895968  1503 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448fc4301723262400894587631_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_3:[dtype=;place=;dim=;lod={};, 0x448fc4301723262400894587631_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.896061  1503 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x448fc4301723262400894587631_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x448fc4301723262400894587631_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.896102  1502 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448fc4301723262400894587631_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.896121  1502 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.896124  1501 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448fc4301723262400894587631_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.896164  1501 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.896175  1502 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448fc4301723262400894587631_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.896195  1502 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448fc4301723262400894587631_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.896212  1502 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.896224  1502 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448fc4301723262400894587631_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.896236  1501 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x448fc4301723262400894587631_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x448fc4301723262400894587631_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.896263  1501 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x448fc4301723262400894587631_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.896281  1501 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.896294  1501 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x448fc4301723262400894587631_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.896328  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x448fc5a0) got event_name: TaskCompletion
2253: I0810 04:00:00.896332  1498 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.896354  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.896378  1268 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.896521  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:123
2253: I0810 04:00:00.896601  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.896618  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:124
2253: I0810 04:00:00.896636  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.897743  1492 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 13016180095601220208 to 7993959110900736729 , after update, data is {current : 1680, peak : 3600}.
2253: I0810 04:00:00.897755  1492 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 13016180095601220208 to 6015713031042148541 , after update, data is {current : -3840, peak : 0}.
2253: I0810 04:00:00.898069  1496 thread_data_registry.h:135] Add data {current : 240, peak : 240} from thread 753228128760470270 to 7993959110900736729 , after update, data is {current : 1920, peak : 3600}.
2253: I0810 04:00:00.898145  1495 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 4976018710619039040 to 7993959110900736729 , after update, data is {current : 5520, peak : 5520}.
2253: I0810 04:00:00.898277  1497 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 4431466935759173892 to 6015713031042148541 , after update, data is {current : -1920, peak : 1920}.
2253: I0810 04:00:00.898438  1498 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 6015713031042148541 to 7993959110900736729 , after update, data is {current : 3600, peak : 5520}.
2253: I0810 04:00:00.898448  1498 thread_data_registry.h:135] Add data {current : -1920, peak : 1920} from thread 6015713031042148541 to 10788832235836042612 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.898623  1502 thread_data_registry.h:135] Add data {current : 240, peak : 240} from thread 11386166155001416730 to 7993959110900736729 , after update, data is {current : 3840, peak : 5520}.
2253: I0810 04:00:00.898700  1501 thread_data_registry.h:135] Add data {current : 3840, peak : 5520} from thread 7993959110900736729 to 3894914143258603765 , after update, data is {current : 1806888, peak : 1806888}.
2253: I0810 04:00:00.898818  1503 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 10788832235836042612 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.899374  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.899396  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.899449  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.899458  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.901285  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.901858  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.902329  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.902345  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.902349  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.904665  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.904749  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.904762  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.904767  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448fb9b0 type is 7
2253: I0810 04:00:00.904776  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.904780  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x447a3fc0 type is 7
2253: I0810 04:00:00.904786  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.904793  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x448c8700 type is 7
2253: I0810 04:00:00.904798  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.904803  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.904875  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.904882  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.904887  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.904891  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.904932  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.904944  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.904992  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.905001  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.905040  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.905047  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.905064  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.905071  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x1960d660Variable Type 7
2253: I0810 04:00:00.905086  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.905105  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.905119  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.905150  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.905158  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.905174  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.905180  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19532870Variable Type 7
2253: I0810 04:00:00.905191  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.905207  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.905220  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.905464  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.905500  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.905521  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.905632  1504 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.905691  1505 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.905721  1506 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.905764  1507 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.905787  1508 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.905831  1509 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.906062  1508 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.906066  1507 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.906180  1507 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.906198  1507 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.906222  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448bf348) got event_name: TaskCompletion
2253: I0810 04:00:00.906356  1504 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 10788832235836042612 to 13016180095601220208 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.906510  1507 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 1808688, peak : 1808688}.
2253: I0810 04:00:00.906584  1508 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1808808, peak : 1808808}.
2253: I0810 04:00:00.906687  1509 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.906875  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.907405  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.907439  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.907452  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.907578  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:00.908555  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.908578  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.908628  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.908638  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.909366  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.909387  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.909428  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.909437  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.909770  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.909834  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.910202  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:00.910308  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:00.910319  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.910399  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.910409  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.912866  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.913496  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.913512  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.913517  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.916904  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.916925  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:00.916955  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.916965  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.916971  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x449fd190 type is 7
2253: I0810 04:00:00.916990  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:00.916994  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44a1c9d0 type is 7
2253: I0810 04:00:00.917001  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.917012  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a1c320 type is 7
2253: I0810 04:00:00.917018  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.917022  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x449fd960 type is 7
2253: I0810 04:00:00.917027  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:00.917032  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x449fdbd0 type is 7
2253: I0810 04:00:00.917037  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:00.917044  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x449fde10 type is 7
2253: I0810 04:00:00.917050  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:00.917054  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x449fe070 type is 7
2253: I0810 04:00:00.917059  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x449fd170 type is 9
2253: I0810 04:00:00.917065  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:00.917073  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x449fddf0 type is 10
2253: I0810 04:00:00.917171  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.917178  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.917182  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.917187  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.917235  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917248  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917296  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917316  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917356  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917366  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917402  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917412  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917441  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917450  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917487  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917496  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917527  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.917536  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.917551  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.917558  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44a3a720Variable Type 7
2253: I0810 04:00:00.917573  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.917593  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.917608  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.917891  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.917923  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.917953  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.918061  1510 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.918144  1511 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.918157  1512 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.918210  1513 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.918223  1514 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.918268  1515 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.918619  1515 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.918650  1515 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.918716  1515 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.918758  1515 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.918852  1514 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.918936  1514 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.918963  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44a1d1b8) got event_name: TaskCompletion
2253: I0810 04:00:00.919126  1510 thread_data_registry.h:135] Add data {current : -5528, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 5528}.
2253: I0810 04:00:00.919281  1514 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 1810608, peak : 1810608}.
2253: I0810 04:00:00.919473  1515 thread_data_registry.h:135] Add data {current : 0, peak : 5528} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.920446  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.920611  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.920653  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.921227  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.921264  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.921382  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x449e4c90)  to GradNodeAccumulation (addr: 0x4481c510)
2253: I0810 04:00:00.921470  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:00.921490  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.921618  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x449e4c90)
2253: I0810 04:00:00.921694  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:00.921701  1268 backward.cc:113] Start Backward
2253: I0810 04:00:00.921710  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:00.921743  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.921775  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:00.921784  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:00.921809  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.921854  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.921875  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.921885  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x449e4c90
2253: I0810 04:00:00.921890  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.921916  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x449e4c90
2253: I0810 04:00:00.921922  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.921936  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.921963  1268 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.921995  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.922001  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x449e4c90, Found pending node: GradNodeAccumulation addr: 0x4481c510
2253: I0810 04:00:00.922008  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.922029  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4481c510
2253: I0810 04:00:00.922035  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.922040  1268 accumulation_node.cc:40] Move Tensor ptr: 0x44859f70
2253: I0810 04:00:00.922044  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.922047  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.924348  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.924367  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.924409  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.924417  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.925879  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.926342  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.926697  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.926709  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.926713  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.928519  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.928587  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.928597  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.928601  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44a37e40 type is 7
2253: I0810 04:00:00.928608  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.928617  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a34820 type is 7
2253: I0810 04:00:00.928622  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.928625  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a352e0 type is 7
2253: I0810 04:00:00.928629  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.928634  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.928689  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.928694  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.928697  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.928701  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.928733  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.928745  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.928782  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.928790  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.928820  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.928828  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.928840  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.928846  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44a388f0Variable Type 7
2253: I0810 04:00:00.928857  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.928874  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.928885  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.928911  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.928920  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.928931  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.928937  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x449038f0Variable Type 7
2253: I0810 04:00:00.928946  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.928959  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.928969  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.929157  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.929185  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.929203  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.929292  1516 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.929369  1517 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.929385  1518 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.929425  1519 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.929454  1520 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.929489  1521 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.929657  1519 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.929661  1520 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.929766  1520 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.929783  1520 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.929806  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44a342b8) got event_name: TaskCompletion
2253: I0810 04:00:00.929929  1516 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 4431466935759173892 to 13016180095601220208 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.930076  1520 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4982686142408154 to 3894914143258603765 , after update, data is {current : 1812408, peak : 1812408}.
2253: I0810 04:00:00.930152  1519 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 9470489340628506630 to 3894914143258603765 , after update, data is {current : 1812528, peak : 1812528}.
2253: I0810 04:00:00.930267  1521 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 13016180095601220208 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.931807  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.931830  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.931880  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.931891  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.933706  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.934255  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.934688  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.934705  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.934710  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.936895  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.936975  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.936986  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.936992  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x449515b0 type is 7
2253: I0810 04:00:00.937003  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.937007  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4494e140 type is 7
2253: I0810 04:00:00.937013  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.937019  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4494ebc0 type is 7
2253: I0810 04:00:00.937026  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.937031  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.937098  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.937105  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.937109  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.937114  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.937153  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.937166  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.937214  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.937224  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.937261  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.937270  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.937286  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.937294  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44928b00Variable Type 7
2253: I0810 04:00:00.937321  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.937343  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.937357  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.937388  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.937397  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.937414  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.937422  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44954920Variable Type 7
2253: I0810 04:00:00.937433  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.937449  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.937462  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.937701  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.937737  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.937760  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.937861  1522 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.937947  1523 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.937978  1524 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.938010  1525 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.938053  1526 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.938091  1527 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.938288  1525 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.938295  1526 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.938405  1525 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.938421  1525 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.938443  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4494dbf8) got event_name: TaskCompletion
2253: I0810 04:00:00.938575  1522 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 13016180095601220208 to 4431466935759173892 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.938733  1525 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4976018710619039040 to 3894914143258603765 , after update, data is {current : 1814328, peak : 1814328}.
2253: I0810 04:00:00.938810  1526 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 753228128760470270 to 3894914143258603765 , after update, data is {current : 1814448, peak : 1814448}.
2253: I0810 04:00:00.938927  1527 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 4431466935759173892 to 3894914143258603765 , after update, data is {current : -196620, peak : 589844}.
2253: I0810 04:00:00.939108  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.941314  1330 thread_data_registry.h:135] Add data {current : 1814448, peak : 1814448} from thread 3894914143258603765 to 7266018504506563179 , after update, data is {current : 2207664, peak : 2207664}.
2253: I0810 04:00:00.941329  1330 thread_data_registry.h:135] Add data {current : -196620, peak : 589844} from thread 3894914143258603765 to 17189945363590869653 , after update, data is {current : 0, peak : 589844}.
2253: I0810 04:00:00.941496  1333 thread_data_registry.h:135] Add data {current : 2207664, peak : 2207664} from thread 7266018504506563179 to 4387486040692420614 , after update, data is {current : 2207688, peak : 2207688}.
2253: I0810 04:00:00.941566  1334 thread_data_registry.h:135] Add data {current : 2207688, peak : 2207688} from thread 4387486040692420614 to 3258848792123612270 , after update, data is {current : 517400, peak : 2207688}.
2253: I0810 04:00:00.941694  1335 thread_data_registry.h:135] Add data {current : 0, peak : 589844} from thread 17189945363590869653 to 3258848792123612270 , after update, data is {current : 1821864, peak : 2555920}.
2253: I0810 04:00:00.944736  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.944757  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.944803  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.944811  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.946390  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.946853  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.947269  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.947283  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.947286  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.949245  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.949326  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.949337  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.949342  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4482c8d0 type is 7
2253: I0810 04:00:00.949349  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.949354  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x19610490 type is 7
2253: I0810 04:00:00.949359  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.949362  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44790fc0 type is 7
2253: I0810 04:00:00.949366  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.949371  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.949436  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.949442  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.949446  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.949450  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.949484  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.949496  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.949537  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.949545  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.949577  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.949585  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.949599  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.949604  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448f7920Variable Type 7
2253: I0810 04:00:00.949617  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.949633  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.949645  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.949672  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.949680  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.949693  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.949699  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447bb4f0Variable Type 7
2253: I0810 04:00:00.949709  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.949721  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.949733  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.949939  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.949972  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.949990  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.950090  1528 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.950160  1529 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.950191  1530 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.950222  1531 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.950249  1532 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.950290  1533 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.950481  1531 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.950481  1532 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.950592  1532 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.950613  1532 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.950634  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44a488d8) got event_name: TaskCompletion
2253: I0810 04:00:00.950752  1528 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 17189945363590869653 to 3894914143258603765 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.950903  1532 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4825685957987445629 to 15215870038455397554 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:00:00.950975  1531 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 15215870038455397554 to 3258848792123612270 , after update, data is {current : 519320, peak : 2207688}.
2253: I0810 04:00:00.951100  1533 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 3894914143258603765 to 3258848792123612270 , after update, data is {current : 1821864, peak : 2555920}.
2253: I0810 04:00:00.952217  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.952394  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.952436  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.952801  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.952833  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.954681  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.954828  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.954869  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:00:00.957682  1268 pir_interpreter.cc:161] PirInterpreter(): 0x4490d7f0 on Place(gpu:0)
2253: I0810 04:00:00.957713  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.957732  1268 scope.cc:202] Create variable 0x4490d7f01723262400957706348_inner_var_1
2253: I0810 04:00:00.957743  1268 scope.cc:202] Create variable 0x4490d7f01723262400957706348_inner_var_2
2253: I0810 04:00:00.957754  1268 scope.cc:202] Create variable 0x4490d7f01723262400957706348_inner_var_3
2253: I0810 04:00:00.957765  1268 scope.cc:202] Create variable 0x4490d7f01723262400957706348_inner_var_4
2253: I0810 04:00:00.957777  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.957789  1268 scope.cc:202] Create variable 0x4490d7f01723262400957706348_inner_var_6
2253: I0810 04:00:00.957799  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.958113  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.958128  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.958132  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x445f9bd0
2253: 1 -> 0x4490d7f01723262400957706348_inner_var_1 -> 0x4479f390
2253: 2 -> 0x4490d7f01723262400957706348_inner_var_2 -> 0x25b9fa0
2253: 3 -> 0x4490d7f01723262400957706348_inner_var_3 -> 0x446ebee0
2253: 4 -> 0x4490d7f01723262400957706348_inner_var_4 -> 0x4482e420
2253: 5 -> fetch0@fetch -> 0x4466a560
2253: 6 -> 0x4490d7f01723262400957706348_inner_var_6 -> 0x447953c0
2253: 7 -> fetch1@fetch -> 0x4479d5a0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.958825  1534 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.958899  1535 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.958931  1536 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.958971  1537 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.959000  1538 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.959048  1539 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.959071  1539 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.959115  1539 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.959151  1539 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4490d7f01723262400957706348_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4490d7f01723262400957706348_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.959273  1539 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4490d7f01723262400957706348_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x4490d7f01723262400957706348_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.959348  1538 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4490d7f01723262400957706348_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.959352  1537 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4490d7f01723262400957706348_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.959389  1538 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.959393  1537 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.959455  1538 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4490d7f01723262400957706348_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.959492  1537 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4490d7f01723262400957706348_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4490d7f01723262400957706348_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.959503  1538 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4490d7f01723262400957706348_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.959523  1538 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.959519  1537 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4490d7f01723262400957706348_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.959537  1537 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.959537  1538 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4490d7f01723262400957706348_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.959550  1537 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4490d7f01723262400957706348_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.959581  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x4490d960) got event_name: TaskCompletion
2253: I0810 04:00:00.959607  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.959635  1268 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.960932  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.961090  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.961133  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<30xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30xf32>) -> builtin.tensor<30xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: I0810 04:00:00.963886  1268 pir_interpreter.cc:161] PirInterpreter(): 0x44a085d0 on Place(gpu:0)
2253: I0810 04:00:00.963917  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.963935  1268 scope.cc:202] Create variable 0x44a085d01723262400963910158_inner_var_1
2253: I0810 04:00:00.963946  1268 scope.cc:202] Create variable 0x44a085d01723262400963910158_inner_var_2
2253: I0810 04:00:00.963958  1268 scope.cc:202] Create variable 0x44a085d01723262400963910158_inner_var_3
2253: I0810 04:00:00.963969  1268 scope.cc:202] Create variable 0x44a085d01723262400963910158_inner_var_4
2253: I0810 04:00:00.963980  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:00.963992  1268 scope.cc:202] Create variable 0x44a085d01723262400963910158_inner_var_6
2253: I0810 04:00:00.964001  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:00.964311  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:00.964326  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.964330  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)0,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<30xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30xf32>) -> cpu_tensor<30xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x445f1880
2253: 1 -> 0x44a085d01723262400963910158_inner_var_1 -> 0x44153d90
2253: 2 -> 0x44a085d01723262400963910158_inner_var_2 -> 0x449d2440
2253: 3 -> 0x44a085d01723262400963910158_inner_var_3 -> 0x448bec40
2253: 4 -> 0x44a085d01723262400963910158_inner_var_4 -> 0x445f5f60
2253: 5 -> fetch0@fetch -> 0x44a3fcb0
2253: 6 -> 0x44a085d01723262400963910158_inner_var_6 -> 0x44a3fc70
2253: 7 -> fetch1@fetch -> 0x44a39290
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:00.964999  1540 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.965093  1541 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.965126  1542 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.965155  1543 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.965230  1545 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.965253  1545 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.965286  1545 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.965332  1545 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44a085d01723262400963910158_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44a085d01723262400963910158_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.965448  1545 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x44a085d01723262400963910158_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};, 0x44a085d01723262400963910158_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.965503  1543 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a085d01723262400963910158_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.965533  1543 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.965510  1542 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a085d01723262400963910158_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.965552  1542 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.965605  1543 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a085d01723262400963910158_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.965651  1542 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44a085d01723262400963910158_inner_var_3:[dtype=float;place=Place(gpu:0);dim=30;lod={};]}, outputs:{0x44a085d01723262400963910158_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.965664  1543 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44a085d01723262400963910158_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.965682  1543 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.965682  1542 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44a085d01723262400963910158_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:00.965692  1543 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44a085d01723262400963910158_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:00.965703  1542 tensor_utils.cc:57] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.965718  1542 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44a085d01723262400963910158_inner_var_6:[dtype=float;place=Place(cpu);dim=30;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=30;lod={};]}.
2253: I0810 04:00:00.965749  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x44a08740) got event_name: TaskCompletion
2253: I0810 04:00:00.965771  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.965797  1268 tensor_util.cc:48] TensorCopy 30 from Place(cpu) to Place(cpu)
2253: I0810 04:00:00.965940  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:149
2253: I0810 04:00:00.966017  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.966020  1544 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.966032  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:150
2253: I0810 04:00:00.966051  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:00.966980  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.967002  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.967053  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.967063  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.968901  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.969456  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.969913  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.969928  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.969933  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.972208  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.972290  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.972311  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.972319  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448cfd60 type is 7
2253: I0810 04:00:00.972327  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.972333  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448f36e0 type is 7
2253: I0810 04:00:00.972339  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.972342  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x448d9780 type is 7
2253: I0810 04:00:00.972348  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.972354  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.972431  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.972440  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.972443  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.972448  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.972489  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.972503  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.972555  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.972566  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.972605  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.972615  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.972631  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.972638  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447c4880Variable Type 7
2253: I0810 04:00:00.972652  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.972672  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.972687  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.972719  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.972728  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.972744  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.972751  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447c4710Variable Type 7
2253: I0810 04:00:00.972764  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.972779  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.972791  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.973078  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.973115  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.973137  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.973271  1546 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.973366  1547 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.973398  1548 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.973438  1549 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.973471  1550 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.973521  1551 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.973740  1549 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.973739  1550 tensor_utils.cc:57] TensorCopy 30 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.973881  1549 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.973906  1549 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:00.973932  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448290c8) got event_name: TaskCompletion
2253: I0810 04:00:00.974061  1546 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 6015713031042148541 to 10788832235836042612 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.974222  1549 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 7993959110900736729 to 11386166155001416730 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:00:00.974292  1550 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 11386166155001416730 to 13016180095601220208 , after update, data is {current : 2160, peak : 2160}.
2253: I0810 04:00:00.974414  1551 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 10788832235836042612 to 4431466935759173892 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:00:00.974620  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.975143  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.975176  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.975190  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.975320  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:00.976280  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.976317  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.976368  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.976378  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.977092  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.977113  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.977152  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:00.977160  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.977492  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.977558  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:00.977922  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:00.978019  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:00.978030  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.978108  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.978118  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.979970  1534 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 3894914143258603765 to 13016180095601220208 , after update, data is {current : 240, peak : 2160}.
2253: I0810 04:00:00.979990  1534 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 3894914143258603765 to 4431466935759173892 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.980252  1537 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 7266018504506563179 to 13016180095601220208 , after update, data is {current : 3840, peak : 3840}.
2253: I0810 04:00:00.980329  1538 thread_data_registry.h:135] Add data {current : 240, peak : 240} from thread 4387486040692420614 to 13016180095601220208 , after update, data is {current : 4080, peak : 4080}.
2253: I0810 04:00:00.980460  1539 thread_data_registry.h:135] Add data {current : 1920, peak : 1920} from thread 17189945363590869653 to 4431466935759173892 , after update, data is {current : 1920, peak : 1920}.
2253: I0810 04:00:00.980649  1540 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 9470489340628506630 to 13016180095601220208 , after update, data is {current : 2160, peak : 4080}.
2253: I0810 04:00:00.980669  1540 thread_data_registry.h:135] Add data {current : -1920, peak : 0} from thread 9470489340628506630 to 4431466935759173892 , after update, data is {current : 0, peak : 1920}.
2253: I0810 04:00:00.980841  1543 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 4976018710619039040 to 13016180095601220208 , after update, data is {current : 5760, peak : 5760}.
2253: I0810 04:00:00.980881  1542 thread_data_registry.h:135] Add data {current : 5760, peak : 5760} from thread 13016180095601220208 to 3258848792123612270 , after update, data is {current : 521240, peak : 2207688}.
2253: I0810 04:00:00.981024  1545 thread_data_registry.h:135] Add data {current : 0, peak : 1920} from thread 4431466935759173892 to 3258848792123612270 , after update, data is {current : 1829064, peak : 2555920}.
2253: I0810 04:00:00.982563  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.983266  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.983284  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.983289  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.986825  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.986847  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:00.986879  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.986891  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.986896  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44164120 type is 7
2253: I0810 04:00:00.986907  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:00.986910  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x447aaf50 type is 7
2253: I0810 04:00:00.986917  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.986923  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4414f2e0 type is 7
2253: I0810 04:00:00.986928  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.986933  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44861340 type is 7
2253: I0810 04:00:00.986939  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:00.986943  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x447c9190 type is 7
2253: I0810 04:00:00.986949  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:00.986956  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x447dc0d0 type is 7
2253: I0810 04:00:00.986963  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:00.986965  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x448a39b0 type is 7
2253: I0810 04:00:00.986971  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x448a8a80 type is 9
2253: I0810 04:00:00.986977  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:00.986984  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x447d1950 type is 10
2253: I0810 04:00:00.987088  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.987097  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.987102  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.987105  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.987155  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987169  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987218  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987228  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987267  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987277  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987340  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987351  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987382  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987392  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987430  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987440  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987470  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.987479  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.987496  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.987504  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445ff6d0Variable Type 7
2253: I0810 04:00:00.987519  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.987540  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.987553  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.987890  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.987923  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:00.987953  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:00.988072  1552 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:00.988149  1553 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:00.988174  1554 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:00.988214  1555 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:00.988240  1556 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:00.988281  1557 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:00.988698  1557 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.988732  1557 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:00.988811  1557 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:00.988860  1557 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.988955  1556 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:00.989032  1556 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:00.989056  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448b3fd8) got event_name: TaskCompletion
2253: I0810 04:00:00.989204  1552 thread_data_registry.h:135] Add data {current : -5528, peak : 0} from thread 4431466935759173892 to 7266018504506563179 , after update, data is {current : 0, peak : 5528}.
2253: I0810 04:00:00.989367  1556 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4825685957987445629 to 3258848792123612270 , after update, data is {current : 521240, peak : 2207688}.
2253: I0810 04:00:00.989545  1557 thread_data_registry.h:135] Add data {current : 0, peak : 5528} from thread 7266018504506563179 to 3258848792123612270 , after update, data is {current : 1829064, peak : 2555920}.
2253: I0810 04:00:00.990517  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:00.990685  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:00.990725  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:00.991297  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.991343  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.991456  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x449e4c90)  to GradNodeAccumulation (addr: 0x4481c510)
2253: I0810 04:00:00.991544  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:00.991564  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.991681  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x449e4c90)
2253: I0810 04:00:00.991755  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:00.991763  1268 backward.cc:113] Start Backward
2253: I0810 04:00:00.991771  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:00.991804  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.991832  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:00.991842  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:00.991866  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.991914  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:00.991935  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.991945  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x449e4c90
2253: I0810 04:00:00.991950  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.991978  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x449e4c90
2253: I0810 04:00:00.991986  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:00.992000  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:00.992030  1268 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:00.992062  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.992069  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x449e4c90, Found pending node: GradNodeAccumulation addr: 0x4481c510
2253: I0810 04:00:00.992075  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:00.992096  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4481c510
2253: I0810 04:00:00.992105  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.992110  1268 accumulation_node.cc:40] Move Tensor ptr: 0x447b85f0
2253: I0810 04:00:00.992113  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:00.992118  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:00.993849  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.993873  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.993924  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:00.993933  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.995767  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.996335  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:00.996805  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.996820  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.996825  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.999140  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:00.999219  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:00.999231  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:00.999238  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44160100 type is 7
2253: I0810 04:00:00.999248  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:00.999251  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448be610 type is 7
2253: I0810 04:00:00.999257  1268 scope.cc:202] Create variable X
2253: I0810 04:00:00.999264  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4417bbc0 type is 7
2253: I0810 04:00:00.999269  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:00.999274  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:00.999361  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:00.999367  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:00.999372  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:00.999377  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:00.999418  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.999430  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.999480  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.999488  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.999526  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.999534  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.999550  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.999558  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19536d20Variable Type 7
2253: I0810 04:00:00.999572  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.999591  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.999605  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.999637  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.999645  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:00.999661  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:00.999668  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x449d1ab0Variable Type 7
2253: I0810 04:00:00.999680  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:00.999696  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:00.999708  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:00.999951  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:00.999986  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.000008  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.000116  1558 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.000188  1559 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.000209  1560 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.000259  1561 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.000284  1562 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.000335  1563 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.000587  1562 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.000602  1561 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.000710  1561 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.000731  1561 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.000756  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4415fce8) got event_name: TaskCompletion
2253: I0810 04:00:01.000890  1558 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 7266018504506563179 to 3894914143258603765 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.001035  1561 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4387486040692420614 to 17189945363590869653 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.001111  1562 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 17189945363590869653 to 3258848792123612270 , after update, data is {current : 523100, peak : 2207688}.
2253: I0810 04:00:01.001219  1563 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 3894914143258603765 to 3258848792123612270 , after update, data is {current : 1829064, peak : 2555920}.
2253: I0810 04:00:01.002835  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.002859  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.002910  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.002919  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.004762  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.005322  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.005769  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.005784  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.005788  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.008064  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.008142  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.008154  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.008160  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x19608a30 type is 7
2253: I0810 04:00:01.008173  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.008177  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448fb420 type is 7
2253: I0810 04:00:01.008183  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.008193  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447a96a0 type is 7
2253: I0810 04:00:01.008198  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:01.008203  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:01.008278  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.008285  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.008289  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.008293  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.008349  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.008363  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.008412  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.008423  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.008460  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.008469  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.008486  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.008492  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4416a070Variable Type 7
2253: I0810 04:00:01.008507  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.008525  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.008539  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.008571  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.008579  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.008595  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.008602  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445f4910Variable Type 7
2253: I0810 04:00:01.008613  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.008630  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.008642  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.008883  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.008919  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.008940  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.009047  1564 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.009120  1565 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.009143  1566 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.009189  1567 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.009213  1568 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.009256  1569 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.009451  1568 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.009454  1567 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.009558  1567 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.009573  1567 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.009596  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448faed8) got event_name: TaskCompletion
2253: I0810 04:00:01.009723  1564 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 3894914143258603765 to 7266018504506563179 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.009869  1567 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 15215870038455397554 to 4825685957987445629 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.009943  1568 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 4825685957987445629 to 3258848792123612270 , after update, data is {current : 524960, peak : 2207688}.
2253: I0810 04:00:01.010053  1569 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 7266018504506563179 to 3258848792123612270 , after update, data is {current : 1829064, peak : 2555920}.
2253: I0810 04:00:01.010251  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.011497  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.011520  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.011570  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.011580  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.013404  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.013964  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.014442  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.014457  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.014462  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.016729  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.016813  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.016825  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.016834  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4488ee20 type is 7
2253: I0810 04:00:01.016844  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.016850  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44823870 type is 7
2253: I0810 04:00:01.016855  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.016860  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44824250 type is 7
2253: I0810 04:00:01.016865  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:01.016871  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:01.016948  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.016956  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.016960  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.016965  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.017005  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.017019  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.017067  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.017077  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.017115  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.017124  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.017140  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.017148  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448b5510Variable Type 7
2253: I0810 04:00:01.017163  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.017182  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.017197  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.017230  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.017237  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.017253  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.017261  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448649c0Variable Type 7
2253: I0810 04:00:01.017272  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.017289  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.017310  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.017552  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.017586  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.017608  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.017704  1570 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.017779  1571 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.017807  1572 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.017845  1573 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.017876  1574 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.017925  1575 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.018118  1574 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.018137  1573 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.018242  1573 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.018267  1573 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.018296  1268 program_interpreter.cc:1308] main_thread_blocker_(0x448234a8) got event_name: TaskCompletion
2253: I0810 04:00:01.018440  1570 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 7266018504506563179 to 3894914143258603765 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.018600  1573 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4387486040692420614 to 17189945363590869653 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.018638  1574 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 17189945363590869653 to 3258848792123612270 , after update, data is {current : 523100, peak : 2207688}.
2253: I0810 04:00:01.018779  1575 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 3894914143258603765 to 3258848792123612270 , after update, data is {current : 1829064, peak : 2555920}.
2253: I0810 04:00:01.019917  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:01.020089  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:01.020133  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.020529  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.020561  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.022485  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:01.022629  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.022670  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:00:01.026185  1268 pir_interpreter.cc:161] PirInterpreter(): 0x4488c910 on Place(gpu:0)
2253: I0810 04:00:01.026211  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.026226  1268 scope.cc:202] Create variable 0x4488c9101723262401026204928_inner_var_1
2253: I0810 04:00:01.026237  1268 scope.cc:202] Create variable 0x4488c9101723262401026204928_inner_var_2
2253: I0810 04:00:01.026242  1268 scope.cc:202] Create variable 0x4488c9101723262401026204928_inner_var_3
2253: I0810 04:00:01.026250  1268 scope.cc:202] Create variable 0x4488c9101723262401026204928_inner_var_4
2253: I0810 04:00:01.026257  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:01.026279  1268 scope.cc:202] Create variable 0x4488c9101723262401026204928_inner_var_6
2253: I0810 04:00:01.026288  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:01.026561  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:01.026575  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.026579  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x449d8390
2253: 1 -> 0x4488c9101723262401026204928_inner_var_1 -> 0x44188c40
2253: 2 -> 0x4488c9101723262401026204928_inner_var_2 -> 0x232c660
2253: 3 -> 0x4488c9101723262401026204928_inner_var_3 -> 0x447dbfd0
2253: 4 -> 0x4488c9101723262401026204928_inner_var_4 -> 0x44894610
2253: 5 -> fetch0@fetch -> 0x44721090
2253: 6 -> 0x4488c9101723262401026204928_inner_var_6 -> 0x449ec890
2253: 7 -> fetch1@fetch -> 0x446efa90
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:01.027141  1576 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.027204  1577 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.027228  1578 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.027249  1579 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.027283  1580 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.027318  1581 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.027340  1581 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.027382  1581 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.027413  1581 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4488c9101723262401026204928_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4488c9101723262401026204928_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.027534  1581 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x4488c9101723262401026204928_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x4488c9101723262401026204928_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.027588  1580 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4488c9101723262401026204928_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.027593  1579 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4488c9101723262401026204928_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.027626  1580 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.027631  1579 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.027695  1580 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4488c9101723262401026204928_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.027729  1580 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4488c9101723262401026204928_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.027727  1579 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4488c9101723262401026204928_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x4488c9101723262401026204928_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.027755  1580 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.027770  1580 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4488c9101723262401026204928_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.027770  1579 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4488c9101723262401026204928_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.027796  1579 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.027808  1579 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4488c9101723262401026204928_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.027844  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x4488ca80) got event_name: TaskCompletion
2253: I0810 04:00:01.027864  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.027887  1268 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.029110  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:01.029273  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.029322  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:00:01.032071  1268 pir_interpreter.cc:161] PirInterpreter(): 0x449e5230 on Place(gpu:0)
2253: I0810 04:00:01.032101  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.032119  1268 scope.cc:202] Create variable 0x449e52301723262401032094658_inner_var_1
2253: I0810 04:00:01.032130  1268 scope.cc:202] Create variable 0x449e52301723262401032094658_inner_var_2
2253: I0810 04:00:01.032138  1268 scope.cc:202] Create variable 0x449e52301723262401032094658_inner_var_3
2253: I0810 04:00:01.032146  1268 scope.cc:202] Create variable 0x449e52301723262401032094658_inner_var_4
2253: I0810 04:00:01.032156  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:01.032168  1268 scope.cc:202] Create variable 0x449e52301723262401032094658_inner_var_6
2253: I0810 04:00:01.032178  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:01.032493  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:01.032510  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.032514  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)0,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x4486b500
2253: 1 -> 0x449e52301723262401032094658_inner_var_1 -> 0x447ebad0
2253: 2 -> 0x449e52301723262401032094658_inner_var_2 -> 0x44903ae0
2253: 3 -> 0x449e52301723262401032094658_inner_var_3 -> 0x448aa030
2253: 4 -> 0x449e52301723262401032094658_inner_var_4 -> 0x4482f1f0
2253: 5 -> fetch0@fetch -> 0x1929b300
2253: 6 -> 0x449e52301723262401032094658_inner_var_6 -> 0x44894820
2253: 7 -> fetch1@fetch -> 0x448a3bc0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:01.033197  1582 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.033274  1583 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.033313  1584 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.033344  1585 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.033377  1586 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.033419  1587 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.033442  1587 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.033474  1587 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.033505  1587 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x449e52301723262401032094658_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_3:[dtype=;place=;dim=;lod={};, 0x449e52301723262401032094658_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.033622  1587 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x449e52301723262401032094658_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x449e52301723262401032094658_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.033671  1586 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449e52301723262401032094658_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.033694  1586 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.033680  1585 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449e52301723262401032094658_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.033712  1585 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.033744  1586 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449e52301723262401032094658_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.033779  1585 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449e52301723262401032094658_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449e52301723262401032094658_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.033790  1586 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x449e52301723262401032094658_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.033807  1586 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.033816  1586 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x449e52301723262401032094658_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.033847  1585 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x449e52301723262401032094658_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.033871  1585 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.033885  1585 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x449e52301723262401032094658_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.033921  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x449e53a0) got event_name: TaskCompletion
2253: I0810 04:00:01.033946  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.033972  1268 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.034112  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:175
2253: I0810 04:00:01.034188  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:01.034204  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:176
2253: I0810 04:00:01.034224  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:01.035152  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.035176  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.035225  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.035235  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.037070  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.037631  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.038089  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.038105  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.038110  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.040407  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.040488  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.040499  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.040505  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x447eb5f0 type is 7
2253: I0810 04:00:01.040521  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.040526  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a13c90 type is 7
2253: I0810 04:00:01.040531  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.040539  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x191d77f0 type is 7
2253: I0810 04:00:01.040544  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:01.040549  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:01.040621  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.040627  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.040630  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.040634  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.040675  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.040686  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.040735  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.040742  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.040779  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.040786  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.040802  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.040807  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447dad70Variable Type 7
2253: I0810 04:00:01.040822  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.040843  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.040856  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.040889  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.040897  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.040912  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.040920  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44860800Variable Type 7
2253: I0810 04:00:01.040931  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.040946  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.040959  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.041211  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.041250  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.041272  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.041404  1588 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.041488  1589 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.041520  1590 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.041545  1591 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.041574  1592 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.041625  1593 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.041821  1592 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.041834  1591 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.041934  1591 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.041950  1591 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.041972  1268 program_interpreter.cc:1308] main_thread_blocker_(0x19538278) got event_name: TaskCompletion
2253: I0810 04:00:01.042101  1588 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 6015713031042148541 to 10788832235836042612 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.042273  1591 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 7993959110900736729 to 11386166155001416730 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.042367  1592 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 11386166155001416730 to 3894914143258603765 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.042477  1593 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 10788832235836042612 to 4431466935759173892 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.042657  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.043182  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.043215  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.043228  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.043363  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:01.044344  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.044366  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.044417  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.044427  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.045138  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:01.045159  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:01.045197  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:01.045205  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:01.045537  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.045601  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.045958  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:01.046052  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:01.046062  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:01.046139  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:01.046149  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:01.048631  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.049263  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.049279  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.049284  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.052702  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.052723  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:01.052753  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.052763  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.052768  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x195507a0 type is 7
2253: I0810 04:00:01.052775  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:01.052781  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44a121e0 type is 7
2253: I0810 04:00:01.052786  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.052790  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44a11b30 type is 7
2253: I0810 04:00:01.052795  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.052799  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19550f70 type is 7
2253: I0810 04:00:01.052804  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:01.052809  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x195511e0 type is 7
2253: I0810 04:00:01.052814  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:01.052817  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x19551420 type is 7
2253: I0810 04:00:01.052825  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:01.052829  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x19551680 type is 7
2253: I0810 04:00:01.052834  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x19550780 type is 9
2253: I0810 04:00:01.052839  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:01.052845  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x19551400 type is 10
2253: I0810 04:00:01.052948  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.052955  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.052960  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.052964  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.053012  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053025  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053076  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053084  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053123  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053133  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053169  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053177  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053207  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053216  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053252  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053262  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053292  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.053310  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.053328  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.053335  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x449de010Variable Type 7
2253: I0810 04:00:01.053350  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.053370  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.053385  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.053694  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.053726  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:01.053759  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.053869  1594 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.053946  1595 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.053975  1596 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.054004  1597 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.054033  1598 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.054075  1599 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.054450  1599 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:01.054488  1599 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:01.054559  1599 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:01.054616  1599 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:01.054723  1598 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.054812  1598 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.054837  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44a06e08) got event_name: TaskCompletion
2253: I0810 04:00:01.054981  1594 thread_data_registry.h:135] Add data {current : -5468, peak : 0} from thread 10788832235836042612 to 9111191648461991135 , after update, data is {current : 0, peak : 5468}.
2253: I0810 04:00:01.055140  1598 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4215436099121689709 to 3894914143258603765 , after update, data is {current : 1800, peak : 1860}.
2253: I0810 04:00:01.055332  1599 thread_data_registry.h:135] Add data {current : 0, peak : 5468} from thread 9111191648461991135 to 4431466935759173892 , after update, data is {current : 1860, peak : 5468}.
2253: I0810 04:00:01.056241  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:01.056416  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.056459  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:01.057031  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.057067  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.057186  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44854080)  to GradNodeAccumulation (addr: 0x4481c510)
2253: I0810 04:00:01.057271  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:01.057291  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.057420  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x44854080)
2253: I0810 04:00:01.057495  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:01.057503  1268 backward.cc:113] Start Backward
2253: I0810 04:00:01.057511  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:01.057545  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:01.057570  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:01.057579  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:01.057605  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.057655  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:01.057677  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:01.057686  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x44854080
2253: I0810 04:00:01.057691  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:01.057718  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44854080
2253: I0810 04:00:01.057725  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:01.057739  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.057768  1268 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:01.057799  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:01.057806  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x44854080, Found pending node: GradNodeAccumulation addr: 0x4481c510
2253: I0810 04:00:01.057811  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:01.057833  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4481c510
2253: I0810 04:00:01.057840  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:01.057845  1268 accumulation_node.cc:40] Move Tensor ptr: 0x447b85f0
2253: I0810 04:00:01.057849  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:01.057854  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:01.060138  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.060158  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.060201  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.060209  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.061095  1576 thread_data_registry.h:135] Add data {current : 1800, peak : 1860} from thread 3894914143258603765 to 4976018710619039040 , after update, data is {current : 5400, peak : 5400}.
2253: I0810 04:00:01.061108  1576 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 3894914143258603765 to 4431466935759173892 , after update, data is {current : 0, peak : 5468}.
2253: I0810 04:00:01.061280  1579 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 15215870038455397554 to 4976018710619039040 , after update, data is {current : 5520, peak : 5520}.
2253: I0810 04:00:01.061362  1580 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 4825685957987445629 to 4976018710619039040 , after update, data is {current : 9120, peak : 9120}.
2253: I0810 04:00:01.061476  1581 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 7266018504506563179 to 4431466935759173892 , after update, data is {current : 1860, peak : 5468}.
2253: I0810 04:00:01.061653  1582 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 9470489340628506630 to 4976018710619039040 , after update, data is {current : 7260, peak : 9120}.
2253: I0810 04:00:01.061662  1582 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 9470489340628506630 to 4431466935759173892 , after update, data is {current : 0, peak : 5468}.
2253: I0810 04:00:01.061830  1585 thread_data_registry.h:135] Add data {current : 7260, peak : 9120} from thread 4976018710619039040 to 753228128760470270 , after update, data is {current : 7380, peak : 9120}.
2253: I0810 04:00:01.061870  1586 thread_data_registry.h:135] Add data {current : 7380, peak : 9120} from thread 753228128760470270 to 3258848792123612270 , after update, data is {current : 524960, peak : 2207688}.
2253: I0810 04:00:01.062021  1587 thread_data_registry.h:135] Add data {current : 0, peak : 5468} from thread 4431466935759173892 to 3258848792123612270 , after update, data is {current : 1838064, peak : 2555920}.
2253: I0810 04:00:01.063558  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.064023  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.064435  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.064448  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.064452  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.066378  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.066445  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.066454  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.066459  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x445f63e0 type is 7
2253: I0810 04:00:01.066466  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.066474  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x4487a6a0 type is 7
2253: I0810 04:00:01.066479  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.066483  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x19551980 type is 7
2253: I0810 04:00:01.066486  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:01.066491  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:01.066555  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.066560  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.066563  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.066567  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.066601  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.066612  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.066649  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.066658  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.066687  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.066695  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.066707  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.066715  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x512ed90Variable Type 7
2253: I0810 04:00:01.066725  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.066741  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.066753  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.066777  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.066784  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.066797  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.066803  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44868c20Variable Type 7
2253: I0810 04:00:01.066813  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.066825  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.066835  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.067025  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.067054  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.067070  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.067162  1600 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.067229  1601 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.067242  1602 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.067281  1603 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.067306  1604 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.067343  1605 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.067554  1604 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.067561  1603 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.067665  1603 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.067684  1603 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.067708  1268 program_interpreter.cc:1308] main_thread_blocker_(0x447db028) got event_name: TaskCompletion
2253: I0810 04:00:01.067831  1600 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 4431466935759173892 to 7266018504506563179 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.067974  1603 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 15215870038455397554 to 4825685957987445629 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.068045  1604 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 4825685957987445629 to 3258848792123612270 , after update, data is {current : 526820, peak : 2207688}.
2253: I0810 04:00:01.068148  1605 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 7266018504506563179 to 3258848792123612270 , after update, data is {current : 1836264, peak : 2555920}.
2253: I0810 04:00:01.069720  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.069744  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.069794  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.069803  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.071646  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.072203  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.072654  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.072670  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.072675  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.074937  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.075017  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.075030  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.075037  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44a157a0 type is 7
2253: I0810 04:00:01.075047  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.075052  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x44153730 type is 7
2253: I0810 04:00:01.075060  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.075064  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447d5140 type is 7
2253: I0810 04:00:01.075070  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:01.075076  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:01.075151  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.075158  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.075163  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.075168  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.075207  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.075220  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.075268  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.075278  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.075325  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.075335  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.075352  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.075359  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19538890Variable Type 7
2253: I0810 04:00:01.075374  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.075394  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.075408  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.075440  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.075448  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.075464  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.075472  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4481e600Variable Type 7
2253: I0810 04:00:01.075484  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.075498  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.075511  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.075748  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.075783  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.075805  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.075914  1606 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.075985  1607 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.076001  1608 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.076050  1609 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.076073  1610 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.076115  1611 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.076310  1610 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.076309  1609 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.076417  1609 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.076434  1609 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.076457  1268 program_interpreter.cc:1308] main_thread_blocker_(0x4478f958) got event_name: TaskCompletion
2253: I0810 04:00:01.076586  1606 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 7266018504506563179 to 3894914143258603765 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.076728  1609 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 4387486040692420614 to 17189945363590869653 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.076799  1610 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 17189945363590869653 to 3258848792123612270 , after update, data is {current : 528680, peak : 2207688}.
2253: I0810 04:00:01.076906  1611 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 3894914143258603765 to 3258848792123612270 , after update, data is {current : 1836264, peak : 2555920}.
2253: I0810 04:00:01.077095  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.078334  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.078356  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.078406  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.078416  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.080245  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.080818  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.081274  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.081290  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.081295  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.083582  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.083662  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.083674  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.083679  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x448fa090 type is 7
2253: I0810 04:00:01.083693  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.083696  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x195364f0 type is 7
2253: I0810 04:00:01.083701  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.083705  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447b1540 type is 7
2253: I0810 04:00:01.083710  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:01.083720  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:01.083793  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.083801  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.083804  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.083809  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.083849  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.083863  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.083909  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.083920  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.083956  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.083966  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.083981  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.083989  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19616910Variable Type 7
2253: I0810 04:00:01.084003  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.084023  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.084038  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.084069  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.084076  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.084092  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.084100  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x19558a60Variable Type 7
2253: I0810 04:00:01.084111  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.084126  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.084139  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.084386  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.084421  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.084442  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.084540  1612 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.084600  1613 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.084621  1614 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.084667  1615 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.084687  1616 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.084728  1617 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.084939  1616 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.084944  1615 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.085054  1615 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.085072  1615 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.085094  1268 program_interpreter.cc:1308] main_thread_blocker_(0x19535fa8) got event_name: TaskCompletion
2253: I0810 04:00:01.085219  1612 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 3894914143258603765 to 7266018504506563179 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.085372  1615 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 15215870038455397554 to 4825685957987445629 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.085445  1616 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 4825685957987445629 to 3258848792123612270 , after update, data is {current : 526820, peak : 2207688}.
2253: I0810 04:00:01.085556  1617 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 7266018504506563179 to 3258848792123612270 , after update, data is {current : 1836264, peak : 2555920}.
2253: I0810 04:00:01.090049  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:01.090226  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:01.090262  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.090559  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.090585  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.092335  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:01.092480  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.092521  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:00:01.095291  1268 pir_interpreter.cc:161] PirInterpreter(): 0x449296b0 on Place(gpu:0)
2253: I0810 04:00:01.095331  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.095350  1268 scope.cc:202] Create variable 0x449296b01723262401095324582_inner_var_1
2253: I0810 04:00:01.095362  1268 scope.cc:202] Create variable 0x449296b01723262401095324582_inner_var_2
2253: I0810 04:00:01.095373  1268 scope.cc:202] Create variable 0x449296b01723262401095324582_inner_var_3
2253: I0810 04:00:01.095386  1268 scope.cc:202] Create variable 0x449296b01723262401095324582_inner_var_4
2253: I0810 04:00:01.095397  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:01.095409  1268 scope.cc:202] Create variable 0x449296b01723262401095324582_inner_var_6
2253: I0810 04:00:01.095419  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:01.095724  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:01.095739  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.095743  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x448a71f0
2253: 1 -> 0x449296b01723262401095324582_inner_var_1 -> 0x448a7250
2253: 2 -> 0x449296b01723262401095324582_inner_var_2 -> 0x19534470
2253: 3 -> 0x449296b01723262401095324582_inner_var_3 -> 0x448fa8d0
2253: 4 -> 0x449296b01723262401095324582_inner_var_4 -> 0x19604590
2253: 5 -> fetch0@fetch -> 0x1955e7f0
2253: 6 -> 0x449296b01723262401095324582_inner_var_6 -> 0x196045b0
2253: 7 -> fetch1@fetch -> 0x448fbf40
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:01.096403  1618 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.096472  1619 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.096488  1620 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.096535  1621 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.096567  1622 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.096608  1623 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.096630  1623 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.096668  1623 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.096699  1623 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x449296b01723262401095324582_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_3:[dtype=;place=;dim=;lod={};, 0x449296b01723262401095324582_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.096843  1623 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x449296b01723262401095324582_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x449296b01723262401095324582_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.096892  1622 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449296b01723262401095324582_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.096905  1621 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449296b01723262401095324582_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.096925  1622 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.096943  1621 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.096995  1622 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449296b01723262401095324582_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.097033  1621 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x449296b01723262401095324582_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x449296b01723262401095324582_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.097038  1622 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x449296b01723262401095324582_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.097067  1622 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.097083  1622 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x449296b01723262401095324582_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.097083  1621 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x449296b01723262401095324582_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.097112  1621 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.097122  1621 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x449296b01723262401095324582_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.097152  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x44929820) got event_name: TaskCompletion
2253: I0810 04:00:01.097177  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.097203  1268 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.098477  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:01.098637  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.098680  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: IR before lowering = {
2253:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> builtin.tensor<30x15xf32>
2253:     (%1, %2) = "pd_op.fake_channel_wise_quantize_dequantize_abs_max" (%0) {bit_length:(Int32)8,quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>, builtin.tensor<15xf32>
2253:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<30x15xf32>) -> builtin.tensor<30x15xf32>
2253:     (%4) = "pd_op.fetch" (%2) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<15xf32>) -> builtin.tensor<15xf32>
2253: }
2253: 
2253: IR after lowering = {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: I0810 04:00:01.101420  1268 pir_interpreter.cc:161] PirInterpreter(): 0x19604c50 on Place(gpu:0)
2253: I0810 04:00:01.101450  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.101467  1268 scope.cc:202] Create variable 0x19604c501723262401101443719_inner_var_1
2253: I0810 04:00:01.101480  1268 scope.cc:202] Create variable 0x19604c501723262401101443719_inner_var_2
2253: I0810 04:00:01.101490  1268 scope.cc:202] Create variable 0x19604c501723262401101443719_inner_var_3
2253: I0810 04:00:01.101501  1268 scope.cc:202] Create variable 0x19604c501723262401101443719_inner_var_4
2253: I0810 04:00:01.101511  1268 scope.cc:202] Create variable fetch0@fetch
2253: I0810 04:00:01.101523  1268 scope.cc:202] Create variable 0x19604c501723262401101443719_inner_var_6
2253: I0810 04:00:01.101532  1268 scope.cc:202] Create variable fetch1@fetch
2253: I0810 04:00:01.101840  1268 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
2253: I0810 04:00:01.101855  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.101859  1268 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
2253: ======================== The network executed by pir interpreter ========================
2253: {
2253:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[30,15],stop_gradient:[true]} : () -> undefined_tensor<30x15xf32>
2253:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>
2253:     (%2, %3) = "fake_channel_wise_quantize_dequantize_abs_max(phi_kernel)" (%1) {bit_length:(Int32)8,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"fake_channel_wise_quantize_dequantize_abs_max",op_name:"pd_op.fake_channel_wise_quantize_dequantize_abs_max",quant_axis:(Int32)1,round_type:(Int32)1,stop_gradient:[true,true]} : (gpu_tensor<30x15xf32>) -> gpu_tensor<30x15xf32>, gpu_tensor<15xf32>
2253:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<30x15xf32>) -> cpu_tensor<30x15xf32>
2253:     (%6) = "memcpy_d2h(phi_kernel)" (%3) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253:     (%7) = "fetch(phi_kernel)" (%6) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<15xf32>) -> cpu_tensor<15xf32>
2253: }
2253: 
2253: ======================== The instruction executed by pir interpreter ========================
2253: {outputs} =  instruction_name[idx] ({inputs})
2253: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
2253: 1: ( 3 ) ( 2 )  = pd_op.fake_channel_wise_quantize_dequantize_abs_max ( 1 ) 
2253: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
2253: 3: ( 5 )  = pd_op.fetch ( 4 ) 
2253: 4: ( 6 )  = pd_op.memcpy_d2h ( 3 ) 
2253: 5: ( 7 )  = pd_op.fetch ( 6 ) 
2253: ---------------------------var_id -> var_name -> variable*---------------------------
2253: 0 -> X -> 0x44601e30
2253: 1 -> 0x19604c501723262401101443719_inner_var_1 -> 0x19604c30
2253: 2 -> 0x19604c501723262401101443719_inner_var_2 -> 0x1955dab0
2253: 3 -> 0x19604c501723262401101443719_inner_var_3 -> 0x44178ee0
2253: 4 -> 0x19604c501723262401101443719_inner_var_4 -> 0x441792c0
2253: 5 -> fetch0@fetch -> 0x44a49070
2253: 6 -> 0x19604c501723262401101443719_inner_var_6 -> 0x441792e0
2253: 7 -> fetch1@fetch -> 0x44a499d0
2253: 
2253: 
2253: ======================= The dependency of all instruction ========================
2253: id -> down_stream_id
2253: 0 -> 1 
2253: 1 -> 2 4 
2253: 2 -> 3 
2253: 4 -> 5 
2253: 
2253: 
2253: ======================== pir interpreter trace order ========================
2253: 
2253: Leaf nodes: 0[pd_op.shadow_feed]->
2253: 0 downstreams: 1[pd_op.fake_channel_wise_quantize_dequantize_abs_max]->
2253: 1 downstreams: 2[pd_op.memcpy_d2h]->4[pd_op.memcpy_d2h]->
2253: 2 downstreams: 3[pd_op.fetch]->
2253: 3 downstreams: 
2253: 4 downstreams: 5[pd_op.fetch]->
2253: 5 downstreams: 
2253: I0810 04:00:01.102531  1624 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.102615  1625 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.102654  1626 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.102681  1627 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.102707  1628 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.102753  1629 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.102773  1629 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_1:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.102795  1629 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.102818  1629 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: Before: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x19604c501723262401101443719_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_3:[dtype=;place=;dim=;lod={};, 0x19604c501723262401101443719_inner_var_2:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.102919  1629 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:1 name:pd_op.fake_channel_wise_quantize_dequantize_abs_max type:kGpuAsync runs on DeviceKernelLaunch_thread_0
2253: After: Place(gpu:0) Op(pd_op.fake_channel_wise_quantize_dequantize_abs_max), inputs:{0x19604c501723262401101443719_inner_var_1:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};, 0x19604c501723262401101443719_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.102972  1627 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x19604c501723262401101443719_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_4:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.102974  1628 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x19604c501723262401101443719_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_6:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.102996  1627 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.103008  1628 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.103052  1627 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x19604c501723262401101443719_inner_var_2:[dtype=float;place=Place(gpu:0);dim=30, 15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.103089  1628 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:4 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
2253: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x19604c501723262401101443719_inner_var_3:[dtype=float;place=Place(gpu:0);dim=15;lod={};]}, outputs:{0x19604c501723262401101443719_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.103099  1627 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x19604c501723262401101443719_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.103116  1627 tensor_utils.cc:57] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.103121  1628 pir_interpreter.cc:1876] 
2253: begin: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x19604c501723262401101443719_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
2253: I0810 04:00:01.103124  1627 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x19604c501723262401101443719_inner_var_4:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=30, 15;lod={};]}.
2253: I0810 04:00:01.103144  1628 tensor_utils.cc:57] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.103155  1628 pir_interpreter.cc:1916] 
2253: done: RunInstructionBase OP id:5 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
2253: After: Place(cpu) Op(pd_op.fetch), inputs:{0x19604c501723262401101443719_inner_var_6:[dtype=float;place=Place(cpu);dim=15;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=15;lod={};]}.
2253: I0810 04:00:01.103185  1268 pir_interpreter.cc:1766] main_thread_blocker_(0x19604dc0) got event_name: TaskCompletion
2253: I0810 04:00:01.103207  1268 tensor_util.cc:48] TensorCopy 30, 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.103233  1268 tensor_util.cc:48] TensorCopy 15 from Place(cpu) to Place(cpu)
2253: I0810 04:00:01.103380  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:201
2253: I0810 04:00:01.103454  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:01.103471  1268 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:202
2253: I0810 04:00:01.103487  1268 pir.cc:2451] Start compare shape and data.
2253: I0810 04:00:01.104413  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.104434  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.104485  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.104494  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.105556  1618 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 7266018504506563179 to 4976018710619039040 , after update, data is {current : 1740, peak : 3600}.
2253: I0810 04:00:01.105566  1618 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 7266018504506563179 to 4431466935759173892 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.105880  1621 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 4387486040692420614 to 4976018710619039040 , after update, data is {current : 1860, peak : 3600}.
2253: I0810 04:00:01.105957  1622 thread_data_registry.h:135] Add data {current : 3600, peak : 3600} from thread 17189945363590869653 to 4976018710619039040 , after update, data is {current : 5460, peak : 5460}.
2253: I0810 04:00:01.106073  1623 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 3894914143258603765 to 4431466935759173892 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.106251  1624 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 9470489340628506630 to 4976018710619039040 , after update, data is {current : 3600, peak : 5460}.
2253: I0810 04:00:01.106261  1624 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 9470489340628506630 to 4431466935759173892 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.106439  1628 thread_data_registry.h:135] Add data {current : 120, peak : 120} from thread 753228128760470270 to 4976018710619039040 , after update, data is {current : 3720, peak : 5460}.
2253: I0810 04:00:01.106511  1627 thread_data_registry.h:135] Add data {current : 3720, peak : 5460} from thread 4976018710619039040 to 3258848792123612270 , after update, data is {current : 530540, peak : 2207688}.
2253: I0810 04:00:01.106626  1629 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 4431466935759173892 to 3258848792123612270 , after update, data is {current : 1843524, peak : 2555920}.
2253: I0810 04:00:01.108181  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.108758  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.109223  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.109239  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.109244  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.111604  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.111685  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.111698  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.111707  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x19616ba0 type is 7
2253: I0810 04:00:01.111716  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.111722  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x447cb800 type is 7
2253: I0810 04:00:01.111728  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.111732  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x447947d0 type is 7
2253: I0810 04:00:01.111738  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44181c20 type is 9
2253: I0810 04:00:01.111747  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44182490 type is 10
2253: I0810 04:00:01.111822  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.111829  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.111835  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.111838  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.111881  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.111893  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.111943  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.111953  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.111990  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.112000  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.112016  1268 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.112025  1268 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x447c7db0Variable Type 7
2253: I0810 04:00:01.112039  1268 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.112061  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.112074  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.112107  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.112115  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.112131  1268 scope.cc:202] Create variable OutScale_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.112139  1268 data_transfer.cc:396] Create Variable OutScale_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44177700Variable Type 7
2253: I0810 04:00:01.112151  1268 data_transfer.cc:439] Insert memcpy_d2h with OutScale(Place(gpu:0)) -> OutScale_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.112167  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.112180  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.112437  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.112473  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.112495  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.112598  1630 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.112664  1631 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.112689  1632 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.112732  1633 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.112756  1634 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.112798  1635 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.113013  1634 tensor_utils.cc:57] TensorCopy 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.113024  1633 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.113113  1633 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.113132  1633 fetch_v2_op.cc:138] Fetch variable OutScale_device_Place(gpu:0)_Place(cpu)'s 1 column.
2253: I0810 04:00:01.113157  1268 program_interpreter.cc:1308] main_thread_blocker_(0x44a0f428) got event_name: TaskCompletion
2253: I0810 04:00:01.113281  1630 thread_data_registry.h:135] Add data {current : -1860, peak : 0} from thread 4431466935759173892 to 7266018504506563179 , after update, data is {current : 0, peak : 1860}.
2253: I0810 04:00:01.113436  1633 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 15215870038455397554 to 4825685957987445629 , after update, data is {current : 1860, peak : 1860}.
2253: I0810 04:00:01.113507  1634 thread_data_registry.h:135] Add data {current : 1860, peak : 1860} from thread 4825685957987445629 to 3258848792123612270 , after update, data is {current : 532400, peak : 2207688}.
2253: I0810 04:00:01.113612  1635 thread_data_registry.h:135] Add data {current : 0, peak : 1860} from thread 7266018504506563179 to 3258848792123612270 , after update, data is {current : 1841724, peak : 2555920}.
2253: I0810 04:00:01.113813  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.114341  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.114374  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.114387  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.114506  1268 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
2253: I0810 04:00:01.115476  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.115499  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.115548  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.115558  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.116268  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:01.116289  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:01.116338  1268 op_desc.cc:1111] CompileTime infer shape on mean
2253: I0810 04:00:01.116348  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:01.116667  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.116729  1268 pybind.cc:1827] need skip: 0
2253: I0810 04:00:01.117084  1268 op_desc.cc:1111] CompileTime infer shape on fill_constant
2253: I0810 04:00:01.117178  1268 op_desc.cc:1111] CompileTime infer shape on mean_grad
2253: I0810 04:00:01.117188  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:01.117265  1268 op_desc.cc:1111] CompileTime infer shape on fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:01.117275  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:01.119767  1268 op_desc.cc:1111] CompileTime infer shape on fetch_v2
2253: I0810 04:00:01.120411  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.120429  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.120433  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.123836  1268 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
2253: I0810 04:00:01.123857  1268 scope.cc:202] Create variable feed
2253: I0810 04:00:01.123888  1268 interpreter_util.cc:1169] Creating Variables
2253: I0810 04:00:01.123898  1268 scope.cc:202] Create variable Out
2253: I0810 04:00:01.123903  1268 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44a3c630 type is 7
2253: I0810 04:00:01.123910  1268 scope.cc:202] Create variable Out@GRAD
2253: I0810 04:00:01.123916  1268 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44856b70 type is 7
2253: I0810 04:00:01.123921  1268 scope.cc:202] Create variable OutScale
2253: I0810 04:00:01.123925  1268 interpreter_util.cc:1206] Create Variable OutScale locally, which pointer is 0x448564c0 type is 7
2253: I0810 04:00:01.123931  1268 scope.cc:202] Create variable X
2253: I0810 04:00:01.123935  1268 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44a3ce00 type is 7
2253: I0810 04:00:01.123940  1268 scope.cc:202] Create variable X@GRAD
2253: I0810 04:00:01.123943  1268 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44a3d070 type is 7
2253: I0810 04:00:01.123950  1268 scope.cc:202] Create variable _generated_var_0
2253: I0810 04:00:01.123952  1268 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44a3d2b0 type is 7
2253: I0810 04:00:01.123957  1268 scope.cc:202] Create variable _generated_var_0@GRAD
2253: I0810 04:00:01.123961  1268 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44a3d510 type is 7
2253: I0810 04:00:01.123966  1268 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44a3c610 type is 9
2253: I0810 04:00:01.123972  1268 scope.cc:202] Create variable fetch
2253: I0810 04:00:01.123977  1268 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44a3d290 type is 10
2253: I0810 04:00:01.124083  1268 interpreter_util.cc:594] Static build: 1
2253: I0810 04:00:01.124090  1268 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
2253: I0810 04:00:01.124095  1268 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
2253: I0810 04:00:01.124100  1268 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
2253: I0810 04:00:01.124147  1268 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124161  1268 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124208  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124218  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124256  1268 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124265  1268 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124325  1268 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124334  1268 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124364  1268 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124374  1268 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124411  1268 operator.cc:2295] op type:fake_channel_wise_quantize_dequantize_abs_max_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124420  1268 interpreter_util.cc:844] fake_channel_wise_quantize_dequantize_abs_max_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124449  1268 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.124459  1268 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
2253: I0810 04:00:01.124475  1268 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
2253: I0810 04:00:01.124481  1268 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x448265c0Variable Type 7
2253: I0810 04:00:01.124497  1268 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
2253: I0810 04:00:01.124517  1268 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
2253: I0810 04:00:01.124531  1268 data_transfer.cc:232] Run memcpy_d2h done.
2253: I0810 04:00:01.124825  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max; inputs: X; attributes: bit_length, round_type, quant_axis; outputs: Out, OutScale
2253: I0810 04:00:01.124857  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
2253: I0810 04:00:01.124886  1268 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
2253: I0810 04:00:01.124992  1636 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
2253: I0810 04:00:01.125064  1637 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
2253: I0810 04:00:01.125079  1638 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
2253: I0810 04:00:01.125124  1639 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
2253: I0810 04:00:01.125149  1640 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
2253: I0810 04:00:01.125182  1641 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
2253: I0810 04:00:01.125546  1641 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:01.125577  1641 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
2253: I0810 04:00:01.125654  1641 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: fake_channel_wise_quantize_dequantize_abs_max_grad; inputs: Out@GRAD; attributes: bit_length, round_type, quant_axis; outputs: X@GRAD
2253: I0810 04:00:01.125696  1641 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:01.125783  1640 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(cpu)
2253: I0810 04:00:01.125860  1640 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
2253: I0810 04:00:01.125886  1268 program_interpreter.cc:1308] main_thread_blocker_(0x449e60d8) got event_name: TaskCompletion
2253: I0810 04:00:01.126032  1636 thread_data_registry.h:135] Add data {current : -5468, peak : 0} from thread 7266018504506563179 to 3894914143258603765 , after update, data is {current : 0, peak : 5468}.
2253: I0810 04:00:01.126181  1640 thread_data_registry.h:135] Add data {current : 1800, peak : 1800} from thread 17189945363590869653 to 3258848792123612270 , after update, data is {current : 528680, peak : 2207688}.
2253: I0810 04:00:01.126359  1641 thread_data_registry.h:135] Add data {current : 0, peak : 5468} from thread 3894914143258603765 to 3258848792123612270 , after update, data is {current : 1843464, peak : 2555920}.
2253: I0810 04:00:01.127293  1268 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4481c510 for it.
2253: I0810 04:00:01.127470  1268 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19291330 for it.
2253: I0810 04:00:01.127511  1268 eager.cc:133] Tensor(OutScale_out_0) have not GradNode, add GradNodeAccumulation0x192e5b60 for it.
2253: I0810 04:00:01.128084  1268 dygraph_functions.cc:27457] Running AD API: fake_channel_wise_quantize_dequantize_abs_max
2253: I0810 04:00:01.128119  1268 dygraph_functions.cc:27517] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.128235  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x445f2ae0)  to GradNodeAccumulation (addr: 0x4481c510)
2253: I0810 04:00:01.128333  1268 dygraph_functions.cc:51780] Running AD API: mean
2253: I0810 04:00:01.128355  1268 dygraph_functions.cc:51837] { Input: [ 
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.128474  1268 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x445f3b90)  to FakeChannelWiseQuantizeDequantizeAbsMaxGradNode (addr: 0x445f2ae0)
2253: I0810 04:00:01.128548  1268 backward.cc:442] Run in Backward
2253: I0810 04:00:01.128556  1268 backward.cc:113] Start Backward
2253: I0810 04:00:01.128564  1268 backward.cc:197] Fill grad input tensor 0 with 1.0
2253: I0810 04:00:01.128597  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:01.128623  1268 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x445f3b90
2253: I0810 04:00:01.128631  1268 nodes.cc:25338] Running AD API GRAD: mean_grad
2253: I0810 04:00:01.128655  1268 nodes.cc:25394] { Input: [ 
2253: ( grad_out , [[ Not specified tensor log level ]]),  
2253: ( x , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.128700  1268 gpu_launch_config.h:156] Get 1-D launch config: numel=450, vec_size=4, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
2253: I0810 04:00:01.128733  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:01.128741  1268 backward.cc:335] Node: MeanGradNode addr:0x445f3b90, Found pending node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr: 0x445f2ae0
2253: I0810 04:00:01.128747  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:01.128774  1268 backward.cc:255] Preparing GradNode:FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x445f2ae0
2253: I0810 04:00:01.128782  1268 nodes.cc:12237] Running AD API GRAD: fake_channel_wise_quantize_dequantize_abs_max_grad
2253: I0810 04:00:01.128794  1268 nodes.cc:12289] { Input: [ 
2253: ( out_grad , [[ Not specified tensor log level ]]), ]} 
2253: I0810 04:00:01.128823  1268 tensor_utils.cc:57] TensorCopy 30, 15 from Place(gpu:0) to Place(gpu:0)
2253: I0810 04:00:01.128855  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:01.128862  1268 backward.cc:335] Node: FakeChannelWiseQuantizeDequantizeAbsMaxGradNode addr:0x445f2ae0, Found pending node: GradNodeAccumulation addr: 0x4481c510
2253: I0810 04:00:01.128867  1268 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
2253: I0810 04:00:01.128890  1268 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4481c510
2253: I0810 04:00:01.128896  1268 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
2253: I0810 04:00:01.128901  1268 accumulation_node.cc:40] Move Tensor ptr: 0x44607650
2253: I0810 04:00:01.128904  1268 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
2253: I0810 04:00:01.128908  1268 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
2253: I0810 04:00:01.196385  1268 mmap_allocator.cc:348] PID: 1268, MemoryMapFdSet: set size - 0
2253: I0810 04:00:01.206405  1268 mmap_allocator.cc:348] PID: 1268, MemoryMapFdSet: set size - 0
2253: I0810 04:00:01.389838  1268 mmap_allocator.cc:348] PID: 1268, MemoryMapFdSet: set size - 0
2/2 Test #2253: test_fake_quantize_op_static_build ...   Passed   12.21 sec

The following tests passed:
	test_fake_quantize_op
	test_fake_quantize_op_static_build

100% tests passed, 0 tests failed out of 2

Total Test time (real) =  25.45 sec
