UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0815 06:16:10.087276 29740 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0815 06:16:10.871030 29740 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=cublaslt_exhaustive_search_times,print_sub_graph_dir,use_virtual_memory_auto_growth,npu_storage_format,check_infer_symbolic,dygraph_debug,jit_engine_type,reader_queue_speed_test_mode,enable_dump_main_program,free_when_no_cache_hit,inner_op_parallelism,cudnn_dir,pir_debug,check_nan_inf_level,enable_gpu_memory_usage_log_mb,conv_workspace_size_limit,prim_check_ops,cuda_malloc_async_pool_memory_throttle_ratio,prim_skip_dynamic,static_executor_perfstat_filepath,enable_adjust_op_order,cuda_memory_async_pool_realease_threshold,gpugraph_slot_feasign_max_num,tracer_onednn_ops_on,apply_pass_to_program,enable_all2all_use_fp16,trt_ibuilder_cache,gpugraph_offload_param_extends,cse_max_count,mklml_dir,benchmark,gpugraph_dedup_pull_push_mode,tracer_profile_fname,use_stride_kernel,enable_auto_rdma_trans,enable_auto_detect_gpu_topo,gpugraph_hbm_table_load_factor,prim_forward,sync_after_alloc,enable_pir_with_pt_in_dy2st,enable_blaslt_global_search,pir_apply_inplace_pass,enable_collect_shape,selected_gpus,enable_cinn_accuracy_check,pinned_memory_as_cpu_backend,cuda_dir,use_pinned_memory,gpugraph_load_node_list_into_hbm,log_memory_stats,reallocate_gpu_memory_in_mb,check_kernel_launch,prim_enable_dynamic,tracer_onednn_ops_off,graph_neighbor_size_percent,curand_dir,nccl_blocking_wait,cudnn_exhaustive_search,mkl_dir,enable_unused_var_check,gpugraph_enable_print_op_debug,cudnn_batchnorm_spatial_persistent,init_allocated_mem,search_cache_max_number,gpugraph_merge_grads_segment_size,enable_record_memory,convert_all_blocks,free_idle_chunk,cublas_dir,executor_log_deps_every_microseconds,async_trace_count,ir_inplace_kernel_blacklist,fuse_parameter_groups_size,sort_sum_gradient,use_system_allocator,new_executor_serial_run,use_cuda_managed_memory,op_dir,initial_gpu_memory_in_mb,use_fast_math,fuse_parameter_memory_size,fleet_executor_with_standalone,logging_pir_py_code_int_tensor_element_limit,use_auto_growth_pinned_allocator,all_blocks_convert_trt,enable_api_kernel_fallback,use_auto_growth_v2,allow_cinn_ops,use_autotune,gpugraph_debug_gpu_memory,static_runtime_data_save_path,accuracy_check_atol_fp16,embedding_deterministic,save_static_runtime_data,tensorrt_dir,cudnn_deterministic,manually_trans_conv_filter,sync_nccl_allreduce,set_to_1d,benchmark_nccl,new_executor_use_inplace,low_precision_op_list,gpugraph_enable_gpu_direct_access,gpugraph_enable_hbm_table_collision_stat,lapack_dir,enable_tracker_all2all,fraction_of_cuda_pinned_memory_to_use,use_mkldnn,accuracy_check_atol_bf16,win_cuda_bin_dir,auto_free_cudagraph_allocations_on_launch,deny_cinn_ops,gpugraph_enable_segment_merge_grads,gpugraph_offload_param_stat,allocator_strategy,enable_dependency_builder_debug_info,accuracy_check_atol_fp32,enable_graph_multi_node_sampling,disable_dyshape_in_train,enable_fuse_parallel_matmul_pass,einsum_opt,allreduce_record_one_event,cusparselt_dir,cinn_compile_thread_num,tensor_operants_mode,print_allocator_trace_info,cudnn_exhaustive_search_times,use_cinn,gpugraph_parallel_stream_num,run_kp_kernel,graph_metapath_split_opt,eager_delete_scope,nccl_dir,dist_threadpool_size,enable_async_trace,cublaslt_device_best_config,enable_cinn_auto_tune,accuracy_check_rtol_fp16,conv2d_disable_cudnn,custom_device_mem_record,alloc_fill_value,enable_interpretercore_launch_cinn,pir_subgraph_saving_dir,accuracy_check_rtol_fp32,enable_opt_get_features,enable_cse_in_dy2st,use_shm_cache,enable_pir_api,cupti_dir,max_inplace_grad_add,local_exe_sub_scope_limit,cinn_subgraph_graphviz_dir,dynamic_static_unified_comm,dataloader_use_file_descriptor,host_trace_level,get_host_by_name_time,cache_inference_while_scope,fraction_of_cpu_memory_to_use,paddle_num_threads,enable_cinn_compile_cache,enable_neighbor_list_use_uva,multi_node_sample_use_gpu_table,check_nan_inf,enable_fusion_fallback,auto_growth_chunk_size_in_mb,use_xqa_optim,use_cuda_malloc_async_allocator,enable_exit_when_partial_worker,cusparse_dir,add_dependency_for_communication_op,gpugraph_force_device_batch_num_equal,enable_gpu_memory_usage_log,logging_trunc_pir_py_code,logging_pir_py_code_dir,query_dest_rank_by_multi_node,fraction_of_gpu_memory_to_use,gpugraph_sparse_table_storage_mode,new_executor_static_build,graph_load_in_parallel,enable_pir_in_executor_trace_run,print_ir,graph_get_neighbor_id,new_executor_use_local_scope,enable_pir_in_executor,pir_broadcast_tree_limit,call_stack_level,initial_cpu_memory_in_mb,eager_delete_tensor_gb,gpugraph_storage_mode,accuracy_check_rtol_bf16,gemm_use_half_precision_compute_type,logging_pir_py_code_dump_symbolic_dims,gpugraph_parallel_copyer_split_maxsize,new_executor_use_cuda_graph,enable_cublas_tensor_op_math,gpu_allocator_retry_time,prim_enabled,prim_backward,use_stream_safe_cuda_allocator,memory_fraction_of_eager_deletion,enable_sparse_inner_gather,gpu_memory_limit_mb,gpugraph_offload_gather_copy_maxsize,nvidia_package_dir,multiple_of_cupti_buffer_size,pir_apply_shape_optimization_pass,cusolver_dir,fast_eager_deletion_mode,new_executor_sequential_run,prim_all,prim_forward_blacklist,graph_embedding_split_infer_mode,dump_chunk_info 
1901: I0815 06:16:10.871140 29740 init.cc:108] After Parse: argc is 2
1901: I0815 06:16:18.764665 29740 scope.cc:202] Create variable X
1901: I0815 06:16:18.764750 29740 scope.cc:202] Create variable Out
1901: I0815 06:16:18.764768 29740 scope.cc:202] Create variable MedianIndex
1901: I0815 06:16:18.764930 29740 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0815 06:16:18.765609 29740 allocator_facade.cc:212] selected allocator strategy:1
1901: I0815 06:16:18.765892 29740 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0815 06:16:21.224535 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.224591 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.224714 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.224723 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.225736 29740 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:16:21.225760 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.225802 29740 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:16:21.225809 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.226181 29740 pybind.cc:1827] need skip: 0
1901: I0815 06:16:21.226261 29740 pybind.cc:1827] need skip: 0
1901: I0815 06:16:21.226661 29740 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 06:16:21.226943 29740 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 06:16:21.226959 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:16:21.227041 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 06:16:21.227054 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:16:21.230386 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.231053 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.231068 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.231081 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.234068 29740 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:16:21.234084 29740 scope.cc:202] Create variable feed
1901: I0815 06:16:21.234151 29740 program_interpreter.cc:243] New Executor is Running.
1901: I0815 06:16:21.234160 29740 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:16:21.234169 29740 scope.cc:202] Create variable MedianIndex
1901: I0815 06:16:21.234179 29740 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x45203270 type is 7
1901: I0815 06:16:21.234190 29740 scope.cc:202] Create variable Out
1901: I0815 06:16:21.234196 29740 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45203760 type is 7
1901: I0815 06:16:21.234201 29740 scope.cc:202] Create variable Out@GRAD
1901: I0815 06:16:21.234205 29740 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x45203c10 type is 7
1901: I0815 06:16:21.234208 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.234211 29740 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45204580 type is 7
1901: I0815 06:16:21.234215 29740 scope.cc:202] Create variable X@GRAD
1901: I0815 06:16:21.234218 29740 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x452047f0 type is 7
1901: I0815 06:16:21.234223 29740 scope.cc:202] Create variable _generated_var_0
1901: I0815 06:16:21.234227 29740 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45204a30 type is 7
1901: I0815 06:16:21.234231 29740 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 06:16:21.234234 29740 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45204c90 type is 7
1901: I0815 06:16:21.234238 29740 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x452031f0 type is 9
1901: I0815 06:16:21.234251 29740 scope.cc:202] Create variable fetch
1901: I0815 06:16:21.234256 29740 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45204a10 type is 10
1901: I0815 06:16:21.234376 29740 interpreter_util.cc:594] Static build: 0
1901: I0815 06:16:21.234382 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.234387 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.234391 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0815 06:16:21.235045 29740 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0815 06:16:21.235239 29740 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0815 06:16:21.236248 29740 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0815 06:16:21.236465 29740 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.236488 29740 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.236617 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.236627 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.236647 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.241351 29740 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241370 29740 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241386 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.241463 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.241572 29740 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241585 29740 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241639 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.241662 29740 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0815 06:16:21.241693 29740 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241701 29740 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241719 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:16:21.241819 29740 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241829 29740 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.241845 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:16:21.241961 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.241986 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.242008 29740 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.242015 29740 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x45282be0Variable Type 7
1901: I0815 06:16:21.242034 29740 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.242058 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.242106 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.242127 29740 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.242241 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.242274 29740 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:16:21.242843 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.242892 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.243901 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.243921 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.243966 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.243975 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.244596 29740 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:16:21.244612 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.244645 29740 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:16:21.244652 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.244913 29740 pybind.cc:1827] need skip: 0
1901: I0815 06:16:21.244966 29740 pybind.cc:1827] need skip: 0
1901: I0815 06:16:21.245270 29740 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 06:16:21.245352 29740 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 06:16:21.245360 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:16:21.245426 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 06:16:21.245435 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:16:21.247490 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.247977 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.247989 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.247994 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.250686 29740 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:16:21.250703 29740 scope.cc:202] Create variable feed
1901: I0815 06:16:21.250730 29740 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:16:21.250739 29740 scope.cc:202] Create variable MedianIndex
1901: I0815 06:16:21.250743 29740 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x452e64d0 type is 7
1901: I0815 06:16:21.250751 29740 scope.cc:202] Create variable Out
1901: I0815 06:16:21.250757 29740 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x452e6a50 type is 7
1901: I0815 06:16:21.250761 29740 scope.cc:202] Create variable Out@GRAD
1901: I0815 06:16:21.250764 29740 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x452e6f00 type is 7
1901: I0815 06:16:21.250768 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.250771 29740 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x452e77e0 type is 7
1901: I0815 06:16:21.250775 29740 scope.cc:202] Create variable X@GRAD
1901: I0815 06:16:21.250778 29740 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x452e7a50 type is 7
1901: I0815 06:16:21.250783 29740 scope.cc:202] Create variable _generated_var_0
1901: I0815 06:16:21.250787 29740 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x452e7c90 type is 7
1901: I0815 06:16:21.250790 29740 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 06:16:21.250797 29740 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x452e7ef0 type is 7
1901: I0815 06:16:21.250800 29740 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x452e6e50 type is 9
1901: I0815 06:16:21.250805 29740 scope.cc:202] Create variable fetch
1901: I0815 06:16:21.250808 29740 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x452e7c70 type is 10
1901: I0815 06:16:21.250913 29740 interpreter_util.cc:594] Static build: 0
1901: I0815 06:16:21.250919 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.250923 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.250927 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.250970 29740 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.250983 29740 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251030 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251039 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251053 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.251564 29740 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251578 29740 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251593 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.251644 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.251721 29740 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251731 29740 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251771 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.251803 29740 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251812 29740 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251827 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:16:21.251912 29740 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251922 29740 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.251938 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:16:21.252041 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.252053 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.252068 29740 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.252074 29740 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x452e92c0Variable Type 7
1901: I0815 06:16:21.252089 29740 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.252103 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.252122 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.252136 29740 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.252209 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.252233 29740 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:16:21.252660 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:16:21.252692 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.254159 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.254349 29740 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a963cc0 for it.
1901: I0815 06:16:21.254400 29740 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.255759 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.255808 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.256453 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x452e6f20)  to GradNodeAccumulation (addr: 0x452b2450)
1901: I0815 06:16:21.256574 29740 dygraph_functions.cc:51757] Running AD API: mean
1901: I0815 06:16:21.256597 29740 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.256673 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.256691 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x2419e540)  to NanmedianGradNode (addr: 0x452e6f20)
1901: I0815 06:16:21.256762 29740 backward.cc:442] Run in Backward
1901: I0815 06:16:21.256772 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.256793 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.256835 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.256861 29740 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x2419e540
1901: I0815 06:16:21.256873 29740 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0815 06:16:21.256911 29740 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.256975 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.256999 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.257010 29740 backward.cc:335] Node: MeanGradNode addr:0x2419e540, Found pending node: NanmedianGradNode addr: 0x452e6f20
1901: I0815 06:16:21.257017 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.257046 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x452e6f20
1901: I0815 06:16:21.257058 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.257081 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.257125 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.257146 29740 backward.cc:335] Node: NanmedianGradNode addr:0x452e6f20, Found pending node: GradNodeAccumulation addr: 0x452b2450
1901: I0815 06:16:21.257153 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.257165 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x452b2450
1901: I0815 06:16:21.257175 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.257181 29740 accumulation_node.cc:40] Move Tensor ptr: 0x452035e0
1901: I0815 06:16:21.257186 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.257191 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0815 06:16:21.265110 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.265267 29740 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.265322 29740 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a963cc0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0815 06:16:21.326577 29740 pir_interpreter.cc:161] PirInterpreter(): 0x47428d90 on Place(gpu:0)
1901: I0815 06:16:21.326619 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.326646 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_1
1901: I0815 06:16:21.326658 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_2
1901: I0815 06:16:21.326666 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_3
1901: I0815 06:16:21.326673 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_4
1901: I0815 06:16:21.326682 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_5
1901: I0815 06:16:21.326689 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_6
1901: I0815 06:16:21.326697 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_7
1901: I0815 06:16:21.326704 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_8
1901: I0815 06:16:21.326712 29740 scope.cc:202] Create variable 0x47428d901723702581326607105_inner_var_9
1901: I0815 06:16:21.326719 29740 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:16:21.327100 29740 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:16:21.327113 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.327116 29740 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0815 06:16:21.327158 29740 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x474273d0
1901: 1 -> 0x47428d901723702581326607105_inner_var_1 -> 0x47428d70
1901: 2 -> 0x47428d901723702581326607105_inner_var_2 -> 0x474265c0
1901: 3 -> 0x47428d901723702581326607105_inner_var_3 -> 0x47428480
1901: 4 -> 0x47428d901723702581326607105_inner_var_4 -> 0x47424fd0
1901: 5 -> 0x47428d901723702581326607105_inner_var_5 -> 0x47429340
1901: 6 -> 0x47428d901723702581326607105_inner_var_6 -> 0x47429760
1901: 7 -> 0x47428d901723702581326607105_inner_var_7 -> 0x47429b80
1901: 8 -> 0x47428d901723702581326607105_inner_var_8 -> 0x474261d0
1901: 9 -> 0x47428d901723702581326607105_inner_var_9 -> 0x47429fa0
1901: 10 -> fetch0@fetch -> 0x4742a7b0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0815 06:16:21.328078 29740 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0815 06:16:21.328296 29777 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:16:21.328419 29778 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:16:21.328526 29779 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:16:21.328541 29780 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:16:21.328605 29781 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:16:21.328626 29779 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x47428d901723702581326607105_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.328653 29782 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:16:21.328716 29779 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x47428d901723702581326607105_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0815 06:16:21.328712 29782 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.328761 29782 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:16:21.328817 29782 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47428d901723702581326607105_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47428d901723702581326607105_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.329324 29782 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47428d901723702581326607105_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47428d901723702581326607105_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.329355 29782 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x47428d901723702581326607105_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.329411 29782 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.329425 29782 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x47428d901723702581326607105_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.329454 29782 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x47428d901723702581326607105_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x47428d901723702581326607105_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.329540 29782 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.329558 29782 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x47428d901723702581326607105_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x47428d901723702581326607105_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.329592 29782 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x47428d901723702581326607105_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47428d901723702581326607105_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.329643 29782 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.329659 29782 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x47428d901723702581326607105_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47428d901723702581326607105_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.329682 29782 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x47428d901723702581326607105_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47428d901723702581326607105_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x47428d901723702581326607105_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.329742 29782 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x47428d901723702581326607105_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47428d901723702581326607105_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x47428d901723702581326607105_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:16:21.329811 29779 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47428d901723702581326607105_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.329835 29779 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.329928 29779 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47428d901723702581326607105_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581326607105_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 06:16:21.329957 29779 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47428d901723702581326607105_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.329981 29779 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.330011 29779 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47428d901723702581326607105_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 06:16:21.330044 29740 pir_interpreter.cc:1766] main_thread_blocker_(0x47428f00) got event_name: TaskCompletion
1901: I0815 06:16:21.330070 29740 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.333036 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.333063 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.333127 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.333137 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.335109 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.335676 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.336128 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.336143 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.336148 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.338436 29740 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:16:21.338454 29740 scope.cc:202] Create variable feed
1901: I0815 06:16:21.338487 29740 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:16:21.338497 29740 scope.cc:202] Create variable MedianIndex
1901: I0815 06:16:21.338502 29740 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x474dff10 type is 7
1901: I0815 06:16:21.338511 29740 scope.cc:202] Create variable Out
1901: I0815 06:16:21.338518 29740 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x474df2b0 type is 7
1901: I0815 06:16:21.338526 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.338529 29740 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x474dfca0 type is 7
1901: I0815 06:16:21.338533 29740 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x474dfef0 type is 9
1901: I0815 06:16:21.338541 29740 scope.cc:202] Create variable fetch
1901: I0815 06:16:21.338546 29740 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x474e0470 type is 10
1901: I0815 06:16:21.338620 29740 interpreter_util.cc:594] Static build: 0
1901: I0815 06:16:21.338627 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.338634 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.338639 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.338691 29740 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.338706 29740 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.338774 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.338784 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.338805 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.339310 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.339327 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.339347 29740 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.339355 29740 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474e4460Variable Type 7
1901: I0815 06:16:21.339375 29740 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.339394 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.339418 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.339437 29740 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.339479 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.339504 29740 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:16:21.339552 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.339563 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.339579 29740 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.339586 29740 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474e85f0Variable Type 7
1901: I0815 06:16:21.339601 29740 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.339614 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.339634 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.339648 29740 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.339684 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.339715 29740 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:16:21.339994 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.340023 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.341351 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.341375 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.341427 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.341437 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.343343 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.343902 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.344347 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.344360 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.344367 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.346592 29740 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:16:21.346665 29740 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:16:21.346678 29740 scope.cc:202] Create variable MedianIndex
1901: I0815 06:16:21.346683 29740 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x4760a540 type is 7
1901: I0815 06:16:21.346693 29740 scope.cc:202] Create variable Out
1901: I0815 06:16:21.346697 29740 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47609870 type is 7
1901: I0815 06:16:21.346704 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.346709 29740 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4760a270 type is 7
1901: I0815 06:16:21.346714 29740 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x474dfef0 type is 9
1901: I0815 06:16:21.346722 29740 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x474e0470 type is 10
1901: I0815 06:16:21.346793 29740 interpreter_util.cc:594] Static build: 0
1901: I0815 06:16:21.346801 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.346807 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.346812 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.346853 29740 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.346866 29740 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.346920 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.346930 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.346948 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.347477 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.347493 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.347512 29740 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.347519 29740 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4760e9e0Variable Type 7
1901: I0815 06:16:21.347537 29740 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.347554 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.347577 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.347594 29740 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.347635 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.347656 29740 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:16:21.347700 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.347710 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.347726 29740 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.347733 29740 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4760ea00Variable Type 7
1901: I0815 06:16:21.347748 29740 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.347761 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.347780 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.347795 29740 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.347829 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.347849 29740 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:16:21.348114 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.348142 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.348722 29777 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 6132186036972868963 to 12985008308672066367 , after update, data is {current : -20004, peak : 16}.
1901: I0815 06:16:21.348739 29777 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 6132186036972868963 to 12985008308672066367 , after update, data is {current : 0, peak : 330659}.
1901: I0815 06:16:21.348897 29779 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 1935202360547024378 to 12985008308672066367 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 06:16:21.349067 29782 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 12985008308672066367 to 15619951352442962525 , after update, data is {current : 20038, peak : 40004}.
1901: I0815 06:16:21.349077 29782 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 12985008308672066367 to 15619951352442962525 , after update, data is {current : 140000, peak : 520631}.
1901: I0815 06:16:21.482007 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a963cc0 for it.
1901: I0815 06:16:21.482465 29740 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.482537 29740 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.483178 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.483228 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.484532 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a963cc0 for it.
1901: I0815 06:16:21.484686 29740 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.484747 29740 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.485105 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.485138 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.487524 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a963cc0 for it.
1901: I0815 06:16:21.487689 29740 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.487738 29740 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 06:16:21.491432 29740 pir_interpreter.cc:161] PirInterpreter(): 0x47428d90 on Place(gpu:0)
1901: I0815 06:16:21.491472 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.491495 29740 scope.cc:202] Create variable 0x47428d901723702581491460375_inner_var_1
1901: I0815 06:16:21.491508 29740 scope.cc:202] Create variable 0x47428d901723702581491460375_inner_var_2
1901: I0815 06:16:21.491518 29740 scope.cc:202] Create variable 0x47428d901723702581491460375_inner_var_3
1901: I0815 06:16:21.491526 29740 scope.cc:202] Create variable 0x47428d901723702581491460375_inner_var_4
1901: I0815 06:16:21.491544 29740 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:16:21.491945 29740 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:16:21.491961 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.491966 29740 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x476dd370
1901: 1 -> 0x47428d901723702581491460375_inner_var_1 -> 0x475e0430
1901: 2 -> 0x47428d901723702581491460375_inner_var_2 -> 0x476ccf70
1901: 3 -> 0x47428d901723702581491460375_inner_var_3 -> 0x1a9d0190
1901: 4 -> 0x47428d901723702581491460375_inner_var_4 -> 0x4749ffe0
1901: 5 -> fetch0@fetch -> 0x1a9223e0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 06:16:21.492718 29784 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:16:21.492889 29785 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:16:21.492921 29786 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:16:21.492962 29787 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:16:21.492996 29788 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:16:21.493058 29789 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:16:21.493103 29789 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581491460375_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.493148 29789 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581491460375_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:16:21.493186 29789 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47428d901723702581491460375_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581491460375_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47428d901723702581491460375_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.493683 29789 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47428d901723702581491460375_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47428d901723702581491460375_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47428d901723702581491460375_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.493769 29788 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47428d901723702581491460375_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47428d901723702581491460375_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.493805 29788 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.493871 29788 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47428d901723702581491460375_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47428d901723702581491460375_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.493904 29788 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47428d901723702581491460375_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.493924 29788 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.493937 29788 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47428d901723702581491460375_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.493968 29740 pir_interpreter.cc:1766] main_thread_blocker_(0x47428f00) got event_name: TaskCompletion
1901: I0815 06:16:21.493993 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.494539 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.494686 29740 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.494730 29740 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a963cc0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 06:16:21.496893 29740 pir_interpreter.cc:161] PirInterpreter(): 0x474b48a0 on Place(gpu:0)
1901: I0815 06:16:21.496920 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.496937 29740 scope.cc:202] Create variable 0x474b48a01723702581496914072_inner_var_1
1901: I0815 06:16:21.496945 29740 scope.cc:202] Create variable 0x474b48a01723702581496914072_inner_var_2
1901: I0815 06:16:21.496958 29740 scope.cc:202] Create variable 0x474b48a01723702581496914072_inner_var_3
1901: I0815 06:16:21.496966 29740 scope.cc:202] Create variable 0x474b48a01723702581496914072_inner_var_4
1901: I0815 06:16:21.496977 29740 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:16:21.497253 29740 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:16:21.497267 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.497270 29740 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x452a1070
1901: 1 -> 0x474b48a01723702581496914072_inner_var_1 -> 0x476120b0
1901: 2 -> 0x474b48a01723702581496914072_inner_var_2 -> 0x4742acb0
1901: 3 -> 0x474b48a01723702581496914072_inner_var_3 -> 0x475dfdc0
1901: 4 -> 0x474b48a01723702581496914072_inner_var_4 -> 0x4742ac90
1901: 5 -> fetch0@fetch -> 0x4760a900
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 06:16:21.497830 29790 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:16:21.498051 29791 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:16:21.498070 29792 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:16:21.498167 29793 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:16:21.498253 29794 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:16:21.498332 29795 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:16:21.498371 29795 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474b48a01723702581496914072_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.498395 29795 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474b48a01723702581496914072_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:16:21.498422 29795 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b48a01723702581496914072_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474b48a01723702581496914072_inner_var_3:[dtype=;place=;dim=;lod={};, 0x474b48a01723702581496914072_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.498833 29795 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b48a01723702581496914072_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474b48a01723702581496914072_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474b48a01723702581496914072_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.498898 29794 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b48a01723702581496914072_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b48a01723702581496914072_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.498932 29794 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.498992 29794 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b48a01723702581496914072_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b48a01723702581496914072_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.499024 29794 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474b48a01723702581496914072_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.499043 29794 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.499055 29794 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474b48a01723702581496914072_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.499082 29740 pir_interpreter.cc:1766] main_thread_blocker_(0x474b4a10) got event_name: TaskCompletion
1901: I0815 06:16:21.499102 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.500392 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a963cc0 for it.
1901: I0815 06:16:21.500562 29740 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.500613 29740 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 06:16:21.503134 29740 pir_interpreter.cc:161] PirInterpreter(): 0x47611390 on Place(gpu:0)
1901: I0815 06:16:21.503163 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.503182 29740 scope.cc:202] Create variable 0x476113901723702581503157483_inner_var_1
1901: I0815 06:16:21.503194 29740 scope.cc:202] Create variable 0x476113901723702581503157483_inner_var_2
1901: I0815 06:16:21.503206 29740 scope.cc:202] Create variable 0x476113901723702581503157483_inner_var_3
1901: I0815 06:16:21.503216 29740 scope.cc:202] Create variable 0x476113901723702581503157483_inner_var_4
1901: I0815 06:16:21.503228 29740 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:16:21.503569 29740 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:16:21.503587 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.503590 29740 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x476112f0
1901: 1 -> 0x476113901723702581503157483_inner_var_1 -> 0x47611370
1901: 2 -> 0x476113901723702581503157483_inner_var_2 -> 0x475eeea0
1901: 3 -> 0x476113901723702581503157483_inner_var_3 -> 0x475ebf90
1901: 4 -> 0x476113901723702581503157483_inner_var_4 -> 0x475eed90
1901: 5 -> fetch0@fetch -> 0x474dd240
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 06:16:21.504220 29796 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:16:21.504431 29797 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:16:21.504495 29798 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:16:21.504554 29799 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:16:21.504644 29800 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:16:21.504738 29801 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:16:21.504771 29801 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476113901723702581503157483_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.504794 29801 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476113901723702581503157483_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:16:21.504820 29801 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476113901723702581503157483_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476113901723702581503157483_inner_var_3:[dtype=;place=;dim=;lod={};, 0x476113901723702581503157483_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.505226 29801 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x476113901723702581503157483_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x476113901723702581503157483_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x476113901723702581503157483_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.505286 29800 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476113901723702581503157483_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476113901723702581503157483_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.505317 29800 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.505369 29800 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x476113901723702581503157483_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x476113901723702581503157483_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.505395 29800 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x476113901723702581503157483_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.505412 29800 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.505424 29800 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x476113901723702581503157483_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.505452 29740 pir_interpreter.cc:1766] main_thread_blocker_(0x47611500) got event_name: TaskCompletion
1901: I0815 06:16:21.505474 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.505656 29740 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0815 06:16:21.556905 29790 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 13695473914486622626 to 6888474867725865289 , after update, data is {current : 2, peak : 4}.
1901: I0815 06:16:21.556918 29790 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 13695473914486622626 to 12714286817720195566 , after update, data is {current : 0, peak : 330659}.
1901: I0815 06:16:21.557077 29794 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 17839995290594080217 to 6888474867725865289 , after update, data is {current : 6, peak : 6}.
1901: I0815 06:16:21.557262 29795 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 9460661039955349681 to 6888474867725865289 , after update, data is {current : 6, peak : 16}.
1901: I0815 06:16:21.557273 29795 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 9460661039955349681 to 12714286817720195566 , after update, data is {current : 18, peak : 330659}.
1901: I0815 06:16:21.557469 29796 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 1187627208347648137 to 6888474867725865289 , after update, data is {current : 4, peak : 16}.
1901: I0815 06:16:21.557477 29796 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 1187627208347648137 to 12714286817720195566 , after update, data is {current : 0, peak : 330659}.
1901: I0815 06:16:21.557633 29800 thread_data_registry.h:135] Add data {current : 4, peak : 16} from thread 6888474867725865289 to 12714286817720195566 , after update, data is {current : 4, peak : 16}.
1901: I0815 06:16:21.557812 29801 thread_data_registry.h:135] Add data {current : 4, peak : 16} from thread 12714286817720195566 to 12985008308672066367 , after update, data is {current : 2, peak : 16}.
1901: I0815 06:16:21.557821 29801 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 12714286817720195566 to 12985008308672066367 , after update, data is {current : -18, peak : 330659}.
1901: I0815 06:16:21.561909 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.562022 29740 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7f4427627c00), and remaining 0
1901: I0815 06:16:21.562135 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.562175 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.562461 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.563424 29740 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.563513 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.563541 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.563727 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.564482 29740 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.564563 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.564594 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.564771 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.565451 29740 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.565533 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.565562 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.565740 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0815 06:16:21.566493 29740 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.566555 29740 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f4427618e00), and remaining 0
1901: I0815 06:16:21.566613 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.566639 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.567163 29740 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.567237 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.567265 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.567785 29740 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.567857 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.567883 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.568352 29740 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.568424 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.568451 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.569077 29740 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.569152 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.569180 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.569407 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.570094 29740 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.570174 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.570201 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.570391 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.571127 29740 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.571208 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.571235 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.571447 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.572111 29740 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.572191 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.572219 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.572408 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.573128 29740 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.573208 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.573236 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.573465 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.574162 29740 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.574244 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.574271 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.574465 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.575227 29740 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.575322 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.575352 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.575538 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.576258 29740 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.576351 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.576380 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.576556 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.577316 29740 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.577395 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.577425 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.577626 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.578306 29740 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.578389 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.578418 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.578598 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.579169 29740 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.579239 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.579267 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.579443 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.580175 29740 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.580250 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.580277 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.580461 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.581166 29740 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.581244 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.581272 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.581560 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0815 06:16:21.584272 29740 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.584362 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.584393 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.584605 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.586038 29740 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.586122 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.586151 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.586391 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.587785 29740 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.587867 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.587896 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.588104 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.589416 29740 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.589498 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.589529 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.589792 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.591099 29740 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.591182 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.591212 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.591430 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.592806 29740 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.592888 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.592917 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.593124 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.594516 29740 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.594597 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.594626 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.594835 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.596133 29740 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.596216 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.596246 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.596513 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.597918 29740 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.598002 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.598030 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.598246 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.599552 29740 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.599634 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.599663 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.599898 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.601198 29740 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.601280 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.601318 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.601528 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.602900 29740 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.602983 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.603013 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.603221 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.604533 29740 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.604617 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.604645 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.604851 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.606213 29740 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.606297 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.606335 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.606546 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.607839 29740 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.607923 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.607951 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.608157 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.609445 29740 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.609527 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.609555 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.609763 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.610561 29740 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.610641 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.610668 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.610869 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.613803 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.613832 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.614723 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.614748 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.615586 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.615609 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.616458 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.616482 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.617290 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.617321 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.620049 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.620666 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.621259 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.621858 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.622440 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.623311 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.623328 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.623335 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.628574 29740 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:16:21.628661 29740 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:16:21.628676 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.628685 29740 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4793fe00 type is 7
1901: I0815 06:16:21.628695 29740 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x474dfef0 type is 9
1901: I0815 06:16:21.628705 29740 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x474e0470 type is 10
1901: I0815 06:16:21.628711 29740 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 06:16:21.628717 29740 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x4793f0c0 type is 7
1901: I0815 06:16:21.628726 29740 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 06:16:21.628731 29740 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x4793fcb0 type is 7
1901: I0815 06:16:21.628737 29740 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 06:16:21.628743 29740 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x474ac3f0 type is 7
1901: I0815 06:16:21.628752 29740 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 06:16:21.628757 29740 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x4793fe80 type is 7
1901: I0815 06:16:21.628767 29740 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 06:16:21.628772 29740 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x4793ea40 type is 7
1901: I0815 06:16:21.628779 29740 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 06:16:21.628787 29740 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x478d0580 type is 7
1901: I0815 06:16:21.628793 29740 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 06:16:21.628798 29740 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x478d0790 type is 7
1901: I0815 06:16:21.628804 29740 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 06:16:21.628811 29740 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x478d09f0 type is 7
1901: I0815 06:16:21.628819 29740 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 06:16:21.628823 29740 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x478d0c50 type is 7
1901: I0815 06:16:21.628829 29740 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 06:16:21.628836 29740 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x478d0eb0 type is 7
1901: I0815 06:16:21.628978 29740 interpreter_util.cc:594] Static build: 0
1901: I0815 06:16:21.628986 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.628991 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.628998 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.629065 29740 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.629084 29740 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.629159 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.629171 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.629196 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.629412 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.629629 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.629644 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.629666 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.629822 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.630028 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.630041 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.630062 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.630213 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.630412 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.630427 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.630447 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.630632 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.630860 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.630875 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.630897 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.631074 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.631285 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.631307 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.631331 29740 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.631340 29740 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x479560b0Variable Type 7
1901: I0815 06:16:21.631364 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.631386 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.631417 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.631438 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.631489 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.631513 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:16:21.631568 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.631582 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.631603 29740 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.631611 29740 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x478d1580Variable Type 7
1901: I0815 06:16:21.631629 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.631646 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.631670 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.631688 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.631728 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.631758 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:16:21.631814 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.631826 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.631847 29740 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.631856 29740 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x479f7e20Variable Type 7
1901: I0815 06:16:21.631873 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.631891 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.631912 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.631930 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.631969 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.631986 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 06:16:21.632038 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.632050 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.632066 29740 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.632076 29740 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47955ff0Variable Type 7
1901: I0815 06:16:21.632091 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.632107 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.632128 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.632143 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.632179 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.632196 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 06:16:21.632243 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.632256 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.632272 29740 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.632282 29740 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x479f8000Variable Type 7
1901: I0815 06:16:21.632297 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.632323 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.632344 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.632362 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.632401 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.632419 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 06:16:21.633066 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.633105 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.633132 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.633158 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.633183 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 06:16:21.640169 29740 pir_interpreter.cc:161] PirInterpreter(): 0x478d15a0 on Place(gpu:0)
1901: I0815 06:16:21.640208 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.640235 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_1
1901: I0815 06:16:21.640250 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_2
1901: I0815 06:16:21.640265 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_3
1901: I0815 06:16:21.640280 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_4
1901: I0815 06:16:21.640292 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_5
1901: I0815 06:16:21.640314 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_6
1901: I0815 06:16:21.640327 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_7
1901: I0815 06:16:21.640340 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_8
1901: I0815 06:16:21.640353 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_9
1901: I0815 06:16:21.640367 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_10
1901: I0815 06:16:21.640380 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_11
1901: I0815 06:16:21.640395 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_12
1901: I0815 06:16:21.640409 29740 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:16:21.640427 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_14
1901: I0815 06:16:21.640440 29740 scope.cc:202] Create variable fetch1@fetch
1901: I0815 06:16:21.640455 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_16
1901: I0815 06:16:21.640468 29740 scope.cc:202] Create variable fetch2@fetch
1901: I0815 06:16:21.640481 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_18
1901: I0815 06:16:21.640494 29740 scope.cc:202] Create variable fetch3@fetch
1901: I0815 06:16:21.640508 29740 scope.cc:202] Create variable 0x478d15a01723702581640197702_inner_var_20
1901: I0815 06:16:21.640522 29740 scope.cc:202] Create variable fetch4@fetch
1901: I0815 06:16:21.640862 29740 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:16:21.640877 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.640882 29740 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x479f9950
1901: 1 -> 0x478d15a01723702581640197702_inner_var_1 -> 0x452b91f0
1901: 2 -> 0x478d15a01723702581640197702_inner_var_2 -> 0x452b9af0
1901: 3 -> 0x478d15a01723702581640197702_inner_var_3 -> 0x4793e890
1901: 4 -> 0x478d15a01723702581640197702_inner_var_4 -> 0x47921e10
1901: 5 -> 0x478d15a01723702581640197702_inner_var_5 -> 0x479f67f0
1901: 6 -> 0x478d15a01723702581640197702_inner_var_6 -> 0x452b9050
1901: 7 -> 0x478d15a01723702581640197702_inner_var_7 -> 0x478d11d0
1901: 8 -> 0x478d15a01723702581640197702_inner_var_8 -> 0x479f9e40
1901: 9 -> 0x478d15a01723702581640197702_inner_var_9 -> 0x479fa260
1901: 10 -> 0x478d15a01723702581640197702_inner_var_10 -> 0x4793f530
1901: 11 -> 0x478d15a01723702581640197702_inner_var_11 -> 0x4793f950
1901: 12 -> 0x478d15a01723702581640197702_inner_var_12 -> 0x47921ca0
1901: 13 -> fetch0@fetch -> 0x478f7560
1901: 14 -> 0x478d15a01723702581640197702_inner_var_14 -> 0x478f7160
1901: 15 -> fetch1@fetch -> 0x47602730
1901: 16 -> 0x478d15a01723702581640197702_inner_var_16 -> 0x478f7540
1901: 17 -> fetch2@fetch -> 0x47a2fe20
1901: 18 -> 0x478d15a01723702581640197702_inner_var_18 -> 0x47602710
1901: 19 -> fetch3@fetch -> 0x47a4a6a0
1901: 20 -> 0x478d15a01723702581640197702_inner_var_20 -> 0x47a2fe00
1901: 21 -> fetch4@fetch -> 0x479a7d20
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 06:16:21.642525 29802 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:16:21.642549 29803 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:16:21.642573 29804 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:16:21.642604 29805 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:16:21.642647 29806 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:16:21.642673 29806 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.642714 29806 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 06:16:21.642760 29806 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_3:[dtype=;place=;dim=;lod={};, 0x478d15a01723702581640197702_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.642946 29806 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.643097 29806 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x478d15a01723702581640197702_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.643147 29806 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_5:[dtype=;place=;dim=;lod={};, 0x478d15a01723702581640197702_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643163 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643189 29805 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.643249 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.643329 29806 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.643316 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643350 29805 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.643368 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.643478 29806 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x478d15a01723702581640197702_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.643520 29806 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_7:[dtype=;place=;dim=;lod={};, 0x478d15a01723702581640197702_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643527 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643540 29805 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.643599 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.643648 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643663 29805 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.643673 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.643693 29806 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.643837 29806 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x478d15a01723702581640197702_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.643877 29806 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_9:[dtype=;place=;dim=;lod={};, 0x478d15a01723702581640197702_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643883 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643898 29805 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.643940 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.643975 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.643991 29805 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.644001 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.644049 29806 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.644201 29806 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x478d15a01723702581640197702_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.644243 29806 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_11:[dtype=;place=;dim=;lod={};, 0x478d15a01723702581640197702_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.644249 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.644263 29805 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.644294 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.644335 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.644351 29805 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.644361 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.644413 29806 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.644564 29806 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x478d15a01723702581640197702_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x478d15a01723702581640197702_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.644609 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.644624 29805 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.644651 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x478d15a01723702581640197702_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x478d15a01723702581640197702_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.644685 29805 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.644698 29805 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.644709 29805 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x478d15a01723702581640197702_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.644737 29740 pir_interpreter.cc:1766] main_thread_blocker_(0x478d1710) got event_name: TaskCompletion
1901: I0815 06:16:21.644760 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.644790 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.644804 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.644819 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.644833 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.647037 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.647140 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.647173 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.647400 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.647516 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x479faa80)  to GradNodeAccumulation (addr: 0x452b2450)
1901: I0815 06:16:21.647655 29740 backward.cc:459] Run in Grad
1901: I0815 06:16:21.647672 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.647732 29740 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x479faa80 to ptr: 0x474cd780
1901: I0815 06:16:21.647745 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.647796 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.647840 29740 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x452b2450 to ptr: 0x475ec7a0
1901: I0815 06:16:21.647871 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x474cd780
1901: I0815 06:16:21.647881 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.647918 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.647997 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.648007 29740 backward.cc:335] Node: NanmedianGradNode addr:0x474cd780, Found pending node: GradNodeAccumulation addr: 0x475ec7a0
1901: I0815 06:16:21.648013 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.648043 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x475ec7a0
1901: I0815 06:16:21.648051 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.648056 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.648065 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.648073 29740 backward.cc:435] Finish Backward
1901: I0815 06:16:21.648874 29740 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 06:16:21.648892 29740 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 06:16:21.649009 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.649036 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.649206 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.649291 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x474cd780)  to GradNodeAccumulation (addr: 0x452b2450)
1901: I0815 06:16:21.649405 29740 backward.cc:442] Run in Backward
1901: I0815 06:16:21.649415 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.649422 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.649462 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.649494 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x474cd780
1901: I0815 06:16:21.649504 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.649538 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.649605 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.649637 29740 backward.cc:335] Node: NanmedianGradNode addr:0x474cd780, Found pending node: GradNodeAccumulation addr: 0x452b2450
1901: I0815 06:16:21.649646 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.649669 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x452b2450
1901: I0815 06:16:21.649677 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.649683 29740 accumulation_node.cc:40] Move Tensor ptr: 0x479172f0
1901: I0815 06:16:21.649688 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.649691 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.651543 29740 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0815 06:16:21.652099 29740 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.652230 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.652257 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.652508 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47922bb0)  to GradNodeAccumulation (addr: 0x1a983080)
1901: I0815 06:16:21.652621 29740 backward.cc:442] Run in Backward
1901: I0815 06:16:21.652629 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.652637 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.652688 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.652715 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47922bb0
1901: I0815 06:16:21.652724 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.652757 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.652817 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.652845 29740 backward.cc:335] Node: NanmedianGradNode addr:0x47922bb0, Found pending node: GradNodeAccumulation addr: 0x1a983080
1901: I0815 06:16:21.652855 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.652876 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a983080
1901: I0815 06:16:21.652884 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.652889 29740 accumulation_node.cc:40] Move Tensor ptr: 0x474e84c0
1901: I0815 06:16:21.652894 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.652899 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.654089 29740 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.654184 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.654214 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.654474 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.654587 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x474cd780)  to GradNodeAccumulation (addr: 0x1a983080)
1901: I0815 06:16:21.654712 29740 backward.cc:459] Run in Grad
1901: I0815 06:16:21.654723 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.654740 29740 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x474cd780 to ptr: 0x478d3940
1901: I0815 06:16:21.654749 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.654788 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.654817 29740 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1a983080 to ptr: 0x475ec7a0
1901: I0815 06:16:21.654841 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x478d3940
1901: I0815 06:16:21.654850 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.654883 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.655042 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.655052 29740 backward.cc:335] Node: NanmedianGradNode addr:0x478d3940, Found pending node: GradNodeAccumulation addr: 0x475ec7a0
1901: I0815 06:16:21.655058 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.655078 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x475ec7a0
1901: I0815 06:16:21.655087 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.655092 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.655098 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.655105 29740 backward.cc:435] Finish Backward
1901: I0815 06:16:21.656100 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.656188 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.656216 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.656414 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.658008 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.658069 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.658094 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.666930 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.666960 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.668017 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.668040 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.668929 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.669019 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.669049 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.669241 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.669858 29740 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.669937 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.669963 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.670140 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.670761 29740 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.670836 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.670862 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.671031 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.671638 29740 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.671713 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.671741 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.671913 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.672523 29740 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.672577 29740 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f4427619200), and remaining 0
1901: I0815 06:16:21.672633 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.672659 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.673138 29740 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.673208 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.673234 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.673753 29740 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.673823 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.673849 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.674336 29740 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.674407 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.674432 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.674929 29740 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.674996 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.675021 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.675207 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.675774 29740 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.675848 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.675874 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.676040 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.676678 29740 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.676751 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.676779 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.676941 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.677526 29740 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.677601 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.677628 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.677799 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.678439 29740 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.678511 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.678539 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.678704 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.679284 29740 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.679368 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.679395 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.679567 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.680202 29740 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.680279 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.680315 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.680477 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.681097 29740 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.681170 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.681196 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.681370 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.682017 29740 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.682090 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.682116 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.682282 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.682857 29740 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.682932 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.682958 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.683125 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.683645 29740 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.683696 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.683717 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.683835 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.684438 29740 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.684501 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.684525 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.684670 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.685322 29740 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.685397 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.685423 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.685621 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.686290 29740 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.686367 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.686390 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.686558 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.687214 29740 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.687280 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.687314 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.687489 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.688114 29740 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.688179 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.688203 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.688382 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.689009 29740 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.689077 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.689101 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.689282 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.689890 29740 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.689958 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.689982 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.690150 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.690760 29740 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.690827 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.690852 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.691023 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.691653 29740 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.691721 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.691745 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.691917 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.692549 29740 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.692617 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.692642 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.692823 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.693441 29740 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.693511 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.693534 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.693706 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.694294 29740 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.694370 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.694394 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.694571 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.695163 29740 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.695230 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.695253 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.695443 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.696033 29740 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.696099 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.696125 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.696290 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.696893 29740 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.696960 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.696985 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.697149 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.697762 29740 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.697829 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.697852 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.698030 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.698714 29740 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.698788 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.698815 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.699004 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.699584 29740 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.699651 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.699674 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.699846 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.700580 29740 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.700656 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.700683 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.700871 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.702979 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.703002 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.703649 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.703667 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.704257 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.704274 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.704890 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.704907 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.705917 29805 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 13695473914486622626 to 2019958634318820669 , after update, data is {current : 0, peak : 1260}.
1901: I0815 06:16:21.705935 29805 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 13695473914486622626 to 2019958634318820669 , after update, data is {current : 20, peak : 24}.
1901: I0815 06:16:21.706310 29806 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 2019958634318820669 to 15619951352442962525 , after update, data is {current : 0, peak : 260}.
1901: I0815 06:16:21.706327 29806 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 2019958634318820669 to 12985008308672066367 , after update, data is {current : 22, peak : 24}.
1901: I0815 06:16:21.706332 29806 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 2019958634318820669 to 12985008308672066367 , after update, data is {current : -18, peak : 330659}.
1901: I0815 06:16:21.706902 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.706921 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.708993 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.709432 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.709851 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.710260 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.710687 29740 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:16:21.711410 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.711424 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.711429 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.715402 29740 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:16:21.715451 29740 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:16:21.715461 29740 scope.cc:202] Create variable X
1901: I0815 06:16:21.715466 29740 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47a2b8a0 type is 7
1901: I0815 06:16:21.715472 29740 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x474dfef0 type is 9
1901: I0815 06:16:21.715479 29740 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x474e0470 type is 10
1901: I0815 06:16:21.715484 29740 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 06:16:21.715488 29740 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x47a2ab30 type is 7
1901: I0815 06:16:21.715493 29740 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 06:16:21.715497 29740 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x47a2b880 type is 7
1901: I0815 06:16:21.715502 29740 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 06:16:21.715504 29740 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x47a2a2b0 type is 7
1901: I0815 06:16:21.715510 29740 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 06:16:21.715515 29740 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x47a2a510 type is 7
1901: I0815 06:16:21.715520 29740 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 06:16:21.715523 29740 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x1a99e560 type is 7
1901: I0815 06:16:21.715529 29740 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 06:16:21.715533 29740 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x1a99e850 type is 7
1901: I0815 06:16:21.715536 29740 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 06:16:21.715540 29740 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x1a99ea60 type is 7
1901: I0815 06:16:21.715544 29740 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 06:16:21.715548 29740 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x1a99ecc0 type is 7
1901: I0815 06:16:21.715551 29740 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 06:16:21.715554 29740 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x1a99ef20 type is 7
1901: I0815 06:16:21.715559 29740 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 06:16:21.715562 29740 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x1a99f180 type is 7
1901: I0815 06:16:21.715680 29740 interpreter_util.cc:594] Static build: 0
1901: I0815 06:16:21.715687 29740 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:16:21.715691 29740 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:16:21.715695 29740 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:16:21.715752 29740 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.715767 29740 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.715824 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.715833 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.715848 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.716019 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.716204 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.716215 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.716229 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.716349 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.716523 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.716533 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.716548 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.716652 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.716820 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.716830 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.716842 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.716967 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.717155 29740 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.717164 29740 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.717178 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.717306 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.717485 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.717496 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.717511 29740 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.717517 29740 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47437300Variable Type 7
1901: I0815 06:16:21.717535 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.717552 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.717573 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.717588 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.717626 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.717643 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:16:21.717679 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.717689 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.717701 29740 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.717707 29740 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4791bef0Variable Type 7
1901: I0815 06:16:21.717721 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.717733 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.717748 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.717761 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.717789 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.717813 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:16:21.717852 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.717860 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.717873 29740 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.717878 29740 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4791c9d0Variable Type 7
1901: I0815 06:16:21.717891 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.717902 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.717916 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.717927 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.717955 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.717967 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 06:16:21.718003 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.718010 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.718020 29740 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.718027 29740 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474c83f0Variable Type 7
1901: I0815 06:16:21.718039 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.718050 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.718065 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.718076 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.718103 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.718114 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 06:16:21.718147 29740 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.718154 29740 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:16:21.718165 29740 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:16:21.718171 29740 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4791dde0Variable Type 7
1901: I0815 06:16:21.718183 29740 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:16:21.718194 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.718207 29740 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:16:21.718219 29740 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.718246 29740 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:16:21.718257 29740 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 06:16:21.718792 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.718822 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.718839 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.718856 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:16:21.718873 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 06:16:21.724337 29740 pir_interpreter.cc:161] PirInterpreter(): 0x47929ef0 on Place(gpu:0)
1901: I0815 06:16:21.724373 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_1
1901: I0815 06:16:21.724385 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_2
1901: I0815 06:16:21.724395 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_3
1901: I0815 06:16:21.724402 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_4
1901: I0815 06:16:21.724411 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_5
1901: I0815 06:16:21.724417 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_6
1901: I0815 06:16:21.724426 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_7
1901: I0815 06:16:21.724432 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_8
1901: I0815 06:16:21.724442 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_9
1901: I0815 06:16:21.724448 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_10
1901: I0815 06:16:21.724457 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_11
1901: I0815 06:16:21.724463 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_12
1901: I0815 06:16:21.724478 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_14
1901: I0815 06:16:21.724490 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_16
1901: I0815 06:16:21.724501 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_18
1901: I0815 06:16:21.724510 29740 scope.cc:202] Create variable 0x47929ef01723702581724358196_inner_var_20
1901: I0815 06:16:21.724757 29740 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x479a8050
1901: 1 -> 0x47929ef01723702581724358196_inner_var_1 -> 0x479f5fa0
1901: 2 -> 0x47929ef01723702581724358196_inner_var_2 -> 0x479d25f0
1901: 3 -> 0x47929ef01723702581724358196_inner_var_3 -> 0x479d22b0
1901: 4 -> 0x47929ef01723702581724358196_inner_var_4 -> 0x479f5f10
1901: 5 -> 0x47929ef01723702581724358196_inner_var_5 -> 0x479a9500
1901: 6 -> 0x47929ef01723702581724358196_inner_var_6 -> 0x479a9640
1901: 7 -> 0x47929ef01723702581724358196_inner_var_7 -> 0x4742e3e0
1901: 8 -> 0x47929ef01723702581724358196_inner_var_8 -> 0x452b6840
1901: 9 -> 0x47929ef01723702581724358196_inner_var_9 -> 0x47605bc0
1901: 10 -> 0x47929ef01723702581724358196_inner_var_10 -> 0x47914bc0
1901: 11 -> 0x47929ef01723702581724358196_inner_var_11 -> 0x47a47920
1901: 12 -> 0x47929ef01723702581724358196_inner_var_12 -> 0x479f5e30
1901: 13 -> fetch0@fetch -> 0x478f7560
1901: 14 -> 0x47929ef01723702581724358196_inner_var_14 -> 0x478f3240
1901: 15 -> fetch1@fetch -> 0x47602730
1901: 16 -> 0x47929ef01723702581724358196_inner_var_16 -> 0x4790cd40
1901: 17 -> fetch2@fetch -> 0x47a2fe20
1901: 18 -> 0x47929ef01723702581724358196_inner_var_18 -> 0x474d18f0
1901: 19 -> fetch3@fetch -> 0x47a4a6a0
1901: 20 -> 0x47929ef01723702581724358196_inner_var_20 -> 0x47a2bca0
1901: 21 -> fetch4@fetch -> 0x479a7d20
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 06:16:21.725978 29807 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:16:21.726027 29809 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:16:21.726064 29810 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:16:21.726083 29811 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:16:21.726117 29811 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.726159 29811 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 06:16:21.726200 29811 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47929ef01723702581724358196_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.726397 29811 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.726553 29811 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47929ef01723702581724358196_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.726603 29811 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_5:[dtype=;place=;dim=;lod={};, 0x47929ef01723702581724358196_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.726635 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.726682 29810 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.726718 29811 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.726773 29808 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:16:21.726774 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.726914 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.726940 29810 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.726948 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.726990 29811 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47929ef01723702581724358196_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.727082 29811 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_7:[dtype=;place=;dim=;lod={};, 0x47929ef01723702581724358196_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.727087 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.727111 29810 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.727144 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.727185 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.727202 29810 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.727207 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.727324 29811 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.727474 29811 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47929ef01723702581724358196_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.727521 29811 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_9:[dtype=;place=;dim=;lod={};, 0x47929ef01723702581724358196_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.727527 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.727543 29810 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.727588 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.727674 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.727691 29810 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.727696 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.727718 29811 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.727872 29811 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47929ef01723702581724358196_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.727916 29811 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_11:[dtype=;place=;dim=;lod={};, 0x47929ef01723702581724358196_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.727922 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.727936 29810 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.727974 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.728018 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.728036 29810 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.728041 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.728102 29811 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.728255 29811 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47929ef01723702581724358196_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47929ef01723702581724358196_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:16:21.728307 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:16:21.728324 29810 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:16:21.728349 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47929ef01723702581724358196_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47929ef01723702581724358196_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.728381 29810 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.728399 29810 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.728403 29810 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47929ef01723702581724358196_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:16:21.728433 29740 pir_interpreter.cc:1766] main_thread_blocker_(0x4792a060) got event_name: TaskCompletion
1901: I0815 06:16:21.728456 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.728482 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.728492 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.728502 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.728513 29740 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:16:21.730181 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a983080 for it.
1901: I0815 06:16:21.730270 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.730309 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.730508 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.730603 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x474d1f70)  to GradNodeAccumulation (addr: 0x1a983080)
1901: I0815 06:16:21.730722 29740 backward.cc:459] Run in Grad
1901: I0815 06:16:21.730732 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.730751 29740 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x474d1f70 to ptr: 0x479d4a50
1901: I0815 06:16:21.730762 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.730795 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.730821 29740 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1a983080 to ptr: 0x475ec7a0
1901: I0815 06:16:21.730844 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x479d4a50
1901: I0815 06:16:21.730851 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.730885 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.730952 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.730959 29740 backward.cc:335] Node: NanmedianGradNode addr:0x479d4a50, Found pending node: GradNodeAccumulation addr: 0x475ec7a0
1901: I0815 06:16:21.730965 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.730991 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x475ec7a0
1901: I0815 06:16:21.730998 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.731003 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.731009 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.731014 29740 backward.cc:435] Finish Backward
1901: I0815 06:16:21.731688 29740 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 06:16:21.731703 29740 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 06:16:21.731787 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.731810 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.731953 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.732026 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x474d1f70)  to GradNodeAccumulation (addr: 0x1a983080)
1901: I0815 06:16:21.732110 29740 backward.cc:442] Run in Backward
1901: I0815 06:16:21.732117 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.732124 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.732154 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.732177 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x474d1f70
1901: I0815 06:16:21.732184 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.732213 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.732270 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.732293 29740 backward.cc:335] Node: NanmedianGradNode addr:0x474d1f70, Found pending node: GradNodeAccumulation addr: 0x1a983080
1901: I0815 06:16:21.732311 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.732331 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a983080
1901: I0815 06:16:21.732337 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.732342 29740 accumulation_node.cc:40] Move Tensor ptr: 0x47933880
1901: I0815 06:16:21.732347 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.732352 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.732801 29740 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.732908 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.732932 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.733094 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x479d4a50)  to GradNodeAccumulation (addr: 0x452b2450)
1901: I0815 06:16:21.733192 29740 backward.cc:442] Run in Backward
1901: I0815 06:16:21.733201 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.733207 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.733238 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.733260 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x479d4a50
1901: I0815 06:16:21.733268 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.733294 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.733347 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.733371 29740 backward.cc:335] Node: NanmedianGradNode addr:0x479d4a50, Found pending node: GradNodeAccumulation addr: 0x452b2450
1901: I0815 06:16:21.733379 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.733398 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x452b2450
1901: I0815 06:16:21.733405 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.733410 29740 accumulation_node.cc:40] Move Tensor ptr: 0x4790d030
1901: I0815 06:16:21.733413 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.733417 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.734114 29740 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.734192 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.734216 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.734416 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.734508 29740 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x474d1f70)  to GradNodeAccumulation (addr: 0x452b2450)
1901: I0815 06:16:21.734622 29740 backward.cc:459] Run in Grad
1901: I0815 06:16:21.734632 29740 backward.cc:113] Start Backward
1901: I0815 06:16:21.734645 29740 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x474d1f70 to ptr: 0x47952380
1901: I0815 06:16:21.734653 29740 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:16:21.734683 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.734704 29740 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x452b2450 to ptr: 0x475ec7a0
1901: I0815 06:16:21.734723 29740 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47952380
1901: I0815 06:16:21.734730 29740 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:16:21.734759 29740 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.734877 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.734886 29740 backward.cc:335] Node: NanmedianGradNode addr:0x47952380, Found pending node: GradNodeAccumulation addr: 0x475ec7a0
1901: I0815 06:16:21.734891 29740 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:16:21.734907 29740 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x475ec7a0
1901: I0815 06:16:21.734915 29740 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.734920 29740 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:16:21.734925 29740 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:16:21.734930 29740 backward.cc:435] Finish Backward
1901: I0815 06:16:21.735833 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.735908 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.735934 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.736094 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.737458 29740 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x452b2450 for it.
1901: I0815 06:16:21.737502 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.737520 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.739634 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.739658 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.740582 29740 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:16:21.740604 29740 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:16:21.741360 29740 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 06:16:21.741377 29740 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 06:16:21.741473 29740 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 06:16:21.741480 29740 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 06:16:21.741541 29740 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 06:16:21.741549 29740 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 06:16:21.741592 29740 dygraph_functions.cc:82227] Running AD API: arange
1901: I0815 06:16:21.741626 29740 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.741768 29740 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0815 06:16:21.741791 29740 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.741809 29740 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0815 06:16:21.741868 29740 dygraph_functions.cc:14224] Running AD API: cast
1901: I0815 06:16:21.741884 29740 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.741954 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:16:21.742013 29740 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:16:21.742028 29740 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:16:21.742210 29740 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: test_nanmedian failed
1901:  ss.E.................
1901: ======================================================================
1901: ERROR: test_check_output (test_nanmedian.TestNanmedianFP16Op)
1901: ----------------------------------------------------------------------
1901: Traceback (most recent call last):
1901:   File "/home/code/Paddle/build/test/legacy_test/test_nanmedian.py", line 617, in test_check_output
1901:     self.check_output(check_pir=True)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2934, in check_output
1901:     res = self.check_output_with_place(
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2786, in check_output_with_place
1901:     symbol_checker.check()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2637, in check
1901:     self.infer_and_compare_symbol()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2645, in infer_and_compare_symbol
1901:     self.op_test._infer_and_compare_symbol(place)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1712, in _infer_and_compare_symbol
1901:     self._compare_symbol(program, outs)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1633, in _compare_symbol
1901:     shape_analysis.get_shape_or_data_for_var(
1901: RuntimeError: (PreconditionNotMet) The op operand index [1] must less than operands size[1].
1901:   [Hint: Expected index < num_operands_, but received index:1 >= num_operands_:1.] (at /home/code/Paddle/paddle/pir/src/core/operation.cc:420)
1901: 
1901: 
1901: ----------------------------------------------------------------------
1901: Ran 21 tests in 2.980s
1901: 
1901: FAILED (errors=1, skipped=2)
1901: 
1901: I0815 06:16:21.743475 29740 mmap_allocator.cc:348] PID: 29740, MemoryMapFdSet: set size - 0
1901: I0815 06:16:21.755856 29740 mmap_allocator.cc:348] PID: 29740, MemoryMapFdSet: set size - 0
1901: I0815 06:16:21.814667 29810 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 12377132455205941448 to 16659862340837710294 , after update, data is {current : 0, peak : 1252}.
1901: I0815 06:16:21.814694 29810 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 12377132455205941448 to 16659862340837710294 , after update, data is {current : 0, peak : 16}.
1901: I0815 06:16:21.815001 29811 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 16659862340837710294 to 15619951352442962525 , after update, data is {current : 0, peak : 260}.
1901: I0815 06:16:21.815016 29811 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 16659862340837710294 to 12985008308672066367 , after update, data is {current : 22, peak : 24}.
1901: I0815 06:16:21.815021 29811 thread_data_registry.h:135] Add data {current : 0, peak : 1252} from thread 16659862340837710294 to 12985008308672066367 , after update, data is {current : -18, peak : 330659}.
1901: I0815 06:16:21.815677 29784 thread_data_registry.h:135] Add data {current : 22, peak : 24} from thread 12985008308672066367 to 7210426564415199836 , after update, data is {current : 26, peak : 26}.
1901: I0815 06:16:21.815708 29784 thread_data_registry.h:135] Add data {current : -18, peak : 330659} from thread 12985008308672066367 to 1935202360547024378 , after update, data is {current : 0, peak : 330659}.
1901: I0815 06:16:21.815991 29788 thread_data_registry.h:135] Add data {current : 26, peak : 26} from thread 7210426564415199836 to 1935202360547024378 , after update, data is {current : 26, peak : 26}.
1901: I0815 06:16:21.816171 29789 thread_data_registry.h:135] Add data {current : 26, peak : 26} from thread 1935202360547024378 to 15619951352442962525 , after update, data is {current : 20026, peak : 40004}.
1901: I0815 06:16:21.816187 29789 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 1935202360547024378 to 15619951352442962525 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 06:16:21.953403 29740 mmap_allocator.cc:348] PID: 29740, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................***Failed   12.81 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  12.99 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
