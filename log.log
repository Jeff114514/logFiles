UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0814 08:12:25.609378 31008 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0814 08:12:26.518870 31008 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=accuracy_check_rtol_fp16,allreduce_record_one_event,new_executor_static_build,new_executor_use_local_scope,custom_device_mem_record,save_static_runtime_data,check_nan_inf,eager_delete_scope,use_system_allocator,gpugraph_force_device_batch_num_equal,gpugraph_slot_feasign_max_num,accuracy_check_rtol_bf16,get_host_by_name_time,fast_eager_deletion_mode,cublaslt_exhaustive_search_times,nccl_dir,gpugraph_debug_gpu_memory,pir_broadcast_tree_limit,tracer_onednn_ops_on,manually_trans_conv_filter,logging_pir_py_code_dir,graph_neighbor_size_percent,gpugraph_offload_gather_copy_maxsize,use_fast_math,async_trace_count,cudnn_exhaustive_search,ir_inplace_kernel_blacklist,print_ir,prim_forward_blacklist,sync_after_alloc,check_kernel_launch,multiple_of_cupti_buffer_size,cudnn_deterministic,gpugraph_sparse_table_storage_mode,apply_pass_to_program,cusparselt_dir,nvidia_package_dir,fraction_of_cpu_memory_to_use,reader_queue_speed_test_mode,cudnn_dir,enable_cinn_auto_tune,enable_tracker_all2all,enable_dump_main_program,low_precision_op_list,fuse_parameter_groups_size,benchmark,gemm_use_half_precision_compute_type,tracer_profile_fname,enable_cse_in_dy2st,logging_pir_py_code_int_tensor_element_limit,lapack_dir,accuracy_check_atol_fp16,alloc_fill_value,gpugraph_load_node_list_into_hbm,local_exe_sub_scope_limit,executor_log_deps_every_microseconds,gpugraph_enable_gpu_direct_access,use_cinn,prim_check_ops,gpu_memory_limit_mb,tracer_onednn_ops_off,prim_enabled,enable_cinn_accuracy_check,enable_cinn_compile_cache,enable_record_memory,print_allocator_trace_info,use_mkldnn,mklml_dir,embedding_deterministic,cudnn_exhaustive_search_times,enable_dependency_builder_debug_info,enable_neighbor_list_use_uva,pir_apply_shape_optimization_pass,reallocate_gpu_memory_in_mb,cinn_subgraph_graphviz_dir,enable_pir_in_executor_trace_run,gpugraph_offload_param_extends,free_idle_chunk,auto_free_cudagraph_allocations_on_launch,fuse_parameter_memory_size,new_executor_serial_run,enable_auto_rdma_trans,cache_inference_while_scope,static_executor_perfstat_filepath,win_cuda_bin_dir,deny_cinn_ops,add_dependency_for_communication_op,use_cuda_managed_memory,cuda_malloc_async_pool_memory_throttle_ratio,enable_graph_multi_node_sampling,jit_engine_type,logging_pir_py_code_dump_symbolic_dims,enable_pir_api,cublaslt_device_best_config,allow_cinn_ops,use_cuda_malloc_async_allocator,enable_all2all_use_fp16,enable_unused_var_check,prim_enable_dynamic,gpugraph_enable_print_op_debug,cuda_dir,gpu_allocator_retry_time,pinned_memory_as_cpu_backend,sort_sum_gradient,dist_threadpool_size,static_runtime_data_save_path,gpugraph_enable_segment_merge_grads,prim_skip_dynamic,pir_debug,logging_trunc_pir_py_code,search_cache_max_number,max_inplace_grad_add,cse_max_count,inner_op_parallelism,gpugraph_enable_hbm_table_collision_stat,accuracy_check_atol_fp32,run_kp_kernel,curand_dir,use_shm_cache,prim_forward,fleet_executor_with_standalone,tensorrt_dir,einsum_opt,use_xqa_optim,graph_embedding_split_infer_mode,allocator_strategy,use_auto_growth_v2,enable_adjust_op_order,convert_all_blocks,init_allocated_mem,enable_cublas_tensor_op_math,dump_chunk_info,pir_apply_inplace_pass,new_executor_use_inplace,cublas_dir,initial_cpu_memory_in_mb,cusolver_dir,nccl_blocking_wait,query_dest_rank_by_multi_node,enable_blaslt_global_search,gpugraph_parallel_copyer_split_maxsize,use_auto_growth_pinned_allocator,host_trace_level,use_autotune,accuracy_check_rtol_fp32,disable_dyshape_in_train,enable_interpretercore_launch_cinn,dataloader_use_file_descriptor,npu_storage_format,check_nan_inf_level,free_when_no_cache_hit,selected_gpus,dygraph_debug,use_virtual_memory_auto_growth,cupti_dir,gpugraph_storage_mode,benchmark_nccl,enable_api_kernel_fallback,conv2d_disable_cudnn,graph_load_in_parallel,op_dir,cinn_compile_thread_num,gpugraph_parallel_stream_num,enable_gpu_memory_usage_log,gpugraph_hbm_table_load_factor,trt_ibuilder_cache,prim_all,use_pinned_memory,memory_fraction_of_eager_deletion,enable_exit_when_partial_worker,call_stack_level,pir_subgraph_saving_dir,all_blocks_convert_trt,enable_pir_with_pt_in_dy2st,gpugraph_dedup_pull_push_mode,print_sub_graph_dir,cuda_memory_async_pool_realease_threshold,enable_opt_get_features,enable_fusion_fallback,auto_growth_chunk_size_in_mb,log_memory_stats,tensor_operants_mode,enable_fuse_parallel_matmul_pass,cusparse_dir,fraction_of_cuda_pinned_memory_to_use,enable_async_trace,enable_pir_in_executor,dynamic_static_unified_comm,enable_gpu_memory_usage_log_mb,enable_collect_shape,conv_workspace_size_limit,use_stride_kernel,check_infer_symbolic,paddle_num_threads,gpugraph_offload_param_stat,fraction_of_gpu_memory_to_use,graph_metapath_split_opt,accuracy_check_atol_bf16,cudnn_batchnorm_spatial_persistent,use_stream_safe_cuda_allocator,prim_backward,enable_auto_detect_gpu_topo,new_executor_sequential_run,gpugraph_merge_grads_segment_size,new_executor_use_cuda_graph,set_to_1d,mkl_dir,sync_nccl_allreduce,initial_gpu_memory_in_mb,enable_sparse_inner_gather,graph_get_neighbor_id,eager_delete_tensor_gb,multi_node_sample_use_gpu_table 
1901: I0814 08:12:26.518988 31008 init.cc:108] After Parse: argc is 2
1901: I0814 08:12:32.498375 31008 scope.cc:202] Create variable X
1901: I0814 08:12:32.498466 31008 scope.cc:202] Create variable Out
1901: I0814 08:12:32.498507 31008 scope.cc:202] Create variable MedianIndex
1901: I0814 08:12:32.498703 31008 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0814 08:12:32.499461 31008 allocator_facade.cc:212] selected allocator strategy:1
1901: I0814 08:12:32.499951 31008 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0814 08:12:35.063640 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.063707 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.063838 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.063848 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.064911 31008 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 08:12:35.064939 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.064981 31008 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 08:12:35.064988 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.065389 31008 pybind.cc:1827] need skip: 0
1901: I0814 08:12:35.065479 31008 pybind.cc:1827] need skip: 0
1901: I0814 08:12:35.065873 31008 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0814 08:12:35.066166 31008 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0814 08:12:35.066184 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 08:12:35.066267 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0814 08:12:35.066280 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 08:12:35.069752 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.070442 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.070461 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.070474 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.073534 31008 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 08:12:35.073550 31008 scope.cc:202] Create variable feed
1901: I0814 08:12:35.073628 31008 program_interpreter.cc:243] New Executor is Running.
1901: I0814 08:12:35.073637 31008 interpreter_util.cc:1169] Creating Variables
1901: I0814 08:12:35.073645 31008 scope.cc:202] Create variable MedianIndex
1901: I0814 08:12:35.073657 31008 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x444d76c0 type is 7
1901: I0814 08:12:35.073668 31008 scope.cc:202] Create variable Out
1901: I0814 08:12:35.073674 31008 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x444d7bb0 type is 7
1901: I0814 08:12:35.073679 31008 scope.cc:202] Create variable Out@GRAD
1901: I0814 08:12:35.073681 31008 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x444d8060 type is 7
1901: I0814 08:12:35.073686 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.073688 31008 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x444d8be0 type is 7
1901: I0814 08:12:35.073693 31008 scope.cc:202] Create variable X@GRAD
1901: I0814 08:12:35.073698 31008 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x444d8e50 type is 7
1901: I0814 08:12:35.073704 31008 scope.cc:202] Create variable _generated_var_0
1901: I0814 08:12:35.073706 31008 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x444d9090 type is 7
1901: I0814 08:12:35.073711 31008 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0814 08:12:35.073714 31008 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x444d92f0 type is 7
1901: I0814 08:12:35.073719 31008 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x444d7640 type is 9
1901: I0814 08:12:35.073722 31008 scope.cc:202] Create variable fetch
1901: I0814 08:12:35.073725 31008 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x444d9070 type is 10
1901: I0814 08:12:35.073844 31008 interpreter_util.cc:594] Static build: 0
1901: I0814 08:12:35.073853 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.073856 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.073860 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0814 08:12:35.074568 31008 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0814 08:12:35.074791 31008 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0814 08:12:35.076159 31008 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0814 08:12:35.076401 31008 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.076426 31008 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.076575 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.076584 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.076603 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.081388 31008 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081411 31008 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081430 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.081513 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.081624 31008 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081636 31008 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081692 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.081713 31008 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0814 08:12:35.081748 31008 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081756 31008 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081773 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 08:12:35.081879 31008 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081889 31008 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.081907 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 08:12:35.082029 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.082058 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.082083 31008 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.082091 31008 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44555400Variable Type 7
1901: I0814 08:12:35.082113 31008 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.082139 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.082185 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.082207 31008 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.082343 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.082381 31008 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 08:12:35.082983 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.083031 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.084266 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.084290 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.084354 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.084363 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.085031 31008 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 08:12:35.085049 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.085081 31008 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 08:12:35.085088 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.085394 31008 pybind.cc:1827] need skip: 0
1901: I0814 08:12:35.085454 31008 pybind.cc:1827] need skip: 0
1901: I0814 08:12:35.085786 31008 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0814 08:12:35.085866 31008 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0814 08:12:35.085875 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 08:12:35.085942 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0814 08:12:35.085952 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 08:12:35.088125 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.088654 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.088670 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.088675 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.091495 31008 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 08:12:35.091516 31008 scope.cc:202] Create variable feed
1901: I0814 08:12:35.091555 31008 interpreter_util.cc:1169] Creating Variables
1901: I0814 08:12:35.091563 31008 scope.cc:202] Create variable MedianIndex
1901: I0814 08:12:35.091568 31008 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x445bb6e0 type is 7
1901: I0814 08:12:35.091575 31008 scope.cc:202] Create variable Out
1901: I0814 08:12:35.091580 31008 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x445bbc60 type is 7
1901: I0814 08:12:35.091585 31008 scope.cc:202] Create variable Out@GRAD
1901: I0814 08:12:35.091588 31008 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x445bc110 type is 7
1901: I0814 08:12:35.091593 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.091594 31008 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x445bca00 type is 7
1901: I0814 08:12:35.091598 31008 scope.cc:202] Create variable X@GRAD
1901: I0814 08:12:35.091601 31008 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x445bcc70 type is 7
1901: I0814 08:12:35.091605 31008 scope.cc:202] Create variable _generated_var_0
1901: I0814 08:12:35.091611 31008 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x445bceb0 type is 7
1901: I0814 08:12:35.091616 31008 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0814 08:12:35.091619 31008 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x445bd110 type is 7
1901: I0814 08:12:35.091624 31008 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x445bc060 type is 9
1901: I0814 08:12:35.091627 31008 scope.cc:202] Create variable fetch
1901: I0814 08:12:35.091631 31008 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x445bce90 type is 10
1901: I0814 08:12:35.091746 31008 interpreter_util.cc:594] Static build: 0
1901: I0814 08:12:35.091753 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.091758 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.091763 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.091820 31008 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.091837 31008 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.091904 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.091913 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.091929 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.092487 31008 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092504 31008 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092518 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.092577 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.092653 31008 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092662 31008 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092703 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.092738 31008 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092748 31008 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092763 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 08:12:35.092860 31008 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092871 31008 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.092888 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 08:12:35.092991 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.093004 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.093020 31008 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.093029 31008 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445be490Variable Type 7
1901: I0814 08:12:35.093046 31008 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.093065 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.093084 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.093098 31008 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.093178 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.093205 31008 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 08:12:35.093684 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 08:12:35.093722 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.095402 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.095623 31008 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1962d2e0 for it.
1901: I0814 08:12:35.095676 31008 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19673990 for it.
1901: I0814 08:12:35.097208 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.097267 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.097977 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x444d8080)  to GradNodeAccumulation (addr: 0x1960db40)
1901: I0814 08:12:35.098106 31008 dygraph_functions.cc:51757] Running AD API: mean
1901: I0814 08:12:35.098131 31008 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.098207 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.098227 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x430721a0)  to NanmedianGradNode (addr: 0x444d8080)
1901: I0814 08:12:35.098309 31008 backward.cc:442] Run in Backward
1901: I0814 08:12:35.098318 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.098340 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.098390 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.098420 31008 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x430721a0
1901: I0814 08:12:35.098433 31008 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0814 08:12:35.098474 31008 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.098534 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.098556 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.098567 31008 backward.cc:335] Node: MeanGradNode addr:0x430721a0, Found pending node: NanmedianGradNode addr: 0x444d8080
1901: I0814 08:12:35.098574 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.098604 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x444d8080
1901: I0814 08:12:35.098616 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.098639 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.098688 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.098709 31008 backward.cc:335] Node: NanmedianGradNode addr:0x444d8080, Found pending node: GradNodeAccumulation addr: 0x1960db40
1901: I0814 08:12:35.098716 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.098729 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1960db40
1901: I0814 08:12:35.098739 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.098744 31008 accumulation_node.cc:40] Move Tensor ptr: 0x440e9660
1901: I0814 08:12:35.098749 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.098753 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0814 08:12:35.107847 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.108094 31008 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19673990 for it.
1901: I0814 08:12:35.108150 31008 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1962d2e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0814 08:12:35.171918 31008 pir_interpreter.cc:161] PirInterpreter(): 0x44f05880 on Place(gpu:0)
1901: I0814 08:12:35.171967 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.171994 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_1
1901: I0814 08:12:35.172004 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_2
1901: I0814 08:12:35.172010 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_3
1901: I0814 08:12:35.172019 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_4
1901: I0814 08:12:35.172025 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_5
1901: I0814 08:12:35.172034 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_6
1901: I0814 08:12:35.172039 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_7
1901: I0814 08:12:35.172046 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_8
1901: I0814 08:12:35.172055 31008 scope.cc:202] Create variable 0x44f058801723623155171949331_inner_var_9
1901: I0814 08:12:35.172061 31008 scope.cc:202] Create variable fetch0@fetch
1901: I0814 08:12:35.172484 31008 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 08:12:35.172499 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.172502 31008 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0814 08:12:35.172549 31008 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x44f02740
1901: 1 -> 0x44f058801723623155171949331_inner_var_1 -> 0x44f056b0
1901: 2 -> 0x44f058801723623155171949331_inner_var_2 -> 0x44f03a60
1901: 3 -> 0x44f058801723623155171949331_inner_var_3 -> 0x44f03870
1901: 4 -> 0x44f058801723623155171949331_inner_var_4 -> 0x44f01a00
1901: 5 -> 0x44f058801723623155171949331_inner_var_5 -> 0x44f01bf0
1901: 6 -> 0x44f058801723623155171949331_inner_var_6 -> 0x44f062e0
1901: 7 -> 0x44f058801723623155171949331_inner_var_7 -> 0x44f06700
1901: 8 -> 0x44f058801723623155171949331_inner_var_8 -> 0x44f05860
1901: 9 -> 0x44f058801723623155171949331_inner_var_9 -> 0x44f06b20
1901: 10 -> fetch0@fetch -> 0x44f07330
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0814 08:12:35.173511 31008 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0814 08:12:35.173781 31045 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 08:12:35.173895 31047 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 08:12:35.173933 31046 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 08:12:35.174007 31048 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 08:12:35.174070 31048 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x44f058801723623155171949331_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.174105 31050 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 08:12:35.174160 31048 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x44f058801723623155171949331_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0814 08:12:35.174160 31050 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.174209 31050 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 08:12:35.174248 31049 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 08:12:35.174266 31050 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x44f058801723623155171949331_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44f058801723623155171949331_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.174793 31050 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x44f058801723623155171949331_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x44f058801723623155171949331_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.174826 31050 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x44f058801723623155171949331_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.174880 31050 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.174896 31050 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x44f058801723623155171949331_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.174921 31050 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x44f058801723623155171949331_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x44f058801723623155171949331_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.175005 31050 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.175025 31050 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x44f058801723623155171949331_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x44f058801723623155171949331_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.175055 31050 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x44f058801723623155171949331_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x44f058801723623155171949331_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.175107 31050 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.175122 31050 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x44f058801723623155171949331_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x44f058801723623155171949331_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.175144 31050 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x44f058801723623155171949331_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x44f058801723623155171949331_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x44f058801723623155171949331_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.175204 31050 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x44f058801723623155171949331_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x44f058801723623155171949331_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x44f058801723623155171949331_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 08:12:35.175271 31049 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44f058801723623155171949331_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.175298 31049 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.175400 31049 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44f058801723623155171949331_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f058801723623155171949331_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0814 08:12:35.175431 31049 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44f058801723623155171949331_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.175453 31049 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.175491 31049 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44f058801723623155171949331_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0814 08:12:35.175523 31008 pir_interpreter.cc:1766] main_thread_blocker_(0x44f059f0) got event_name: TaskCompletion
1901: I0814 08:12:35.175554 31008 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.178731 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.178767 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.178835 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.178845 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.180894 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.181468 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.181944 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.181960 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.181967 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.184317 31008 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 08:12:35.184340 31008 scope.cc:202] Create variable feed
1901: I0814 08:12:35.184381 31008 interpreter_util.cc:1169] Creating Variables
1901: I0814 08:12:35.184391 31008 scope.cc:202] Create variable MedianIndex
1901: I0814 08:12:35.184396 31008 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x44f37380 type is 7
1901: I0814 08:12:35.184407 31008 scope.cc:202] Create variable Out
1901: I0814 08:12:35.184413 31008 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44f36720 type is 7
1901: I0814 08:12:35.184419 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.184422 31008 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44f37110 type is 7
1901: I0814 08:12:35.184428 31008 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44f37360 type is 9
1901: I0814 08:12:35.184433 31008 scope.cc:202] Create variable fetch
1901: I0814 08:12:35.184437 31008 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44f378e0 type is 10
1901: I0814 08:12:35.184517 31008 interpreter_util.cc:594] Static build: 0
1901: I0814 08:12:35.184525 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.184530 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.184535 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.184597 31008 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.184614 31008 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.184695 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.184705 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.184727 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.185272 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.185292 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.185321 31008 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.185330 31008 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44f3b8a0Variable Type 7
1901: I0814 08:12:35.185350 31008 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.185374 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.185401 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.185420 31008 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.185465 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.185493 31008 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 08:12:35.185545 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.185557 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.185573 31008 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.185580 31008 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44f3fa30Variable Type 7
1901: I0814 08:12:35.185595 31008 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.185609 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.185629 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.185644 31008 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.185680 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.185714 31008 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 08:12:35.186033 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.186064 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.187487 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.187515 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.187572 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.187582 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.189590 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.190150 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.190618 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.190634 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.190639 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.192941 31008 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 08:12:35.193044 31008 interpreter_util.cc:1169] Creating Variables
1901: I0814 08:12:35.193056 31008 scope.cc:202] Create variable MedianIndex
1901: I0814 08:12:35.193066 31008 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x44f6f910 type is 7
1901: I0814 08:12:35.193075 31008 scope.cc:202] Create variable Out
1901: I0814 08:12:35.193081 31008 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44f6ec40 type is 7
1901: I0814 08:12:35.193086 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.193090 31008 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44f6f640 type is 7
1901: I0814 08:12:35.193095 31008 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44f37360 type is 9
1901: I0814 08:12:35.193100 31008 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44f378e0 type is 10
1901: I0814 08:12:35.193177 31008 interpreter_util.cc:594] Static build: 0
1901: I0814 08:12:35.193184 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.193189 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.193193 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.193251 31008 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.193269 31008 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.193351 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.193360 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.193382 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.193962 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.193980 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.194000 31008 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.194007 31008 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44f73e60Variable Type 7
1901: I0814 08:12:35.194028 31008 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.194049 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.194075 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.194092 31008 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.194139 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.194165 31008 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 08:12:35.194214 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.194226 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.194242 31008 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.194249 31008 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44f73e80Variable Type 7
1901: I0814 08:12:35.194262 31008 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.194278 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.194296 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.194320 31008 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.194357 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.194380 31008 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 08:12:35.194693 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.194725 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.195394 31045 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 3843318342523410502 to 1578293350546932472 , after update, data is {current : 19996, peak : 40000}.
1901: I0814 08:12:35.195420 31045 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 3843318342523410502 to 13078948732153049733 , after update, data is {current : 0, peak : 330659}.
1901: I0814 08:12:35.195613 31049 thread_data_registry.h:135] Add data {current : 19996, peak : 40000} from thread 1578293350546932472 to 13078948732153049733 , after update, data is {current : 19996, peak : 40000}.
1901: I0814 08:12:35.195683 31048 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 9580114961673449745 to 13078948732153049733 , after update, data is {current : 20000, peak : 40000}.
1901: I0814 08:12:35.195828 31050 thread_data_registry.h:135] Add data {current : 20000, peak : 40000} from thread 13078948732153049733 to 14999222321141054918 , after update, data is {current : 20038, peak : 40000}.
1901: I0814 08:12:35.195842 31050 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 13078948732153049733 to 14999222321141054918 , after update, data is {current : 140000, peak : 520631}.
1901: I0814 08:12:35.314031 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1962d2e0 for it.
1901: I0814 08:12:35.314486 31008 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19673990 for it.
1901: I0814 08:12:35.314558 31008 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.315191 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.315243 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.316515 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1962d2e0 for it.
1901: I0814 08:12:35.316681 31008 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.316737 31008 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x19673990 for it.
1901: I0814 08:12:35.317099 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.317137 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.319514 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1962d2e0 for it.
1901: I0814 08:12:35.319679 31008 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19673990 for it.
1901: I0814 08:12:35.319729 31008 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0814 08:12:35.323400 31008 pir_interpreter.cc:161] PirInterpreter(): 0x4559cea0 on Place(gpu:0)
1901: I0814 08:12:35.323441 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.323467 31008 scope.cc:202] Create variable 0x4559cea01723623155323430428_inner_var_1
1901: I0814 08:12:35.323477 31008 scope.cc:202] Create variable 0x4559cea01723623155323430428_inner_var_2
1901: I0814 08:12:35.323488 31008 scope.cc:202] Create variable 0x4559cea01723623155323430428_inner_var_3
1901: I0814 08:12:35.323499 31008 scope.cc:202] Create variable 0x4559cea01723623155323430428_inner_var_4
1901: I0814 08:12:35.323513 31008 scope.cc:202] Create variable fetch0@fetch
1901: I0814 08:12:35.323913 31008 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 08:12:35.323931 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.323935 31008 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x445e30c0
1901: 1 -> 0x4559cea01723623155323430428_inner_var_1 -> 0x44f09000
1901: 2 -> 0x4559cea01723623155323430428_inner_var_2 -> 0x44f3d280
1901: 3 -> 0x4559cea01723623155323430428_inner_var_3 -> 0x44f33990
1901: 4 -> 0x4559cea01723623155323430428_inner_var_4 -> 0x44f1b890
1901: 5 -> fetch0@fetch -> 0x19475a50
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0814 08:12:35.324692 31052 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 08:12:35.324837 31053 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 08:12:35.324882 31054 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 08:12:35.324949 31055 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 08:12:35.325039 31056 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 08:12:35.325105 31057 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 08:12:35.325162 31057 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4559cea01723623155323430428_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.325212 31057 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4559cea01723623155323430428_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 08:12:35.325250 31057 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4559cea01723623155323430428_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4559cea01723623155323430428_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4559cea01723623155323430428_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.325748 31057 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4559cea01723623155323430428_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4559cea01723623155323430428_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4559cea01723623155323430428_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.325826 31056 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4559cea01723623155323430428_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4559cea01723623155323430428_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.325865 31056 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.325942 31056 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4559cea01723623155323430428_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4559cea01723623155323430428_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.325975 31056 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4559cea01723623155323430428_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.325994 31056 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.326006 31056 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4559cea01723623155323430428_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.326040 31008 pir_interpreter.cc:1766] main_thread_blocker_(0x4559d010) got event_name: TaskCompletion
1901: I0814 08:12:35.326066 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.326730 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.326889 31008 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19673990 for it.
1901: I0814 08:12:35.326938 31008 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1962d2e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0814 08:12:35.329370 31008 pir_interpreter.cc:161] PirInterpreter(): 0x44f0ad00 on Place(gpu:0)
1901: I0814 08:12:35.329402 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.329422 31008 scope.cc:202] Create variable 0x44f0ad001723623155329394329_inner_var_1
1901: I0814 08:12:35.329432 31008 scope.cc:202] Create variable 0x44f0ad001723623155329394329_inner_var_2
1901: I0814 08:12:35.329438 31008 scope.cc:202] Create variable 0x44f0ad001723623155329394329_inner_var_3
1901: I0814 08:12:35.329447 31008 scope.cc:202] Create variable 0x44f0ad001723623155329394329_inner_var_4
1901: I0814 08:12:35.329454 31008 scope.cc:202] Create variable fetch0@fetch
1901: I0814 08:12:35.329754 31008 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 08:12:35.329767 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.329770 31008 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x43920ea0
1901: 1 -> 0x44f0ad001723623155329394329_inner_var_1 -> 0x44f7b060
1901: 2 -> 0x44f0ad001723623155329394329_inner_var_2 -> 0x44f3fa50
1901: 3 -> 0x44f0ad001723623155329394329_inner_var_3 -> 0x44f105f0
1901: 4 -> 0x44f0ad001723623155329394329_inner_var_4 -> 0x44f784b0
1901: 5 -> fetch0@fetch -> 0x44f04cc0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0814 08:12:35.330344 31058 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 08:12:35.330560 31059 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 08:12:35.330577 31060 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 08:12:35.330639 31061 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 08:12:35.330726 31062 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 08:12:35.330821 31063 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 08:12:35.330863 31063 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f0ad001723623155329394329_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.330894 31063 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f0ad001723623155329394329_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 08:12:35.330926 31063 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x44f0ad001723623155329394329_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f0ad001723623155329394329_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44f0ad001723623155329394329_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.331382 31063 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x44f0ad001723623155329394329_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f0ad001723623155329394329_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x44f0ad001723623155329394329_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.331452 31062 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44f0ad001723623155329394329_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f0ad001723623155329394329_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.331487 31062 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.331552 31062 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44f0ad001723623155329394329_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f0ad001723623155329394329_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.331583 31062 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44f0ad001723623155329394329_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.331601 31062 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.331614 31062 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44f0ad001723623155329394329_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.331640 31008 pir_interpreter.cc:1766] main_thread_blocker_(0x44f0ae70) got event_name: TaskCompletion
1901: I0814 08:12:35.331660 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.333070 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1962d2e0 for it.
1901: I0814 08:12:35.333245 31008 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x19673990 for it.
1901: I0814 08:12:35.333308 31008 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0814 08:12:35.336087 31008 pir_interpreter.cc:161] PirInterpreter(): 0x44f49810 on Place(gpu:0)
1901: I0814 08:12:35.336124 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.336146 31008 scope.cc:202] Create variable 0x44f498101723623155336114952_inner_var_1
1901: I0814 08:12:35.336158 31008 scope.cc:202] Create variable 0x44f498101723623155336114952_inner_var_2
1901: I0814 08:12:35.336169 31008 scope.cc:202] Create variable 0x44f498101723623155336114952_inner_var_3
1901: I0814 08:12:35.336176 31008 scope.cc:202] Create variable 0x44f498101723623155336114952_inner_var_4
1901: I0814 08:12:35.336189 31008 scope.cc:202] Create variable fetch0@fetch
1901: I0814 08:12:35.336546 31008 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 08:12:35.336563 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.336567 31008 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x43920db0
1901: 1 -> 0x44f498101723623155336114952_inner_var_1 -> 0x44588710
1901: 2 -> 0x44f498101723623155336114952_inner_var_2 -> 0x44f0b470
1901: 3 -> 0x44f498101723623155336114952_inner_var_3 -> 0x44f3b060
1901: 4 -> 0x44f498101723623155336114952_inner_var_4 -> 0x44f0b360
1901: 5 -> fetch0@fetch -> 0x44f79cd0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0814 08:12:35.337257 31064 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 08:12:35.337510 31065 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 08:12:35.337540 31066 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 08:12:35.337630 31067 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 08:12:35.337718 31068 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 08:12:35.337821 31069 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 08:12:35.337862 31069 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f498101723623155336114952_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.337896 31069 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f498101723623155336114952_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 08:12:35.337930 31069 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x44f498101723623155336114952_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f498101723623155336114952_inner_var_3:[dtype=;place=;dim=;lod={};, 0x44f498101723623155336114952_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.338397 31069 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x44f498101723623155336114952_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x44f498101723623155336114952_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x44f498101723623155336114952_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.338464 31068 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44f498101723623155336114952_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f498101723623155336114952_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.338487 31068 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.338537 31068 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x44f498101723623155336114952_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x44f498101723623155336114952_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.338562 31068 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x44f498101723623155336114952_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.338577 31068 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.338589 31068 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x44f498101723623155336114952_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.338614 31008 pir_interpreter.cc:1766] main_thread_blocker_(0x44f49980) got event_name: TaskCompletion
1901: I0814 08:12:35.338634 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.338809 31008 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0814 08:12:35.387032 31058 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 15156202349397987344 to 6888966042355053314 , after update, data is {current : -4, peak : 0}.
1901: I0814 08:12:35.387076 31058 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 15156202349397987344 to 6888966042355053314 , after update, data is {current : -36, peak : 0}.
1901: I0814 08:12:35.387262 31062 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 8633647840578075954 to 6888966042355053314 , after update, data is {current : 0, peak : 4}.
1901: I0814 08:12:35.387449 31063 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 13229498184486589621 to 6888966042355053314 , after update, data is {current : 0, peak : 16}.
1901: I0814 08:12:35.387463 31063 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 13229498184486589621 to 6888966042355053314 , after update, data is {current : -18, peak : 330659}.
1901: I0814 08:12:35.387653 31064 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 6888966042355053314 to 489318388919563243 , after update, data is {current : 0, peak : 16}.
1901: I0814 08:12:35.387667 31064 thread_data_registry.h:135] Add data {current : -18, peak : 330659} from thread 6888966042355053314 to 489318388919563243 , after update, data is {current : 0, peak : 330659}.
1901: I0814 08:12:35.387823 31068 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 2128315322805203006 to 489318388919563243 , after update, data is {current : 4, peak : 16}.
1901: I0814 08:12:35.387991 31069 thread_data_registry.h:135] Add data {current : 4, peak : 16} from thread 489318388919563243 to 13078948732153049733 , after update, data is {current : 2, peak : 16}.
1901: I0814 08:12:35.388005 31069 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 489318388919563243 to 13078948732153049733 , after update, data is {current : -18, peak : 330659}.
1901: I0814 08:12:35.392367 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.392558 31008 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7f289c027c00), and remaining 0
1901: I0814 08:12:35.392675 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.392719 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.393035 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.394058 31008 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.394145 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.394176 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.394362 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.395066 31008 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.395138 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.395164 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.395330 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.395953 31008 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.396025 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.396050 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.396209 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0814 08:12:35.396912 31008 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.396970 31008 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f289c018e00), and remaining 0
1901: I0814 08:12:35.397022 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.397046 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.397536 31008 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.397604 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.397627 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.398082 31008 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.398145 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.398169 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.398592 31008 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.398658 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.398681 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.399253 31008 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.399339 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.399365 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.399578 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.400223 31008 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.400295 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.400329 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.400485 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.401170 31008 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.401242 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.401266 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.401500 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.402117 31008 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.402189 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.402215 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.402383 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.403046 31008 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.403117 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.403143 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.403365 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.404011 31008 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.404083 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.404107 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.404265 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.404971 31008 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.405045 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.405071 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.405234 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.405913 31008 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.405988 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.406013 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.406168 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.406870 31008 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.406941 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.406966 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.407164 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.407801 31008 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.407873 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.407899 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.408057 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.408596 31008 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.408661 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.408686 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.408834 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.409526 31008 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.409592 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.409617 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.409766 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.410429 31008 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.410501 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.410526 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.410811 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0814 08:12:35.414327 31008 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.414408 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.414436 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.414634 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.416006 31008 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.416083 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.416110 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.416358 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.417698 31008 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.417773 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.417798 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.417984 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.419211 31008 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.419286 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.419320 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.419596 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.420830 31008 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.420903 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.420929 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.421113 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.422405 31008 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.422478 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.422504 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.422688 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.423979 31008 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.424052 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.424078 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.424263 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.425478 31008 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.425552 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.425578 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.425817 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.427137 31008 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.427212 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.427238 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.427434 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.428644 31008 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.428718 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.428745 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.428988 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.430203 31008 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.430279 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.430313 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.430500 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.431787 31008 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.431861 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.431887 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.432075 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.433326 31008 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.433400 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.433426 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.433607 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.434887 31008 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.434962 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.434988 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.435169 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.436393 31008 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.436467 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.436493 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.436672 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.437870 31008 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.437944 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.437971 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.438150 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.438910 31008 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.438980 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.439005 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.439179 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.442086 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.442118 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.442991 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.443013 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.443797 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.443819 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.444612 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.444634 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.445397 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.445420 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.448065 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.448625 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.449151 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.449684 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.450204 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.451092 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.451112 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.451118 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.456157 31008 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 08:12:35.456264 31008 interpreter_util.cc:1169] Creating Variables
1901: I0814 08:12:35.456277 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.456285 31008 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x46cca710 type is 7
1901: I0814 08:12:35.456295 31008 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44f37360 type is 9
1901: I0814 08:12:35.456311 31008 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44f378e0 type is 10
1901: I0814 08:12:35.456319 31008 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0814 08:12:35.456323 31008 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x46cc99d0 type is 7
1901: I0814 08:12:35.456328 31008 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0814 08:12:35.456332 31008 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x46cca5c0 type is 7
1901: I0814 08:12:35.456338 31008 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0814 08:12:35.456342 31008 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x44f43930 type is 7
1901: I0814 08:12:35.456346 31008 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0814 08:12:35.456350 31008 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x46cc93a0 type is 7
1901: I0814 08:12:35.456355 31008 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0814 08:12:35.456359 31008 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x46cca7c0 type is 7
1901: I0814 08:12:35.456365 31008 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0814 08:12:35.456369 31008 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x46cca980 type is 7
1901: I0814 08:12:35.456374 31008 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0814 08:12:35.456378 31008 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x46ccab90 type is 7
1901: I0814 08:12:35.456383 31008 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0814 08:12:35.456389 31008 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x46ccadf0 type is 7
1901: I0814 08:12:35.456394 31008 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0814 08:12:35.456398 31008 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x46ccb050 type is 7
1901: I0814 08:12:35.456403 31008 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0814 08:12:35.456406 31008 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x46ccb2b0 type is 7
1901: I0814 08:12:35.456550 31008 interpreter_util.cc:594] Static build: 0
1901: I0814 08:12:35.456559 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.456565 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.456570 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.456646 31008 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.456665 31008 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.456740 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.456750 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.456768 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.457005 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.457211 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.457226 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.457242 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.457386 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.457580 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.457593 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.457610 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.457741 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.457926 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.457939 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.457957 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.458114 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.458330 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.458343 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.458360 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.458510 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.458709 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.458721 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.458740 31008 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.458748 31008 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46be3320Variable Type 7
1901: I0814 08:12:35.458770 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.458792 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.458818 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.458837 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.458884 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.458907 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 08:12:35.458954 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.458966 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.458981 31008 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.458987 31008 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46cc9b40Variable Type 7
1901: I0814 08:12:35.459002 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.459017 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.459035 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.459049 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.459082 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.459115 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 08:12:35.459165 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.459177 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.459192 31008 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.459199 31008 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46be34b0Variable Type 7
1901: I0814 08:12:35.459213 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.459226 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.459244 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.459259 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.459291 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.459314 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0814 08:12:35.459359 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.459370 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.459384 31008 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.459390 31008 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46be4000Variable Type 7
1901: I0814 08:12:35.459404 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.459416 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.459431 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.459441 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.459471 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.459486 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0814 08:12:35.459524 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.459534 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.459549 31008 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.459556 31008 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46be1000Variable Type 7
1901: I0814 08:12:35.459569 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.459582 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.459599 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.459612 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.459643 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.459656 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0814 08:12:35.460322 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.460358 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.460381 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.460400 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.460419 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0814 08:12:35.467088 31008 pir_interpreter.cc:161] PirInterpreter(): 0x46bdeed0 on Place(gpu:0)
1901: I0814 08:12:35.467128 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.467152 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_1
1901: I0814 08:12:35.467164 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_2
1901: I0814 08:12:35.467175 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_3
1901: I0814 08:12:35.467183 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_4
1901: I0814 08:12:35.467192 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_5
1901: I0814 08:12:35.467200 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_6
1901: I0814 08:12:35.467209 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_7
1901: I0814 08:12:35.467216 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_8
1901: I0814 08:12:35.467224 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_9
1901: I0814 08:12:35.467232 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_10
1901: I0814 08:12:35.467242 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_11
1901: I0814 08:12:35.467249 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_12
1901: I0814 08:12:35.467260 31008 scope.cc:202] Create variable fetch0@fetch
1901: I0814 08:12:35.467275 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_14
1901: I0814 08:12:35.467285 31008 scope.cc:202] Create variable fetch1@fetch
1901: I0814 08:12:35.467293 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_16
1901: I0814 08:12:35.467310 31008 scope.cc:202] Create variable fetch2@fetch
1901: I0814 08:12:35.467321 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_18
1901: I0814 08:12:35.467332 31008 scope.cc:202] Create variable fetch3@fetch
1901: I0814 08:12:35.467339 31008 scope.cc:202] Create variable 0x46bdeed01723623155467119481_inner_var_20
1901: I0814 08:12:35.467348 31008 scope.cc:202] Create variable fetch4@fetch
1901: I0814 08:12:35.467680 31008 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 08:12:35.467695 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.467700 31008 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x46ccc210
1901: 1 -> 0x46bdeed01723623155467119481_inner_var_1 -> 0x46be7930
1901: 2 -> 0x46bdeed01723623155467119481_inner_var_2 -> 0x44f50700
1901: 3 -> 0x46bdeed01723623155467119481_inner_var_3 -> 0x44553f20
1901: 4 -> 0x46bdeed01723623155467119481_inner_var_4 -> 0x44f12680
1901: 5 -> 0x46bdeed01723623155467119481_inner_var_5 -> 0x46c04820
1901: 6 -> 0x46bdeed01723623155467119481_inner_var_6 -> 0x46c23f60
1901: 7 -> 0x46bdeed01723623155467119481_inner_var_7 -> 0x44f11e80
1901: 8 -> 0x46bdeed01723623155467119481_inner_var_8 -> 0x46cc9fb0
1901: 9 -> 0x46bdeed01723623155467119481_inner_var_9 -> 0x46be37a0
1901: 10 -> 0x46bdeed01723623155467119481_inner_var_10 -> 0x46cf89b0
1901: 11 -> 0x46bdeed01723623155467119481_inner_var_11 -> 0x44f13c30
1901: 12 -> 0x46bdeed01723623155467119481_inner_var_12 -> 0x46be0390
1901: 13 -> fetch0@fetch -> 0x46c29240
1901: 14 -> 0x46bdeed01723623155467119481_inner_var_14 -> 0x46c29200
1901: 15 -> fetch1@fetch -> 0x46bdeac0
1901: 16 -> 0x46bdeed01723623155467119481_inner_var_16 -> 0x46c29220
1901: 17 -> fetch2@fetch -> 0x44f2c4f0
1901: 18 -> 0x46bdeed01723623155467119481_inner_var_18 -> 0x46bdeaa0
1901: 19 -> fetch3@fetch -> 0x46be0330
1901: 20 -> 0x46bdeed01723623155467119481_inner_var_20 -> 0x44f2c4d0
1901: 21 -> fetch4@fetch -> 0x46bc29d0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0814 08:12:35.469240 31070 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 08:12:35.469305 31071 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 08:12:35.469357 31072 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 08:12:35.469355 31073 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 08:12:35.469486 31074 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 08:12:35.469547 31074 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.469621 31074 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0814 08:12:35.469687 31074 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_3:[dtype=;place=;dim=;lod={};, 0x46bdeed01723623155467119481_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470017 31074 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.470185 31074 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46bdeed01723623155467119481_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.470247 31074 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_5:[dtype=;place=;dim=;lod={};, 0x46bdeed01723623155467119481_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470306 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470363 31073 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.470381 31074 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.470557 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.470575 31074 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46bdeed01723623155467119481_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.470628 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470652 31073 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.470650 31074 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_7:[dtype=;place=;dim=;lod={};, 0x46bdeed01723623155467119481_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470667 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.470685 31072 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470731 31072 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.470769 31074 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.470808 31072 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.470927 31074 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46bdeed01723623155467119481_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.470963 31072 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470986 31072 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.470984 31074 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_9:[dtype=;place=;dim=;lod={};, 0x46bdeed01723623155467119481_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470991 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.470999 31072 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.471009 31073 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.471045 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.471084 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.471101 31073 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.471112 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.471163 31074 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.471323 31074 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46bdeed01723623155467119481_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.471369 31074 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_11:[dtype=;place=;dim=;lod={};, 0x46bdeed01723623155467119481_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.471374 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.471390 31073 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.471426 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.471465 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.471482 31073 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.471493 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.471544 31074 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.471695 31074 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46bdeed01723623155467119481_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46bdeed01723623155467119481_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.471745 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.471761 31073 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.471788 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46bdeed01723623155467119481_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46bdeed01723623155467119481_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.471822 31073 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.471837 31073 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.471848 31073 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46bdeed01723623155467119481_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.471876 31008 pir_interpreter.cc:1766] main_thread_blocker_(0x46bdf040) got event_name: TaskCompletion
1901: I0814 08:12:35.471905 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.471940 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.471951 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.471962 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.471973 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.473699 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.473824 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.473863 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.474123 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.474236 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x44f1ae80)  to GradNodeAccumulation (addr: 0x1960db40)
1901: I0814 08:12:35.474387 31008 backward.cc:459] Run in Grad
1901: I0814 08:12:35.474407 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.474467 31008 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x44f1ae80 to ptr: 0x46c02440
1901: I0814 08:12:35.474479 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.474530 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.474574 31008 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1960db40 to ptr: 0x44f41f30
1901: I0814 08:12:35.474604 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46c02440
1901: I0814 08:12:35.474613 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.474649 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.474726 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.474736 31008 backward.cc:335] Node: NanmedianGradNode addr:0x46c02440, Found pending node: GradNodeAccumulation addr: 0x44f41f30
1901: I0814 08:12:35.474741 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.474769 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x44f41f30
1901: I0814 08:12:35.474776 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.474781 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.474788 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.474792 31008 backward.cc:435] Finish Backward
1901: I0814 08:12:35.475597 31008 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0814 08:12:35.475616 31008 dygraph_functions.cc:77659] { Input: []} 
1901: I0814 08:12:35.475739 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.475764 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.475919 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.475996 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x44f1ae80)  to GradNodeAccumulation (addr: 0x1960db40)
1901: I0814 08:12:35.476092 31008 backward.cc:442] Run in Backward
1901: I0814 08:12:35.476100 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.476107 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.476138 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.476174 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x44f1ae80
1901: I0814 08:12:35.476183 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.476212 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.476272 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.476308 31008 backward.cc:335] Node: NanmedianGradNode addr:0x44f1ae80, Found pending node: GradNodeAccumulation addr: 0x1960db40
1901: I0814 08:12:35.476317 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.476336 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1960db40
1901: I0814 08:12:35.476342 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.476346 31008 accumulation_node.cc:40] Move Tensor ptr: 0x46bd2650
1901: I0814 08:12:35.476351 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.476356 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.478214 31008 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0814 08:12:35.478763 31008 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.478888 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.478914 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.479089 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x44f6cae0)  to GradNodeAccumulation (addr: 0x46bffc50)
1901: I0814 08:12:35.479193 31008 backward.cc:442] Run in Backward
1901: I0814 08:12:35.479202 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.479208 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.479241 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.479264 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x44f6cae0
1901: I0814 08:12:35.479272 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.479310 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.479358 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.479384 31008 backward.cc:335] Node: NanmedianGradNode addr:0x44f6cae0, Found pending node: GradNodeAccumulation addr: 0x46bffc50
1901: I0814 08:12:35.479393 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.479409 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x46bffc50
1901: I0814 08:12:35.479415 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.479419 31008 accumulation_node.cc:40] Move Tensor ptr: 0x44f01d70
1901: I0814 08:12:35.479424 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.479429 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.480221 31008 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.480314 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.480340 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.480566 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.480674 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x44f1ae80)  to GradNodeAccumulation (addr: 0x46bffc50)
1901: I0814 08:12:35.480798 31008 backward.cc:459] Run in Grad
1901: I0814 08:12:35.480808 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.480829 31008 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x44f1ae80 to ptr: 0x44f6cae0
1901: I0814 08:12:35.480839 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.480870 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.480895 31008 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x46bffc50 to ptr: 0x44f41f30
1901: I0814 08:12:35.480918 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x44f6cae0
1901: I0814 08:12:35.480926 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.480954 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.481098 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.481108 31008 backward.cc:335] Node: NanmedianGradNode addr:0x44f6cae0, Found pending node: GradNodeAccumulation addr: 0x44f41f30
1901: I0814 08:12:35.481114 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.481129 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x44f41f30
1901: I0814 08:12:35.481137 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.481140 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.481146 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.481150 31008 backward.cc:435] Finish Backward
1901: I0814 08:12:35.482121 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.482204 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.482231 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.482417 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.483958 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.484019 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.484042 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.503770 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.503818 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.504943 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.504972 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.506000 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.506145 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.506187 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.506461 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.507112 31008 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.507197 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.507227 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.507431 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.508044 31008 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.508121 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.508149 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.508327 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.508903 31008 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.508983 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.509011 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.509184 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.509794 31008 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.509850 31008 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f289c019200), and remaining 0
1901: I0814 08:12:35.509908 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.509934 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.510480 31008 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.510548 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.510573 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.511055 31008 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.511128 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.511155 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.511644 31008 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.511718 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.511745 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.512249 31008 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.512332 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.512359 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.512560 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.513134 31008 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.513213 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.513240 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.513427 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.514034 31008 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.514110 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.514138 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.514312 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.514896 31008 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.514976 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.515003 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.515177 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.515792 31008 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.515870 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.515897 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.516067 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.516657 31008 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.516741 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.516770 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.516942 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.517566 31008 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.517644 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.517673 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.517838 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.518450 31008 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.518529 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.518558 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.518724 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.519362 31008 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.519440 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.519469 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.519647 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.520220 31008 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.520308 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.520339 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.520510 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.521028 31008 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.521082 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.521103 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.521227 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.521842 31008 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.521908 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.521934 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.522081 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.522733 31008 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.522812 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.522841 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.523043 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.523747 31008 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.523819 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.523845 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.524019 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.524701 31008 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.524772 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.524797 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.524977 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.525624 31008 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.525694 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.525719 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.525892 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.526540 31008 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.526611 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.526636 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.526820 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.527441 31008 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.527511 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.527536 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.527712 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.528337 31008 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.528407 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.528434 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.528605 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.529237 31008 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.529316 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.529343 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.529520 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.530150 31008 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.530222 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.530247 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.530431 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.531044 31008 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.531112 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.531137 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.531322 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.531924 31008 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.531993 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.532018 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.532197 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.532807 31008 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.532878 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.532903 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.533077 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.533687 31008 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.533758 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.533784 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.533957 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.534569 31008 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.534641 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.534665 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.534837 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.535463 31008 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.535533 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.535558 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.535732 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.536419 31008 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.536497 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.536525 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.536721 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.537313 31008 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.537384 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.537408 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.537581 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.538321 31008 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.538398 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.538426 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.538615 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.540863 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.540894 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.541569 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.541590 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.542189 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.542207 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.542836 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.542855 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.543964 31072 thread_data_registry.h:135] Add data {current : -4, peak : 0} from thread 4388433003102908681 to 7525722563901322461 , after update, data is {current : 16, peak : 1260}.
1901: I0814 08:12:35.543993 31072 thread_data_registry.h:135] Add data {current : 4, peak : 8} from thread 4388433003102908681 to 7525722563901322461 , after update, data is {current : 4, peak : 16}.
1901: I0814 08:12:35.544001 31073 thread_data_registry.h:135] Add data {current : -16, peak : 0} from thread 15156202349397987344 to 7525722563901322461 , after update, data is {current : 0, peak : 1260}.
1901: I0814 08:12:35.544023 31073 thread_data_registry.h:135] Add data {current : 16, peak : 20} from thread 15156202349397987344 to 7525722563901322461 , after update, data is {current : 20, peak : 20}.
1901: I0814 08:12:35.544641 31074 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 7525722563901322461 to 14999222321141054918 , after update, data is {current : 0, peak : 260}.
1901: I0814 08:12:35.544660 31074 thread_data_registry.h:135] Add data {current : 20, peak : 20} from thread 7525722563901322461 to 13078948732153049733 , after update, data is {current : 22, peak : 22}.
1901: I0814 08:12:35.544667 31074 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 7525722563901322461 to 13078948732153049733 , after update, data is {current : -18, peak : 330659}.
1901: I0814 08:12:35.545678 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.545711 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.548471 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.548925 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.549358 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.549785 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.550210 31008 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 08:12:35.551110 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.551126 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.551134 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.555577 31008 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 08:12:35.555646 31008 interpreter_util.cc:1169] Creating Variables
1901: I0814 08:12:35.555657 31008 scope.cc:202] Create variable X
1901: I0814 08:12:35.555665 31008 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x455a2370 type is 7
1901: I0814 08:12:35.555672 31008 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44f37360 type is 9
1901: I0814 08:12:35.555680 31008 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44f378e0 type is 10
1901: I0814 08:12:35.555684 31008 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0814 08:12:35.555689 31008 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x46cfd610 type is 7
1901: I0814 08:12:35.555694 31008 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0814 08:12:35.555699 31008 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x46cfdf70 type is 7
1901: I0814 08:12:35.555703 31008 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0814 08:12:35.555707 31008 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x46cfe050 type is 7
1901: I0814 08:12:35.555718 31008 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0814 08:12:35.555728 31008 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x46cfe2b0 type is 7
1901: I0814 08:12:35.555733 31008 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0814 08:12:35.555737 31008 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x46cfe510 type is 7
1901: I0814 08:12:35.555742 31008 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0814 08:12:35.555745 31008 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x44f20450 type is 7
1901: I0814 08:12:35.555750 31008 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0814 08:12:35.555753 31008 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x44f20660 type is 7
1901: I0814 08:12:35.555759 31008 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0814 08:12:35.555763 31008 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x44f20870 type is 7
1901: I0814 08:12:35.555766 31008 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0814 08:12:35.555770 31008 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x44f20ad0 type is 7
1901: I0814 08:12:35.555774 31008 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0814 08:12:35.555778 31008 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x44f20d30 type is 7
1901: I0814 08:12:35.555920 31008 interpreter_util.cc:594] Static build: 0
1901: I0814 08:12:35.555929 31008 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 08:12:35.555934 31008 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 08:12:35.555939 31008 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 08:12:35.556011 31008 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556030 31008 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556100 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556109 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556128 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.556432 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.556631 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556644 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556661 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.556789 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.556968 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556979 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.556994 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.557102 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.557274 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.557286 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.557305 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.557482 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.557678 31008 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.557689 31008 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.557704 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.557829 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.558010 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558022 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558038 31008 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.558045 31008 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46bf1530Variable Type 7
1901: I0814 08:12:35.558068 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.558086 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.558109 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.558125 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.558168 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.558187 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 08:12:35.558229 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558238 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558252 31008 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.558259 31008 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46cfd6e0Variable Type 7
1901: I0814 08:12:35.558272 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.558284 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.558306 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.558319 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.558351 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.558383 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 08:12:35.558425 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558434 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558449 31008 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.558458 31008 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46c7d370Variable Type 7
1901: I0814 08:12:35.558472 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.558485 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.558499 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.558511 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.558538 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.558550 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0814 08:12:35.558589 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558598 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558611 31008 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.558617 31008 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46cfcbe0Variable Type 7
1901: I0814 08:12:35.558629 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.558640 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.558653 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.558665 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.558692 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.558704 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0814 08:12:35.558737 31008 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558744 31008 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 08:12:35.558756 31008 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 08:12:35.558763 31008 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46c7d000Variable Type 7
1901: I0814 08:12:35.558773 31008 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 08:12:35.558784 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.558796 31008 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 08:12:35.558808 31008 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.558833 31008 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 08:12:35.558845 31008 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0814 08:12:35.559458 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.559489 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.559506 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.559525 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 08:12:35.559541 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0814 08:12:35.566917 31008 pir_interpreter.cc:161] PirInterpreter(): 0x46d195d0 on Place(gpu:0)
1901: I0814 08:12:35.566974 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_1
1901: I0814 08:12:35.566988 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_2
1901: I0814 08:12:35.566994 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_3
1901: I0814 08:12:35.567000 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_4
1901: I0814 08:12:35.567006 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_5
1901: I0814 08:12:35.567013 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_6
1901: I0814 08:12:35.567018 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_7
1901: I0814 08:12:35.567025 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_8
1901: I0814 08:12:35.567031 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_9
1901: I0814 08:12:35.567037 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_10
1901: I0814 08:12:35.567044 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_11
1901: I0814 08:12:35.567051 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_12
1901: I0814 08:12:35.567065 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_14
1901: I0814 08:12:35.567078 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_16
1901: I0814 08:12:35.567091 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_18
1901: I0814 08:12:35.567102 31008 scope.cc:202] Create variable 0x46d195d01723623155566951493_inner_var_20
1901: I0814 08:12:35.567543 31008 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x46c136e0
1901: 1 -> 0x46d195d01723623155566951493_inner_var_1 -> 0x46cfd3a0
1901: 2 -> 0x46d195d01723623155566951493_inner_var_2 -> 0x46cfd310
1901: 3 -> 0x46d195d01723623155566951493_inner_var_3 -> 0x1964b080
1901: 4 -> 0x46d195d01723623155566951493_inner_var_4 -> 0x46c7cb80
1901: 5 -> 0x46d195d01723623155566951493_inner_var_5 -> 0x1964c9c0
1901: 6 -> 0x46d195d01723623155566951493_inner_var_6 -> 0x46beec80
1901: 7 -> 0x46d195d01723623155566951493_inner_var_7 -> 0x46c7f740
1901: 8 -> 0x46d195d01723623155566951493_inner_var_8 -> 0x455a0810
1901: 9 -> 0x46d195d01723623155566951493_inner_var_9 -> 0x46be06c0
1901: 10 -> 0x46d195d01723623155566951493_inner_var_10 -> 0x46c7c4b0
1901: 11 -> 0x46d195d01723623155566951493_inner_var_11 -> 0x1964bfe0
1901: 12 -> 0x46d195d01723623155566951493_inner_var_12 -> 0x46bd5290
1901: 13 -> fetch0@fetch -> 0x46c29240
1901: 14 -> 0x46d195d01723623155566951493_inner_var_14 -> 0x46d09e70
1901: 15 -> fetch1@fetch -> 0x46bdeac0
1901: 16 -> 0x46d195d01723623155566951493_inner_var_16 -> 0x46ca23f0
1901: 17 -> fetch2@fetch -> 0x44f2c4f0
1901: 18 -> 0x46d195d01723623155566951493_inner_var_18 -> 0x4559ae00
1901: 19 -> fetch3@fetch -> 0x46be0330
1901: 20 -> 0x46d195d01723623155566951493_inner_var_20 -> 0x46d193a0
1901: 21 -> fetch4@fetch -> 0x46bc29d0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0814 08:12:35.568976 31075 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 08:12:35.569053 31076 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 08:12:35.569105 31077 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 08:12:35.569157 31078 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 08:12:35.569207 31079 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 08:12:35.569232 31079 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.569279 31079 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0814 08:12:35.569329 31079 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_3:[dtype=;place=;dim=;lod={};, 0x46d195d01723623155566951493_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.569607 31079 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.569768 31079 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x46d195d01723623155566951493_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.569820 31079 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_5:[dtype=;place=;dim=;lod={};, 0x46d195d01723623155566951493_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.569864 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.569909 31078 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.569932 31079 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.569991 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570106 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570127 31078 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.570129 31079 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x46d195d01723623155566951493_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.570135 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570175 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.570178 31079 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_7:[dtype=;place=;dim=;lod={};, 0x46d195d01723623155566951493_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.570192 31078 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.570230 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570267 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570284 31078 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.570289 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570348 31079 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.570493 31079 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x46d195d01723623155566951493_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.570534 31079 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_9:[dtype=;place=;dim=;lod={};, 0x46d195d01723623155566951493_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.570541 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.570557 31078 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.570587 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570673 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570691 31078 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.570698 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.570715 31079 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.570866 31079 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x46d195d01723623155566951493_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.570907 31079 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_11:[dtype=;place=;dim=;lod={};, 0x46d195d01723623155566951493_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.570914 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.570930 31078 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.570964 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.571014 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.571031 31078 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.571038 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.571086 31079 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.571236 31079 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46d195d01723623155566951493_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x46d195d01723623155566951493_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 08:12:35.571285 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0814 08:12:35.571305 31078 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 08:12:35.571332 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46d195d01723623155566951493_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46d195d01723623155566951493_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.571367 31078 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.571383 31078 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.571389 31078 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46d195d01723623155566951493_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 08:12:35.571414 31008 pir_interpreter.cc:1766] main_thread_blocker_(0x46d19740) got event_name: TaskCompletion
1901: I0814 08:12:35.571440 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.571468 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.571478 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.571487 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.571497 31008 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 08:12:35.573669 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x46bffc50 for it.
1901: I0814 08:12:35.573783 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.573824 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.574034 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.574134 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46bcd4c0)  to GradNodeAccumulation (addr: 0x46bffc50)
1901: I0814 08:12:35.574267 31008 backward.cc:459] Run in Grad
1901: I0814 08:12:35.574280 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.574309 31008 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x46bcd4c0 to ptr: 0x46cb1180
1901: I0814 08:12:35.574321 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.574362 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.574391 31008 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x46bffc50 to ptr: 0x44f41f30
1901: I0814 08:12:35.574416 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46cb1180
1901: I0814 08:12:35.574425 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.574461 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.574535 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.574544 31008 backward.cc:335] Node: NanmedianGradNode addr:0x46cb1180, Found pending node: GradNodeAccumulation addr: 0x44f41f30
1901: I0814 08:12:35.574550 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.574579 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x44f41f30
1901: I0814 08:12:35.574585 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.574589 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.574595 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.574599 31008 backward.cc:435] Finish Backward
1901: I0814 08:12:35.575405 31008 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0814 08:12:35.575424 31008 dygraph_functions.cc:77659] { Input: []} 
1901: I0814 08:12:35.575520 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.575546 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.575695 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.575770 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46bcd4c0)  to GradNodeAccumulation (addr: 0x46bffc50)
1901: I0814 08:12:35.575862 31008 backward.cc:442] Run in Backward
1901: I0814 08:12:35.575870 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.575877 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.575909 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.575933 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46bcd4c0
1901: I0814 08:12:35.575942 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.575971 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.576030 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.576056 31008 backward.cc:335] Node: NanmedianGradNode addr:0x46bcd4c0, Found pending node: GradNodeAccumulation addr: 0x46bffc50
1901: I0814 08:12:35.576064 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.576082 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x46bffc50
1901: I0814 08:12:35.576089 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.576093 31008 accumulation_node.cc:40] Move Tensor ptr: 0x46bd2650
1901: I0814 08:12:35.576097 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.576102 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.576596 31008 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.576717 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.576745 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.576912 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46cb10f0)  to GradNodeAccumulation (addr: 0x1960db40)
1901: I0814 08:12:35.577015 31008 backward.cc:442] Run in Backward
1901: I0814 08:12:35.577024 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.577030 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.577064 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.577086 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46cb10f0
1901: I0814 08:12:35.577095 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.577123 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.577169 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.577194 31008 backward.cc:335] Node: NanmedianGradNode addr:0x46cb10f0, Found pending node: GradNodeAccumulation addr: 0x1960db40
1901: I0814 08:12:35.577203 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.577219 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1960db40
1901: I0814 08:12:35.577226 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.577230 31008 accumulation_node.cc:40] Move Tensor ptr: 0x440e9660
1901: I0814 08:12:35.577234 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.577237 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.578001 31008 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.578097 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.578123 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.578325 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.578418 31008 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46bcd4c0)  to GradNodeAccumulation (addr: 0x1960db40)
1901: I0814 08:12:35.578541 31008 backward.cc:459] Run in Grad
1901: I0814 08:12:35.578552 31008 backward.cc:113] Start Backward
1901: I0814 08:12:35.578567 31008 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x46bcd4c0 to ptr: 0x46cb10f0
1901: I0814 08:12:35.578576 31008 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 08:12:35.578608 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.578634 31008 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1960db40 to ptr: 0x44f41f30
1901: I0814 08:12:35.578655 31008 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46cb10f0
1901: I0814 08:12:35.578662 31008 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 08:12:35.578692 31008 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.578819 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.578828 31008 backward.cc:335] Node: NanmedianGradNode addr:0x46cb10f0, Found pending node: GradNodeAccumulation addr: 0x44f41f30
1901: I0814 08:12:35.578833 31008 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 08:12:35.578848 31008 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x44f41f30
1901: I0814 08:12:35.578856 31008 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.578859 31008 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 08:12:35.578864 31008 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 08:12:35.578868 31008 backward.cc:435] Finish Backward
1901: I0814 08:12:35.579841 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.579922 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.579949 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.580121 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.581542 31008 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1960db40 for it.
1901: I0814 08:12:35.581590 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.581610 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.583967 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.584002 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.584980 31008 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 08:12:35.585006 31008 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 08:12:35.585799 31008 dygraph_functions.cc:33459] Running AD API: full
1901: I0814 08:12:35.585819 31008 dygraph_functions.cc:33480] { Input: []} 
1901: I0814 08:12:35.585920 31008 dygraph_functions.cc:33459] Running AD API: full
1901: I0814 08:12:35.585929 31008 dygraph_functions.cc:33480] { Input: []} 
1901: I0814 08:12:35.585989 31008 dygraph_functions.cc:33459] Running AD API: full
1901: I0814 08:12:35.585997 31008 dygraph_functions.cc:33480] { Input: []} 
1901: I0814 08:12:35.586052 31008 dygraph_functions.cc:82227] Running AD API: arange
1901: I0814 08:12:35.586090 31008 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.586254 31008 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0814 08:12:35.586277 31008 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.586297 31008 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0814 08:12:35.586369 31008 dygraph_functions.cc:14224] Running AD API: cast
1901: I0814 08:12:35.586387 31008 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.586472 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0814 08:12:35.586541 31008 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 08:12:35.586560 31008 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 08:12:35.586759 31008 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: test_nanmedian failed
1901:  ss.E.................
1901: ======================================================================
1901: ERROR: test_check_output (test_nanmedian.TestNanmedianFP16Op)
1901: ----------------------------------------------------------------------
1901: Traceback (most recent call last):
1901:   File "/home/code/Paddle/build/test/legacy_test/test_nanmedian.py", line 617, in test_check_output
1901:     self.check_output(check_pir=True)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2934, in check_output
1901:     res = self.check_output_with_place(
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2786, in check_output_with_place
1901:     symbol_checker.check()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2637, in check
1901:     self.infer_and_compare_symbol()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2645, in infer_and_compare_symbol
1901:     self.op_test._infer_and_compare_symbol(place)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1712, in _infer_and_compare_symbol
1901:     self._compare_symbol(program, outs)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1633, in _compare_symbol
1901:     shape_analysis.get_shape_or_data_for_var(
1901: RuntimeError: (PreconditionNotMet) The op operand index [1] must less than operands size[1].
1901:   [Hint: Expected index < num_operands_, but received index:1 >= num_operands_:1.] (at /home/code/Paddle/paddle/pir/src/core/operation.cc:420)
1901: 
1901: 
1901: ----------------------------------------------------------------------
1901: Ran 21 tests in 3.092s
1901: 
1901: FAILED (errors=1, skipped=2)
1901: 
1901: I0814 08:12:35.588092 31008 mmap_allocator.cc:348] PID: 31008, MemoryMapFdSet: set size - 0
1901: I0814 08:12:35.599861 31008 mmap_allocator.cc:348] PID: 31008, MemoryMapFdSet: set size - 0
1901: I0814 08:12:35.664551 31078 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 1651190509856109546 to 13078948732153049733 , after update, data is {current : -38, peak : 330659}.
1901: I0814 08:12:35.664579 31078 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 1651190509856109546 to 13078948732153049733 , after update, data is {current : 22, peak : 22}.
1901: I0814 08:12:35.664912 31079 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 11932523119525555780 to 14999222321141054918 , after update, data is {current : 0, peak : 260}.
1901: I0814 08:12:35.664932 31079 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 11932523119525555780 to 13078948732153049733 , after update, data is {current : 22, peak : 22}.
1901: I0814 08:12:35.664937 31079 thread_data_registry.h:135] Add data {current : 20, peak : 1252} from thread 11932523119525555780 to 13078948732153049733 , after update, data is {current : -18, peak : 330659}.
1901: I0814 08:12:35.665585 31052 thread_data_registry.h:135] Add data {current : 22, peak : 22} from thread 13078948732153049733 to 8131521400302728042 , after update, data is {current : 26, peak : 26}.
1901: I0814 08:12:35.665598 31052 thread_data_registry.h:135] Add data {current : -18, peak : 330659} from thread 13078948732153049733 to 15217090619034384529 , after update, data is {current : 0, peak : 330659}.
1901: I0814 08:12:35.665859 31056 thread_data_registry.h:135] Add data {current : 26, peak : 26} from thread 8131521400302728042 to 15217090619034384529 , after update, data is {current : 26, peak : 26}.
1901: I0814 08:12:35.666049 31057 thread_data_registry.h:135] Add data {current : 26, peak : 26} from thread 15217090619034384529 to 14999222321141054918 , after update, data is {current : 20026, peak : 40000}.
1901: I0814 08:12:35.666066 31057 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 15217090619034384529 to 14999222321141054918 , after update, data is {current : 162560, peak : 560633}.
1901: I0814 08:12:35.842816 31008 mmap_allocator.cc:348] PID: 31008, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................***Failed   11.38 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  11.57 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
