UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0815 09:27:24.521217 30053 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0815 09:27:25.308802 30053 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=enable_auto_detect_gpu_topo,enable_cse_in_dy2st,executor_log_deps_every_microseconds,enable_neighbor_list_use_uva,enable_record_memory,set_to_1d,enable_pir_api,logging_pir_py_code_dir,tensor_operants_mode,static_runtime_data_save_path,gpugraph_debug_gpu_memory,gpu_memory_limit_mb,fuse_parameter_groups_size,add_dependency_for_communication_op,gpugraph_load_node_list_into_hbm,enable_cinn_accuracy_check,cusolver_dir,npu_storage_format,pir_apply_inplace_pass,tracer_onednn_ops_on,log_memory_stats,manually_trans_conv_filter,alloc_fill_value,pir_subgraph_saving_dir,dump_chunk_info,free_idle_chunk,query_dest_rank_by_multi_node,graph_metapath_split_opt,jit_engine_type,enable_pir_in_executor_trace_run,op_dir,enable_dump_main_program,use_autotune,deny_cinn_ops,nccl_blocking_wait,pinned_memory_as_cpu_backend,accuracy_check_rtol_fp16,convert_all_blocks,auto_free_cudagraph_allocations_on_launch,check_infer_symbolic,enable_unused_var_check,gpugraph_parallel_copyer_split_maxsize,reallocate_gpu_memory_in_mb,check_nan_inf,auto_growth_chunk_size_in_mb,cusparse_dir,custom_device_mem_record,dataloader_use_file_descriptor,enable_auto_rdma_trans,prim_all,prim_check_ops,enable_cinn_auto_tune,pir_debug,disable_dyshape_in_train,gpugraph_slot_feasign_max_num,memory_fraction_of_eager_deletion,low_precision_op_list,new_executor_use_local_scope,gpu_allocator_retry_time,multiple_of_cupti_buffer_size,benchmark_nccl,einsum_opt,accuracy_check_atol_bf16,use_fast_math,enable_fuse_parallel_matmul_pass,gpugraph_merge_grads_segment_size,cse_max_count,local_exe_sub_scope_limit,cublas_dir,free_when_no_cache_hit,prim_skip_dynamic,nccl_dir,benchmark,cublaslt_device_best_config,nvidia_package_dir,dynamic_static_unified_comm,initial_cpu_memory_in_mb,enable_collect_shape,allow_cinn_ops,conv2d_disable_cudnn,call_stack_level,gpugraph_dedup_pull_push_mode,use_cuda_malloc_async_allocator,fraction_of_gpu_memory_to_use,mkl_dir,gpugraph_sparse_table_storage_mode,enable_tracker_all2all,cudnn_exhaustive_search,print_allocator_trace_info,gpugraph_enable_print_op_debug,enable_exit_when_partial_worker,graph_get_neighbor_id,use_system_allocator,all_blocks_convert_trt,apply_pass_to_program,fuse_parameter_memory_size,cudnn_exhaustive_search_times,new_executor_static_build,prim_forward_blacklist,cuda_memory_async_pool_realease_threshold,accuracy_check_rtol_fp32,enable_graph_multi_node_sampling,gpugraph_parallel_stream_num,graph_load_in_parallel,use_auto_growth_pinned_allocator,embedding_deterministic,enable_adjust_op_order,dist_threadpool_size,gpugraph_enable_hbm_table_collision_stat,initial_gpu_memory_in_mb,cudnn_batchnorm_spatial_persistent,paddle_num_threads,cinn_subgraph_graphviz_dir,gpugraph_enable_segment_merge_grads,dygraph_debug,enable_dependency_builder_debug_info,reader_queue_speed_test_mode,sort_sum_gradient,gpugraph_offload_param_stat,gpugraph_enable_gpu_direct_access,enable_sparse_inner_gather,cinn_compile_thread_num,new_executor_serial_run,prim_forward,sync_nccl_allreduce,cache_inference_while_scope,enable_async_trace,use_auto_growth_v2,prim_enable_dynamic,prim_enabled,eager_delete_tensor_gb,max_inplace_grad_add,conv_workspace_size_limit,allocator_strategy,fast_eager_deletion_mode,cusparselt_dir,graph_embedding_split_infer_mode,use_mkldnn,gpugraph_hbm_table_load_factor,cublaslt_exhaustive_search_times,logging_pir_py_code_int_tensor_element_limit,tracer_onednn_ops_off,logging_pir_py_code_dump_symbolic_dims,enable_gpu_memory_usage_log,search_cache_max_number,gpugraph_storage_mode,check_nan_inf_level,static_executor_perfstat_filepath,inner_op_parallelism,enable_fusion_fallback,new_executor_use_cuda_graph,enable_cublas_tensor_op_math,fraction_of_cuda_pinned_memory_to_use,lapack_dir,win_cuda_bin_dir,sync_after_alloc,check_kernel_launch,ir_inplace_kernel_blacklist,accuracy_check_rtol_bf16,use_stream_safe_cuda_allocator,print_ir,cudnn_dir,allreduce_record_one_event,use_cuda_managed_memory,gpugraph_force_device_batch_num_equal,new_executor_use_inplace,trt_ibuilder_cache,accuracy_check_atol_fp32,tracer_profile_fname,save_static_runtime_data,cuda_malloc_async_pool_memory_throttle_ratio,use_xqa_optim,fleet_executor_with_standalone,cupti_dir,accuracy_check_atol_fp16,cuda_dir,enable_interpretercore_launch_cinn,fraction_of_cpu_memory_to_use,enable_pir_with_pt_in_dy2st,async_trace_count,run_kp_kernel,enable_blaslt_global_search,init_allocated_mem,pir_broadcast_tree_limit,enable_gpu_memory_usage_log_mb,enable_pir_in_executor,tensorrt_dir,selected_gpus,print_sub_graph_dir,use_virtual_memory_auto_growth,pir_apply_shape_optimization_pass,use_shm_cache,eager_delete_scope,gemm_use_half_precision_compute_type,curand_dir,gpugraph_offload_param_extends,use_stride_kernel,host_trace_level,use_cinn,logging_trunc_pir_py_code,enable_api_kernel_fallback,cudnn_deterministic,new_executor_sequential_run,enable_all2all_use_fp16,use_pinned_memory,enable_opt_get_features,enable_cinn_compile_cache,get_host_by_name_time,multi_node_sample_use_gpu_table,graph_neighbor_size_percent,mklml_dir,gpugraph_offload_gather_copy_maxsize,prim_backward 
1901: I0815 09:27:25.308913 30053 init.cc:108] After Parse: argc is 2
1901: I0815 09:27:31.251235 30053 scope.cc:202] Create variable X
1901: I0815 09:27:31.251317 30053 scope.cc:202] Create variable Out
1901: I0815 09:27:31.251331 30053 scope.cc:202] Create variable MedianIndex
1901: I0815 09:27:31.251482 30053 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0815 09:27:31.252097 30053 allocator_facade.cc:212] selected allocator strategy:1
1901: I0815 09:27:31.252404 30053 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0815 09:27:33.746714 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.746771 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.746887 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.746897 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.747905 30053 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:27:33.747931 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.747972 30053 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:27:33.747980 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.748365 30053 pybind.cc:1827] need skip: 0
1901: I0815 09:27:33.748450 30053 pybind.cc:1827] need skip: 0
1901: I0815 09:27:33.748839 30053 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 09:27:33.749120 30053 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 09:27:33.749137 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:27:33.749218 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 09:27:33.749233 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:27:33.752172 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:33.752843 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.752861 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.752873 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:33.755882 30053 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:27:33.755899 30053 scope.cc:202] Create variable feed
1901: I0815 09:27:33.755965 30053 program_interpreter.cc:243] New Executor is Running.
1901: I0815 09:27:33.755973 30053 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:27:33.755981 30053 scope.cc:202] Create variable MedianIndex
1901: I0815 09:27:33.755991 30053 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x4590ee60 type is 7
1901: I0815 09:27:33.756006 30053 scope.cc:202] Create variable Out
1901: I0815 09:27:33.756011 30053 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4590f350 type is 7
1901: I0815 09:27:33.756016 30053 scope.cc:202] Create variable Out@GRAD
1901: I0815 09:27:33.756019 30053 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4590f800 type is 7
1901: I0815 09:27:33.756023 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.756026 30053 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x45910390 type is 7
1901: I0815 09:27:33.756031 30053 scope.cc:202] Create variable X@GRAD
1901: I0815 09:27:33.756034 30053 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45910600 type is 7
1901: I0815 09:27:33.756039 30053 scope.cc:202] Create variable _generated_var_0
1901: I0815 09:27:33.756042 30053 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45910840 type is 7
1901: I0815 09:27:33.756047 30053 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 09:27:33.756050 30053 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45910aa0 type is 7
1901: I0815 09:27:33.756054 30053 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4590ede0 type is 9
1901: I0815 09:27:33.756059 30053 scope.cc:202] Create variable fetch
1901: I0815 09:27:33.756062 30053 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45910820 type is 10
1901: I0815 09:27:33.756184 30053 interpreter_util.cc:594] Static build: 0
1901: I0815 09:27:33.756191 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.756196 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.756201 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0815 09:27:33.756809 30053 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0815 09:27:33.757009 30053 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0815 09:27:33.758023 30053 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0815 09:27:33.758226 30053 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.758249 30053 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.758383 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.758394 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.758414 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.762806 30053 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.762828 30053 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.762847 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.762923 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.763037 30053 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.763049 30053 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.763103 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.763125 30053 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0815 09:27:33.763157 30053 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.763165 30053 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.763182 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:27:33.763286 30053 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.763298 30053 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.763325 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:27:33.763449 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.763474 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.763497 30053 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:33.763505 30053 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4598d680Variable Type 7
1901: I0815 09:27:33.763523 30053 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:33.763546 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.763592 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.763612 30053 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.763731 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:33.763763 30053 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:27:33.764330 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.764375 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.765374 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.765396 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.765440 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.765450 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.766067 30053 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:27:33.766085 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.766119 30053 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:27:33.766125 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.766410 30053 pybind.cc:1827] need skip: 0
1901: I0815 09:27:33.766467 30053 pybind.cc:1827] need skip: 0
1901: I0815 09:27:33.766785 30053 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 09:27:33.766862 30053 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 09:27:33.766871 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:27:33.766937 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 09:27:33.766947 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:27:33.769001 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:33.769498 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.769512 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.769517 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:33.772933 30053 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:27:33.772953 30053 scope.cc:202] Create variable feed
1901: I0815 09:27:33.772979 30053 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:27:33.772989 30053 scope.cc:202] Create variable MedianIndex
1901: I0815 09:27:33.772992 30053 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x458e5c70 type is 7
1901: I0815 09:27:33.773000 30053 scope.cc:202] Create variable Out
1901: I0815 09:27:33.773005 30053 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x442e9750 type is 7
1901: I0815 09:27:33.773010 30053 scope.cc:202] Create variable Out@GRAD
1901: I0815 09:27:33.773012 30053 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44ca5f80 type is 7
1901: I0815 09:27:33.773016 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.773020 30053 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44b93500 type is 7
1901: I0815 09:27:33.773025 30053 scope.cc:202] Create variable X@GRAD
1901: I0815 09:27:33.773027 30053 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4413e280 type is 7
1901: I0815 09:27:33.773032 30053 scope.cc:202] Create variable _generated_var_0
1901: I0815 09:27:33.773036 30053 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x458de4c0 type is 7
1901: I0815 09:27:33.773039 30053 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 09:27:33.773042 30053 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44c94050 type is 7
1901: I0815 09:27:33.773047 30053 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45472920 type is 9
1901: I0815 09:27:33.773051 30053 scope.cc:202] Create variable fetch
1901: I0815 09:27:33.773056 30053 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x440853f0 type is 10
1901: I0815 09:27:33.773144 30053 interpreter_util.cc:594] Static build: 0
1901: I0815 09:27:33.773151 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.773155 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.773159 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:33.773202 30053 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773216 30053 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773264 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773273 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773289 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.773779 30053 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773797 30053 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773810 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.773859 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.773922 30053 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773932 30053 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.773968 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.774001 30053 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.774010 30053 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.774025 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:27:33.774099 30053 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.774109 30053 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.774125 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:27:33.774225 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.774238 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.774255 30053 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:33.774262 30053 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x458ec400Variable Type 7
1901: I0815 09:27:33.774278 30053 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:33.774292 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.774319 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.774334 30053 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.774389 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:33.774410 30053 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:27:33.774827 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:27:33.774863 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.776402 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:33.776592 30053 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1af73560 for it.
1901: I0815 09:27:33.776645 30053 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1afad0a0 for it.
1901: I0815 09:27:33.777465 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:33.777523 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:33.778050 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x458e6050)  to GradNodeAccumulation (addr: 0x1af6f050)
1901: I0815 09:27:33.778182 30053 dygraph_functions.cc:51757] Running AD API: mean
1901: I0815 09:27:33.778208 30053 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:33.778293 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.778326 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x2fcb39c0)  to NanmedianGradNode (addr: 0x458e6050)
1901: I0815 09:27:33.778412 30053 backward.cc:442] Run in Backward
1901: I0815 09:27:33.778424 30053 backward.cc:113] Start Backward
1901: I0815 09:27:33.778448 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:33.778502 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.778535 30053 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x2fcb39c0
1901: I0815 09:27:33.778549 30053 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0815 09:27:33.778592 30053 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:33.778666 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.778695 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:33.778707 30053 backward.cc:335] Node: MeanGradNode addr:0x2fcb39c0, Found pending node: NanmedianGradNode addr: 0x458e6050
1901: I0815 09:27:33.778714 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:33.778748 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x458e6050
1901: I0815 09:27:33.778764 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:33.778789 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:33.778844 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:33.778868 30053 backward.cc:335] Node: NanmedianGradNode addr:0x458e6050, Found pending node: GradNodeAccumulation addr: 0x1af6f050
1901: I0815 09:27:33.778877 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:33.778893 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1af6f050
1901: I0815 09:27:33.778904 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:33.778913 30053 accumulation_node.cc:40] Move Tensor ptr: 0x458f4010
1901: I0815 09:27:33.778918 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:33.778923 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0815 09:27:33.786197 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:33.786343 30053 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1afad0a0 for it.
1901: I0815 09:27:33.786386 30053 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1af73560 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0815 09:27:33.841204 30053 pir_interpreter.cc:161] PirInterpreter(): 0x47d35f20 on Place(gpu:0)
1901: I0815 09:27:33.841248 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.841274 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_1
1901: I0815 09:27:33.841284 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_2
1901: I0815 09:27:33.841292 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_3
1901: I0815 09:27:33.841307 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_4
1901: I0815 09:27:33.841317 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_5
1901: I0815 09:27:33.841324 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_6
1901: I0815 09:27:33.841332 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_7
1901: I0815 09:27:33.841339 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_8
1901: I0815 09:27:33.841347 30053 scope.cc:202] Create variable 0x47d35f201723714053841233140_inner_var_9
1901: I0815 09:27:33.841354 30053 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:27:33.841732 30053 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:27:33.841747 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.841750 30053 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0815 09:27:33.841790 30053 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47d35ee0
1901: 1 -> 0x47d35f201723714053841233140_inner_var_1 -> 0x47d35f00
1901: 2 -> 0x47d35f201723714053841233140_inner_var_2 -> 0x47d33300
1901: 3 -> 0x47d35f201723714053841233140_inner_var_3 -> 0x47d326c0
1901: 4 -> 0x47d35f201723714053841233140_inner_var_4 -> 0x47d336f0
1901: 5 -> 0x47d35f201723714053841233140_inner_var_5 -> 0x47d36590
1901: 6 -> 0x47d35f201723714053841233140_inner_var_6 -> 0x47d36880
1901: 7 -> 0x47d35f201723714053841233140_inner_var_7 -> 0x47d36ca0
1901: 8 -> 0x47d35f201723714053841233140_inner_var_8 -> 0x47d33930
1901: 9 -> 0x47d35f201723714053841233140_inner_var_9 -> 0x47d370c0
1901: 10 -> fetch0@fetch -> 0x47d378d0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0815 09:27:33.842710 30053 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0815 09:27:33.842926 30090 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:27:33.843015 30091 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:27:33.843128 30092 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:27:33.843142 30093 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:27:33.843202 30092 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x47d35f201723714053841233140_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.843258 30095 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:27:33.843271 30094 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:27:33.843307 30092 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x47d35f201723714053841233140_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0815 09:27:33.843325 30095 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.843374 30095 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:27:33.843428 30095 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47d35f201723714053841233140_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47d35f201723714053841233140_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.843926 30095 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47d35f201723714053841233140_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47d35f201723714053841233140_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:33.843958 30095 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x47d35f201723714053841233140_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.844007 30095 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.844022 30095 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x47d35f201723714053841233140_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:33.844048 30095 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x47d35f201723714053841233140_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x47d35f201723714053841233140_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.844133 30095 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.844151 30095 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x47d35f201723714053841233140_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x47d35f201723714053841233140_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:33.844179 30095 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x47d35f201723714053841233140_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47d35f201723714053841233140_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.844228 30095 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:33.844244 30095 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x47d35f201723714053841233140_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47d35f201723714053841233140_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:33.844265 30095 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x47d35f201723714053841233140_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47d35f201723714053841233140_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x47d35f201723714053841233140_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.844332 30095 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x47d35f201723714053841233140_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47d35f201723714053841233140_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x47d35f201723714053841233140_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:27:33.844400 30092 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47d35f201723714053841233140_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.844426 30092 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.844516 30092 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47d35f201723714053841233140_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d35f201723714053841233140_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 09:27:33.844547 30092 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47d35f201723714053841233140_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.844568 30092 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 09:27:33.844597 30092 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47d35f201723714053841233140_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 09:27:33.844630 30053 pir_interpreter.cc:1766] main_thread_blocker_(0x47d36090) got event_name: TaskCompletion
1901: I0815 09:27:33.844656 30053 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 09:27:33.847653 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.847684 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.847746 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.847759 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.848928 30090 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 5826817894723558918 to 12011369515868976376 , after update, data is {current : -20004, peak : 16}.
1901: I0815 09:27:33.848945 30090 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 5826817894723558918 to 12011369515868976376 , after update, data is {current : 0, peak : 330659}.
1901: I0815 09:27:33.849112 30092 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 11343631737347780108 to 12011369515868976376 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 09:27:33.849279 30095 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 12011369515868976376 to 3280877352669103884 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 09:27:33.849292 30095 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 12011369515868976376 to 3280877352669103884 , after update, data is {current : 120000, peak : 440631}.
1901: I0815 09:27:33.850673 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:33.851244 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:33.851732 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.851748 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.851754 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:33.854084 30053 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:27:33.854104 30053 scope.cc:202] Create variable feed
1901: I0815 09:27:33.854139 30053 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:27:33.854149 30053 scope.cc:202] Create variable MedianIndex
1901: I0815 09:27:33.854156 30053 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47da5020 type is 7
1901: I0815 09:27:33.854166 30053 scope.cc:202] Create variable Out
1901: I0815 09:27:33.854171 30053 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47da45b0 type is 7
1901: I0815 09:27:33.854175 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.854182 30053 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47da4fa0 type is 7
1901: I0815 09:27:33.854187 30053 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47da45d0 type is 9
1901: I0815 09:27:33.854193 30053 scope.cc:202] Create variable fetch
1901: I0815 09:27:33.854197 30053 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47da53d0 type is 10
1901: I0815 09:27:33.854270 30053 interpreter_util.cc:594] Static build: 0
1901: I0815 09:27:33.854277 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.854282 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.854287 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:33.854346 30053 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.854362 30053 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.854429 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.854439 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.854458 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.854952 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.854969 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.854991 30053 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:33.855000 30053 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47da9360Variable Type 7
1901: I0815 09:27:33.855018 30053 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:33.855038 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.855062 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.855080 30053 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.855123 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:33.855146 30053 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:27:33.855194 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.855206 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.855222 30053 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:33.855230 30053 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47d5be10Variable Type 7
1901: I0815 09:27:33.855244 30053 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:33.855259 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.855278 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.855293 30053 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.855340 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:33.855368 30053 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:27:33.855649 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.855679 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.856971 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.856998 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.857051 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:33.857062 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.858987 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:33.859566 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:33.860002 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.860018 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.860023 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:33.862279 30053 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:27:33.862365 30053 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:27:33.862376 30053 scope.cc:202] Create variable MedianIndex
1901: I0815 09:27:33.862385 30053 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47d897a0 type is 7
1901: I0815 09:27:33.862393 30053 scope.cc:202] Create variable Out
1901: I0815 09:27:33.862399 30053 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47d88ad0 type is 7
1901: I0815 09:27:33.862404 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.862408 30053 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47d894d0 type is 7
1901: I0815 09:27:33.862413 30053 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47da45d0 type is 9
1901: I0815 09:27:33.862419 30053 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47da53d0 type is 10
1901: I0815 09:27:33.862493 30053 interpreter_util.cc:594] Static build: 0
1901: I0815 09:27:33.862501 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:33.862505 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:33.862510 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:33.862551 30053 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.862565 30053 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.862620 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.862630 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.862648 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:33.863171 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.863188 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.863209 30053 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:33.863217 30053 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47d91040Variable Type 7
1901: I0815 09:27:33.863234 30053 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:33.863251 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.863274 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.863291 30053 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.863340 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:33.863363 30053 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:27:33.863411 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.863422 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:33.863440 30053 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:33.863447 30053 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47d8dc50Variable Type 7
1901: I0815 09:27:33.863461 30053 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:33.863476 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.863495 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:33.863510 30053 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.863545 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:33.863565 30053 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:27:33.863830 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.863859 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:33.979353 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af73560 for it.
1901: I0815 09:27:33.979777 30053 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1afad0a0 for it.
1901: I0815 09:27:33.979844 30053 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:33.980440 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:33.980486 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:33.981699 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af73560 for it.
1901: I0815 09:27:33.981853 30053 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:33.981907 30053 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1afad0a0 for it.
1901: I0815 09:27:33.983011 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:33.983049 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:33.985388 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af73560 for it.
1901: I0815 09:27:33.985543 30053 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1afad0a0 for it.
1901: I0815 09:27:33.985592 30053 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 09:27:33.988794 30053 pir_interpreter.cc:161] PirInterpreter(): 0x47d8a3b0 on Place(gpu:0)
1901: I0815 09:27:33.988831 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.988853 30053 scope.cc:202] Create variable 0x47d8a3b01723714053988821537_inner_var_1
1901: I0815 09:27:33.988865 30053 scope.cc:202] Create variable 0x47d8a3b01723714053988821537_inner_var_2
1901: I0815 09:27:33.988875 30053 scope.cc:202] Create variable 0x47d8a3b01723714053988821537_inner_var_3
1901: I0815 09:27:33.988884 30053 scope.cc:202] Create variable 0x47d8a3b01723714053988821537_inner_var_4
1901: I0815 09:27:33.988895 30053 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:27:33.989261 30053 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:27:33.989277 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.989281 30053 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x44d29ed0
1901: 1 -> 0x47d8a3b01723714053988821537_inner_var_1 -> 0x47d889c0
1901: 2 -> 0x47d8a3b01723714053988821537_inner_var_2 -> 0x47d33e70
1901: 3 -> 0x47d8a3b01723714053988821537_inner_var_3 -> 0x47d91760
1901: 4 -> 0x47d8a3b01723714053988821537_inner_var_4 -> 0x47d889e0
1901: 5 -> fetch0@fetch -> 0x47d32720
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 09:27:33.989955 30097 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:27:33.990097 30098 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:27:33.990159 30099 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:27:33.990206 30100 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:27:33.990214 30101 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:27:33.990307 30102 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:27:33.990348 30102 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d8a3b01723714053988821537_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.990388 30102 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d8a3b01723714053988821537_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:27:33.990424 30102 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47d8a3b01723714053988821537_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d8a3b01723714053988821537_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47d8a3b01723714053988821537_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.990852 30102 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47d8a3b01723714053988821537_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47d8a3b01723714053988821537_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47d8a3b01723714053988821537_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:33.990940 30101 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47d8a3b01723714053988821537_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47d8a3b01723714053988821537_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.990991 30101 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.991062 30101 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47d8a3b01723714053988821537_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47d8a3b01723714053988821537_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:33.991096 30101 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47d8a3b01723714053988821537_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.991114 30101 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:33.991128 30101 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47d8a3b01723714053988821537_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:33.991154 30053 pir_interpreter.cc:1766] main_thread_blocker_(0x47d8a520) got event_name: TaskCompletion
1901: I0815 09:27:33.991175 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:33.991689 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:33.991827 30053 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1afad0a0 for it.
1901: I0815 09:27:33.991869 30053 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1af73560 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 09:27:33.993974 30053 pir_interpreter.cc:161] PirInterpreter(): 0x1b1899a0 on Place(gpu:0)
1901: I0815 09:27:33.994000 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.994015 30053 scope.cc:202] Create variable 0x1b1899a01723714053993994629_inner_var_1
1901: I0815 09:27:33.994025 30053 scope.cc:202] Create variable 0x1b1899a01723714053993994629_inner_var_2
1901: I0815 09:27:33.994032 30053 scope.cc:202] Create variable 0x1b1899a01723714053993994629_inner_var_3
1901: I0815 09:27:33.994041 30053 scope.cc:202] Create variable 0x1b1899a01723714053993994629_inner_var_4
1901: I0815 09:27:33.994048 30053 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:27:33.994318 30053 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:27:33.994333 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.994335 30053 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47da75d0
1901: 1 -> 0x1b1899a01723714053993994629_inner_var_1 -> 0x47db2bd0
1901: 2 -> 0x1b1899a01723714053993994629_inner_var_2 -> 0x47d47a30
1901: 3 -> 0x1b1899a01723714053993994629_inner_var_3 -> 0x455cac30
1901: 4 -> 0x1b1899a01723714053993994629_inner_var_4 -> 0x47da2fe0
1901: 5 -> fetch0@fetch -> 0x47d6abf0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 09:27:33.994846 30103 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:27:33.995028 30104 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:27:33.995059 30105 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:27:33.995121 30106 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:27:33.995194 30107 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:27:33.995239 30108 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:27:33.995277 30108 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1b1899a01723714053993994629_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.995316 30108 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1b1899a01723714053993994629_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:27:33.995349 30108 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x1b1899a01723714053993994629_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1b1899a01723714053993994629_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1b1899a01723714053993994629_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.995767 30108 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x1b1899a01723714053993994629_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1b1899a01723714053993994629_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x1b1899a01723714053993994629_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:33.995828 30107 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1b1899a01723714053993994629_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x1b1899a01723714053993994629_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.995852 30107 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:33.995908 30107 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1b1899a01723714053993994629_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x1b1899a01723714053993994629_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:33.995931 30107 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1b1899a01723714053993994629_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:33.995949 30107 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:33.995959 30107 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1b1899a01723714053993994629_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:33.995985 30053 pir_interpreter.cc:1766] main_thread_blocker_(0x1b189b10) got event_name: TaskCompletion
1901: I0815 09:27:33.996004 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:33.997088 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af73560 for it.
1901: I0815 09:27:33.997227 30053 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1afad0a0 for it.
1901: I0815 09:27:33.997269 30053 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 09:27:33.999336 30053 pir_interpreter.cc:161] PirInterpreter(): 0x47dafb80 on Place(gpu:0)
1901: I0815 09:27:33.999361 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.999377 30053 scope.cc:202] Create variable 0x47dafb801723714053999356366_inner_var_1
1901: I0815 09:27:33.999387 30053 scope.cc:202] Create variable 0x47dafb801723714053999356366_inner_var_2
1901: I0815 09:27:33.999392 30053 scope.cc:202] Create variable 0x47dafb801723714053999356366_inner_var_3
1901: I0815 09:27:33.999401 30053 scope.cc:202] Create variable 0x47dafb801723714053999356366_inner_var_4
1901: I0815 09:27:33.999409 30053 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:27:33.999670 30053 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:27:33.999682 30053 scope.cc:202] Create variable X
1901: I0815 09:27:33.999686 30053 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47db1a10
1901: 1 -> 0x47dafb801723714053999356366_inner_var_1 -> 0x47db1a90
1901: 2 -> 0x47dafb801723714053999356366_inner_var_2 -> 0x47db0ed0
1901: 3 -> 0x47dafb801723714053999356366_inner_var_3 -> 0x47db1c50
1901: 4 -> 0x47dafb801723714053999356366_inner_var_4 -> 0x47d60700
1901: 5 -> fetch0@fetch -> 0x47d8d0b0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 09:27:34.000172 30109 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:27:34.000360 30110 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:27:34.000372 30111 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:27:34.000433 30112 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:27:34.000525 30113 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:27:34.000584 30114 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:27:34.000627 30114 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47dafb801723714053999356366_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.000646 30114 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47dafb801723714053999356366_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:27:34.000670 30114 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47dafb801723714053999356366_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47dafb801723714053999356366_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47dafb801723714053999356366_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.001062 30114 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47dafb801723714053999356366_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47dafb801723714053999356366_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47dafb801723714053999356366_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.001116 30113 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47dafb801723714053999356366_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47dafb801723714053999356366_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.001134 30113 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.001178 30113 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47dafb801723714053999356366_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47dafb801723714053999356366_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.001199 30113 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47dafb801723714053999356366_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.001214 30113 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.001225 30113 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47dafb801723714053999356366_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.001250 30053 pir_interpreter.cc:1766] main_thread_blocker_(0x47dafcf0) got event_name: TaskCompletion
1901: I0815 09:27:34.001268 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.001417 30053 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0815 09:27:34.001513 30053 unary_infer_sym.cc:1363] NanmedianOpInferSymbolicShape
1901: I0815 09:27:34.044310 30097 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 12011369515868976376 to 11930124498404334244 , after update, data is {current : 2, peak : 4}.
1901: I0815 09:27:34.044322 30097 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 12011369515868976376 to 11219253591607565080 , after update, data is {current : 0, peak : 330659}.
1901: I0815 09:27:34.044545 30101 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 13215644345520930588 to 11930124498404334244 , after update, data is {current : 6, peak : 6}.
1901: I0815 09:27:34.044659 30102 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 11343631737347780108 to 11930124498404334244 , after update, data is {current : 6, peak : 16}.
1901: I0815 09:27:34.044672 30102 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 11343631737347780108 to 11219253591607565080 , after update, data is {current : 18, peak : 330659}.
1901: I0815 09:27:34.044819 30103 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 4227082113078938370 to 11930124498404334244 , after update, data is {current : 4, peak : 16}.
1901: I0815 09:27:34.044828 30103 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 4227082113078938370 to 11219253591607565080 , after update, data is {current : 0, peak : 330659}.
1901: I0815 09:27:34.044978 30107 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 9235265874173315262 to 11930124498404334244 , after update, data is {current : 8, peak : 16}.
1901: I0815 09:27:34.045154 30108 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 8594562937494067232 to 11930124498404334244 , after update, data is {current : 8, peak : 16}.
1901: I0815 09:27:34.045164 30108 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 8594562937494067232 to 11219253591607565080 , after update, data is {current : 18, peak : 330659}.
1901: I0815 09:27:34.045291 30109 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 2503580035889787007 to 11930124498404334244 , after update, data is {current : 6, peak : 16}.
1901: I0815 09:27:34.045307 30109 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 2503580035889787007 to 11219253591607565080 , after update, data is {current : 0, peak : 330659}.
1901: I0815 09:27:34.045447 30113 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 11930124498404334244 to 11219253591607565080 , after update, data is {current : 6, peak : 16}.
1901: I0815 09:27:34.045614 30114 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 11219253591607565080 to 3280877352669103884 , after update, data is {current : 20006, peak : 40004}.
1901: I0815 09:27:34.045621 30114 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 11219253591607565080 to 3280877352669103884 , after update, data is {current : 200000, peak : 560633}.
1901: I0815 09:27:34.049888 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.049983 30053 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7f99bc027c00), and remaining 0
1901: I0815 09:27:34.050065 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.050093 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.050343 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.051100 30053 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.051178 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.051203 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.051378 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.052060 30053 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.052132 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.052157 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.052318 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.052934 30053 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.053005 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.053030 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.053184 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0815 09:27:34.053874 30053 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.053929 30053 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f99bc018e00), and remaining 0
1901: I0815 09:27:34.053979 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.054003 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.054476 30053 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.054543 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.054567 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.055016 30053 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.055079 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.055104 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.055519 30053 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.055584 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.055608 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.056164 30053 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.056233 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.056258 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.056443 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.057068 30053 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.057140 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.057165 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.057327 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.058002 30053 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.058072 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.058099 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.058295 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.058910 30053 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.058981 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.059006 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.059162 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.059827 30053 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.059899 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.059926 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.060117 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.060766 30053 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.060838 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.060864 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.061024 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.061728 30053 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.061800 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.061826 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.061981 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.062656 30053 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.062731 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.062757 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.062908 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.063612 30053 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.063683 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.063709 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.063879 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.064508 30053 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x47da5a60 for it.
1901: I0815 09:27:34.064580 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.064605 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.064762 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.065282 30053 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.065358 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.065384 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.065533 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.066205 30053 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.066269 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.066294 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.066448 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.067091 30053 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.067159 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.067184 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.067435 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0815 09:27:34.069262 30053 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.069344 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.069371 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.069555 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.070895 30053 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.070971 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.070996 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.071211 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.072536 30053 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.072610 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.072636 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.072813 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.074031 30053 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.074105 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.074131 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.074398 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.075623 30053 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.075699 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.075724 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.075906 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.077193 30053 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.077268 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.077294 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.077486 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.078775 30053 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.078850 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.078876 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.079052 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.080264 30053 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.080348 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.080374 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.080610 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.081921 30053 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.081996 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.082022 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.082204 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.083415 30053 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.083488 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.083514 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.083717 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.084932 30053 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.085007 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.085033 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.085214 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.086498 30053 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.086572 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.086598 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.086778 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.088004 30053 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.088078 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.088104 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.088280 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.089550 30053 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.089624 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.089650 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.089828 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.091037 30053 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.091111 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.091137 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.091321 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.092519 30053 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.092593 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.092618 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.092794 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.093531 30053 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.093602 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.093627 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.093799 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.096449 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.096477 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.097317 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.097340 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.098109 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.098130 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.098915 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.098938 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.099699 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.099720 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.102227 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.102771 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.103286 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.103808 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.104329 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.105149 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:34.105166 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:34.105172 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:34.110116 30053 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:27:34.110189 30053 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:27:34.110201 30053 scope.cc:202] Create variable X
1901: I0815 09:27:34.110209 30053 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x48068420 type is 7
1901: I0815 09:27:34.110219 30053 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47da45d0 type is 9
1901: I0815 09:27:34.110225 30053 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47da53d0 type is 10
1901: I0815 09:27:34.110234 30053 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 09:27:34.110237 30053 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x47d7bbc0 type is 7
1901: I0815 09:27:34.110244 30053 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 09:27:34.110247 30053 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x47d7b4f0 type is 7
1901: I0815 09:27:34.110252 30053 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 09:27:34.110260 30053 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x47d7b5f0 type is 7
1901: I0815 09:27:34.110265 30053 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 09:27:34.110270 30053 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x47d5f940 type is 7
1901: I0815 09:27:34.110275 30053 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 09:27:34.110278 30053 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x48068590 type is 7
1901: I0815 09:27:34.110283 30053 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 09:27:34.110291 30053 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x480686c0 type is 7
1901: I0815 09:27:34.110296 30053 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 09:27:34.110311 30053 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x480688d0 type is 7
1901: I0815 09:27:34.110319 30053 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 09:27:34.110323 30053 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x48068b30 type is 7
1901: I0815 09:27:34.110328 30053 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 09:27:34.110332 30053 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x48068d90 type is 7
1901: I0815 09:27:34.110338 30053 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 09:27:34.110342 30053 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x48068ff0 type is 7
1901: I0815 09:27:34.110473 30053 interpreter_util.cc:594] Static build: 0
1901: I0815 09:27:34.110481 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:34.110486 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:34.110491 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:34.110553 30053 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.110567 30053 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.110632 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.110642 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.110659 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.110836 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.111042 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.111053 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.111070 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.111203 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.111395 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.111408 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.111424 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.111552 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.111737 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.111747 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.111764 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.111922 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.112125 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.112138 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.112154 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.112315 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.112511 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.112524 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.112541 30053 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.112550 30053 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4804f300Variable Type 7
1901: I0815 09:27:34.112569 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.112588 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.112612 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.112629 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.112673 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.112694 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:27:34.112737 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.112747 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.112762 30053 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.112771 30053 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x48076c80Variable Type 7
1901: I0815 09:27:34.112784 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.112798 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.112818 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.112831 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.112866 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.112891 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:27:34.112937 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.112947 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.112962 30053 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.112969 30053 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x48076930Variable Type 7
1901: I0815 09:27:34.112983 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.112996 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.113015 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.113029 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.113060 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.113072 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 09:27:34.113111 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.113122 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.113137 30053 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.113143 30053 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4804f1e0Variable Type 7
1901: I0815 09:27:34.113157 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.113169 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.113188 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.113201 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.113233 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.113247 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 09:27:34.113286 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.113296 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.113322 30053 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.113329 30053 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x48076000Variable Type 7
1901: I0815 09:27:34.113343 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.113356 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.113374 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.113389 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.113421 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.113435 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 09:27:34.114035 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.114070 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.114090 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.114110 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.114130 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 09:27:34.120203 30053 pir_interpreter.cc:161] PirInterpreter(): 0x4816fe50 on Place(gpu:0)
1901: I0815 09:27:34.120234 30053 scope.cc:202] Create variable X
1901: I0815 09:27:34.120254 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_1
1901: I0815 09:27:34.120265 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_2
1901: I0815 09:27:34.120275 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_3
1901: I0815 09:27:34.120286 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_4
1901: I0815 09:27:34.120294 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_5
1901: I0815 09:27:34.120312 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_6
1901: I0815 09:27:34.120322 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_7
1901: I0815 09:27:34.120330 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_8
1901: I0815 09:27:34.120339 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_9
1901: I0815 09:27:34.120347 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_10
1901: I0815 09:27:34.120357 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_11
1901: I0815 09:27:34.120366 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_12
1901: I0815 09:27:34.120376 30053 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:27:34.120391 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_14
1901: I0815 09:27:34.120401 30053 scope.cc:202] Create variable fetch1@fetch
1901: I0815 09:27:34.120410 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_16
1901: I0815 09:27:34.120420 30053 scope.cc:202] Create variable fetch2@fetch
1901: I0815 09:27:34.120429 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_18
1901: I0815 09:27:34.120437 30053 scope.cc:202] Create variable fetch3@fetch
1901: I0815 09:27:34.120445 30053 scope.cc:202] Create variable 0x4816fe501723714054120226661_inner_var_20
1901: I0815 09:27:34.120455 30053 scope.cc:202] Create variable fetch4@fetch
1901: I0815 09:27:34.120731 30053 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:27:34.120745 30053 scope.cc:202] Create variable X
1901: I0815 09:27:34.120749 30053 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x1b052bf0
1901: 1 -> 0x4816fe501723714054120226661_inner_var_1 -> 0x481966c0
1901: 2 -> 0x4816fe501723714054120226661_inner_var_2 -> 0x48194730
1901: 3 -> 0x4816fe501723714054120226661_inner_var_3 -> 0x48074250
1901: 4 -> 0x4816fe501723714054120226661_inner_var_4 -> 0x4598ec00
1901: 5 -> 0x4816fe501723714054120226661_inner_var_5 -> 0x4806b530
1901: 6 -> 0x4816fe501723714054120226661_inner_var_6 -> 0x48068030
1901: 7 -> 0x4816fe501723714054120226661_inner_var_7 -> 0x4819b2c0
1901: 8 -> 0x4816fe501723714054120226661_inner_var_8 -> 0x48084860
1901: 9 -> 0x4816fe501723714054120226661_inner_var_9 -> 0x48081cf0
1901: 10 -> 0x4816fe501723714054120226661_inner_var_10 -> 0x480820c0
1901: 11 -> 0x4816fe501723714054120226661_inner_var_11 -> 0x47d874d0
1901: 12 -> 0x4816fe501723714054120226661_inner_var_12 -> 0x48099ea0
1901: 13 -> fetch0@fetch -> 0x47d86e70
1901: 14 -> 0x4816fe501723714054120226661_inner_var_14 -> 0x47d86a30
1901: 15 -> fetch1@fetch -> 0x4808d8a0
1901: 16 -> 0x4816fe501723714054120226661_inner_var_16 -> 0x47d86e50
1901: 17 -> fetch2@fetch -> 0x4818e9c0
1901: 18 -> 0x4816fe501723714054120226661_inner_var_18 -> 0x4808d880
1901: 19 -> fetch3@fetch -> 0x480747a0
1901: 20 -> 0x4816fe501723714054120226661_inner_var_20 -> 0x4818e9a0
1901: 21 -> fetch4@fetch -> 0x4819ea30
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 09:27:34.122167 30115 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:27:34.122182 30116 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:27:34.122208 30117 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:27:34.122238 30118 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:27:34.122278 30119 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:27:34.122309 30119 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.122344 30119 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 09:27:34.122387 30119 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4816fe501723714054120226661_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.122560 30119 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.122717 30119 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4816fe501723714054120226661_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.122766 30119 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_5:[dtype=;place=;dim=;lod={};, 0x4816fe501723714054120226661_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.122786 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.122819 30118 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.122901 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.122920 30119 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.122958 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.122977 30118 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.122988 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.123095 30119 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4816fe501723714054120226661_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.123136 30119 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_7:[dtype=;place=;dim=;lod={};, 0x4816fe501723714054120226661_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123142 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123157 30118 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.123212 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.123261 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123276 30118 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.123286 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.123310 30119 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.123458 30119 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4816fe501723714054120226661_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.123497 30119 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_9:[dtype=;place=;dim=;lod={};, 0x4816fe501723714054120226661_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123504 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123517 30118 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.123548 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.123584 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123598 30118 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.123607 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.123656 30119 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.123806 30119 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4816fe501723714054120226661_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.123845 30119 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_11:[dtype=;place=;dim=;lod={};, 0x4816fe501723714054120226661_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123853 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123867 30118 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.123898 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.123981 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.123997 30118 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.124006 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.124023 30119 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.124173 30119 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4816fe501723714054120226661_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4816fe501723714054120226661_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.124222 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.124236 30118 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.124262 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4816fe501723714054120226661_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4816fe501723714054120226661_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.124297 30118 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.124316 30118 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.124328 30118 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4816fe501723714054120226661_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.124356 30053 pir_interpreter.cc:1766] main_thread_blocker_(0x4816ffc0) got event_name: TaskCompletion
1901: I0815 09:27:34.124377 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.124401 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.124410 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.124418 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.124428 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.126027 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.126116 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.126144 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.126327 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.126432 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x4818c9c0)  to GradNodeAccumulation (addr: 0x481a2c50)
1901: I0815 09:27:34.126560 30053 backward.cc:459] Run in Grad
1901: I0815 09:27:34.126575 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.126624 30053 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x4818c9c0 to ptr: 0x47d3c410
1901: I0815 09:27:34.126636 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.126680 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.126715 30053 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x481a2c50 to ptr: 0x48030390
1901: I0815 09:27:34.126742 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47d3c410
1901: I0815 09:27:34.126750 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.126785 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.126849 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.126858 30053 backward.cc:335] Node: NanmedianGradNode addr:0x47d3c410, Found pending node: GradNodeAccumulation addr: 0x48030390
1901: I0815 09:27:34.126864 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.126889 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x48030390
1901: I0815 09:27:34.126897 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.126901 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.126907 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.126912 30053 backward.cc:435] Finish Backward
1901: I0815 09:27:34.127614 30053 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 09:27:34.127633 30053 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 09:27:34.127733 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.127756 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.127902 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.127977 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47d3c410)  to GradNodeAccumulation (addr: 0x481a2c50)
1901: I0815 09:27:34.128072 30053 backward.cc:442] Run in Backward
1901: I0815 09:27:34.128080 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.128086 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.128118 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.128144 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47d3c410
1901: I0815 09:27:34.128152 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.128180 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.128237 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.128264 30053 backward.cc:335] Node: NanmedianGradNode addr:0x47d3c410, Found pending node: GradNodeAccumulation addr: 0x481a2c50
1901: I0815 09:27:34.128273 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.128290 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x481a2c50
1901: I0815 09:27:34.128297 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.128312 30053 accumulation_node.cc:40] Move Tensor ptr: 0x48191ca0
1901: I0815 09:27:34.128316 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.128321 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.130124 30053 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0815 09:27:34.130630 30053 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.130746 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.130774 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.130941 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x48094600)  to GradNodeAccumulation (addr: 0x1af6f050)
1901: I0815 09:27:34.131043 30053 backward.cc:442] Run in Backward
1901: I0815 09:27:34.131052 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.131059 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.131090 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.131114 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x48094600
1901: I0815 09:27:34.131122 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.131152 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.131201 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.131227 30053 backward.cc:335] Node: NanmedianGradNode addr:0x48094600, Found pending node: GradNodeAccumulation addr: 0x1af6f050
1901: I0815 09:27:34.131234 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.131251 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1af6f050
1901: I0815 09:27:34.131258 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.131263 30053 accumulation_node.cc:40] Move Tensor ptr: 0x4818aef0
1901: I0815 09:27:34.131266 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.131270 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.132019 30053 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.132102 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.132128 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.132339 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.132439 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47d3c410)  to GradNodeAccumulation (addr: 0x1af6f050)
1901: I0815 09:27:34.132560 30053 backward.cc:459] Run in Grad
1901: I0815 09:27:34.132570 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.132581 30053 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47d3c410 to ptr: 0x47d76ab0
1901: I0815 09:27:34.132591 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.132622 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.132645 30053 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1af6f050 to ptr: 0x48030390
1901: I0815 09:27:34.132664 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47d76ab0
1901: I0815 09:27:34.132673 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.132701 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.132831 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.132841 30053 backward.cc:335] Node: NanmedianGradNode addr:0x47d76ab0, Found pending node: GradNodeAccumulation addr: 0x48030390
1901: I0815 09:27:34.132846 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.132863 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x48030390
1901: I0815 09:27:34.132870 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.132874 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.132879 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.132884 30053 backward.cc:435] Finish Backward
1901: I0815 09:27:34.133775 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.133855 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.133882 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.134043 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.135484 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.135541 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.135564 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.140933 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.140973 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.144547 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.144569 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.145514 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.145651 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.145690 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.145958 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.160319 30053 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.160410 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.160439 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.160632 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.161239 30053 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.161326 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.161355 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.161526 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.162096 30053 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.162173 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.162200 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.162384 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.162986 30053 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.163038 30053 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f99bc019200), and remaining 0
1901: I0815 09:27:34.163095 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.163121 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.164461 30053 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.164542 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.164572 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.165104 30053 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.165176 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.165203 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.165823 30053 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.165910 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.165938 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.166488 30053 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.166560 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.166586 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.166779 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.167542 30053 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.167637 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.167668 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.167866 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.168498 30053 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.168578 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.168606 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.168776 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.169373 30053 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.169452 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.169481 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.169651 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.170260 30053 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.170347 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.170377 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.170543 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.171128 30053 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.171209 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.171236 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.171422 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.172036 30053 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.172114 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.172142 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.172320 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.172923 30053 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.173002 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.173030 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.173197 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.173825 30053 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.173902 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.173930 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.174098 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.174681 30053 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.174760 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.174787 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.174957 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.175486 30053 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.175541 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.175561 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.175683 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.176275 30053 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.176352 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.176378 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.176524 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.177162 30053 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.177237 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.177264 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.177479 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.178159 30053 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.178228 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.178254 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.178440 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.179101 30053 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.179172 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.179196 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.179386 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.180028 30053 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.180097 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.180122 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.180295 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.180943 30053 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.181011 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.181036 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.181211 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.181834 30053 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.181903 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.181929 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.182101 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.182723 30053 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.182793 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.182818 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.182991 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.183634 30053 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.183703 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.183729 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.183900 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.184543 30053 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.184613 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.184639 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.184810 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.185432 30053 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.185503 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.185528 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.185699 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.186311 30053 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.186383 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.186407 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.186589 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.187189 30053 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.187258 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.187283 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.187464 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.188067 30053 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.188136 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.188161 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.188339 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.188939 30053 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.189006 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.189031 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.189195 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.189821 30053 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.189890 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.189915 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.190084 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.190766 30053 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.190843 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.190871 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.191059 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.191653 30053 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.191725 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.191749 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.191918 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.192652 30053 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.192730 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.192759 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.192945 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.195077 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.195101 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.195734 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.195753 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.196362 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.196379 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.196987 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.197006 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.197613 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.197633 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.198951 30118 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 13215644345520930588 to 11343631737347780108 , after update, data is {current : 0, peak : 1260}.
1901: I0815 09:27:34.198966 30118 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 13215644345520930588 to 11343631737347780108 , after update, data is {current : 20, peak : 24}.
1901: I0815 09:27:34.199276 30119 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 11343631737347780108 to 3280877352669103884 , after update, data is {current : 0, peak : 260}.
1901: I0815 09:27:34.199288 30119 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 11343631737347780108 to 3280877352669103884 , after update, data is {current : 20026, peak : 40004}.
1901: I0815 09:27:34.199293 30119 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 11343631737347780108 to 3280877352669103884 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 09:27:34.200701 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.201129 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.201555 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.201973 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.202396 30053 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:27:34.203092 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:34.203106 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:34.203111 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:34.207051 30053 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:27:34.207093 30053 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:27:34.207103 30053 scope.cc:202] Create variable X
1901: I0815 09:27:34.207108 30053 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47d719d0 type is 7
1901: I0815 09:27:34.207114 30053 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47da45d0 type is 9
1901: I0815 09:27:34.207121 30053 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47da53d0 type is 10
1901: I0815 09:27:34.207126 30053 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 09:27:34.207129 30053 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x481aa9f0 type is 7
1901: I0815 09:27:34.207134 30053 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 09:27:34.207137 30053 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x481aa530 type is 7
1901: I0815 09:27:34.207141 30053 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 09:27:34.207144 30053 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x47d71b50 type is 7
1901: I0815 09:27:34.207149 30053 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 09:27:34.207152 30053 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x47d71c30 type is 7
1901: I0815 09:27:34.207156 30053 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 09:27:34.207159 30053 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x47d71d60 type is 7
1901: I0815 09:27:34.207165 30053 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 09:27:34.207167 30053 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x47d71fc0 type is 7
1901: I0815 09:27:34.207171 30053 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 09:27:34.207175 30053 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x47d721d0 type is 7
1901: I0815 09:27:34.207178 30053 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 09:27:34.207181 30053 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x47d72430 type is 7
1901: I0815 09:27:34.207186 30053 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 09:27:34.207190 30053 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x47d72690 type is 7
1901: I0815 09:27:34.207194 30053 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 09:27:34.207198 30053 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x47d72860 type is 7
1901: I0815 09:27:34.207315 30053 interpreter_util.cc:594] Static build: 0
1901: I0815 09:27:34.207322 30053 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:27:34.207326 30053 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:27:34.207330 30053 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:27:34.207377 30053 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.207391 30053 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.207437 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.207446 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.207460 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.207607 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.207789 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.207800 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.207814 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.207930 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.208106 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.208114 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.208128 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.208233 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.208402 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.208412 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.208426 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.208550 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.208734 30053 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.208743 30053 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.208756 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.208880 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.209055 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209065 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209079 30053 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.209086 30053 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x48055570Variable Type 7
1901: I0815 09:27:34.209102 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.209117 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.209136 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.209151 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.209184 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.209200 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:27:34.209235 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209244 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209256 30053 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.209262 30053 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47d71090Variable Type 7
1901: I0815 09:27:34.209275 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.209286 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.209311 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.209323 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.209354 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.209376 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:27:34.209415 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209424 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209436 30053 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.209442 30053 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4805ac90Variable Type 7
1901: I0815 09:27:34.209455 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.209465 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.209481 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.209492 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.209520 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.209532 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 09:27:34.209568 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209576 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209587 30053 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.209594 30053 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4816dac0Variable Type 7
1901: I0815 09:27:34.209604 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.209614 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.209630 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.209641 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.209669 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.209681 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 09:27:34.209712 30053 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209720 30053 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:27:34.209731 30053 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:27:34.209738 30053 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4807a000Variable Type 7
1901: I0815 09:27:34.209748 30053 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:27:34.209758 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.209774 30053 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:27:34.209785 30053 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.209812 30053 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:27:34.209823 30053 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 09:27:34.210314 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.210343 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.210361 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.210376 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:27:34.210393 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 09:27:34.215605 30053 pir_interpreter.cc:161] PirInterpreter(): 0x48093a30 on Place(gpu:0)
1901: I0815 09:27:34.215636 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_1
1901: I0815 09:27:34.215647 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_2
1901: I0815 09:27:34.215657 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_3
1901: I0815 09:27:34.215664 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_4
1901: I0815 09:27:34.215670 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_5
1901: I0815 09:27:34.215677 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_6
1901: I0815 09:27:34.215687 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_7
1901: I0815 09:27:34.215692 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_8
1901: I0815 09:27:34.215699 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_9
1901: I0815 09:27:34.215706 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_10
1901: I0815 09:27:34.215715 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_11
1901: I0815 09:27:34.215723 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_12
1901: I0815 09:27:34.215734 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_14
1901: I0815 09:27:34.215746 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_16
1901: I0815 09:27:34.215759 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_18
1901: I0815 09:27:34.215770 30053 scope.cc:202] Create variable 0x48093a301723714054215625153_inner_var_20
1901: I0815 09:27:34.215994 30053 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x4819ed40
1901: 1 -> 0x48093a301723714054215625153_inner_var_1 -> 0x4804c640
1901: 2 -> 0x48093a301723714054215625153_inner_var_2 -> 0x4804c680
1901: 3 -> 0x48093a301723714054215625153_inner_var_3 -> 0x48170bc0
1901: 4 -> 0x48093a301723714054215625153_inner_var_4 -> 0x6a0cc40
1901: 5 -> 0x48093a301723714054215625153_inner_var_5 -> 0x4807acf0
1901: 6 -> 0x48093a301723714054215625153_inner_var_6 -> 0x480926b0
1901: 7 -> 0x48093a301723714054215625153_inner_var_7 -> 0x48077780
1901: 8 -> 0x48093a301723714054215625153_inner_var_8 -> 0x1b03bb20
1901: 9 -> 0x48093a301723714054215625153_inner_var_9 -> 0x47da3e70
1901: 10 -> 0x48093a301723714054215625153_inner_var_10 -> 0x48185fe0
1901: 11 -> 0x48093a301723714054215625153_inner_var_11 -> 0x4807dee0
1901: 12 -> 0x48093a301723714054215625153_inner_var_12 -> 0x48030820
1901: 13 -> fetch0@fetch -> 0x47d86e70
1901: 14 -> 0x48093a301723714054215625153_inner_var_14 -> 0x47d3b680
1901: 15 -> fetch1@fetch -> 0x4808d8a0
1901: 16 -> 0x48093a301723714054215625153_inner_var_16 -> 0x4808cc50
1901: 17 -> fetch2@fetch -> 0x4818e9c0
1901: 18 -> 0x48093a301723714054215625153_inner_var_18 -> 0x48089c80
1901: 19 -> fetch3@fetch -> 0x480747a0
1901: 20 -> 0x48093a301723714054215625153_inner_var_20 -> 0x480827e0
1901: 21 -> fetch4@fetch -> 0x4819ea30
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 09:27:34.217173 30120 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:27:34.217185 30121 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:27:34.217209 30122 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:27:34.217237 30123 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:27:34.217271 30124 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:27:34.217289 30124 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.217325 30124 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 09:27:34.217358 30124 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_3:[dtype=;place=;dim=;lod={};, 0x48093a301723714054215625153_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.217526 30124 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.217679 30124 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x48093a301723714054215625153_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.217721 30124 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_5:[dtype=;place=;dim=;lod={};, 0x48093a301723714054215625153_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.217737 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.217767 30123 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.217824 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.217880 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.217895 30124 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.217900 30123 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.217906 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218037 30124 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x48093a301723714054215625153_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.218076 30124 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_7:[dtype=;place=;dim=;lod={};, 0x48093a301723714054215625153_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.218084 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.218098 30123 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.218163 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218215 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218233 30123 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.218235 30124 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.218238 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218380 30124 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x48093a301723714054215625153_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.218420 30124 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_9:[dtype=;place=;dim=;lod={};, 0x48093a301723714054215625153_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.218426 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.218439 30123 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.218477 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218533 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218550 30123 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.218555 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218590 30124 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.218741 30124 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x48093a301723714054215625153_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.218781 30124 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_11:[dtype=;place=;dim=;lod={};, 0x48093a301723714054215625153_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.218786 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.218801 30123 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.218829 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218873 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218889 30123 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.218895 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.218947 30124 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.219097 30124 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x48093a301723714054215625153_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x48093a301723714054215625153_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:27:34.219142 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:27:34.219157 30123 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:27:34.219182 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x48093a301723714054215625153_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x48093a301723714054215625153_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.219214 30123 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.219229 30123 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.219234 30123 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x48093a301723714054215625153_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:27:34.219257 30053 pir_interpreter.cc:1766] main_thread_blocker_(0x48093ba0) got event_name: TaskCompletion
1901: I0815 09:27:34.219277 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.219305 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.219316 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.219323 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.219333 30053 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:27:34.220927 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1af6f050 for it.
1901: I0815 09:27:34.221012 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.221040 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.221210 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.221315 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x481a13e0)  to GradNodeAccumulation (addr: 0x1af6f050)
1901: I0815 09:27:34.221431 30053 backward.cc:459] Run in Grad
1901: I0815 09:27:34.221441 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.221454 30053 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x481a13e0 to ptr: 0x4802cdf0
1901: I0815 09:27:34.221464 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.221498 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.221522 30053 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1af6f050 to ptr: 0x48030390
1901: I0815 09:27:34.221542 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x4802cdf0
1901: I0815 09:27:34.221551 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.221581 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.221645 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.221654 30053 backward.cc:335] Node: NanmedianGradNode addr:0x4802cdf0, Found pending node: GradNodeAccumulation addr: 0x48030390
1901: I0815 09:27:34.221659 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.221685 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x48030390
1901: I0815 09:27:34.221693 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.221696 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.221701 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.221706 30053 backward.cc:435] Finish Backward
1901: I0815 09:27:34.222344 30053 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 09:27:34.222363 30053 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 09:27:34.222446 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.222469 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.222612 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.222694 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x481a13e0)  to GradNodeAccumulation (addr: 0x1af6f050)
1901: I0815 09:27:34.222776 30053 backward.cc:442] Run in Backward
1901: I0815 09:27:34.222783 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.222790 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.222819 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.222842 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x481a13e0
1901: I0815 09:27:34.222851 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.222878 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.222934 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.222959 30053 backward.cc:335] Node: NanmedianGradNode addr:0x481a13e0, Found pending node: GradNodeAccumulation addr: 0x1af6f050
1901: I0815 09:27:34.222967 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.222985 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1af6f050
1901: I0815 09:27:34.222992 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.222996 30053 accumulation_node.cc:40] Move Tensor ptr: 0x480769c0
1901: I0815 09:27:34.222999 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.223003 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.223449 30053 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.223560 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.223585 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.223747 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x4802cdf0)  to GradNodeAccumulation (addr: 0x481a2c50)
1901: I0815 09:27:34.223845 30053 backward.cc:442] Run in Backward
1901: I0815 09:27:34.223852 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.223858 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.223891 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.223913 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x4802cdf0
1901: I0815 09:27:34.223922 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.223948 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.223995 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.224020 30053 backward.cc:335] Node: NanmedianGradNode addr:0x4802cdf0, Found pending node: GradNodeAccumulation addr: 0x481a2c50
1901: I0815 09:27:34.224028 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.224045 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x481a2c50
1901: I0815 09:27:34.224051 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.224056 30053 accumulation_node.cc:40] Move Tensor ptr: 0x47d3dea0
1901: I0815 09:27:34.224059 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.224063 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.224774 30053 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.224854 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.224879 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.225061 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.225152 30053 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x4802cdf0)  to GradNodeAccumulation (addr: 0x481a2c50)
1901: I0815 09:27:34.225267 30053 backward.cc:459] Run in Grad
1901: I0815 09:27:34.225278 30053 backward.cc:113] Start Backward
1901: I0815 09:27:34.225291 30053 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x4802cdf0 to ptr: 0x481a13e0
1901: I0815 09:27:34.225309 30053 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:27:34.225343 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.225368 30053 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x481a2c50 to ptr: 0x48030390
1901: I0815 09:27:34.225386 30053 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x481a13e0
1901: I0815 09:27:34.225394 30053 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:27:34.225425 30053 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.225544 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.225554 30053 backward.cc:335] Node: NanmedianGradNode addr:0x481a13e0, Found pending node: GradNodeAccumulation addr: 0x48030390
1901: I0815 09:27:34.225559 30053 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:27:34.225575 30053 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x48030390
1901: I0815 09:27:34.225584 30053 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.225586 30053 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:27:34.225591 30053 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:27:34.225595 30053 backward.cc:435] Finish Backward
1901: I0815 09:27:34.226482 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.226562 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.226588 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.226745 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.228104 30053 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x481a2c50 for it.
1901: I0815 09:27:34.228150 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.228169 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.230260 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.230288 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.231218 30053 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:27:34.231242 30053 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:27:34.232002 30053 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 09:27:34.232020 30053 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 09:27:34.232112 30053 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 09:27:34.232121 30053 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 09:27:34.232182 30053 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 09:27:34.232189 30053 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 09:27:34.232236 30053 dygraph_functions.cc:82227] Running AD API: arange
1901: I0815 09:27:34.232270 30053 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.232412 30053 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0815 09:27:34.232434 30053 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.232453 30053 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0815 09:27:34.232511 30053 dygraph_functions.cc:14224] Running AD API: cast
1901: I0815 09:27:34.232527 30053 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.232592 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:27:34.232654 30053 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:27:34.232671 30053 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:27:34.232851 30053 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: test_nanmedian failed
1901:  ss.E.................
1901: ======================================================================
1901: ERROR: test_check_output (test_nanmedian.TestNanmedianFP16Op)
1901: ----------------------------------------------------------------------
1901: Traceback (most recent call last):
1901:   File "/home/code/Paddle/build/test/legacy_test/test_nanmedian.py", line 617, in test_check_output
1901:     self.check_output(check_pir=True)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2934, in check_output
1901:     res = self.check_output_with_place(
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2786, in check_output_with_place
1901:     symbol_checker.check()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2637, in check
1901:     self.infer_and_compare_symbol()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2645, in infer_and_compare_symbol
1901:     self.op_test._infer_and_compare_symbol(place)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1712, in _infer_and_compare_symbol
1901:     self._compare_symbol(program, outs)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1633, in _compare_symbol
1901:     shape_analysis.get_shape_or_data_for_var(
1901: RuntimeError: (PreconditionNotMet) The op operand index [1] must less than operands size[1].
1901:   [Hint: Expected index < num_operands_, but received index:1 >= num_operands_:1.] (at /home/code/Paddle/paddle/pir/src/core/operation.cc:420)
1901: 
1901: 
1901: ----------------------------------------------------------------------
1901: Ran 21 tests in 2.984s
1901: 
1901: FAILED (errors=1, skipped=2)
1901: 
1901: I0815 09:27:34.234114 30053 mmap_allocator.cc:348] PID: 30053, MemoryMapFdSet: set size - 0
1901: I0815 09:27:34.245857 30053 mmap_allocator.cc:348] PID: 30053, MemoryMapFdSet: set size - 0
1901: I0815 09:27:34.297963 30123 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 12135234960496479749 to 10594084330489555080 , after update, data is {current : 0, peak : 1252}.
1901: I0815 09:27:34.297986 30123 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 12135234960496479749 to 10594084330489555080 , after update, data is {current : 0, peak : 16}.
1901: I0815 09:27:34.298219 30124 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 10594084330489555080 to 3280877352669103884 , after update, data is {current : 0, peak : 260}.
1901: I0815 09:27:34.298236 30124 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 10594084330489555080 to 3280877352669103884 , after update, data is {current : 20026, peak : 40004}.
1901: I0815 09:27:34.298241 30124 thread_data_registry.h:135] Add data {current : 0, peak : 1252} from thread 10594084330489555080 to 3280877352669103884 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 09:27:34.427672 30053 mmap_allocator.cc:348] PID: 30053, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................***Failed   10.82 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  11.00 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
