UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0816 03:41:47.775032 31488 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0816 03:41:48.589069 31488 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=gpugraph_hbm_table_load_factor,accuracy_check_atol_fp32,cinn_compile_thread_num,use_mkldnn,save_static_runtime_data,pir_apply_shape_optimization_pass,npu_storage_format,static_executor_perfstat_filepath,cublas_dir,dump_chunk_info,use_cuda_malloc_async_allocator,run_kp_kernel,use_stream_safe_cuda_allocator,search_cache_max_number,cublaslt_device_best_config,enable_dump_main_program,dynamic_static_unified_comm,prim_forward_blacklist,mkl_dir,init_allocated_mem,allreduce_record_one_event,use_autotune,enable_api_kernel_fallback,gpugraph_offload_gather_copy_maxsize,cusparse_dir,sort_sum_gradient,enable_pir_in_executor_trace_run,enable_gpu_memory_usage_log,use_stride_kernel,enable_opt_get_features,enable_fuse_parallel_matmul_pass,jit_engine_type,cusparselt_dir,eager_delete_tensor_gb,custom_device_mem_record,tracer_onednn_ops_on,enable_blaslt_global_search,sync_after_alloc,auto_free_cudagraph_allocations_on_launch,gpugraph_storage_mode,pir_broadcast_tree_limit,tensor_operants_mode,cache_inference_while_scope,use_cuda_managed_memory,use_auto_growth_pinned_allocator,auto_growth_chunk_size_in_mb,prim_all,tensorrt_dir,fraction_of_gpu_memory_to_use,free_when_no_cache_hit,pinned_memory_as_cpu_backend,fraction_of_cpu_memory_to_use,nccl_dir,new_executor_serial_run,add_dependency_for_communication_op,graph_neighbor_size_percent,dist_threadpool_size,gpu_allocator_retry_time,dataloader_use_file_descriptor,enable_sparse_inner_gather,check_kernel_launch,prim_check_ops,nvidia_package_dir,print_allocator_trace_info,enable_unused_var_check,conv2d_disable_cudnn,check_nan_inf,accuracy_check_atol_fp16,use_shm_cache,apply_pass_to_program,gpugraph_force_device_batch_num_equal,gpugraph_enable_segment_merge_grads,pir_subgraph_saving_dir,disable_dyshape_in_train,curand_dir,enable_collect_shape,embedding_deterministic,paddle_num_threads,accuracy_check_atol_bf16,benchmark_nccl,enable_graph_multi_node_sampling,einsum_opt,trt_ibuilder_cache,enable_adjust_op_order,convert_all_blocks,enable_auto_detect_gpu_topo,graph_metapath_split_opt,enable_fusion_fallback,deny_cinn_ops,tracer_profile_fname,get_host_by_name_time,selected_gpus,enable_cinn_auto_tune,enable_cublas_tensor_op_math,use_auto_growth_v2,nccl_blocking_wait,cinn_subgraph_graphviz_dir,eager_delete_scope,new_executor_use_local_scope,inner_op_parallelism,cuda_dir,new_executor_sequential_run,low_precision_op_list,enable_cse_in_dy2st,gpugraph_enable_gpu_direct_access,enable_pir_api,accuracy_check_rtol_fp32,enable_cinn_accuracy_check,print_sub_graph_dir,fast_eager_deletion_mode,enable_dependency_builder_debug_info,allocator_strategy,use_virtual_memory_auto_growth,cupti_dir,alloc_fill_value,check_nan_inf_level,fuse_parameter_memory_size,use_system_allocator,cublaslt_exhaustive_search_times,call_stack_level,enable_pir_in_executor,benchmark,log_memory_stats,prim_backward,use_xqa_optim,mklml_dir,new_executor_static_build,max_inplace_grad_add,multiple_of_cupti_buffer_size,fraction_of_cuda_pinned_memory_to_use,gpugraph_sparse_table_storage_mode,gpugraph_debug_gpu_memory,fuse_parameter_groups_size,gemm_use_half_precision_compute_type,cudnn_deterministic,set_to_1d,graph_load_in_parallel,fleet_executor_with_standalone,win_cuda_bin_dir,reader_queue_speed_test_mode,static_runtime_data_save_path,logging_pir_py_code_dir,use_fast_math,new_executor_use_inplace,cudnn_exhaustive_search,use_pinned_memory,graph_embedding_split_infer_mode,enable_exit_when_partial_worker,manually_trans_conv_filter,tracer_onednn_ops_off,executor_log_deps_every_microseconds,sync_nccl_allreduce,logging_pir_py_code_dump_symbolic_dims,multi_node_sample_use_gpu_table,pir_apply_inplace_pass,print_ir,gpugraph_load_node_list_into_hbm,initial_gpu_memory_in_mb,cusolver_dir,enable_gpu_memory_usage_log_mb,reallocate_gpu_memory_in_mb,gpugraph_parallel_copyer_split_maxsize,cse_max_count,allow_cinn_ops,dygraph_debug,gpugraph_slot_feasign_max_num,cudnn_exhaustive_search_times,ir_inplace_kernel_blacklist,cuda_malloc_async_pool_memory_throttle_ratio,initial_cpu_memory_in_mb,conv_workspace_size_limit,host_trace_level,prim_skip_dynamic,gpu_memory_limit_mb,gpugraph_parallel_stream_num,all_blocks_convert_trt,cudnn_batchnorm_spatial_persistent,pir_debug,accuracy_check_rtol_bf16,cudnn_dir,async_trace_count,logging_pir_py_code_int_tensor_element_limit,new_executor_use_cuda_graph,enable_all2all_use_fp16,lapack_dir,memory_fraction_of_eager_deletion,graph_get_neighbor_id,gpugraph_dedup_pull_push_mode,use_cinn,check_infer_symbolic,enable_auto_rdma_trans,local_exe_sub_scope_limit,cuda_memory_async_pool_realease_threshold,free_idle_chunk,enable_async_trace,gpugraph_offload_param_stat,enable_tracker_all2all,gpugraph_enable_hbm_table_collision_stat,prim_enable_dynamic,accuracy_check_rtol_fp16,query_dest_rank_by_multi_node,gpugraph_offload_param_extends,logging_trunc_pir_py_code,prim_forward,gpugraph_enable_print_op_debug,enable_cinn_compile_cache,enable_neighbor_list_use_uva,enable_pir_with_pt_in_dy2st,gpugraph_merge_grads_segment_size,op_dir,enable_interpretercore_launch_cinn,enable_record_memory,prim_enabled 
1901: I0816 03:41:48.589177 31488 init.cc:108] After Parse: argc is 2
1901: I0816 03:41:53.327136 31488 scope.cc:202] Create variable X
1901: I0816 03:41:53.327211 31488 scope.cc:202] Create variable Out
1901: I0816 03:41:53.327227 31488 scope.cc:202] Create variable MedianIndex
1901: I0816 03:41:53.327404 31488 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0816 03:41:53.328037 31488 allocator_facade.cc:212] selected allocator strategy:1
1901: I0816 03:41:53.328346 31488 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0816 03:41:55.770643 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.770709 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.770846 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.770856 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.771948 31488 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:41:55.771975 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.772017 31488 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:41:55.772024 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.772528 31488 pybind.cc:1827] need skip: 0
1901: I0816 03:41:55.772621 31488 pybind.cc:1827] need skip: 0
1901: I0816 03:41:55.773042 31488 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0816 03:41:55.773435 31488 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0816 03:41:55.773453 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:41:55.773538 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0816 03:41:55.773552 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:41:55.776767 31488 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:41:55.777463 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.777480 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.777495 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:41:55.780572 31488 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:41:55.780588 31488 scope.cc:202] Create variable feed
1901: I0816 03:41:55.780664 31488 program_interpreter.cc:243] New Executor is Running.
1901: I0816 03:41:55.780673 31488 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:41:55.780680 31488 scope.cc:202] Create variable MedianIndex
1901: I0816 03:41:55.780690 31488 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x4509d390 type is 7
1901: I0816 03:41:55.780701 31488 scope.cc:202] Create variable Out
1901: I0816 03:41:55.780705 31488 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4509d900 type is 7
1901: I0816 03:41:55.780710 31488 scope.cc:202] Create variable Out@GRAD
1901: I0816 03:41:55.780714 31488 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4509ddb0 type is 7
1901: I0816 03:41:55.780719 31488 scope.cc:202] Create variable X
1901: I0816 03:41:55.780722 31488 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4509e8f0 type is 7
1901: I0816 03:41:55.780727 31488 scope.cc:202] Create variable X@GRAD
1901: I0816 03:41:55.780731 31488 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4509eb60 type is 7
1901: I0816 03:41:55.780736 31488 scope.cc:202] Create variable _generated_var_0
1901: I0816 03:41:55.780740 31488 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4509eda0 type is 7
1901: I0816 03:41:55.780750 31488 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0816 03:41:55.780752 31488 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x4509f000 type is 7
1901: I0816 03:41:55.780757 31488 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4509dd00 type is 9
1901: I0816 03:41:55.780762 31488 scope.cc:202] Create variable fetch
1901: I0816 03:41:55.780766 31488 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4509ed80 type is 10
1901: I0816 03:41:55.780881 31488 interpreter_util.cc:594] Static build: 0
1901: I0816 03:41:55.780887 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.780892 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.780897 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0816 03:41:55.781536 31488 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0816 03:41:55.781934 31488 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0816 03:41:55.782963 31488 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0816 03:41:55.783171 31488 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.783197 31488 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.783365 31488 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.783373 31488 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.783392 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.787779 31488 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.787798 31488 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.787815 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.787894 31488 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.788004 31488 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.788015 31488 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.788069 31488 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.788089 31488 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0816 03:41:55.788121 31488 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.788130 31488 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.788147 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:41:55.788246 31488 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.788256 31488 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.788273 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:41:55.788393 31488 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.788421 31488 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.788444 31488 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:41:55.788452 31488 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4511c930Variable Type 7
1901: I0816 03:41:55.788480 31488 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:41:55.788504 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.788551 31488 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.788573 31488 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:55.788688 31488 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:41:55.788726 31488 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:41:55.789309 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.789355 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.790433 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.790454 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.790499 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.790508 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.791141 31488 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:41:55.791157 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.791189 31488 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0816 03:41:55.791196 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.791484 31488 pybind.cc:1827] need skip: 0
1901: I0816 03:41:55.791538 31488 pybind.cc:1827] need skip: 0
1901: I0816 03:41:55.791859 31488 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0816 03:41:55.791939 31488 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0816 03:41:55.791947 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:41:55.792013 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0816 03:41:55.792022 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:41:55.794088 31488 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:41:55.794591 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.794605 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.794610 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:41:55.798192 31488 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:41:55.798209 31488 scope.cc:202] Create variable feed
1901: I0816 03:41:55.798239 31488 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:41:55.798249 31488 scope.cc:202] Create variable MedianIndex
1901: I0816 03:41:55.798252 31488 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x450721f0 type is 7
1901: I0816 03:41:55.798260 31488 scope.cc:202] Create variable Out
1901: I0816 03:41:55.798264 31488 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4514c590 type is 7
1901: I0816 03:41:55.798269 31488 scope.cc:202] Create variable Out@GRAD
1901: I0816 03:41:55.798272 31488 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x4507e1f0 type is 7
1901: I0816 03:41:55.798277 31488 scope.cc:202] Create variable X
1901: I0816 03:41:55.798280 31488 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x43745770 type is 7
1901: I0816 03:41:55.798285 31488 scope.cc:202] Create variable X@GRAD
1901: I0816 03:41:55.798288 31488 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44c98fe0 type is 7
1901: I0816 03:41:55.798292 31488 scope.cc:202] Create variable _generated_var_0
1901: I0816 03:41:55.798296 31488 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x450786c0 type is 7
1901: I0816 03:41:55.798307 31488 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0816 03:41:55.798311 31488 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44c7cc30 type is 7
1901: I0816 03:41:55.798316 31488 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45076ce0 type is 9
1901: I0816 03:41:55.798321 31488 scope.cc:202] Create variable fetch
1901: I0816 03:41:55.798326 31488 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44c7cc10 type is 10
1901: I0816 03:41:55.798413 31488 interpreter_util.cc:594] Static build: 0
1901: I0816 03:41:55.798420 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.798425 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.798429 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:41:55.798472 31488 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.798488 31488 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.798534 31488 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.798543 31488 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.798558 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.799031 31488 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799044 31488 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799059 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.799110 31488 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.799170 31488 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799180 31488 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799217 31488 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.799248 31488 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799257 31488 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799271 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0816 03:41:55.799355 31488 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799365 31488 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799382 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0816 03:41:55.799479 31488 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.799492 31488 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.799508 31488 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:41:55.799515 31488 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4514a9d0Variable Type 7
1901: I0816 03:41:55.799530 31488 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:41:55.799546 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.799564 31488 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.799578 31488 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:55.799634 31488 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:41:55.799656 31488 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:41:55.800078 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0816 03:41:55.800112 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.801735 31488 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x21e7bb0 for it.
1901: I0816 03:41:55.801920 31488 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a70f2b0 for it.
1901: I0816 03:41:55.801970 31488 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a65e6f0 for it.
1901: I0816 03:41:55.802824 31488 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:41:55.802882 31488 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:41:55.803409 31488 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x4507d1b0)  to GradNodeAccumulation (addr: 0x21e7bb0)
1901: I0816 03:41:55.803551 31488 dygraph_functions.cc:51757] Running AD API: mean
1901: I0816 03:41:55.803576 31488 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:41:55.803664 31488 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.803686 31488 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x438cda30)  to NanmedianGradNode (addr: 0x4507d1b0)
1901: I0816 03:41:55.803802 31488 backward.cc:442] Run in Backward
1901: I0816 03:41:55.803813 31488 backward.cc:113] Start Backward
1901: I0816 03:41:55.803836 31488 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0816 03:41:55.803889 31488 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.803920 31488 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x438cda30
1901: I0816 03:41:55.803934 31488 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0816 03:41:55.803977 31488 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:41:55.804050 31488 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.804075 31488 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:41:55.804085 31488 backward.cc:335] Node: MeanGradNode addr:0x438cda30, Found pending node: NanmedianGradNode addr: 0x4507d1b0
1901: I0816 03:41:55.804092 31488 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:41:55.804127 31488 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x4507d1b0
1901: I0816 03:41:55.804142 31488 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0816 03:41:55.804168 31488 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:41:55.804222 31488 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0816 03:41:55.804245 31488 backward.cc:335] Node: NanmedianGradNode addr:0x4507d1b0, Found pending node: GradNodeAccumulation addr: 0x21e7bb0
1901: I0816 03:41:55.804253 31488 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0816 03:41:55.804271 31488 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x21e7bb0
1901: I0816 03:41:55.804283 31488 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0816 03:41:55.804292 31488 accumulation_node.cc:40] Move Tensor ptr: 0x45068a50
1901: I0816 03:41:55.804296 31488 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0816 03:41:55.804311 31488 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0816 03:41:55.813079 31488 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x21e7bb0 for it.
1901: I0816 03:41:55.813241 31488 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a65e6f0 for it.
1901: I0816 03:41:55.813288 31488 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a70f2b0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0816 03:41:55.875360 31488 pir_interpreter.cc:161] PirInterpreter(): 0x474c5010 on Place(gpu:0)
1901: I0816 03:41:55.875406 31488 scope.cc:202] Create variable X
1901: I0816 03:41:55.875435 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_1
1901: I0816 03:41:55.875447 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_2
1901: I0816 03:41:55.875452 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_3
1901: I0816 03:41:55.875461 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_4
1901: I0816 03:41:55.875468 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_5
1901: I0816 03:41:55.875475 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_6
1901: I0816 03:41:55.875483 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_7
1901: I0816 03:41:55.875490 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_8
1901: I0816 03:41:55.875496 31488 scope.cc:202] Create variable 0x474c50101723779715875391586_inner_var_9
1901: I0816 03:41:55.875505 31488 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:41:55.875910 31488 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:41:55.875923 31488 scope.cc:202] Create variable X
1901: I0816 03:41:55.875927 31488 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0816 03:41:55.875969 31488 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x474c4fb0
1901: 1 -> 0x474c50101723779715875391586_inner_var_1 -> 0x474c4ff0
1901: 2 -> 0x474c50101723779715875391586_inner_var_2 -> 0x474c2440
1901: 3 -> 0x474c50101723779715875391586_inner_var_3 -> 0x474c4700
1901: 4 -> 0x474c50101723779715875391586_inner_var_4 -> 0x474c4f10
1901: 5 -> 0x474c50101723779715875391586_inner_var_5 -> 0x474c5a70
1901: 6 -> 0x474c50101723779715875391586_inner_var_6 -> 0x474c5e90
1901: 7 -> 0x474c50101723779715875391586_inner_var_7 -> 0x474c62b0
1901: 8 -> 0x474c50101723779715875391586_inner_var_8 -> 0x474c2a20
1901: 9 -> 0x474c50101723779715875391586_inner_var_9 -> 0x474c66d0
1901: 10 -> fetch0@fetch -> 0x474c6ee0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0816 03:41:55.876901 31488 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0816 03:41:55.877136 31525 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:41:55.877266 31526 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:41:55.877293 31527 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:41:55.877370 31528 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:41:55.877406 31529 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:41:55.877436 31528 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x474c50101723779715875391586_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.877480 31530 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:41:55.877529 31528 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x474c50101723779715875391586_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0816 03:41:55.877538 31530 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.877588 31530 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:41:55.877643 31530 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474c50101723779715875391586_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_3:[dtype=;place=;dim=;lod={};, 0x474c50101723779715875391586_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.878134 31530 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474c50101723779715875391586_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474c50101723779715875391586_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:41:55.878165 31530 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x474c50101723779715875391586_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.878216 31530 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.878232 31530 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x474c50101723779715875391586_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:41:55.878258 31530 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x474c50101723779715875391586_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x474c50101723779715875391586_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.878347 31530 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.878365 31530 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x474c50101723779715875391586_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x474c50101723779715875391586_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:41:55.878394 31530 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x474c50101723779715875391586_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x474c50101723779715875391586_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.878445 31530 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0816 03:41:55.878461 31530 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x474c50101723779715875391586_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x474c50101723779715875391586_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:41:55.878484 31530 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x474c50101723779715875391586_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x474c50101723779715875391586_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x474c50101723779715875391586_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.878542 31530 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x474c50101723779715875391586_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x474c50101723779715875391586_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x474c50101723779715875391586_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:41:55.878608 31528 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474c50101723779715875391586_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.878633 31528 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:55.878720 31528 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474c50101723779715875391586_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779715875391586_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0816 03:41:55.878749 31528 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474c50101723779715875391586_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:55.878772 31528 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0816 03:41:55.878801 31528 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474c50101723779715875391586_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0816 03:41:55.878834 31488 pir_interpreter.cc:1766] main_thread_blocker_(0x474c5180) got event_name: TaskCompletion
1901: I0816 03:41:55.878860 31488 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0816 03:41:55.882023 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.882052 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.882117 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.882128 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.883308 31525 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 6023404169535345013 to 9340889676226921689 , after update, data is {current : -20004, peak : 16}.
1901: I0816 03:41:55.883327 31525 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 6023404169535345013 to 9340889676226921689 , after update, data is {current : 0, peak : 330659}.
1901: I0816 03:41:55.883491 31528 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 3611090414905538017 to 9340889676226921689 , after update, data is {current : 20000, peak : 40004}.
1901: I0816 03:41:55.883659 31530 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 9340889676226921689 to 13537021654093543874 , after update, data is {current : 20000, peak : 40004}.
1901: I0816 03:41:55.883670 31530 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 9340889676226921689 to 13537021654093543874 , after update, data is {current : 120000, peak : 440631}.
1901: I0816 03:41:55.885046 31488 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:41:55.885628 31488 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:41:55.886114 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.886129 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.886135 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:41:55.888468 31488 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:41:55.888486 31488 scope.cc:202] Create variable feed
1901: I0816 03:41:55.888520 31488 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:41:55.888530 31488 scope.cc:202] Create variable MedianIndex
1901: I0816 03:41:55.888535 31488 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47534030 type is 7
1901: I0816 03:41:55.888543 31488 scope.cc:202] Create variable Out
1901: I0816 03:41:55.888549 31488 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x475335c0 type is 7
1901: I0816 03:41:55.888556 31488 scope.cc:202] Create variable X
1901: I0816 03:41:55.888559 31488 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47533fb0 type is 7
1901: I0816 03:41:55.888564 31488 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x475335e0 type is 9
1901: I0816 03:41:55.888571 31488 scope.cc:202] Create variable fetch
1901: I0816 03:41:55.888576 31488 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x475343e0 type is 10
1901: I0816 03:41:55.888650 31488 interpreter_util.cc:594] Static build: 0
1901: I0816 03:41:55.888657 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.888664 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.888669 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:41:55.888727 31488 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.888743 31488 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.888814 31488 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.888823 31488 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.888844 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.889336 31488 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.889354 31488 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.889375 31488 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:41:55.889384 31488 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47538400Variable Type 7
1901: I0816 03:41:55.889402 31488 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:41:55.889423 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.889449 31488 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.889467 31488 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:55.889514 31488 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:41:55.889539 31488 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:41:55.889587 31488 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.889598 31488 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.889617 31488 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:41:55.889624 31488 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474eaf20Variable Type 7
1901: I0816 03:41:55.889638 31488 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:41:55.889653 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.889672 31488 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.889688 31488 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:55.889724 31488 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:41:55.889752 31488 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0816 03:41:55.890041 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.890070 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.891402 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.891427 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.891479 31488 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0816 03:41:55.891489 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.893399 31488 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:41:55.893958 31488 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0816 03:41:55.894403 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.894418 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.894423 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:41:55.896672 31488 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0816 03:41:55.896744 31488 interpreter_util.cc:1169] Creating Variables
1901: I0816 03:41:55.896756 31488 scope.cc:202] Create variable MedianIndex
1901: I0816 03:41:55.896761 31488 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47518780 type is 7
1901: I0816 03:41:55.896771 31488 scope.cc:202] Create variable Out
1901: I0816 03:41:55.896775 31488 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47517ab0 type is 7
1901: I0816 03:41:55.896781 31488 scope.cc:202] Create variable X
1901: I0816 03:41:55.896785 31488 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x475184b0 type is 7
1901: I0816 03:41:55.896790 31488 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x475335e0 type is 9
1901: I0816 03:41:55.896796 31488 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x475343e0 type is 10
1901: I0816 03:41:55.896870 31488 interpreter_util.cc:594] Static build: 0
1901: I0816 03:41:55.896876 31488 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0816 03:41:55.896883 31488 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0816 03:41:55.896886 31488 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0816 03:41:55.896929 31488 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.896942 31488 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.896998 31488 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.897008 31488 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.897027 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0816 03:41:55.897547 31488 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.897563 31488 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.897583 31488 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:41:55.897590 31488 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4751cc40Variable Type 7
1901: I0816 03:41:55.897608 31488 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:41:55.897626 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.897650 31488 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.897665 31488 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:55.897706 31488 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:41:55.897727 31488 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0816 03:41:55.897773 31488 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.897783 31488 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0816 03:41:55.897799 31488 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0816 03:41:55.897807 31488 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4751cc60Variable Type 7
1901: I0816 03:41:55.897820 31488 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0816 03:41:55.897835 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.897853 31488 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0816 03:41:55.897867 31488 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:55.897902 31488 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0816 03:41:55.897922 31488 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0816 03:41:55.898190 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:55.898217 31488 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0816 03:41:56.027745 31488 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a70f2b0 for it.
1901: I0816 03:41:56.028226 31488 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a65e6f0 for it.
1901: I0816 03:41:56.028316 31488 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x21e7bb0 for it.
1901: I0816 03:41:56.028998 31488 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:41:56.029053 31488 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:41:56.030442 31488 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a70f2b0 for it.
1901: I0816 03:41:56.030614 31488 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x21e7bb0 for it.
1901: I0816 03:41:56.030678 31488 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a65e6f0 for it.
1901: I0816 03:41:56.031915 31488 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0816 03:41:56.031958 31488 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0816 03:41:56.034615 31488 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a70f2b0 for it.
1901: I0816 03:41:56.034785 31488 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a65e6f0 for it.
1901: I0816 03:41:56.034842 31488 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x21e7bb0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0816 03:41:56.038470 31488 pir_interpreter.cc:161] PirInterpreter(): 0x474c5010 on Place(gpu:0)
1901: I0816 03:41:56.038537 31488 scope.cc:202] Create variable X
1901: I0816 03:41:56.038564 31488 scope.cc:202] Create variable 0x474c50101723779716038524653_inner_var_1
1901: I0816 03:41:56.038579 31488 scope.cc:202] Create variable 0x474c50101723779716038524653_inner_var_2
1901: I0816 03:41:56.038594 31488 scope.cc:202] Create variable 0x474c50101723779716038524653_inner_var_3
1901: I0816 03:41:56.038609 31488 scope.cc:202] Create variable 0x474c50101723779716038524653_inner_var_4
1901: I0816 03:41:56.038622 31488 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:41:56.039055 31488 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:41:56.039073 31488 scope.cc:202] Create variable X
1901: I0816 03:41:56.039080 31488 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x475b79f0
1901: 1 -> 0x474c50101723779716038524653_inner_var_1 -> 0x47541430
1901: 2 -> 0x474c50101723779716038524653_inner_var_2 -> 0x61f9270
1901: 3 -> 0x474c50101723779716038524653_inner_var_3 -> 0x474d6a10
1901: 4 -> 0x474c50101723779716038524653_inner_var_4 -> 0x47541450
1901: 5 -> fetch0@fetch -> 0x45139520
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0816 03:41:56.039865 31532 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:41:56.040017 31533 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:41:56.040091 31534 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:41:56.040148 31535 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:41:56.040184 31536 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:41:56.040266 31537 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:41:56.040320 31537 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779716038524653_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.040392 31537 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779716038524653_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:41:56.040441 31537 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474c50101723779716038524653_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779716038524653_inner_var_3:[dtype=;place=;dim=;lod={};, 0x474c50101723779716038524653_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.040993 31537 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474c50101723779716038524653_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474c50101723779716038524653_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474c50101723779716038524653_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:41:56.041072 31536 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474c50101723779716038524653_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474c50101723779716038524653_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.041117 31536 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:56.041189 31536 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474c50101723779716038524653_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474c50101723779716038524653_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:41:56.041225 31536 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474c50101723779716038524653_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.041245 31536 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:41:56.041257 31536 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474c50101723779716038524653_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:41:56.041296 31488 pir_interpreter.cc:1766] main_thread_blocker_(0x474c5180) got event_name: TaskCompletion
1901: I0816 03:41:56.041332 31488 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:41:56.042191 31488 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x21e7bb0 for it.
1901: I0816 03:41:56.042371 31488 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a65e6f0 for it.
1901: I0816 03:41:56.042426 31488 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a70f2b0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0816 03:41:56.045202 31488 pir_interpreter.cc:161] PirInterpreter(): 0x474fe3d0 on Place(gpu:0)
1901: I0816 03:41:56.045234 31488 scope.cc:202] Create variable X
1901: I0816 03:41:56.045255 31488 scope.cc:202] Create variable 0x474fe3d01723779716045225483_inner_var_1
1901: I0816 03:41:56.045264 31488 scope.cc:202] Create variable 0x474fe3d01723779716045225483_inner_var_2
1901: I0816 03:41:56.045272 31488 scope.cc:202] Create variable 0x474fe3d01723779716045225483_inner_var_3
1901: I0816 03:41:56.045281 31488 scope.cc:202] Create variable 0x474fe3d01723779716045225483_inner_var_4
1901: I0816 03:41:56.045290 31488 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:41:56.045614 31488 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:41:56.045627 31488 scope.cc:202] Create variable X
1901: I0816 03:41:56.045631 31488 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x474c9230
1901: 1 -> 0x474fe3d01723779716045225483_inner_var_1 -> 0x474c9270
1901: 2 -> 0x474fe3d01723779716045225483_inner_var_2 -> 0x474c9550
1901: 3 -> 0x474fe3d01723779716045225483_inner_var_3 -> 0x475bd090
1901: 4 -> 0x474fe3d01723779716045225483_inner_var_4 -> 0x47540c50
1901: 5 -> fetch0@fetch -> 0x474f9ac0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0816 03:41:56.046221 31538 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:41:56.046425 31539 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:41:56.046494 31540 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:41:56.046512 31541 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:41:56.046594 31542 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:41:56.046669 31543 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:41:56.046701 31543 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474fe3d01723779716045225483_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.046723 31543 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474fe3d01723779716045225483_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:41:56.046749 31543 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474fe3d01723779716045225483_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474fe3d01723779716045225483_inner_var_3:[dtype=;place=;dim=;lod={};, 0x474fe3d01723779716045225483_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.047140 31543 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474fe3d01723779716045225483_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x474fe3d01723779716045225483_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474fe3d01723779716045225483_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:41:56.047204 31542 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474fe3d01723779716045225483_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474fe3d01723779716045225483_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.047240 31542 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:56.047304 31542 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474fe3d01723779716045225483_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474fe3d01723779716045225483_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:41:56.047336 31542 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474fe3d01723779716045225483_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.047354 31542 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:41:56.047366 31542 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474fe3d01723779716045225483_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:41:56.047401 31488 pir_interpreter.cc:1766] main_thread_blocker_(0x474fe540) got event_name: TaskCompletion
1901: I0816 03:41:56.047428 31488 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:41:56.048949 31488 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a70f2b0 for it.
1901: I0816 03:41:56.049116 31488 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a65e6f0 for it.
1901: I0816 03:41:56.049167 31488 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x21e7bb0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0816 03:41:56.051739 31488 pir_interpreter.cc:161] PirInterpreter(): 0x47536700 on Place(gpu:0)
1901: I0816 03:41:56.051769 31488 scope.cc:202] Create variable X
1901: I0816 03:41:56.051787 31488 scope.cc:202] Create variable 0x475367001723779716051762928_inner_var_1
1901: I0816 03:41:56.051798 31488 scope.cc:202] Create variable 0x475367001723779716051762928_inner_var_2
1901: I0816 03:41:56.051810 31488 scope.cc:202] Create variable 0x475367001723779716051762928_inner_var_3
1901: I0816 03:41:56.051820 31488 scope.cc:202] Create variable 0x475367001723779716051762928_inner_var_4
1901: I0816 03:41:56.051829 31488 scope.cc:202] Create variable fetch0@fetch
1901: I0816 03:41:56.052163 31488 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0816 03:41:56.052177 31488 scope.cc:202] Create variable X
1901: I0816 03:41:56.052181 31488 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x4753d830
1901: 1 -> 0x475367001723779716051762928_inner_var_1 -> 0x474d1ed0
1901: 2 -> 0x475367001723779716051762928_inner_var_2 -> 0x47536ea0
1901: 3 -> 0x475367001723779716051762928_inner_var_3 -> 0x474cfd20
1901: 4 -> 0x475367001723779716051762928_inner_var_4 -> 0x474c4cc0
1901: 5 -> fetch0@fetch -> 0x475001b0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0816 03:41:56.052816 31544 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0816 03:41:56.052991 31545 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0816 03:41:56.053036 31546 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0816 03:41:56.053113 31547 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0816 03:41:56.053145 31548 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0816 03:41:56.053228 31549 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0816 03:41:56.053267 31549 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x475367001723779716051762928_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.053288 31549 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x475367001723779716051762928_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0816 03:41:56.053319 31549 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x475367001723779716051762928_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x475367001723779716051762928_inner_var_3:[dtype=;place=;dim=;lod={};, 0x475367001723779716051762928_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.053742 31549 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x475367001723779716051762928_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x475367001723779716051762928_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x475367001723779716051762928_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0816 03:41:56.053808 31548 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x475367001723779716051762928_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x475367001723779716051762928_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.053839 31548 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0816 03:41:56.053897 31548 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x475367001723779716051762928_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x475367001723779716051762928_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:41:56.053927 31548 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x475367001723779716051762928_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0816 03:41:56.053944 31548 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:41:56.053957 31548 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x475367001723779716051762928_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0816 03:41:56.053987 31488 pir_interpreter.cc:1766] main_thread_blocker_(0x47536870) got event_name: TaskCompletion
1901: I0816 03:41:56.054009 31488 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0816 03:41:56.054193 31488 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0816 03:41:56.054317 31488 unary_infer_sym.cc:1363] NanmedianOpInferSymbolicShape
1901: I0816 03:41:56.054332 31488 unary_infer_sym.cc:1373] axis_list: 0
1901: I0816 03:41:56.054338 31488 unary_infer_sym.cc:1377] x_dim: 2
1901: I0816 03:41:56.054344 31488 unary_infer_sym.cc:1379] x_rank: 2
1901: 
1901: 
1901: --------------------------------------
1901: C++ Traceback (most recent call last):
1901: --------------------------------------
1901: 0   pir::ShapeConstraintIRAnalysis::GetShapeOrDataForValue(pir::Value)
1901: 1   pir::ShapeConstraintIRAnalysis::InferShapeOrDataForValue(pir::Value)
1901: 2   pir::InferSymbolicShapeInterface::Model<paddle::dialect::NanmedianOp>::InferSymbolicShape(pir::Operation*, pir::InferSymbolicShapeContext*)
1901: 3   paddle::dialect::NanmedianOpInferSymbolicShape(pir::Operation*, pir::InferSymbolicShapeContext*)
1901: 4   pir::BoolAttribute::data() const
1901: 
1901: ----------------------
1901: Error Message Summary:
1901: ----------------------
1901: FatalError: `Segmentation fault` is detected by the operating system.
1901:   [TimeInfo: *** Aborted at 1723779716 (unix time) try "date -d @1723779716" if you are using GNU date ***]
1901:   [SignalInfo: *** SIGSEGV (@0x8) received by PID 31488 (TID 0x7fb1c77c3740) from PID 8 ***]
1901: 
1901: Segmentation fault
1/1 Test #1901: test_nanmedian ...................***Failed   17.17 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  17.35 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
