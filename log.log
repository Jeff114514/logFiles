UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0815 06:49:42.727260  8045 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0815 06:49:43.511802  8045 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=conv2d_disable_cudnn,cudnn_dir,enable_gpu_memory_usage_log_mb,new_executor_sequential_run,init_allocated_mem,gpugraph_debug_gpu_memory,use_system_allocator,gpugraph_sparse_table_storage_mode,use_cuda_malloc_async_allocator,pir_apply_inplace_pass,query_dest_rank_by_multi_node,benchmark,cinn_compile_thread_num,gpugraph_load_node_list_into_hbm,max_inplace_grad_add,tracer_onednn_ops_on,gpugraph_enable_hbm_table_collision_stat,dataloader_use_file_descriptor,prim_forward,benchmark_nccl,custom_device_mem_record,allocator_strategy,alloc_fill_value,accuracy_check_rtol_bf16,enable_neighbor_list_use_uva,prim_enable_dynamic,reallocate_gpu_memory_in_mb,cudnn_exhaustive_search,disable_dyshape_in_train,initial_gpu_memory_in_mb,use_virtual_memory_auto_growth,use_stride_kernel,cinn_subgraph_graphviz_dir,new_executor_use_cuda_graph,print_allocator_trace_info,op_dir,enable_pir_in_executor,run_kp_kernel,enable_pir_api,get_host_by_name_time,eager_delete_tensor_gb,enable_adjust_op_order,dygraph_debug,search_cache_max_number,graph_metapath_split_opt,enable_dump_main_program,enable_record_memory,enable_cinn_auto_tune,dynamic_static_unified_comm,apply_pass_to_program,mklml_dir,multiple_of_cupti_buffer_size,free_when_no_cache_hit,enable_auto_rdma_trans,use_cuda_managed_memory,auto_free_cudagraph_allocations_on_launch,prim_skip_dynamic,enable_cublas_tensor_op_math,use_auto_growth_pinned_allocator,memory_fraction_of_eager_deletion,gpugraph_force_device_batch_num_equal,pir_broadcast_tree_limit,cudnn_exhaustive_search_times,tensorrt_dir,gpugraph_merge_grads_segment_size,graph_get_neighbor_id,accuracy_check_atol_fp32,gpugraph_parallel_stream_num,selected_gpus,gemm_use_half_precision_compute_type,prim_all,async_trace_count,cupti_dir,curand_dir,set_to_1d,pir_apply_shape_optimization_pass,gpugraph_enable_segment_merge_grads,check_nan_inf,cuda_memory_async_pool_realease_threshold,enable_api_kernel_fallback,low_precision_op_list,tracer_profile_fname,graph_load_in_parallel,logging_pir_py_code_dir,logging_trunc_pir_py_code,gpugraph_offload_param_stat,accuracy_check_atol_bf16,pinned_memory_as_cpu_backend,all_blocks_convert_trt,multi_node_sample_use_gpu_table,gpugraph_enable_gpu_direct_access,enable_graph_multi_node_sampling,auto_growth_chunk_size_in_mb,enable_opt_get_features,npu_storage_format,mkl_dir,enable_pir_in_executor_trace_run,enable_cse_in_dy2st,cusparse_dir,use_fast_math,use_shm_cache,use_pinned_memory,call_stack_level,nccl_dir,trt_ibuilder_cache,fuse_parameter_memory_size,use_cinn,prim_forward_blacklist,add_dependency_for_communication_op,embedding_deterministic,gpugraph_enable_print_op_debug,enable_fuse_parallel_matmul_pass,pir_debug,dist_threadpool_size,ir_inplace_kernel_blacklist,use_xqa_optim,win_cuda_bin_dir,conv_workspace_size_limit,lapack_dir,nvidia_package_dir,logging_pir_py_code_int_tensor_element_limit,accuracy_check_rtol_fp16,sync_after_alloc,cuda_malloc_async_pool_memory_throttle_ratio,logging_pir_py_code_dump_symbolic_dims,paddle_num_threads,enable_gpu_memory_usage_log,check_kernel_launch,jit_engine_type,check_infer_symbolic,cublaslt_device_best_config,cublaslt_exhaustive_search_times,enable_collect_shape,save_static_runtime_data,gpugraph_parallel_copyer_split_maxsize,gpugraph_hbm_table_load_factor,use_auto_growth_v2,gpugraph_offload_param_extends,enable_pir_with_pt_in_dy2st,cudnn_deterministic,enable_interpretercore_launch_cinn,nccl_blocking_wait,use_stream_safe_cuda_allocator,gpugraph_storage_mode,cublas_dir,static_executor_perfstat_filepath,use_autotune,fuse_parameter_groups_size,fraction_of_cpu_memory_to_use,graph_embedding_split_infer_mode,fraction_of_gpu_memory_to_use,convert_all_blocks,reader_queue_speed_test_mode,dump_chunk_info,log_memory_stats,gpugraph_dedup_pull_push_mode,enable_fusion_fallback,deny_cinn_ops,prim_check_ops,prim_enabled,use_mkldnn,new_executor_use_inplace,enable_all2all_use_fp16,eager_delete_scope,enable_blaslt_global_search,cuda_dir,cache_inference_while_scope,cse_max_count,pir_subgraph_saving_dir,cudnn_batchnorm_spatial_persistent,fleet_executor_with_standalone,gpu_allocator_retry_time,manually_trans_conv_filter,new_executor_serial_run,fraction_of_cuda_pinned_memory_to_use,prim_backward,enable_cinn_compile_cache,new_executor_static_build,enable_async_trace,free_idle_chunk,cusparselt_dir,sort_sum_gradient,executor_log_deps_every_microseconds,inner_op_parallelism,enable_tracker_all2all,enable_dependency_builder_debug_info,enable_unused_var_check,new_executor_use_local_scope,sync_nccl_allreduce,initial_cpu_memory_in_mb,enable_cinn_accuracy_check,fast_eager_deletion_mode,gpugraph_slot_feasign_max_num,accuracy_check_atol_fp16,gpugraph_offload_gather_copy_maxsize,einsum_opt,static_runtime_data_save_path,local_exe_sub_scope_limit,enable_sparse_inner_gather,allreduce_record_one_event,gpu_memory_limit_mb,enable_exit_when_partial_worker,print_ir,enable_auto_detect_gpu_topo,tensor_operants_mode,print_sub_graph_dir,host_trace_level,allow_cinn_ops,tracer_onednn_ops_off,graph_neighbor_size_percent,accuracy_check_rtol_fp32,cusolver_dir,check_nan_inf_level 
1901: I0815 06:49:43.511909  8045 init.cc:108] After Parse: argc is 2
1901: I0815 06:49:50.445195  8045 scope.cc:202] Create variable X
1901: I0815 06:49:50.445268  8045 scope.cc:202] Create variable Out
1901: I0815 06:49:50.445286  8045 scope.cc:202] Create variable MedianIndex
1901: I0815 06:49:50.445452  8045 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0815 06:49:50.446065  8045 allocator_facade.cc:212] selected allocator strategy:1
1901: I0815 06:49:50.446355  8045 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0815 06:49:52.897468  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:52.897527  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:52.897653  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:52.897665  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:52.898733  8045 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:49:52.898759  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.898802  8045 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:49:52.898809  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.899228  8045 pybind.cc:1827] need skip: 0
1901: I0815 06:49:52.899324  8045 pybind.cc:1827] need skip: 0
1901: I0815 06:49:52.899734  8045 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 06:49:52.900041  8045 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 06:49:52.900058  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:49:52.900143  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 06:49:52.900156  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:49:52.903218  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:52.903918  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:52.903936  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:52.903952  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:52.906991  8045 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:49:52.907008  8045 scope.cc:202] Create variable feed
1901: I0815 06:49:52.907083  8045 program_interpreter.cc:243] New Executor is Running.
1901: I0815 06:49:52.907090  8045 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:49:52.907099  8045 scope.cc:202] Create variable MedianIndex
1901: I0815 06:49:52.907109  8045 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x44145970 type is 7
1901: I0815 06:49:52.907121  8045 scope.cc:202] Create variable Out
1901: I0815 06:49:52.907127  8045 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44145e60 type is 7
1901: I0815 06:49:52.907131  8045 scope.cc:202] Create variable Out@GRAD
1901: I0815 06:49:52.907135  8045 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44146310 type is 7
1901: I0815 06:49:52.907138  8045 scope.cc:202] Create variable X
1901: I0815 06:49:52.907141  8045 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44146c80 type is 7
1901: I0815 06:49:52.907145  8045 scope.cc:202] Create variable X@GRAD
1901: I0815 06:49:52.907152  8045 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44146ef0 type is 7
1901: I0815 06:49:52.907156  8045 scope.cc:202] Create variable _generated_var_0
1901: I0815 06:49:52.907159  8045 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44147130 type is 7
1901: I0815 06:49:52.907164  8045 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 06:49:52.907167  8045 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44147390 type is 7
1901: I0815 06:49:52.907171  8045 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x441458f0 type is 9
1901: I0815 06:49:52.907176  8045 scope.cc:202] Create variable fetch
1901: I0815 06:49:52.907179  8045 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44147110 type is 10
1901: I0815 06:49:52.907306  8045 interpreter_util.cc:594] Static build: 0
1901: I0815 06:49:52.907313  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:52.907317  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:52.907321  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0815 06:49:52.907941  8045 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0815 06:49:52.908231  8045 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0815 06:49:52.909292  8045 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0815 06:49:52.909523  8045 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.909547  8045 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.909699  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.909709  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.909727  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:52.914104  8045 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914125  8045 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914142  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.914222  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:52.914336  8045 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914350  8045 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914404  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:52.914425  8045 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0815 06:49:52.914458  8045 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914466  8045 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914482  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:49:52.914587  8045 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914598  8045 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914614  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:49:52.914732  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:52.914757  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:52.914778  8045 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:52.914786  8045 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x441c5070Variable Type 7
1901: I0815 06:49:52.914811  8045 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:52.914835  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:52.914880  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.914901  8045 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:52.915020  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:52.915055  8045 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:49:52.915643  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.915691  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:52.916715  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:52.916736  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:52.916780  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:52.916790  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:52.917420  8045 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:49:52.917438  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.917470  8045 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 06:49:52.917477  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.917752  8045 pybind.cc:1827] need skip: 0
1901: I0815 06:49:52.917805  8045 pybind.cc:1827] need skip: 0
1901: I0815 06:49:52.918118  8045 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 06:49:52.918193  8045 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 06:49:52.918202  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:49:52.918269  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 06:49:52.918279  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:49:52.920348  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:52.920835  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:52.920850  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:52.920852  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:52.924283  8045 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:49:52.924309  8045 scope.cc:202] Create variable feed
1901: I0815 06:49:52.924340  8045 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:49:52.924347  8045 scope.cc:202] Create variable MedianIndex
1901: I0815 06:49:52.924351  8045 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x43d04be0 type is 7
1901: I0815 06:49:52.924357  8045 scope.cc:202] Create variable Out
1901: I0815 06:49:52.924362  8045 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x43ce82d0 type is 7
1901: I0815 06:49:52.924367  8045 scope.cc:202] Create variable Out@GRAD
1901: I0815 06:49:52.924371  8045 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x429f7130 type is 7
1901: I0815 06:49:52.924374  8045 scope.cc:202] Create variable X
1901: I0815 06:49:52.924377  8045 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44123650 type is 7
1901: I0815 06:49:52.924381  8045 scope.cc:202] Create variable X@GRAD
1901: I0815 06:49:52.924384  8045 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x4410efe0 type is 7
1901: I0815 06:49:52.924389  8045 scope.cc:202] Create variable _generated_var_0
1901: I0815 06:49:52.924392  8045 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44123f90 type is 7
1901: I0815 06:49:52.924396  8045 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 06:49:52.924399  8045 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44124010 type is 7
1901: I0815 06:49:52.924403  8045 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x43cca810 type is 9
1901: I0815 06:49:52.924408  8045 scope.cc:202] Create variable fetch
1901: I0815 06:49:52.924412  8045 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x43d06b10 type is 10
1901: I0815 06:49:52.924500  8045 interpreter_util.cc:594] Static build: 0
1901: I0815 06:49:52.924507  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:52.924511  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:52.924515  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:52.924557  8045 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.924572  8045 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.924619  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.924628  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.924643  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:52.925113  8045 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925128  8045 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925143  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.925191  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:52.925251  8045 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925261  8045 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925308  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:52.925341  8045 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925351  8045 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925365  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 06:49:52.925442  8045 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925452  8045 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925467  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 06:49:52.925566  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:52.925580  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:52.925595  8045 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:52.925602  8045 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4414e3d0Variable Type 7
1901: I0815 06:49:52.925617  8045 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:52.925631  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:52.925648  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:52.925662  8045 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:52.925717  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:52.925738  8045 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:49:52.926155  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 06:49:52.926188  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:52.927780  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:52.927937  8045 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1312bb0 for it.
1901: I0815 06:49:52.927979  8045 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:52.928659  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:52.928709  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:52.929170  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x44146330)  to GradNodeAccumulation (addr: 0x4358b5e0)
1901: I0815 06:49:52.929286  8045 dygraph_functions.cc:51757] Running AD API: mean
1901: I0815 06:49:52.929317  8045 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:52.929396  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:52.929415  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x4412b880)  to NanmedianGradNode (addr: 0x44146330)
1901: I0815 06:49:52.929489  8045 backward.cc:442] Run in Backward
1901: I0815 06:49:52.929498  8045 backward.cc:113] Start Backward
1901: I0815 06:49:52.929519  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:52.929563  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:52.929591  8045 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x4412b880
1901: I0815 06:49:52.929605  8045 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0815 06:49:52.929641  8045 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:52.929704  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:52.929724  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:52.929734  8045 backward.cc:335] Node: MeanGradNode addr:0x4412b880, Found pending node: NanmedianGradNode addr: 0x44146330
1901: I0815 06:49:52.929741  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:52.929769  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x44146330
1901: I0815 06:49:52.929780  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:52.929802  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:52.929848  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:52.929868  8045 backward.cc:335] Node: NanmedianGradNode addr:0x44146330, Found pending node: GradNodeAccumulation addr: 0x4358b5e0
1901: I0815 06:49:52.929875  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:52.929888  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4358b5e0
1901: I0815 06:49:52.929898  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:52.929906  8045 accumulation_node.cc:40] Move Tensor ptr: 0x435391c0
1901: I0815 06:49:52.929909  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:52.929913  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0815 06:49:52.938553  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:52.938720  8045 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:52.938772  8045 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1312bb0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0815 06:49:53.000762  8045 pir_interpreter.cc:161] PirInterpreter(): 0x4642e0e0 on Place(gpu:0)
1901: I0815 06:49:53.000809  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.000838  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_1
1901: I0815 06:49:53.000849  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_2
1901: I0815 06:49:53.000856  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_3
1901: I0815 06:49:53.000864  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_4
1901: I0815 06:49:53.000872  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_5
1901: I0815 06:49:53.000878  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_6
1901: I0815 06:49:53.000886  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_7
1901: I0815 06:49:53.000893  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_8
1901: I0815 06:49:53.000901  8045 scope.cc:202] Create variable 0x4642e0e01723704593000792959_inner_var_9
1901: I0815 06:49:53.000908  8045 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:49:53.001308  8045 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:49:53.001323  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.001327  8045 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0815 06:49:53.001370  8045 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x4642c720
1901: 1 -> 0x4642e0e01723704593000792959_inner_var_1 -> 0x4642e0c0
1901: 2 -> 0x4642e0e01723704593000792959_inner_var_2 -> 0x4642a830
1901: 3 -> 0x4642e0e01723704593000792959_inner_var_3 -> 0x4642d7d0
1901: 4 -> 0x4642e0e01723704593000792959_inner_var_4 -> 0x4642a890
1901: 5 -> 0x4642e0e01723704593000792959_inner_var_5 -> 0x4642e820
1901: 6 -> 0x4642e0e01723704593000792959_inner_var_6 -> 0x4642ec40
1901: 7 -> 0x4642e0e01723704593000792959_inner_var_7 -> 0x4642f060
1901: 8 -> 0x4642e0e01723704593000792959_inner_var_8 -> 0x4642cb80
1901: 9 -> 0x4642e0e01723704593000792959_inner_var_9 -> 0x4642f480
1901: 10 -> fetch0@fetch -> 0x4642fc90
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0815 06:49:53.002306  8045 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0815 06:49:53.002512  8082 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:49:53.002626  8083 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:49:53.002660  8084 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:49:53.002846  8085 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:49:53.002862  8086 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:49:53.002921  8087 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:49:53.002905  8084 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x4642e0e01723704593000792959_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.002991  8087 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.003050  8087 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:49:53.003057  8084 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x4642e0e01723704593000792959_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0815 06:49:53.003110  8087 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4642e0e01723704593000792959_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4642e0e01723704593000792959_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.003630  8087 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4642e0e01723704593000792959_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4642e0e01723704593000792959_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.003664  8087 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x4642e0e01723704593000792959_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.003717  8087 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.003733  8087 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x4642e0e01723704593000792959_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.003760  8087 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x4642e0e01723704593000792959_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x4642e0e01723704593000792959_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.003814  8087 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.003886  8087 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x4642e0e01723704593000792959_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x4642e0e01723704593000792959_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.003945  8087 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x4642e0e01723704593000792959_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x4642e0e01723704593000792959_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.004016  8087 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.004032  8087 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x4642e0e01723704593000792959_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x4642e0e01723704593000792959_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.004055  8087 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x4642e0e01723704593000792959_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x4642e0e01723704593000792959_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x4642e0e01723704593000792959_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.004135  8087 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x4642e0e01723704593000792959_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x4642e0e01723704593000792959_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x4642e0e01723704593000792959_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:49:53.004218  8084 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4642e0e01723704593000792959_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.004253  8084 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.004372  8084 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_1
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4642e0e01723704593000792959_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4642e0e01723704593000792959_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 06:49:53.004410  8084 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4642e0e01723704593000792959_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.004436  8084 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.004468  8084 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_1
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4642e0e01723704593000792959_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 06:49:53.004503  8045 pir_interpreter.cc:1766] main_thread_blocker_(0x4642e250) got event_name: TaskCompletion
1901: I0815 06:49:53.004534  8045 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.007596  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.007627  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.007692  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.007704  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.008899  8082 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 4955968380307860128 to 11183144775165096844 , after update, data is {current : -20004, peak : 16}.
1901: I0815 06:49:53.008919  8082 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 4955968380307860128 to 11183144775165096844 , after update, data is {current : 0, peak : 330659}.
1901: I0815 06:49:53.009110  8084 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 978453623184611468 to 11183144775165096844 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 06:49:53.009294  8087 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 11183144775165096844 to 11754429395199136992 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 06:49:53.009312  8087 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 11183144775165096844 to 11754429395199136992 , after update, data is {current : 120000, peak : 440631}.
1901: I0815 06:49:53.010702  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.011269  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.011765  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.011782  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.011788  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.014158  8045 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:49:53.014181  8045 scope.cc:202] Create variable feed
1901: I0815 06:49:53.014216  8045 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:49:53.014226  8045 scope.cc:202] Create variable MedianIndex
1901: I0815 06:49:53.014231  8045 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x46448aa0 type is 7
1901: I0815 06:49:53.014242  8045 scope.cc:202] Create variable Out
1901: I0815 06:49:53.014245  8045 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x46448030 type is 7
1901: I0815 06:49:53.014250  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.014256  8045 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x46448a20 type is 7
1901: I0815 06:49:53.014259  8045 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x46448050 type is 9
1901: I0815 06:49:53.014266  8045 scope.cc:202] Create variable fetch
1901: I0815 06:49:53.014272  8045 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x46448e50 type is 10
1901: I0815 06:49:53.014355  8045 interpreter_util.cc:594] Static build: 0
1901: I0815 06:49:53.014364  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.014367  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.014372  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.014428  8045 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.014443  8045 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.014513  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.014523  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.014544  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.015046  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.015064  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.015086  8045 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.015094  8045 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4644ce60Variable Type 7
1901: I0815 06:49:53.015113  8045 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.015134  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.015159  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.015178  8045 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.015223  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.015251  8045 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:49:53.015327  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.015339  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.015357  8045 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.015363  8045 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46450b30Variable Type 7
1901: I0815 06:49:53.015377  8045 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.015393  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.015412  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.015429  8045 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.015465  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.015496  8045 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:49:53.015781  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.015811  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.017127  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.017153  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.017203  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.017215  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.019147  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.019719  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.020156  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.020170  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.020175  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.022433  8045 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:49:53.022506  8045 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:49:53.022518  8045 scope.cc:202] Create variable MedianIndex
1901: I0815 06:49:53.022523  8045 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x4658bf30 type is 7
1901: I0815 06:49:53.022533  8045 scope.cc:202] Create variable Out
1901: I0815 06:49:53.022537  8045 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x4658b260 type is 7
1901: I0815 06:49:53.022542  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.022547  8045 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4658bc60 type is 7
1901: I0815 06:49:53.022552  8045 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x46448050 type is 9
1901: I0815 06:49:53.022559  8045 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x46448e50 type is 10
1901: I0815 06:49:53.022631  8045 interpreter_util.cc:594] Static build: 0
1901: I0815 06:49:53.022639  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.022643  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.022648  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.022688  8045 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.022702  8045 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.022759  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.022769  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.022789  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.023321  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.023339  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.023358  8045 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.023365  8045 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46590390Variable Type 7
1901: I0815 06:49:53.023382  8045 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.023401  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.023423  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.023440  8045 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.023481  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.023504  8045 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:49:53.023555  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.023566  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.023581  8045 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.023588  8045 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x465903b0Variable Type 7
1901: I0815 06:49:53.023602  8045 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.023617  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.023636  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.023651  8045 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.023686  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.023707  8045 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:49:53.024080  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.024113  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.140412  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1312bb0 for it.
1901: I0815 06:49:53.140830  8045 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.140897  8045 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.141500  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.141551  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.142768  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1312bb0 for it.
1901: I0815 06:49:53.142926  8045 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.142982  8045 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.144078  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.144115  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.146468  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1312bb0 for it.
1901: I0815 06:49:53.146622  8045 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.146672  8045 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 06:49:53.149958  8045 pir_interpreter.cc:161] PirInterpreter(): 0x46561620 on Place(gpu:0)
1901: I0815 06:49:53.149996  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.150020  8045 scope.cc:202] Create variable 0x465616201723704593149985756_inner_var_1
1901: I0815 06:49:53.150031  8045 scope.cc:202] Create variable 0x465616201723704593149985756_inner_var_2
1901: I0815 06:49:53.150041  8045 scope.cc:202] Create variable 0x465616201723704593149985756_inner_var_3
1901: I0815 06:49:53.150050  8045 scope.cc:202] Create variable 0x465616201723704593149985756_inner_var_4
1901: I0815 06:49:53.150061  8045 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:49:53.150437  8045 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:49:53.150454  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.150458  8045 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x465902c0
1901: 1 -> 0x465616201723704593149985756_inner_var_1 -> 0x46590340
1901: 2 -> 0x465616201723704593149985756_inner_var_2 -> 0x46594970
1901: 3 -> 0x465616201723704593149985756_inner_var_3 -> 0x4666ff70
1901: 4 -> 0x465616201723704593149985756_inner_var_4 -> 0x44145ae0
1901: 5 -> fetch0@fetch -> 0x464300a0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 06:49:53.151146  8089 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:49:53.151347  8090 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:49:53.151355  8091 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:49:53.151436  8092 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:49:53.151459  8093 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:49:53.151551  8094 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:49:53.151594  8094 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x465616201723704593149985756_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.151634  8094 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x465616201723704593149985756_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:49:53.151669  8094 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x465616201723704593149985756_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x465616201723704593149985756_inner_var_3:[dtype=;place=;dim=;lod={};, 0x465616201723704593149985756_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.152104  8094 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x465616201723704593149985756_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x465616201723704593149985756_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x465616201723704593149985756_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.152199  8093 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x465616201723704593149985756_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x465616201723704593149985756_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.152243  8093 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.152312  8093 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x465616201723704593149985756_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x465616201723704593149985756_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.152346  8093 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x465616201723704593149985756_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.152366  8093 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.152379  8093 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x465616201723704593149985756_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.152406  8045 pir_interpreter.cc:1766] main_thread_blocker_(0x46561790) got event_name: TaskCompletion
1901: I0815 06:49:53.152427  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.152930  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.153079  8045 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.153123  8045 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1312bb0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 06:49:53.155247  8045 pir_interpreter.cc:161] PirInterpreter(): 0x4644ff70 on Place(gpu:0)
1901: I0815 06:49:53.155274  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.155290  8045 scope.cc:202] Create variable 0x4644ff701723704593155268623_inner_var_1
1901: I0815 06:49:53.155308  8045 scope.cc:202] Create variable 0x4644ff701723704593155268623_inner_var_2
1901: I0815 06:49:53.155318  8045 scope.cc:202] Create variable 0x4644ff701723704593155268623_inner_var_3
1901: I0815 06:49:53.155324  8045 scope.cc:202] Create variable 0x4644ff701723704593155268623_inner_var_4
1901: I0815 06:49:53.155333  8045 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:49:53.155592  8045 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:49:53.155606  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.155608  8045 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x464663d0
1901: 1 -> 0x4644ff701723704593155268623_inner_var_1 -> 0x46466450
1901: 2 -> 0x4644ff701723704593155268623_inner_var_2 -> 0x4642fab0
1901: 3 -> 0x4644ff701723704593155268623_inner_var_3 -> 0x4656cf30
1901: 4 -> 0x4644ff701723704593155268623_inner_var_4 -> 0x46567380
1901: 5 -> fetch0@fetch -> 0x441fb8c0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 06:49:53.156149  8095 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:49:53.156354  8096 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:49:53.156380  8097 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:49:53.156464  8098 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:49:53.156553  8099 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:49:53.156620  8100 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:49:53.156668  8100 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4644ff701723704593155268623_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.156701  8100 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4644ff701723704593155268623_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:49:53.156737  8100 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4644ff701723704593155268623_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4644ff701723704593155268623_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4644ff701723704593155268623_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.157239  8100 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4644ff701723704593155268623_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x4644ff701723704593155268623_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4644ff701723704593155268623_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.157328  8099 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4644ff701723704593155268623_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4644ff701723704593155268623_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.157384  8099 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.157464  8099 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4644ff701723704593155268623_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4644ff701723704593155268623_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.157505  8099 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4644ff701723704593155268623_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.157529  8099 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.157543  8099 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4644ff701723704593155268623_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.157588  8045 pir_interpreter.cc:1766] main_thread_blocker_(0x464500e0) got event_name: TaskCompletion
1901: I0815 06:49:53.157619  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.159196  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1312bb0 for it.
1901: I0815 06:49:53.159380  8045 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.159430  8045 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 06:49:53.162006  8045 pir_interpreter.cc:161] PirInterpreter(): 0x46568fa0 on Place(gpu:0)
1901: I0815 06:49:53.162036  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.162055  8045 scope.cc:202] Create variable 0x46568fa01723704593162029063_inner_var_1
1901: I0815 06:49:53.162065  8045 scope.cc:202] Create variable 0x46568fa01723704593162029063_inner_var_2
1901: I0815 06:49:53.162073  8045 scope.cc:202] Create variable 0x46568fa01723704593162029063_inner_var_3
1901: I0815 06:49:53.162081  8045 scope.cc:202] Create variable 0x46568fa01723704593162029063_inner_var_4
1901: I0815 06:49:53.162088  8045 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:49:53.162402  8045 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:49:53.162416  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.162420  8045 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x4656c910
1901: 1 -> 0x46568fa01723704593162029063_inner_var_1 -> 0x46568f80
1901: 2 -> 0x46568fa01723704593162029063_inner_var_2 -> 0x464334d0
1901: 3 -> 0x46568fa01723704593162029063_inner_var_3 -> 0x465954a0
1901: 4 -> 0x46568fa01723704593162029063_inner_var_4 -> 0x46433420
1901: 5 -> fetch0@fetch -> 0x4644daa0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 06:49:53.162986  8101 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 06:49:53.163184  8102 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:49:53.163208  8103 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:49:53.163277  8104 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:49:53.163379  8105 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:49:53.163380  8106 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:49:53.163426  8106 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46568fa01723704593162029063_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.163450  8106 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46568fa01723704593162029063_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 06:49:53.163476  8106 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46568fa01723704593162029063_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46568fa01723704593162029063_inner_var_3:[dtype=;place=;dim=;lod={};, 0x46568fa01723704593162029063_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.163882  8106 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x46568fa01723704593162029063_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x46568fa01723704593162029063_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x46568fa01723704593162029063_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.163944  8105 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46568fa01723704593162029063_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46568fa01723704593162029063_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.163976  8105 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.164033  8105 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x46568fa01723704593162029063_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x46568fa01723704593162029063_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.164063  8105 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x46568fa01723704593162029063_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.164081  8105 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.164094  8105 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x46568fa01723704593162029063_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.164124  8045 pir_interpreter.cc:1766] main_thread_blocker_(0x46569110) got event_name: TaskCompletion
1901: I0815 06:49:53.164142  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.164309  8045 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0815 06:49:53.216864  8089 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 11183144775165096844 to 17425843833308192534 , after update, data is {current : -4, peak : 0}.
1901: I0815 06:49:53.216881  8089 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 11183144775165096844 to 17425843833308192534 , after update, data is {current : -36, peak : 0}.
1901: I0815 06:49:53.217123  8093 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 16741692470487512593 to 17425843833308192534 , after update, data is {current : 0, peak : 4}.
1901: I0815 06:49:53.217262  8094 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 978453623184611468 to 17425843833308192534 , after update, data is {current : 0, peak : 16}.
1901: I0815 06:49:53.217278  8094 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 978453623184611468 to 17425843833308192534 , after update, data is {current : -18, peak : 330659}.
1901: I0815 06:49:53.217504  8095 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 17494740670183811911 to 17425843833308192534 , after update, data is {current : -2, peak : 16}.
1901: I0815 06:49:53.217519  8095 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 17494740670183811911 to 17425843833308192534 , after update, data is {current : -36, peak : 330659}.
1901: I0815 06:49:53.217698  8099 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 14874870302300464888 to 17425843833308192534 , after update, data is {current : 2, peak : 16}.
1901: I0815 06:49:53.217881  8100 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 7082414722811983458 to 17425843833308192534 , after update, data is {current : 2, peak : 16}.
1901: I0815 06:49:53.217895  8100 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 7082414722811983458 to 17425843833308192534 , after update, data is {current : -18, peak : 330659}.
1901: I0815 06:49:53.218065  8101 thread_data_registry.h:135] Add data {current : 2, peak : 16} from thread 17425843833308192534 to 13480262868974433502 , after update, data is {current : 2, peak : 16}.
1901: I0815 06:49:53.218075  8101 thread_data_registry.h:135] Add data {current : -18, peak : 330659} from thread 17425843833308192534 to 13480262868974433502 , after update, data is {current : 0, peak : 330659}.
1901: I0815 06:49:53.218232  8105 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 3657943729023590833 to 13480262868974433502 , after update, data is {current : 6, peak : 16}.
1901: I0815 06:49:53.218420  8106 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 13480262868974433502 to 11754429395199136992 , after update, data is {current : 20006, peak : 40004}.
1901: I0815 06:49:53.218429  8106 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 13480262868974433502 to 11754429395199136992 , after update, data is {current : 200000, peak : 560633}.
1901: I0815 06:49:53.222805  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.223044  8045 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7f9c9c027c00), and remaining 0
1901: I0815 06:49:53.223183  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.223217  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.223688  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.224625  8045 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.224706  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.224731  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.224905  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.225631  8045 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.225703  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.225729  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.225885  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.226507  8045 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.226584  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.226609  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.226768  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0815 06:49:53.227507  8045 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.227563  8045 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f9c9c018e00), and remaining 0
1901: I0815 06:49:53.227617  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.227639  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.228106  8045 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.228171  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.228194  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.228658  8045 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.228724  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.228747  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.229154  8045 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.229218  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.229240  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.229808  8045 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.229878  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.229902  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.230089  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.230731  8045 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.230803  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.230827  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.230988  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.231690  8045 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.231763  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.231788  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.232026  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.232645  8045 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.232717  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.232741  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.232905  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.233572  8045 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.233642  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.233667  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.233911  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.234563  8045 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.234637  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.234661  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.234822  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.235529  8045 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.235602  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.235627  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.235790  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.236465  8045 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.236539  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.236564  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.236717  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.237429  8045 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.237500  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.237525  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.237737  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.238371  8045 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.238443  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.238468  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.238628  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.239161  8045 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.239225  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.239249  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.239410  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.240085  8045 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.240151  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.240175  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.240334  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.240983  8045 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.241051  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.241076  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.241446  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0815 06:49:53.243407  8045 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.243480  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.243506  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.243690  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.245055  8045 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.245129  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.245154  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.245404  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.246713  8045 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.246788  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.246812  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.246994  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.248201  8045 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.248275  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.248309  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.248643  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.249872  8045 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.249946  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.249971  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.250156  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.251456  8045 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.251529  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.251554  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.251734  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.253029  8045 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.253103  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.253129  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.253317  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.254526  8045 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.254601  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.254626  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.255041  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.256775  8045 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.256863  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.256892  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.257104  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.258361  8045 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.258438  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.258466  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.258706  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.259944  8045 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.260021  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.260048  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.260236  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.261543  8045 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.261621  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.261648  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.261833  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.263053  8045 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.263129  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.263155  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.263345  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.264626  8045 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.264701  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.264729  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.264907  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.266126  8045 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.266202  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.266228  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.266425  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.267639  8045 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.267715  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.267741  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.267921  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.268694  8045 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.268767  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.268793  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.268968  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.271807  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.271835  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.272677  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.272701  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.273475  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.273499  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.274272  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.274295  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.275069  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.275091  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.277797  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.278347  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.278874  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.279400  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.279920  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.280840  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.280859  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.280865  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.285884  8045 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:49:53.285964  8045 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:49:53.285976  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.285984  8045 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x46889f80 type is 7
1901: I0815 06:49:53.285993  8045 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x46448050 type is 9
1901: I0815 06:49:53.286001  8045 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x46448e50 type is 10
1901: I0815 06:49:53.286006  8045 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 06:49:53.286010  8045 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x46889240 type is 7
1901: I0815 06:49:53.286015  8045 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 06:49:53.286018  8045 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x46889e30 type is 7
1901: I0815 06:49:53.286024  8045 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 06:49:53.286028  8045 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x46467960 type is 7
1901: I0815 06:49:53.286033  8045 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 06:49:53.286037  8045 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x46888b90 type is 7
1901: I0815 06:49:53.286043  8045 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 06:49:53.286049  8045 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x46888cc0 type is 7
1901: I0815 06:49:53.286055  8045 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 06:49:53.286059  8045 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x4688a180 type is 7
1901: I0815 06:49:53.286064  8045 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 06:49:53.286067  8045 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x4688a390 type is 7
1901: I0815 06:49:53.286072  8045 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 06:49:53.286077  8045 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x4688a5f0 type is 7
1901: I0815 06:49:53.286082  8045 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 06:49:53.286088  8045 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x4688a850 type is 7
1901: I0815 06:49:53.286093  8045 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 06:49:53.286096  8045 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x4688aab0 type is 7
1901: I0815 06:49:53.286247  8045 interpreter_util.cc:594] Static build: 0
1901: I0815 06:49:53.286255  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.286260  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.286264  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.286343  8045 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.286360  8045 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.286434  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.286445  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.286463  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.286645  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.286854  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.286868  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.286887  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.287024  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.287215  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.287227  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.287245  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.287382  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.287569  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.287582  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.287600  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.287748  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.287957  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.287971  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.287987  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.288136  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.288339  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.288352  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.288372  8045 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.288379  8045 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x469634d0Variable Type 7
1901: I0815 06:49:53.288400  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.288420  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.288447  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.288465  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.288511  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.288533  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:49:53.288580  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.288591  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.288606  8045 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.288614  8045 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4688bc00Variable Type 7
1901: I0815 06:49:53.288628  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.288642  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.288661  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.288676  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.288710  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.288744  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:49:53.288797  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.288808  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.288825  8045 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.288831  8045 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x469689b0Variable Type 7
1901: I0815 06:49:53.288844  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.288858  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.288877  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.288892  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.288925  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.288938  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 06:49:53.288981  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.288991  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.289005  8045 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.289012  8045 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4688b1c0Variable Type 7
1901: I0815 06:49:53.289026  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.289038  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.289057  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.289070  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.289103  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.289117  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 06:49:53.289158  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.289168  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.289182  8045 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.289188  8045 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x46966000Variable Type 7
1901: I0815 06:49:53.289202  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.289215  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.289232  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.289247  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.289278  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.289291  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 06:49:53.289997  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.290040  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.290056  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.290073  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.290089  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 06:49:53.296052  8045 pir_interpreter.cc:161] PirInterpreter(): 0x4688aca0 on Place(gpu:0)
1901: I0815 06:49:53.296082  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.296101  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_1
1901: I0815 06:49:53.296113  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_2
1901: I0815 06:49:53.296123  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_3
1901: I0815 06:49:53.296133  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_4
1901: I0815 06:49:53.296142  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_5
1901: I0815 06:49:53.296150  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_6
1901: I0815 06:49:53.296159  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_7
1901: I0815 06:49:53.296166  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_8
1901: I0815 06:49:53.296175  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_9
1901: I0815 06:49:53.296182  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_10
1901: I0815 06:49:53.296193  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_11
1901: I0815 06:49:53.296203  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_12
1901: I0815 06:49:53.296213  8045 scope.cc:202] Create variable fetch0@fetch
1901: I0815 06:49:53.296227  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_14
1901: I0815 06:49:53.296237  8045 scope.cc:202] Create variable fetch1@fetch
1901: I0815 06:49:53.296248  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_16
1901: I0815 06:49:53.296258  8045 scope.cc:202] Create variable fetch2@fetch
1901: I0815 06:49:53.296268  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_18
1901: I0815 06:49:53.296277  8045 scope.cc:202] Create variable fetch3@fetch
1901: I0815 06:49:53.296286  8045 scope.cc:202] Create variable 0x4688aca01723704593296075740_inner_var_20
1901: I0815 06:49:53.296295  8045 scope.cc:202] Create variable fetch4@fetch
1901: I0815 06:49:53.296586  8045 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 06:49:53.296600  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.296603  8045 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x468888c0
1901: 1 -> 0x4688aca01723704593296075740_inner_var_1 -> 0x469b9520
1901: 2 -> 0x4688aca01723704593296075740_inner_var_2 -> 0x46888eb0
1901: 3 -> 0x4688aca01723704593296075740_inner_var_3 -> 0x46965400
1901: 4 -> 0x4688aca01723704593296075740_inner_var_4 -> 0x469b9500
1901: 5 -> 0x4688aca01723704593296075740_inner_var_5 -> 0x46936460
1901: 6 -> 0x4688aca01723704593296075740_inner_var_6 -> 0x468cc2b0
1901: 7 -> 0x4688aca01723704593296075740_inner_var_7 -> 0x46889820
1901: 8 -> 0x4688aca01723704593296075740_inner_var_8 -> 0x46890790
1901: 9 -> 0x4688aca01723704593296075740_inner_var_9 -> 0x197acc40
1901: 10 -> 0x4688aca01723704593296075740_inner_var_10 -> 0x196f7aa0
1901: 11 -> 0x4688aca01723704593296075740_inner_var_11 -> 0x46897f30
1901: 12 -> 0x4688aca01723704593296075740_inner_var_12 -> 0x469b9540
1901: 13 -> fetch0@fetch -> 0x4693ab00
1901: 14 -> 0x4688aca01723704593296075740_inner_var_14 -> 0x4693aac0
1901: 15 -> fetch1@fetch -> 0x4689fdd0
1901: 16 -> 0x4688aca01723704593296075740_inner_var_16 -> 0x4693aae0
1901: 17 -> fetch2@fetch -> 0x4688b430
1901: 18 -> 0x4688aca01723704593296075740_inner_var_18 -> 0x4689fdb0
1901: 19 -> fetch3@fetch -> 0x46964c30
1901: 20 -> 0x4688aca01723704593296075740_inner_var_20 -> 0x4688b410
1901: 21 -> fetch4@fetch -> 0x4688f260
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 06:49:53.298044  8107 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:49:53.298089  8109 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:49:53.298106  8108 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:49:53.298141  8110 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:49:53.298174  8111 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:49:53.298205  8111 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.298243  8111 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 06:49:53.298288  8111 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4688aca01723704593296075740_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.298475  8111 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.298629  8111 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4688aca01723704593296075740_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.298679  8111 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_5:[dtype=;place=;dim=;lod={};, 0x4688aca01723704593296075740_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.298700  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.298732  8110 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.298810  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.298828  8111 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.298866  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.298887  8110 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.298898  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.299005  8111 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4688aca01723704593296075740_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.299046  8111 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_7:[dtype=;place=;dim=;lod={};, 0x4688aca01723704593296075740_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299054  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299068  8110 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.299124  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.299172  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299187  8110 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.299197  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.299216  8111 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.299360  8111 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4688aca01723704593296075740_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.299399  8111 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_9:[dtype=;place=;dim=;lod={};, 0x4688aca01723704593296075740_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299407  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299422  8110 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.299455  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.299491  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299506  8110 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.299515  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.299567  8111 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.299718  8111 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4688aca01723704593296075740_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.299759  8111 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_11:[dtype=;place=;dim=;lod={};, 0x4688aca01723704593296075740_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299764  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299779  8110 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.299809  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.299892  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.299907  8110 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.299917  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.299935  8111 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.300084  8111 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4688aca01723704593296075740_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x4688aca01723704593296075740_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.300130  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.300145  8110 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.300171  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4688aca01723704593296075740_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4688aca01723704593296075740_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.300205  8110 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.300220  8110 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.300230  8110 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4688aca01723704593296075740_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.300256  8045 pir_interpreter.cc:1766] main_thread_blocker_(0x4688ae10) got event_name: TaskCompletion
1901: I0815 06:49:53.300276  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.300304  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.300315  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.300326  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.300336  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.301797  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.301885  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.301913  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.302091  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.302194  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x468cca40)  to GradNodeAccumulation (addr: 0x4358b5e0)
1901: I0815 06:49:53.302335  8045 backward.cc:459] Run in Grad
1901: I0815 06:49:53.302352  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.302407  8045 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x468cca40 to ptr: 0x46939fa0
1901: I0815 06:49:53.302419  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.302466  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.302500  8045 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x4358b5e0 to ptr: 0x468681c0
1901: I0815 06:49:53.302531  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46939fa0
1901: I0815 06:49:53.302539  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.302574  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.302637  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.302646  8045 backward.cc:335] Node: NanmedianGradNode addr:0x46939fa0, Found pending node: GradNodeAccumulation addr: 0x468681c0
1901: I0815 06:49:53.302652  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.302678  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x468681c0
1901: I0815 06:49:53.302685  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.302690  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.302695  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.302700  8045 backward.cc:435] Finish Backward
1901: I0815 06:49:53.303408  8045 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 06:49:53.303426  8045 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 06:49:53.303540  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.303565  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.303709  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.303789  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46939fa0)  to GradNodeAccumulation (addr: 0x4358b5e0)
1901: I0815 06:49:53.303889  8045 backward.cc:442] Run in Backward
1901: I0815 06:49:53.303896  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.303902  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.303934  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.303961  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46939fa0
1901: I0815 06:49:53.303969  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.303998  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.304054  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.304080  8045 backward.cc:335] Node: NanmedianGradNode addr:0x46939fa0, Found pending node: GradNodeAccumulation addr: 0x4358b5e0
1901: I0815 06:49:53.304088  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.304106  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4358b5e0
1901: I0815 06:49:53.304113  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.304117  8045 accumulation_node.cc:40] Move Tensor ptr: 0x46576840
1901: I0815 06:49:53.304121  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.304126  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.307107  8045 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0815 06:49:53.307624  8045 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.307744  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.307770  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.307943  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46934630)  to GradNodeAccumulation (addr: 0x197ab080)
1901: I0815 06:49:53.308046  8045 backward.cc:442] Run in Backward
1901: I0815 06:49:53.308055  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.308063  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.308094  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.308116  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46934630
1901: I0815 06:49:53.308125  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.308153  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.308202  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.308226  8045 backward.cc:335] Node: NanmedianGradNode addr:0x46934630, Found pending node: GradNodeAccumulation addr: 0x197ab080
1901: I0815 06:49:53.308235  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.308252  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x197ab080
1901: I0815 06:49:53.308259  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.308264  8045 accumulation_node.cc:40] Move Tensor ptr: 0x441c8ed0
1901: I0815 06:49:53.308267  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.308271  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.309046  8045 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.309128  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.309155  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.309381  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.309480  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46939fa0)  to GradNodeAccumulation (addr: 0x197ab080)
1901: I0815 06:49:53.309602  8045 backward.cc:459] Run in Grad
1901: I0815 06:49:53.309612  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.309625  8045 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x46939fa0 to ptr: 0x469345b0
1901: I0815 06:49:53.309634  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.309665  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.309689  8045 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x197ab080 to ptr: 0x468681c0
1901: I0815 06:49:53.309710  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x469345b0
1901: I0815 06:49:53.309716  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.309746  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.309885  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.309895  8045 backward.cc:335] Node: NanmedianGradNode addr:0x469345b0, Found pending node: GradNodeAccumulation addr: 0x468681c0
1901: I0815 06:49:53.309899  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.309916  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x468681c0
1901: I0815 06:49:53.309922  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.309926  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.309931  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.309935  8045 backward.cc:435] Finish Backward
1901: I0815 06:49:53.310843  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.310922  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.310948  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.311117  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.312585  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.312642  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.312665  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.317405  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.317437  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.318521  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.318545  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.319475  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.319579  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.319610  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.319833  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.320454  8045 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.320534  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.320562  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.320739  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.321372  8045 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.321449  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.321477  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.321646  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.322237  8045 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.322325  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.322355  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.322530  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.323128  8045 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.323180  8045 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f9c9c019200), and remaining 0
1901: I0815 06:49:53.323237  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.323263  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.323765  8045 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.323837  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.323863  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.324398  8045 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.324470  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.324496  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.324971  8045 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.325043  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.325068  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.325579  8045 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.325649  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.325675  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.325954  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.326614  8045 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.326700  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.326728  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.326915  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.327536  8045 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.327616  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.327644  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.327811  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.328402  8045 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.328481  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.328510  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.328682  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.329290  8045 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.329381  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.329409  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.329576  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.330158  8045 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.330235  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.330263  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.330447  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.331060  8045 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.331138  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.331167  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.331342  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.331946  8045 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.332026  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.332052  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.332218  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.332878  8045 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.332954  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.332983  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.333148  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.333730  8045 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.333808  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.333837  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.334010  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.334537  8045 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.334590  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.334611  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.334733  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.335345  8045 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.335413  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.335438  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.335588  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.336225  8045 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.336313  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.336341  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.336539  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.337203  8045 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.337275  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.337311  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.337483  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.338138  8045 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.338208  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.338234  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.338423  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.339054  8045 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.339124  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.339149  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.339332  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.339967  8045 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.340036  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.340062  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.340240  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.340858  8045 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.340929  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.340955  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.341122  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.341751  8045 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.341822  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.341848  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.342022  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.342664  8045 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.342733  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.342758  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.342928  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.343575  8045 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.343647  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.343672  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.343844  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.344465  8045 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.344537  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.344561  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.344733  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.345337  8045 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.345408  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.345433  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.345608  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.346204  8045 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.346274  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.346310  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.346484  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.347082  8045 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.347158  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.347183  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.347365  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.347966  8045 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.348038  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.348063  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.348229  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.348855  8045 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.348927  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.348951  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.349123  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.349809  8045 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.349889  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.349916  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.350108  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.350701  8045 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.350772  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.350797  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.350975  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.351712  8045 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.351791  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.351819  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.352010  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.354117  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.354139  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.354769  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.354789  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.355399  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.355418  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.356032  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.356051  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.356658  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.356678  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.358070  8110 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 16741692470487512593 to 978453623184611468 , after update, data is {current : 0, peak : 1260}.
1901: I0815 06:49:53.358081  8110 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 16741692470487512593 to 978453623184611468 , after update, data is {current : 20, peak : 24}.
1901: I0815 06:49:53.358424  8111 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 978453623184611468 to 11754429395199136992 , after update, data is {current : 0, peak : 260}.
1901: I0815 06:49:53.358435  8111 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 978453623184611468 to 11754429395199136992 , after update, data is {current : 20026, peak : 40004}.
1901: I0815 06:49:53.358440  8111 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 978453623184611468 to 11754429395199136992 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 06:49:53.359858  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.360284  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.360713  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.361129  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.361553  8045 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 06:49:53.362258  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.362273  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.362277  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.366207  8045 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 06:49:53.366250  8045 interpreter_util.cc:1169] Creating Variables
1901: I0815 06:49:53.366259  8045 scope.cc:202] Create variable X
1901: I0815 06:49:53.366263  8045 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x4693d1a0 type is 7
1901: I0815 06:49:53.366272  8045 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x46448050 type is 9
1901: I0815 06:49:53.366277  8045 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x46448e50 type is 10
1901: I0815 06:49:53.366281  8045 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 06:49:53.366284  8045 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x4693c770 type is 7
1901: I0815 06:49:53.366288  8045 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 06:49:53.366291  8045 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x469a8580 type is 7
1901: I0815 06:49:53.366295  8045 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 06:49:53.366298  8045 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x4693d320 type is 7
1901: I0815 06:49:53.366312  8045 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 06:49:53.366317  8045 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x4693d400 type is 7
1901: I0815 06:49:53.366319  8045 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 06:49:53.366322  8045 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x4693d660 type is 7
1901: I0815 06:49:53.366328  8045 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 06:49:53.366330  8045 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x4693d950 type is 7
1901: I0815 06:49:53.366334  8045 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 06:49:53.366338  8045 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x4693db60 type is 7
1901: I0815 06:49:53.366341  8045 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 06:49:53.366343  8045 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x4693ddc0 type is 7
1901: I0815 06:49:53.366348  8045 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 06:49:53.366350  8045 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x4693e020 type is 7
1901: I0815 06:49:53.366355  8045 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 06:49:53.366358  8045 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x468cd470 type is 7
1901: I0815 06:49:53.366467  8045 interpreter_util.cc:594] Static build: 0
1901: I0815 06:49:53.366474  8045 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 06:49:53.366478  8045 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 06:49:53.366482  8045 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 06:49:53.366529  8045 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.366541  8045 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.366591  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.366600  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.366613  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.366762  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.366945  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.366956  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.366971  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.367080  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.367254  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.367264  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.367277  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.367393  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.367561  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.367571  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.367585  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.367707  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.367892  8045 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.367902  8045 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.367914  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.368036  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.368211  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368220  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368234  8045 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.368240  8045 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x468b42a0Variable Type 7
1901: I0815 06:49:53.368256  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.368271  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.368290  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.368314  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.368348  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.368364  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 06:49:53.368402  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368412  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368424  8045 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.368430  8045 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4698ff80Variable Type 7
1901: I0815 06:49:53.368443  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.368454  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.368470  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.368482  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.368510  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.368535  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 06:49:53.368574  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368583  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368597  8045 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.368602  8045 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x469d2b80Variable Type 7
1901: I0815 06:49:53.368613  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.368625  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.368640  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.368651  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.368680  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.368691  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 06:49:53.368727  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368736  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368746  8045 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.368752  8045 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x468a1d40Variable Type 7
1901: I0815 06:49:53.368762  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.368773  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.368788  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.368799  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.368826  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.368839  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 06:49:53.368870  8045 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368880  8045 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 06:49:53.368889  8045 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 06:49:53.368896  8045 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x468c1000Variable Type 7
1901: I0815 06:49:53.368907  8045 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 06:49:53.368917  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.368932  8045 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 06:49:53.368942  8045 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.368968  8045 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 06:49:53.368980  8045 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 06:49:53.369484  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.369513  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.369531  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.369547  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 06:49:53.369563  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 06:49:53.375221  8045 pir_interpreter.cc:161] PirInterpreter(): 0x4657d540 on Place(gpu:0)
1901: I0815 06:49:53.375258  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_1
1901: I0815 06:49:53.375272  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_2
1901: I0815 06:49:53.375283  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_3
1901: I0815 06:49:53.375293  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_4
1901: I0815 06:49:53.375313  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_5
1901: I0815 06:49:53.375324  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_6
1901: I0815 06:49:53.375334  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_7
1901: I0815 06:49:53.375344  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_8
1901: I0815 06:49:53.375355  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_9
1901: I0815 06:49:53.375365  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_10
1901: I0815 06:49:53.375375  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_11
1901: I0815 06:49:53.375382  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_12
1901: I0815 06:49:53.375399  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_14
1901: I0815 06:49:53.375414  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_16
1901: I0815 06:49:53.375427  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_18
1901: I0815 06:49:53.375439  8045 scope.cc:202] Create variable 0x4657d5401723704593375245300_inner_var_20
1901: I0815 06:49:53.375716  8045 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x469a8e80
1901: 1 -> 0x4657d5401723704593375245300_inner_var_1 -> 0x468a2040
1901: 2 -> 0x4657d5401723704593375245300_inner_var_2 -> 0x46941f50
1901: 3 -> 0x4657d5401723704593375245300_inner_var_3 -> 0x468c7d90
1901: 4 -> 0x4657d5401723704593375245300_inner_var_4 -> 0x468be400
1901: 5 -> 0x4657d5401723704593375245300_inner_var_5 -> 0x4687a250
1901: 6 -> 0x4657d5401723704593375245300_inner_var_6 -> 0x46575f40
1901: 7 -> 0x4657d5401723704593375245300_inner_var_7 -> 0x46597810
1901: 8 -> 0x4657d5401723704593375245300_inner_var_8 -> 0x46566a10
1901: 9 -> 0x4657d5401723704593375245300_inner_var_9 -> 0x4642bea0
1901: 10 -> 0x4657d5401723704593375245300_inner_var_10 -> 0x46968c60
1901: 11 -> 0x4657d5401723704593375245300_inner_var_11 -> 0x4689a050
1901: 12 -> 0x4657d5401723704593375245300_inner_var_12 -> 0x469d6ad0
1901: 13 -> fetch0@fetch -> 0x4693ab00
1901: 14 -> 0x4657d5401723704593375245300_inner_var_14 -> 0x4689a860
1901: 15 -> fetch1@fetch -> 0x4689fdd0
1901: 16 -> 0x4657d5401723704593375245300_inner_var_16 -> 0x19770400
1901: 17 -> fetch2@fetch -> 0x4688b430
1901: 18 -> 0x4657d5401723704593375245300_inner_var_18 -> 0x196f4d30
1901: 19 -> fetch3@fetch -> 0x46964c30
1901: 20 -> 0x4657d5401723704593375245300_inner_var_20 -> 0x46451c70
1901: 21 -> fetch4@fetch -> 0x4688f260
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 06:49:53.377156  8112 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 06:49:53.377180  8113 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 06:49:53.377199  8114 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 06:49:53.377239  8115 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 06:49:53.377290  8116 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 06:49:53.377326  8116 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.377375  8116 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 06:49:53.377419  8116 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_3:[dtype=;place=;dim=;lod={};, 0x4657d5401723704593375245300_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.377640  8116 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.377796  8116 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x4657d5401723704593375245300_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.377849  8116 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_5:[dtype=;place=;dim=;lod={};, 0x4657d5401723704593375245300_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.377871  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.377908  8115 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.377976  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.377995  8116 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.378036  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378059  8115 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.378067  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378172  8116 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x4657d5401723704593375245300_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.378217  8116 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_7:[dtype=;place=;dim=;lod={};, 0x4657d5401723704593375245300_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.378224  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.378242  8115 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.378283  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378330  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378350  8115 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.378355  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378391  8116 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.378536  8116 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x4657d5401723704593375245300_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.378578  8116 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_9:[dtype=;place=;dim=;lod={};, 0x4657d5401723704593375245300_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.378583  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.378608  8115 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.378641  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378680  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378697  8115 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.378703  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.378757  8116 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.378909  8116 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x4657d5401723704593375245300_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.378952  8116 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_11:[dtype=;place=;dim=;lod={};, 0x4657d5401723704593375245300_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.378958  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.378974  8115 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.379004  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.379042  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.379060  8115 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.379065  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.379122  8116 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.379271  8116 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x4657d5401723704593375245300_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x4657d5401723704593375245300_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 06:49:53.379326  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 06:49:53.379343  8115 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 06:49:53.379367  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x4657d5401723704593375245300_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x4657d5401723704593375245300_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.379400  8115 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.379417  8115 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.379422  8115 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x4657d5401723704593375245300_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 06:49:53.379449  8045 pir_interpreter.cc:1766] main_thread_blocker_(0x4657d6b0) got event_name: TaskCompletion
1901: I0815 06:49:53.379472  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.379493  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.379506  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.379516  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.379526  8045 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 06:49:53.380950  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x197ab080 for it.
1901: I0815 06:49:53.381039  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.381067  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.381247  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.381353  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46568fa0)  to GradNodeAccumulation (addr: 0x197ab080)
1901: I0815 06:49:53.381467  8045 backward.cc:459] Run in Grad
1901: I0815 06:49:53.381476  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.381489  8045 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x46568fa0 to ptr: 0x468942d0
1901: I0815 06:49:53.381497  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.381531  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.381556  8045 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x197ab080 to ptr: 0x468681c0
1901: I0815 06:49:53.381574  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x468942d0
1901: I0815 06:49:53.381582  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.381611  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.381671  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.381680  8045 backward.cc:335] Node: NanmedianGradNode addr:0x468942d0, Found pending node: GradNodeAccumulation addr: 0x468681c0
1901: I0815 06:49:53.381685  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.381709  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x468681c0
1901: I0815 06:49:53.381716  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.381719  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.381724  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.381728  8045 backward.cc:435] Finish Backward
1901: I0815 06:49:53.382364  8045 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 06:49:53.382381  8045 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 06:49:53.382467  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.382490  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.382633  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.382709  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x46568fa0)  to GradNodeAccumulation (addr: 0x197ab080)
1901: I0815 06:49:53.382789  8045 backward.cc:442] Run in Backward
1901: I0815 06:49:53.382797  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.382803  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.382831  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.382853  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x46568fa0
1901: I0815 06:49:53.382861  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.382889  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.382941  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.382966  8045 backward.cc:335] Node: NanmedianGradNode addr:0x46568fa0, Found pending node: GradNodeAccumulation addr: 0x197ab080
1901: I0815 06:49:53.382974  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.382992  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x197ab080
1901: I0815 06:49:53.382999  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.383003  8045 accumulation_node.cc:40] Move Tensor ptr: 0x46451090
1901: I0815 06:49:53.383008  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.383011  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.383457  8045 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.383569  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.383594  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.383759  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x468942d0)  to GradNodeAccumulation (addr: 0x4358b5e0)
1901: I0815 06:49:53.383858  8045 backward.cc:442] Run in Backward
1901: I0815 06:49:53.383867  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.383874  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.383904  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.383927  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x468942d0
1901: I0815 06:49:53.383936  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.383962  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.384009  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.384034  8045 backward.cc:335] Node: NanmedianGradNode addr:0x468942d0, Found pending node: GradNodeAccumulation addr: 0x4358b5e0
1901: I0815 06:49:53.384042  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.384058  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4358b5e0
1901: I0815 06:49:53.384065  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.384069  8045 accumulation_node.cc:40] Move Tensor ptr: 0x46562710
1901: I0815 06:49:53.384073  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.384078  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.384785  8045 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.384867  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.384893  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.385076  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.385169  8045 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x468942d0)  to GradNodeAccumulation (addr: 0x4358b5e0)
1901: I0815 06:49:53.385284  8045 backward.cc:459] Run in Grad
1901: I0815 06:49:53.385294  8045 backward.cc:113] Start Backward
1901: I0815 06:49:53.385316  8045 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x468942d0 to ptr: 0x4688bd30
1901: I0815 06:49:53.385325  8045 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 06:49:53.385357  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.385380  8045 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x4358b5e0 to ptr: 0x468681c0
1901: I0815 06:49:53.385399  8045 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x4688bd30
1901: I0815 06:49:53.385406  8045 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 06:49:53.385435  8045 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.385555  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.385564  8045 backward.cc:335] Node: NanmedianGradNode addr:0x4688bd30, Found pending node: GradNodeAccumulation addr: 0x468681c0
1901: I0815 06:49:53.385569  8045 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 06:49:53.385586  8045 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x468681c0
1901: I0815 06:49:53.385592  8045 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.385596  8045 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 06:49:53.385600  8045 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 06:49:53.385604  8045 backward.cc:435] Finish Backward
1901: I0815 06:49:53.386509  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.386590  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.386616  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.386780  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.388144  8045 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4358b5e0 for it.
1901: I0815 06:49:53.388190  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.388208  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.390291  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.390327  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.391244  8045 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 06:49:53.391268  8045 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 06:49:53.392030  8045 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 06:49:53.392047  8045 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 06:49:53.392143  8045 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 06:49:53.392150  8045 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 06:49:53.392208  8045 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 06:49:53.392215  8045 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 06:49:53.392263  8045 dygraph_functions.cc:82227] Running AD API: arange
1901: I0815 06:49:53.392308  8045 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.392448  8045 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0815 06:49:53.392470  8045 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.392491  8045 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0815 06:49:53.392554  8045 dygraph_functions.cc:14224] Running AD API: cast
1901: I0815 06:49:53.392571  8045 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.392647  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0815 06:49:53.392716  8045 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 06:49:53.392733  8045 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 06:49:53.392907  8045 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: test_nanmedian failed
1901:  ss.E.................
1901: ======================================================================
1901: ERROR: test_check_output (test_nanmedian.TestNanmedianFP16Op)
1901: ----------------------------------------------------------------------
1901: Traceback (most recent call last):
1901:   File "/home/code/Paddle/build/test/legacy_test/test_nanmedian.py", line 617, in test_check_output
1901:     self.check_output(check_pir=True)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2934, in check_output
1901:     res = self.check_output_with_place(
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2786, in check_output_with_place
1901:     symbol_checker.check()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2637, in check
1901:     self.infer_and_compare_symbol()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2645, in infer_and_compare_symbol
1901:     self.op_test._infer_and_compare_symbol(place)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1712, in _infer_and_compare_symbol
1901:     self._compare_symbol(program, outs)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1633, in _compare_symbol
1901:     shape_analysis.get_shape_or_data_for_var(
1901: RuntimeError: (PreconditionNotMet) The op operand index [1] must less than operands size[1].
1901:   [Hint: Expected index < num_operands_, but received index:1 >= num_operands_:1.] (at /home/code/Paddle/paddle/pir/src/core/operation.cc:420)
1901: 
1901: 
1901: ----------------------------------------------------------------------
1901: Ran 21 tests in 2.950s
1901: 
1901: FAILED (errors=1, skipped=2)
1901: 
1901: I0815 06:49:53.394215  8045 mmap_allocator.cc:348] PID: 8045, MemoryMapFdSet: set size - 0
1901: I0815 06:49:53.406540  8045 mmap_allocator.cc:348] PID: 8045, MemoryMapFdSet: set size - 0
1901: I0815 06:49:53.462811  8115 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 5774704642923158941 to 7410942064695059867 , after update, data is {current : 0, peak : 1252}.
1901: I0815 06:49:53.462822  8115 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 5774704642923158941 to 7410942064695059867 , after update, data is {current : 0, peak : 16}.
1901: I0815 06:49:53.463073  8116 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 7410942064695059867 to 11754429395199136992 , after update, data is {current : 0, peak : 260}.
1901: I0815 06:49:53.463086  8116 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 7410942064695059867 to 11754429395199136992 , after update, data is {current : 20026, peak : 40004}.
1901: I0815 06:49:53.463092  8116 thread_data_registry.h:135] Add data {current : 0, peak : 1252} from thread 7410942064695059867 to 11754429395199136992 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 06:49:53.593006  8045 mmap_allocator.cc:348] PID: 8045, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................***Failed   11.83 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  12.01 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
