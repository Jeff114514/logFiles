UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0814 09:40:28.293867 26923 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0814 09:40:29.071595 26923 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=init_allocated_mem,cinn_subgraph_graphviz_dir,use_fast_math,tracer_profile_fname,initial_gpu_memory_in_mb,new_executor_sequential_run,enable_cinn_accuracy_check,dump_chunk_info,enable_pir_in_executor,cuda_memory_async_pool_realease_threshold,lapack_dir,auto_free_cudagraph_allocations_on_launch,graph_neighbor_size_percent,mkl_dir,tensorrt_dir,add_dependency_for_communication_op,gpugraph_slot_feasign_max_num,multiple_of_cupti_buffer_size,convert_all_blocks,use_cinn,gpugraph_debug_gpu_memory,use_pinned_memory,dygraph_debug,enable_interpretercore_launch_cinn,enable_sparse_inner_gather,enable_tracker_all2all,log_memory_stats,new_executor_serial_run,reader_queue_speed_test_mode,accuracy_check_atol_fp32,eager_delete_tensor_gb,static_runtime_data_save_path,sync_nccl_allreduce,enable_pir_in_executor_trace_run,new_executor_static_build,check_infer_symbolic,fuse_parameter_groups_size,nccl_dir,gemm_use_half_precision_compute_type,gpugraph_parallel_copyer_split_maxsize,op_dir,benchmark,auto_growth_chunk_size_in_mb,paddle_num_threads,tensor_operants_mode,sort_sum_gradient,pir_apply_shape_optimization_pass,curand_dir,accuracy_check_atol_fp16,gpugraph_parallel_stream_num,use_virtual_memory_auto_growth,fraction_of_gpu_memory_to_use,prim_all,apply_pass_to_program,cudnn_deterministic,dynamic_static_unified_comm,fuse_parameter_memory_size,prim_check_ops,enable_dependency_builder_debug_info,cusolver_dir,accuracy_check_rtol_fp32,gpugraph_hbm_table_load_factor,cusparselt_dir,enable_cinn_compile_cache,fleet_executor_with_standalone,win_cuda_bin_dir,enable_cinn_auto_tune,gpugraph_enable_gpu_direct_access,use_stride_kernel,pir_broadcast_tree_limit,enable_neighbor_list_use_uva,npu_storage_format,cache_inference_while_scope,gpugraph_offload_param_stat,enable_adjust_op_order,executor_log_deps_every_microseconds,use_auto_growth_v2,nvidia_package_dir,free_when_no_cache_hit,enable_pir_with_pt_in_dy2st,selected_gpus,cusparse_dir,cse_max_count,enable_graph_multi_node_sampling,logging_pir_py_code_int_tensor_element_limit,print_allocator_trace_info,enable_api_kernel_fallback,embedding_deterministic,cublaslt_device_best_config,check_kernel_launch,sync_after_alloc,query_dest_rank_by_multi_node,inner_op_parallelism,trt_ibuilder_cache,gpugraph_dedup_pull_push_mode,pir_apply_inplace_pass,disable_dyshape_in_train,cudnn_dir,host_trace_level,save_static_runtime_data,fast_eager_deletion_mode,check_nan_inf,nccl_blocking_wait,run_kp_kernel,enable_record_memory,gpugraph_offload_gather_copy_maxsize,eager_delete_scope,cinn_compile_thread_num,ir_inplace_kernel_blacklist,new_executor_use_cuda_graph,deny_cinn_ops,use_system_allocator,cupti_dir,tracer_onednn_ops_on,conv2d_disable_cudnn,alloc_fill_value,dist_threadpool_size,enable_fusion_fallback,pir_subgraph_saving_dir,gpugraph_force_device_batch_num_equal,reallocate_gpu_memory_in_mb,prim_forward_blacklist,call_stack_level,print_sub_graph_dir,enable_opt_get_features,memory_fraction_of_eager_deletion,max_inplace_grad_add,cuda_malloc_async_pool_memory_throttle_ratio,cublaslt_exhaustive_search_times,use_mkldnn,manually_trans_conv_filter,use_shm_cache,allow_cinn_ops,low_precision_op_list,graph_embedding_split_infer_mode,cudnn_exhaustive_search_times,search_cache_max_number,prim_forward,initial_cpu_memory_in_mb,gpugraph_enable_print_op_debug,logging_trunc_pir_py_code,cudnn_batchnorm_spatial_persistent,custom_device_mem_record,enable_auto_rdma_trans,enable_gpu_memory_usage_log,enable_collect_shape,cuda_dir,async_trace_count,graph_metapath_split_opt,gpu_allocator_retry_time,enable_fuse_parallel_matmul_pass,prim_skip_dynamic,prim_enabled,mklml_dir,gpugraph_load_node_list_into_hbm,pinned_memory_as_cpu_backend,accuracy_check_atol_bf16,allocator_strategy,new_executor_use_inplace,print_ir,use_auto_growth_pinned_allocator,accuracy_check_rtol_fp16,enable_auto_detect_gpu_topo,jit_engine_type,cudnn_exhaustive_search,enable_blaslt_global_search,use_cuda_malloc_async_allocator,einsum_opt,gpugraph_enable_segment_merge_grads,logging_pir_py_code_dump_symbolic_dims,tracer_onednn_ops_off,enable_all2all_use_fp16,enable_pir_api,conv_workspace_size_limit,enable_gpu_memory_usage_log_mb,accuracy_check_rtol_bf16,set_to_1d,gpugraph_storage_mode,enable_cublas_tensor_op_math,use_cuda_managed_memory,free_idle_chunk,new_executor_use_local_scope,local_exe_sub_scope_limit,pir_debug,gpugraph_sparse_table_storage_mode,get_host_by_name_time,prim_enable_dynamic,use_autotune,gpugraph_merge_grads_segment_size,static_executor_perfstat_filepath,check_nan_inf_level,gpugraph_offload_param_extends,gpu_memory_limit_mb,fraction_of_cuda_pinned_memory_to_use,fraction_of_cpu_memory_to_use,logging_pir_py_code_dir,use_stream_safe_cuda_allocator,graph_load_in_parallel,benchmark_nccl,enable_exit_when_partial_worker,graph_get_neighbor_id,gpugraph_enable_hbm_table_collision_stat,enable_async_trace,all_blocks_convert_trt,prim_backward,enable_unused_var_check,cublas_dir,multi_node_sample_use_gpu_table,enable_cse_in_dy2st,enable_dump_main_program,dataloader_use_file_descriptor,allreduce_record_one_event,use_xqa_optim 
1901: I0814 09:40:29.071704 26923 init.cc:108] After Parse: argc is 2
1901: I0814 09:40:35.166172 26923 scope.cc:202] Create variable X
1901: I0814 09:40:35.166244 26923 scope.cc:202] Create variable Out
1901: I0814 09:40:35.166260 26923 scope.cc:202] Create variable MedianIndex
1901: I0814 09:40:35.166407 26923 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0814 09:40:35.167011 26923 allocator_facade.cc:212] selected allocator strategy:1
1901: I0814 09:40:35.167337 26923 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0814 09:40:37.609493 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.609552 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.609685 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.609696 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.610720 26923 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 09:40:37.610744 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.610782 26923 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 09:40:37.610790 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.611235 26923 pybind.cc:1827] need skip: 0
1901: I0814 09:40:37.611331 26923 pybind.cc:1827] need skip: 0
1901: I0814 09:40:37.611737 26923 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0814 09:40:37.612095 26923 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0814 09:40:37.612111 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 09:40:37.612187 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0814 09:40:37.612201 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 09:40:37.615267 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.615942 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.615959 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.615972 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.618985 26923 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 09:40:37.619004 26923 scope.cc:202] Create variable feed
1901: I0814 09:40:37.619071 26923 program_interpreter.cc:243] New Executor is Running.
1901: I0814 09:40:37.619079 26923 interpreter_util.cc:1169] Creating Variables
1901: I0814 09:40:37.619086 26923 scope.cc:202] Create variable MedianIndex
1901: I0814 09:40:37.619094 26923 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x45752260 type is 7
1901: I0814 09:40:37.619107 26923 scope.cc:202] Create variable Out
1901: I0814 09:40:37.619113 26923 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x457527d0 type is 7
1901: I0814 09:40:37.619117 26923 scope.cc:202] Create variable Out@GRAD
1901: I0814 09:40:37.619120 26923 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x45752c80 type is 7
1901: I0814 09:40:37.619125 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.619128 26923 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x457535b0 type is 7
1901: I0814 09:40:37.619132 26923 scope.cc:202] Create variable X@GRAD
1901: I0814 09:40:37.619135 26923 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45753820 type is 7
1901: I0814 09:40:37.619140 26923 scope.cc:202] Create variable _generated_var_0
1901: I0814 09:40:37.619143 26923 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x45753a60 type is 7
1901: I0814 09:40:37.619148 26923 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0814 09:40:37.619150 26923 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x45753cc0 type is 7
1901: I0814 09:40:37.619154 26923 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x45752bd0 type is 9
1901: I0814 09:40:37.619163 26923 scope.cc:202] Create variable fetch
1901: I0814 09:40:37.619170 26923 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x45753a40 type is 10
1901: I0814 09:40:37.619283 26923 interpreter_util.cc:594] Static build: 0
1901: I0814 09:40:37.619289 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.619293 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.619298 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0814 09:40:37.619932 26923 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0814 09:40:37.620141 26923 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0814 09:40:37.621186 26923 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0814 09:40:37.621361 26923 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.621387 26923 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.621527 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.621537 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.621558 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.626510 26923 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.626547 26923 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.626580 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.626701 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.626796 26923 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.626807 26923 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.626875 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.626904 26923 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0814 09:40:37.626932 26923 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.626940 26923 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.626960 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 09:40:37.627063 26923 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.627074 26923 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.627094 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 09:40:37.627233 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.627262 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.627287 26923 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.627306 26923 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x457d08d0Variable Type 7
1901: I0814 09:40:37.627341 26923 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.627367 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.627393 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.627416 26923 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.627559 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.627599 26923 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 09:40:37.628218 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.628275 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.629824 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.629848 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.629902 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.629910 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.630607 26923 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 09:40:37.630625 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.630661 26923 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0814 09:40:37.630668 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.630997 26923 pybind.cc:1827] need skip: 0
1901: I0814 09:40:37.631057 26923 pybind.cc:1827] need skip: 0
1901: I0814 09:40:37.631443 26923 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0814 09:40:37.631532 26923 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0814 09:40:37.631541 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 09:40:37.631610 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0814 09:40:37.631620 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 09:40:37.639891 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.640586 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.640601 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.640607 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.645186 26923 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 09:40:37.645205 26923 scope.cc:202] Create variable feed
1901: I0814 09:40:37.645254 26923 interpreter_util.cc:1169] Creating Variables
1901: I0814 09:40:37.645263 26923 scope.cc:202] Create variable MedianIndex
1901: I0814 09:40:37.645268 26923 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x43423b80 type is 7
1901: I0814 09:40:37.645277 26923 scope.cc:202] Create variable Out
1901: I0814 09:40:37.645282 26923 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x45301d10 type is 7
1901: I0814 09:40:37.645287 26923 scope.cc:202] Create variable Out@GRAD
1901: I0814 09:40:37.645290 26923 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x45313580 type is 7
1901: I0814 09:40:37.645294 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.645298 26923 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x452f9010 type is 7
1901: I0814 09:40:37.645309 26923 scope.cc:202] Create variable X@GRAD
1901: I0814 09:40:37.645313 26923 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x45315930 type is 7
1901: I0814 09:40:37.645316 26923 scope.cc:202] Create variable _generated_var_0
1901: I0814 09:40:37.645319 26923 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x452e0ad0 type is 7
1901: I0814 09:40:37.645324 26923 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0814 09:40:37.645327 26923 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x452d45f0 type is 7
1901: I0814 09:40:37.645331 26923 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4572d7a0 type is 9
1901: I0814 09:40:37.645336 26923 scope.cc:202] Create variable fetch
1901: I0814 09:40:37.645339 26923 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x452e0ab0 type is 10
1901: I0814 09:40:37.645440 26923 interpreter_util.cc:594] Static build: 0
1901: I0814 09:40:37.645447 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.645452 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.645457 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.645560 26923 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.645581 26923 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.645658 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.645666 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.645684 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.646374 26923 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646389 26923 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646406 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.646466 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.646557 26923 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646566 26923 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646607 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.646656 26923 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646665 26923 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646682 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0814 09:40:37.646773 26923 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646785 26923 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.646800 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0814 09:40:37.646914 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.646929 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.646946 26923 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.646952 26923 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x445c0010Variable Type 7
1901: I0814 09:40:37.646975 26923 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.646993 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.647037 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.647053 26923 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.647117 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.647141 26923 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 09:40:37.647601 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0814 09:40:37.647640 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.649823 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.650002 26923 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1abec6a0 for it.
1901: I0814 09:40:37.650050 26923 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:37.651010 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.651067 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.651577 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x45752ca0)  to GradNodeAccumulation (addr: 0x44b78ef0)
1901: I0814 09:40:37.651746 26923 dygraph_functions.cc:51757] Running AD API: mean
1901: I0814 09:40:37.651768 26923 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.651849 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.651871 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x3e5fc7f0)  to NanmedianGradNode (addr: 0x45752ca0)
1901: I0814 09:40:37.651974 26923 backward.cc:442] Run in Backward
1901: I0814 09:40:37.651984 26923 backward.cc:113] Start Backward
1901: I0814 09:40:37.652001 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:37.652055 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.652086 26923 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x3e5fc7f0
1901: I0814 09:40:37.652104 26923 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0814 09:40:37.652139 26923 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.652207 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.652230 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:37.652241 26923 backward.cc:335] Node: MeanGradNode addr:0x3e5fc7f0, Found pending node: NanmedianGradNode addr: 0x45752ca0
1901: I0814 09:40:37.652248 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:37.652278 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x45752ca0
1901: I0814 09:40:37.652293 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:37.652325 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.652377 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:37.652398 26923 backward.cc:335] Node: NanmedianGradNode addr:0x45752ca0, Found pending node: GradNodeAccumulation addr: 0x44b78ef0
1901: I0814 09:40:37.652405 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:37.652419 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x44b78ef0
1901: I0814 09:40:37.652427 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:37.652434 26923 accumulation_node.cc:40] Move Tensor ptr: 0x452dc120
1901: I0814 09:40:37.652438 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:37.652442 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0814 09:40:37.661742 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.661983 26923 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:37.662036 26923 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1abec6a0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0814 09:40:37.720309 26923 pir_interpreter.cc:161] PirInterpreter(): 0x479fc540 on Place(gpu:0)
1901: I0814 09:40:37.720358 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.720391 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_1
1901: I0814 09:40:37.720400 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_2
1901: I0814 09:40:37.720409 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_3
1901: I0814 09:40:37.720417 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_4
1901: I0814 09:40:37.720425 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_5
1901: I0814 09:40:37.720431 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_6
1901: I0814 09:40:37.720439 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_7
1901: I0814 09:40:37.720445 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_8
1901: I0814 09:40:37.720453 26923 scope.cc:202] Create variable 0x479fc5401723628437720341611_inner_var_9
1901: I0814 09:40:37.720460 26923 scope.cc:202] Create variable fetch0@fetch
1901: I0814 09:40:37.720882 26923 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 09:40:37.720897 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.720901 26923 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0814 09:40:37.720947 26923 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x479f8460
1901: 1 -> 0x479fc5401723628437720341611_inner_var_1 -> 0x479fc520
1901: 2 -> 0x479fc5401723628437720341611_inner_var_2 -> 0x479fac40
1901: 3 -> 0x479fc5401723628437720341611_inner_var_3 -> 0x479fbc30
1901: 4 -> 0x479fc5401723628437720341611_inner_var_4 -> 0x479f9350
1901: 5 -> 0x479fc5401723628437720341611_inner_var_5 -> 0x479fcfc0
1901: 6 -> 0x479fc5401723628437720341611_inner_var_6 -> 0x479fd3e0
1901: 7 -> 0x479fc5401723628437720341611_inner_var_7 -> 0x479fd800
1901: 8 -> 0x479fc5401723628437720341611_inner_var_8 -> 0x479fafe0
1901: 9 -> 0x479fc5401723628437720341611_inner_var_9 -> 0x479fdc20
1901: 10 -> fetch0@fetch -> 0x479fe430
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0814 09:40:37.721909 26923 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0814 09:40:37.722124 26960 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 09:40:37.722296 26961 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 09:40:37.722360 26962 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 09:40:37.722378 26963 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 09:40:37.722445 26964 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 09:40:37.722476 26963 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x479fc5401723628437720341611_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.722543 26965 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 09:40:37.722570 26963 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x479fc5401723628437720341611_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0814 09:40:37.722584 26965 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.722627 26965 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 09:40:37.722679 26965 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x479fc5401723628437720341611_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_3:[dtype=;place=;dim=;lod={};, 0x479fc5401723628437720341611_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.723160 26965 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x479fc5401723628437720341611_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x479fc5401723628437720341611_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:37.723191 26965 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x479fc5401723628437720341611_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.723241 26965 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.723258 26965 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x479fc5401723628437720341611_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:37.723284 26965 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x479fc5401723628437720341611_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x479fc5401723628437720341611_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.723378 26965 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.723397 26965 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x479fc5401723628437720341611_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x479fc5401723628437720341611_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:37.723426 26965 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x479fc5401723628437720341611_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x479fc5401723628437720341611_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.723476 26965 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.723495 26965 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x479fc5401723628437720341611_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x479fc5401723628437720341611_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:37.723517 26965 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x479fc5401723628437720341611_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x479fc5401723628437720341611_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x479fc5401723628437720341611_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.723582 26965 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x479fc5401723628437720341611_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x479fc5401723628437720341611_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x479fc5401723628437720341611_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 09:40:37.723649 26963 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x479fc5401723628437720341611_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.723676 26963 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.723768 26963 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x479fc5401723628437720341611_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x479fc5401723628437720341611_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0814 09:40:37.723799 26963 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x479fc5401723628437720341611_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.723824 26963 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0814 09:40:37.723855 26963 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x479fc5401723628437720341611_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0814 09:40:37.723886 26923 pir_interpreter.cc:1766] main_thread_blocker_(0x479fc6b0) got event_name: TaskCompletion
1901: I0814 09:40:37.723914 26923 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0814 09:40:37.727211 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.727242 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.727317 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.727329 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.728540 26960 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 6121037699464866882 to 7893306207478841525 , after update, data is {current : -20004, peak : 16}.
1901: I0814 09:40:37.728559 26960 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 6121037699464866882 to 7893306207478841525 , after update, data is {current : 0, peak : 330659}.
1901: I0814 09:40:37.728726 26963 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 9005339895796172907 to 7893306207478841525 , after update, data is {current : 20000, peak : 40004}.
1901: I0814 09:40:37.728902 26965 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 7893306207478841525 to 4427487881527490888 , after update, data is {current : 20000, peak : 40004}.
1901: I0814 09:40:37.728912 26965 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 7893306207478841525 to 4427487881527490888 , after update, data is {current : 120000, peak : 440631}.
1901: I0814 09:40:37.730291 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.730875 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.731387 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.731405 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.731410 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.733742 26923 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 09:40:37.733762 26923 scope.cc:202] Create variable feed
1901: I0814 09:40:37.733798 26923 interpreter_util.cc:1169] Creating Variables
1901: I0814 09:40:37.733808 26923 scope.cc:202] Create variable MedianIndex
1901: I0814 09:40:37.733814 26923 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47a18890 type is 7
1901: I0814 09:40:37.733824 26923 scope.cc:202] Create variable Out
1901: I0814 09:40:37.733829 26923 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47a17e20 type is 7
1901: I0814 09:40:37.733834 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.733836 26923 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47a18810 type is 7
1901: I0814 09:40:37.733841 26923 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47a17e40 type is 9
1901: I0814 09:40:37.733847 26923 scope.cc:202] Create variable fetch
1901: I0814 09:40:37.733855 26923 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47a18c40 type is 10
1901: I0814 09:40:37.733927 26923 interpreter_util.cc:594] Static build: 0
1901: I0814 09:40:37.733934 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.733939 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.733944 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.734001 26923 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.734016 26923 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.734087 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.734098 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.734117 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.734634 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.734652 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.734673 26923 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.734680 26923 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a1cc10Variable Type 7
1901: I0814 09:40:37.734700 26923 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.734722 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.734748 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.734766 26923 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.734809 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.734835 26923 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 09:40:37.734884 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.734895 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.734913 26923 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.734920 26923 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a208f0Variable Type 7
1901: I0814 09:40:37.734935 26923 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.734949 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.734975 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.734990 26923 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.735026 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.735059 26923 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 09:40:37.735365 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.735396 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.736732 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.736759 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.736812 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.736822 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.738765 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.739339 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.739775 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.739790 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.739795 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.742031 26923 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 09:40:37.742105 26923 interpreter_util.cc:1169] Creating Variables
1901: I0814 09:40:37.742117 26923 scope.cc:202] Create variable MedianIndex
1901: I0814 09:40:37.742126 26923 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47a4efc0 type is 7
1901: I0814 09:40:37.742134 26923 scope.cc:202] Create variable Out
1901: I0814 09:40:37.742141 26923 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47a4e2f0 type is 7
1901: I0814 09:40:37.742146 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.742148 26923 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47a4ecf0 type is 7
1901: I0814 09:40:37.742153 26923 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47a17e40 type is 9
1901: I0814 09:40:37.742159 26923 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47a18c40 type is 10
1901: I0814 09:40:37.742234 26923 interpreter_util.cc:594] Static build: 0
1901: I0814 09:40:37.742241 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.742245 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.742250 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.742291 26923 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.742319 26923 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.742378 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.742388 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.742406 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.742939 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.742956 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.742978 26923 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.742986 26923 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a53460Variable Type 7
1901: I0814 09:40:37.743003 26923 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.743021 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.743043 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.743060 26923 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.743101 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.743124 26923 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 09:40:37.743170 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.743181 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.743198 26923 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.743206 26923 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a53480Variable Type 7
1901: I0814 09:40:37.743218 26923 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.743233 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.743252 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.743266 26923 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.743312 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.743335 26923 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 09:40:37.743597 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.743626 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.865252 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1abec6a0 for it.
1901: I0814 09:40:37.865715 26923 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:37.865787 26923 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.866436 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.866487 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.867775 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1abec6a0 for it.
1901: I0814 09:40:37.867930 26923 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.867990 26923 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:37.869231 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.869272 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.871840 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1abec6a0 for it.
1901: I0814 09:40:37.871995 26923 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:37.872045 26923 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0814 09:40:37.875423 26923 pir_interpreter.cc:161] PirInterpreter(): 0x47a28020 on Place(gpu:0)
1901: I0814 09:40:37.875461 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.875485 26923 scope.cc:202] Create variable 0x47a280201723628437875451051_inner_var_1
1901: I0814 09:40:37.875496 26923 scope.cc:202] Create variable 0x47a280201723628437875451051_inner_var_2
1901: I0814 09:40:37.875506 26923 scope.cc:202] Create variable 0x47a280201723628437875451051_inner_var_3
1901: I0814 09:40:37.875515 26923 scope.cc:202] Create variable 0x47a280201723628437875451051_inner_var_4
1901: I0814 09:40:37.875527 26923 scope.cc:202] Create variable fetch0@fetch
1901: I0814 09:40:37.875910 26923 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 09:40:37.875928 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.875931 26923 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47a58850
1901: 1 -> 0x47a280201723628437875451051_inner_var_1 -> 0x47a02c60
1901: 2 -> 0x47a280201723628437875451051_inner_var_2 -> 0x47a5a680
1901: 3 -> 0x47a280201723628437875451051_inner_var_3 -> 0x4580aa70
1901: 4 -> 0x47a280201723628437875451051_inner_var_4 -> 0x479fc170
1901: 5 -> fetch0@fetch -> 0x47a574b0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0814 09:40:37.876873 26968 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 09:40:37.876873 26969 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 09:40:37.876919 26970 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 09:40:37.876953 26967 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 09:40:37.877004 26971 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 09:40:37.877046 26972 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 09:40:37.877100 26972 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a280201723628437875451051_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.877156 26972 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a280201723628437875451051_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 09:40:37.877202 26972 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a280201723628437875451051_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a280201723628437875451051_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47a280201723628437875451051_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.877727 26972 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a280201723628437875451051_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a280201723628437875451051_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a280201723628437875451051_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:37.877806 26971 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a280201723628437875451051_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a280201723628437875451051_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.877847 26971 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.877918 26971 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a280201723628437875451051_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a280201723628437875451051_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:37.877954 26971 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a280201723628437875451051_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.877975 26971 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:37.877988 26971 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a280201723628437875451051_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:37.878024 26923 pir_interpreter.cc:1766] main_thread_blocker_(0x47a28190) got event_name: TaskCompletion
1901: I0814 09:40:37.878050 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:37.878858 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.879017 26923 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:37.879072 26923 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1abec6a0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0814 09:40:37.881779 26923 pir_interpreter.cc:161] PirInterpreter(): 0x1aeb8f30 on Place(gpu:0)
1901: I0814 09:40:37.881811 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.881832 26923 scope.cc:202] Create variable 0x1aeb8f301723628437881802850_inner_var_1
1901: I0814 09:40:37.881842 26923 scope.cc:202] Create variable 0x1aeb8f301723628437881802850_inner_var_2
1901: I0814 09:40:37.881850 26923 scope.cc:202] Create variable 0x1aeb8f301723628437881802850_inner_var_3
1901: I0814 09:40:37.881860 26923 scope.cc:202] Create variable 0x1aeb8f301723628437881802850_inner_var_4
1901: I0814 09:40:37.881868 26923 scope.cc:202] Create variable fetch0@fetch
1901: I0814 09:40:37.882187 26923 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 09:40:37.882200 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.882205 26923 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47a007e0
1901: 1 -> 0x1aeb8f301723628437881802850_inner_var_1 -> 0x47a254e0
1901: 2 -> 0x1aeb8f301723628437881802850_inner_var_2 -> 0x457ff8d0
1901: 3 -> 0x1aeb8f301723628437881802850_inner_var_3 -> 0x47a24410
1901: 4 -> 0x1aeb8f301723628437881802850_inner_var_4 -> 0x47a255f0
1901: 5 -> fetch0@fetch -> 0x47a30160
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0814 09:40:37.883013 26974 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 09:40:37.883026 26975 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 09:40:37.883100 26976 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 09:40:37.883220 26978 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 09:40:37.883231 26977 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 09:40:37.883262 26978 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1aeb8f301723628437881802850_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.883292 26978 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1aeb8f301723628437881802850_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 09:40:37.883327 26978 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x1aeb8f301723628437881802850_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1aeb8f301723628437881802850_inner_var_3:[dtype=;place=;dim=;lod={};, 0x1aeb8f301723628437881802850_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.883349 26973 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 09:40:37.883764 26978 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x1aeb8f301723628437881802850_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x1aeb8f301723628437881802850_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x1aeb8f301723628437881802850_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:37.883828 26977 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1aeb8f301723628437881802850_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x1aeb8f301723628437881802850_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.883852 26977 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.883900 26977 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x1aeb8f301723628437881802850_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x1aeb8f301723628437881802850_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:37.883927 26977 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x1aeb8f301723628437881802850_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.883944 26977 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:37.883955 26977 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x1aeb8f301723628437881802850_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:37.883984 26923 pir_interpreter.cc:1766] main_thread_blocker_(0x1aeb90a0) got event_name: TaskCompletion
1901: I0814 09:40:37.884006 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:37.885313 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1abec6a0 for it.
1901: I0814 09:40:37.885457 26923 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:37.885500 26923 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0814 09:40:37.887631 26923 pir_interpreter.cc:161] PirInterpreter(): 0x47a2e860 on Place(gpu:0)
1901: I0814 09:40:37.887658 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.887676 26923 scope.cc:202] Create variable 0x47a2e8601723628437887652534_inner_var_1
1901: I0814 09:40:37.887686 26923 scope.cc:202] Create variable 0x47a2e8601723628437887652534_inner_var_2
1901: I0814 09:40:37.887694 26923 scope.cc:202] Create variable 0x47a2e8601723628437887652534_inner_var_3
1901: I0814 09:40:37.887705 26923 scope.cc:202] Create variable 0x47a2e8601723628437887652534_inner_var_4
1901: I0814 09:40:37.887713 26923 scope.cc:202] Create variable fetch0@fetch
1901: I0814 09:40:37.887987 26923 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 09:40:37.888001 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.888005 26923 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47a27e90
1901: 1 -> 0x47a2e8601723628437887652534_inner_var_1 -> 0x47a27ef0
1901: 2 -> 0x47a2e8601723628437887652534_inner_var_2 -> 0x47a2efa0
1901: 3 -> 0x47a2e8601723628437887652534_inner_var_3 -> 0x47a29900
1901: 4 -> 0x47a2e8601723628437887652534_inner_var_4 -> 0x47a26ec0
1901: 5 -> fetch0@fetch -> 0x47a2a160
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0814 09:40:37.888690 26980 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 09:40:37.888759 26981 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 09:40:37.888816 26982 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 09:40:37.888931 26983 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 09:40:37.888944 26984 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 09:40:37.888984 26984 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a2e8601723628437887652534_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.889014 26984 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a2e8601723628437887652534_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0814 09:40:37.889048 26984 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a2e8601723628437887652534_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a2e8601723628437887652534_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47a2e8601723628437887652534_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.889349 26979 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0814 09:40:37.889474 26984 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a2e8601723628437887652534_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47a2e8601723628437887652534_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a2e8601723628437887652534_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:37.889536 26983 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a2e8601723628437887652534_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a2e8601723628437887652534_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.889556 26983 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.889600 26983 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a2e8601723628437887652534_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a2e8601723628437887652534_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:37.889626 26983 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a2e8601723628437887652534_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:37.889643 26983 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:37.889657 26983 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a2e8601723628437887652534_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:37.889688 26923 pir_interpreter.cc:1766] main_thread_blocker_(0x47a2e9d0) got event_name: TaskCompletion
1901: I0814 09:40:37.889703 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: E0814 09:40:37.889817 26923 pir.cc:2522] The op: pd_op.nanmedian does not implement InferSymbolicShapeInterface.
1901: I0814 09:40:37.891005 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.891027 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.891080 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.891090 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.892797 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.893257 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.893672 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.893685 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.893692 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.895591 26923 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 09:40:37.895658 26923 interpreter_util.cc:1169] Creating Variables
1901: I0814 09:40:37.895668 26923 scope.cc:202] Create variable MedianIndex
1901: I0814 09:40:37.895673 26923 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x47adad10 type is 7
1901: I0814 09:40:37.895679 26923 scope.cc:202] Create variable Out
1901: I0814 09:40:37.895691 26923 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x47ada530 type is 7
1901: I0814 09:40:37.895696 26923 scope.cc:202] Create variable X
1901: I0814 09:40:37.895700 26923 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47adaea0 type is 7
1901: I0814 09:40:37.895705 26923 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47a17e40 type is 9
1901: I0814 09:40:37.895710 26923 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47a18c40 type is 10
1901: I0814 09:40:37.895782 26923 interpreter_util.cc:594] Static build: 0
1901: I0814 09:40:37.895788 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:37.895792 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:37.895795 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:37.895843 26923 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.895856 26923 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.895918 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.895927 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.895944 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.896392 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.896407 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.896425 26923 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.896432 26923 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47adf330Variable Type 7
1901: I0814 09:40:37.896450 26923 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.896468 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.896490 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.896505 26923 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.896544 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.896569 26923 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 09:40:37.896620 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.896631 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:37.896644 26923 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:37.896651 26923 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47ae3240Variable Type 7
1901: I0814 09:40:37.896663 26923 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:37.896675 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.896692 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:37.896704 26923 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:37.896735 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:37.896760 26923 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 09:40:37.897063 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.897087 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:37.897539 26923 pybind.cc:1827] need skip: 0
1901: I0814 09:40:37.939517 26967 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 7893306207478841525 to 5503357962038009419 , after update, data is {current : -2, peak : 16}.
1901: I0814 09:40:37.939539 26967 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 7893306207478841525 to 5503357962038009419 , after update, data is {current : 0, peak : 330659}.
1901: I0814 09:40:37.939704 26971 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 5302905106477029857 to 5503357962038009419 , after update, data is {current : 2, peak : 16}.
1901: I0814 09:40:37.939901 26972 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 13257462756501487875 to 5503357962038009419 , after update, data is {current : 2, peak : 16}.
1901: I0814 09:40:37.939918 26972 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 13257462756501487875 to 5503357962038009419 , after update, data is {current : 18, peak : 330659}.
1901: I0814 09:40:37.940097 26973 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 13213330633931028468 to 5503357962038009419 , after update, data is {current : 0, peak : 16}.
1901: I0814 09:40:37.940106 26973 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 13213330633931028468 to 5503357962038009419 , after update, data is {current : 0, peak : 330659}.
1901: I0814 09:40:37.940255 26977 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 10255763187856473411 to 5503357962038009419 , after update, data is {current : 4, peak : 16}.
1901: I0814 09:40:37.940433 26978 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 1162648977247988027 to 5503357962038009419 , after update, data is {current : 4, peak : 16}.
1901: I0814 09:40:37.940443 26978 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 1162648977247988027 to 5503357962038009419 , after update, data is {current : 18, peak : 330659}.
1901: I0814 09:40:37.940589 26979 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 16035078360054203332 to 5503357962038009419 , after update, data is {current : 2, peak : 16}.
1901: I0814 09:40:37.940599 26979 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 16035078360054203332 to 5503357962038009419 , after update, data is {current : 0, peak : 330659}.
1901: I0814 09:40:37.940749 26983 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 5523180302185676660 to 5503357962038009419 , after update, data is {current : 6, peak : 16}.
1901: I0814 09:40:37.940922 26984 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 5503357962038009419 to 4427487881527490888 , after update, data is {current : 20006, peak : 40004}.
1901: I0814 09:40:37.940930 26984 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 5503357962038009419 to 4427487881527490888 , after update, data is {current : 180000, peak : 560633}.
1901: I0814 09:40:37.945490 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.945597 26923 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7ff44fc18e00), and remaining 0
1901: I0814 09:40:37.945699 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.945735 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.945974 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.946800 26923 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.946877 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.946903 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.947063 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.947751 26923 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.947821 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.947849 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.947996 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.948623 26923 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.948695 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.948720 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.948873 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0814 09:40:37.949584 26923 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.949637 26923 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7ff44fc19000), and remaining 0
1901: I0814 09:40:37.949688 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.949712 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.950170 26923 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.950234 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.950258 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.950718 26923 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.950781 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.950805 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.951215 26923 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.951278 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.951310 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.951869 26923 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.951936 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.951961 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.952145 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.952778 26923 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.952850 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.952874 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.953027 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.953706 26923 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.953775 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.953801 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.953984 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.954594 26923 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.954666 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.954692 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.954845 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.955502 26923 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.955575 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.955601 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.955793 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.956439 26923 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.956511 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.956537 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.956694 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.957399 26923 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.957473 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.957499 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.957656 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.958323 26923 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.958396 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.958421 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.958571 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.959264 26923 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.959342 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.959369 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.959544 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.960160 26923 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.960232 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.960258 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.960422 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.960937 26923 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.960999 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.961023 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.961169 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.961838 26923 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.961903 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.961928 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.962072 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.962723 26923 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.962792 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.962817 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.963053 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0814 09:40:37.964932 26923 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.965004 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.965031 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.965210 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.966567 26923 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.966640 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.966666 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.966867 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.968168 26923 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.968242 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.968268 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.968462 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.969676 26923 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.969749 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.969775 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.970008 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.971231 26923 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.971314 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.971340 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.971522 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.972805 26923 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.972877 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.972903 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.973078 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.974385 26923 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.974457 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.974483 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.974659 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.975867 26923 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.975942 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.975968 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.976190 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.977506 26923 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.977579 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.977605 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.977785 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.978992 26923 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.979065 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.979091 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.979295 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.980528 26923 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.980602 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.980628 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.980806 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.982092 26923 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.982165 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.982192 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.982375 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.983569 26923 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.983642 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.983668 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.983839 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.985109 26923 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.985183 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.985209 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.985392 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.986611 26923 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.986685 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.986711 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.986886 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.988085 26923 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.988158 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.988184 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.988368 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.989089 26923 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:37.989159 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:37.989184 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:37.989362 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:37.992077 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.992106 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.992931 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.992954 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.993714 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.993736 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.994513 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.994535 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.995276 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:37.995297 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:37.997756 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.998278 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.998806 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.999325 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:37.999835 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:38.000666 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:38.000684 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:38.000690 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:38.005513 26923 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 09:40:38.005591 26923 interpreter_util.cc:1169] Creating Variables
1901: I0814 09:40:38.005604 26923 scope.cc:202] Create variable X
1901: I0814 09:40:38.005611 26923 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47f83900 type is 7
1901: I0814 09:40:38.005626 26923 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47a17e40 type is 9
1901: I0814 09:40:38.005632 26923 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47a18c40 type is 10
1901: I0814 09:40:38.005637 26923 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0814 09:40:38.005648 26923 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x47f82ae0 type is 7
1901: I0814 09:40:38.005654 26923 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0814 09:40:38.005658 26923 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x47f836d0 type is 7
1901: I0814 09:40:38.005663 26923 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0814 09:40:38.005667 26923 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x47a0b5d0 type is 7
1901: I0814 09:40:38.005673 26923 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0814 09:40:38.005677 26923 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x47f82500 type is 7
1901: I0814 09:40:38.005682 26923 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0814 09:40:38.005687 26923 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x47f83a10 type is 7
1901: I0814 09:40:38.005693 26923 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0814 09:40:38.005697 26923 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x47f83bd0 type is 7
1901: I0814 09:40:38.005702 26923 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0814 09:40:38.005705 26923 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x47f83de0 type is 7
1901: I0814 09:40:38.005712 26923 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0814 09:40:38.005715 26923 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x47f84040 type is 7
1901: I0814 09:40:38.005720 26923 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0814 09:40:38.005724 26923 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x47f842a0 type is 7
1901: I0814 09:40:38.005729 26923 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0814 09:40:38.005735 26923 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x47f84500 type is 7
1901: I0814 09:40:38.005872 26923 interpreter_util.cc:594] Static build: 0
1901: I0814 09:40:38.005879 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:38.005883 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:38.005888 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:38.005957 26923 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.005975 26923 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.006050 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.006060 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.006078 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.006251 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.006454 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.006469 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.006486 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.006621 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.006811 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.006824 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.006840 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.006966 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.007149 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.007161 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.007179 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.007335 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.007545 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.007557 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.007575 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.007728 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.007925 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.007937 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.007956 26923 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.007964 26923 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47fd08d0Variable Type 7
1901: I0814 09:40:38.007985 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.008004 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.008028 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.008046 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.008088 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.008108 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 09:40:38.008153 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008164 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008181 26923 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.008188 26923 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47ee21c0Variable Type 7
1901: I0814 09:40:38.008203 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.008217 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.008234 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.008249 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.008282 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.008316 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 09:40:38.008366 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008378 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008394 26923 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.008400 26923 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47f10d70Variable Type 7
1901: I0814 09:40:38.008415 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.008430 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.008447 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.008460 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.008494 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.008508 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0814 09:40:38.008550 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008560 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008574 26923 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.008580 26923 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47a4c540Variable Type 7
1901: I0814 09:40:38.008594 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.008606 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.008623 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.008636 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.008668 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.008682 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0814 09:40:38.008718 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008729 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.008742 26923 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.008749 26923 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47ee3000Variable Type 7
1901: I0814 09:40:38.008764 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.008776 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.008792 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.008806 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.008837 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.008852 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0814 09:40:38.009472 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.009507 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.009529 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.009548 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.009568 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0814 09:40:38.015794 26923 pir_interpreter.cc:161] PirInterpreter(): 0x47a60770 on Place(gpu:0)
1901: I0814 09:40:38.015826 26923 scope.cc:202] Create variable X
1901: I0814 09:40:38.015849 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_1
1901: I0814 09:40:38.015861 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_2
1901: I0814 09:40:38.015869 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_3
1901: I0814 09:40:38.015880 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_4
1901: I0814 09:40:38.015888 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_5
1901: I0814 09:40:38.015900 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_6
1901: I0814 09:40:38.015908 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_7
1901: I0814 09:40:38.015920 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_8
1901: I0814 09:40:38.015928 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_9
1901: I0814 09:40:38.015938 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_10
1901: I0814 09:40:38.015946 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_11
1901: I0814 09:40:38.015957 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_12
1901: I0814 09:40:38.015966 26923 scope.cc:202] Create variable fetch0@fetch
1901: I0814 09:40:38.015981 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_14
1901: I0814 09:40:38.015991 26923 scope.cc:202] Create variable fetch1@fetch
1901: I0814 09:40:38.016000 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_16
1901: I0814 09:40:38.016009 26923 scope.cc:202] Create variable fetch2@fetch
1901: I0814 09:40:38.016017 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_18
1901: I0814 09:40:38.016026 26923 scope.cc:202] Create variable fetch3@fetch
1901: I0814 09:40:38.016034 26923 scope.cc:202] Create variable 0x47a607701723628438015818883_inner_var_20
1901: I0814 09:40:38.016043 26923 scope.cc:202] Create variable fetch4@fetch
1901: I0814 09:40:38.016350 26923 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0814 09:40:38.016366 26923 scope.cc:202] Create variable X
1901: I0814 09:40:38.016369 26923 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47f17f00
1901: 1 -> 0x47a607701723628438015818883_inner_var_1 -> 0x47fe4500
1901: 2 -> 0x47a607701723628438015818883_inner_var_2 -> 0x47ee4470
1901: 3 -> 0x47a607701723628438015818883_inner_var_3 -> 0x47f166b0
1901: 4 -> 0x47a607701723628438015818883_inner_var_4 -> 0x47fe4660
1901: 5 -> 0x47a607701723628438015818883_inner_var_5 -> 0x47ae2200
1901: 6 -> 0x47a607701723628438015818883_inner_var_6 -> 0x48003de0
1901: 7 -> 0x47a607701723628438015818883_inner_var_7 -> 0x47ee76b0
1901: 8 -> 0x47a607701723628438015818883_inner_var_8 -> 0x47f84270
1901: 9 -> 0x47a607701723628438015818883_inner_var_9 -> 0x47a4a7a0
1901: 10 -> 0x47a607701723628438015818883_inner_var_10 -> 0x47a4ab70
1901: 11 -> 0x47a607701723628438015818883_inner_var_11 -> 0x47f82ef0
1901: 12 -> 0x47a607701723628438015818883_inner_var_12 -> 0x47fe4680
1901: 13 -> fetch0@fetch -> 0x47f10810
1901: 14 -> 0x47a607701723628438015818883_inner_var_14 -> 0x47f83310
1901: 15 -> fetch1@fetch -> 0x47fe2a70
1901: 16 -> 0x47a607701723628438015818883_inner_var_16 -> 0x47f107f0
1901: 17 -> fetch2@fetch -> 0x48012240
1901: 18 -> 0x47a607701723628438015818883_inner_var_18 -> 0x47fe2a50
1901: 19 -> fetch3@fetch -> 0x47a39ed0
1901: 20 -> 0x47a607701723628438015818883_inner_var_20 -> 0x48012220
1901: 21 -> fetch4@fetch -> 0x47a46790
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0814 09:40:38.017843 26985 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 09:40:38.017884 26987 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 09:40:38.017910 26986 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 09:40:38.017953 26988 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 09:40:38.017966 26989 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 09:40:38.018008 26989 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.018050 26989 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0814 09:40:38.018093 26989 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47a607701723628438015818883_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.018260 26989 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.018415 26989 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a607701723628438015818883_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.018465 26989 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_5:[dtype=;place=;dim=;lod={};, 0x47a607701723628438015818883_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.018486 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.018518 26988 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.018599 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.018617 26989 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.018657 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.018678 26988 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.018690 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.018795 26989 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a607701723628438015818883_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.018838 26989 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_7:[dtype=;place=;dim=;lod={};, 0x47a607701723628438015818883_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.018846 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.018862 26988 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.018919 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.018980 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019002 26988 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.019008 26989 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.019011 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.019155 26989 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a607701723628438015818883_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.019196 26989 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_9:[dtype=;place=;dim=;lod={};, 0x47a607701723628438015818883_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019201 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019223 26988 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.019255 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.019321 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019337 26988 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.019346 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.019378 26989 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.019531 26989 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a607701723628438015818883_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.019573 26989 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_11:[dtype=;place=;dim=;lod={};, 0x47a607701723628438015818883_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019580 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019593 26988 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.019625 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.019668 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019685 26988 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.019693 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.019743 26989 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.019893 26989 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a607701723628438015818883_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47a607701723628438015818883_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.019939 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.019953 26988 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.019979 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a607701723628438015818883_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a607701723628438015818883_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.020013 26988 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.020027 26988 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.020038 26988 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a607701723628438015818883_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.020063 26923 pir_interpreter.cc:1766] main_thread_blocker_(0x47a608e0) got event_name: TaskCompletion
1901: I0814 09:40:38.020084 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.020109 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.020119 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.020128 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.020138 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.021601 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.021687 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.021714 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.021886 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.021987 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47ac76c0)  to GradNodeAccumulation (addr: 0x44b78ef0)
1901: I0814 09:40:38.022117 26923 backward.cc:459] Run in Grad
1901: I0814 09:40:38.022130 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.022186 26923 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47ac76c0 to ptr: 0x47ee64f0
1901: I0814 09:40:38.022197 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.022243 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.022275 26923 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x44b78ef0 to ptr: 0x47eaa260
1901: I0814 09:40:38.022320 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47ee64f0
1901: I0814 09:40:38.022329 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.022365 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.022429 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.022439 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47ee64f0, Found pending node: GradNodeAccumulation addr: 0x47eaa260
1901: I0814 09:40:38.022444 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.022470 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47eaa260
1901: I0814 09:40:38.022478 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.022483 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.022490 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.022495 26923 backward.cc:435] Finish Backward
1901: I0814 09:40:38.023221 26923 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0814 09:40:38.023237 26923 dygraph_functions.cc:77659] { Input: []} 
1901: I0814 09:40:38.023351 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.023375 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.023520 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.023595 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47ee64f0)  to GradNodeAccumulation (addr: 0x44b78ef0)
1901: I0814 09:40:38.023694 26923 backward.cc:442] Run in Backward
1901: I0814 09:40:38.023701 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.023708 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.023739 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.023766 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47ee64f0
1901: I0814 09:40:38.023775 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.023805 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.023864 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.023890 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47ee64f0, Found pending node: GradNodeAccumulation addr: 0x44b78ef0
1901: I0814 09:40:38.023898 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.023917 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x44b78ef0
1901: I0814 09:40:38.023926 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.023931 26923 accumulation_node.cc:40] Move Tensor ptr: 0x47efbd60
1901: I0814 09:40:38.023936 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.023941 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.026894 26923 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0814 09:40:38.027426 26923 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.027542 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.027568 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.027737 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47fce350)  to GradNodeAccumulation (addr: 0x1ac7c870)
1901: I0814 09:40:38.027837 26923 backward.cc:442] Run in Backward
1901: I0814 09:40:38.027845 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.027853 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.027884 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.027906 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47fce350
1901: I0814 09:40:38.027915 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.027943 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.027989 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.028013 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47fce350, Found pending node: GradNodeAccumulation addr: 0x1ac7c870
1901: I0814 09:40:38.028023 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.028039 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1ac7c870
1901: I0814 09:40:38.028046 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.028052 26923 accumulation_node.cc:40] Move Tensor ptr: 0x44b9cd00
1901: I0814 09:40:38.028055 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.028060 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.028807 26923 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.028888 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.028914 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.029125 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.029223 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47ee64f0)  to GradNodeAccumulation (addr: 0x1ac7c870)
1901: I0814 09:40:38.029350 26923 backward.cc:459] Run in Grad
1901: I0814 09:40:38.029361 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.029374 26923 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47ee64f0 to ptr: 0x47fcf410
1901: I0814 09:40:38.029383 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.029417 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.029441 26923 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1ac7c870 to ptr: 0x47eaa260
1901: I0814 09:40:38.029460 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47fcf410
1901: I0814 09:40:38.029467 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.029497 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.029633 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.029644 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47fcf410, Found pending node: GradNodeAccumulation addr: 0x47eaa260
1901: I0814 09:40:38.029649 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.029666 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47eaa260
1901: I0814 09:40:38.029673 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.029678 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.029683 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.029688 26923 backward.cc:435] Finish Backward
1901: I0814 09:40:38.030591 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.030670 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.030696 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.030855 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.032297 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.032366 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.032389 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.040690 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.040714 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.041730 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.041750 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.042649 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.042740 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.042770 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.042953 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.043637 26923 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.043720 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.043749 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.043924 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.044538 26923 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.044612 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.044641 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.044803 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.045385 26923 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.045461 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.045488 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.045656 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.046252 26923 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.046314 26923 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7ff44fc19400), and remaining 0
1901: I0814 09:40:38.046371 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.046398 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.046878 26923 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.046949 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.046976 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.047576 26923 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.047645 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.047669 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.048111 26923 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.048182 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.048207 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.048735 26923 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.048805 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.048832 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.049014 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.049592 26923 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.049667 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.049695 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.049860 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.050470 26923 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.050544 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.050571 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.050734 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.051363 26923 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.051445 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.051473 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.051641 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.052232 26923 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.052316 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.052345 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.052515 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.053090 26923 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.053166 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.053193 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.053377 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.053987 26923 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.054062 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.054090 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.054250 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.054849 26923 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.054925 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.054953 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.055117 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.055748 26923 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.055822 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.055850 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.056015 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.056593 26923 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.056669 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.056697 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.056867 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.057389 26923 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.057443 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.057463 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.057585 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.058173 26923 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.058238 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.058261 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.058419 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.059054 26923 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.059126 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.059154 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.059360 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.060027 26923 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.060096 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.060122 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.060289 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.060956 26923 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.061024 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.061049 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.061221 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.061858 26923 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.061928 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.061954 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.062122 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.062768 26923 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.062839 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.062863 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.063038 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.063656 26923 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.063726 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.063752 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.063923 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.064543 26923 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.064611 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.064637 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.064807 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.065444 26923 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.065513 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.065538 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.065711 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.066351 26923 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.066421 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.066447 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.066617 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.067225 26923 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.067294 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.067330 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.067500 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.068091 26923 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.068159 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.068184 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.068369 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.068969 26923 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.069037 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.069062 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.069233 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.069842 26923 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.069909 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.069934 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.070103 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.070710 26923 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.070780 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.070804 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.070969 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.071593 26923 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.071661 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.071686 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.071852 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.072532 26923 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.072609 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.072638 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.072822 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.073415 26923 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.073483 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.073508 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.073674 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.074406 26923 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.074482 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.074509 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.074698 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.076686 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.076709 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.077332 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.077350 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.077939 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.077957 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.078576 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.078594 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.079187 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.079205 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.080725 26988 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 5302905106477029857 to 13257462756501487875 , after update, data is {current : 0, peak : 1260}.
1901: I0814 09:40:38.080740 26988 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 5302905106477029857 to 13257462756501487875 , after update, data is {current : 20, peak : 24}.
1901: I0814 09:40:38.081110 26989 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 13257462756501487875 to 4427487881527490888 , after update, data is {current : 0, peak : 260}.
1901: I0814 09:40:38.081127 26989 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 13257462756501487875 to 4427487881527490888 , after update, data is {current : 20026, peak : 40004}.
1901: I0814 09:40:38.081132 26989 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 13257462756501487875 to 4427487881527490888 , after update, data is {current : 162560, peak : 560633}.
1901: I0814 09:40:38.082576 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:38.083002 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:38.083423 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:38.083833 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:38.084244 26923 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0814 09:40:38.085011 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:38.085026 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:38.085031 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:38.088985 26923 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0814 09:40:38.089033 26923 interpreter_util.cc:1169] Creating Variables
1901: I0814 09:40:38.089043 26923 scope.cc:202] Create variable X
1901: I0814 09:40:38.089049 26923 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x47ac9aa0 type is 7
1901: I0814 09:40:38.089058 26923 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x47a17e40 type is 9
1901: I0814 09:40:38.089064 26923 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x47a18c40 type is 10
1901: I0814 09:40:38.089071 26923 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0814 09:40:38.089073 26923 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x47fe7ec0 type is 7
1901: I0814 09:40:38.089078 26923 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0814 09:40:38.089082 26923 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x47fe7870 type is 7
1901: I0814 09:40:38.089085 26923 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0814 09:40:38.089089 26923 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x47ac9be0 type is 7
1901: I0814 09:40:38.089093 26923 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0814 09:40:38.089097 26923 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x47ac9cc0 type is 7
1901: I0814 09:40:38.089102 26923 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0814 09:40:38.089107 26923 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x47ac9ed0 type is 7
1901: I0814 09:40:38.089111 26923 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0814 09:40:38.089115 26923 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x47aca170 type is 7
1901: I0814 09:40:38.089119 26923 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0814 09:40:38.089124 26923 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x47aca380 type is 7
1901: I0814 09:40:38.089129 26923 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0814 09:40:38.089133 26923 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x47aca590 type is 7
1901: I0814 09:40:38.089136 26923 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0814 09:40:38.089140 26923 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x47aca7f0 type is 7
1901: I0814 09:40:38.089144 26923 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0814 09:40:38.089148 26923 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x47acaa50 type is 7
1901: I0814 09:40:38.089260 26923 interpreter_util.cc:594] Static build: 0
1901: I0814 09:40:38.089267 26923 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0814 09:40:38.089272 26923 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0814 09:40:38.089275 26923 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0814 09:40:38.089342 26923 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.089357 26923 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.089418 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.089426 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.089442 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.089596 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.089779 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.089790 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.089805 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.089915 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.090090 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.090099 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.090113 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.090215 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.090385 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.090396 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.090411 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.090536 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.090720 26923 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.090731 26923 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.090744 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.090864 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.091042 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091053 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091069 26923 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.091077 26923 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47ed79d0Variable Type 7
1901: I0814 09:40:38.091094 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.091111 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.091131 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.091146 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.091181 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.091198 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0814 09:40:38.091236 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091245 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091259 26923 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.091264 26923 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47ed8bb0Variable Type 7
1901: I0814 09:40:38.091276 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.091288 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.091311 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.091324 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.091356 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.091379 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0814 09:40:38.091419 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091427 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091440 26923 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.091447 26923 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47eabfd0Variable Type 7
1901: I0814 09:40:38.091461 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.091472 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.091486 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.091497 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.091526 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.091537 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0814 09:40:38.091573 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091581 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091593 26923 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.091599 26923 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x48007730Variable Type 7
1901: I0814 09:40:38.091612 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.091622 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.091635 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.091647 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.091674 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.091686 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0814 09:40:38.091717 26923 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091727 26923 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0814 09:40:38.091738 26923 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0814 09:40:38.091744 26923 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x48007ef0Variable Type 7
1901: I0814 09:40:38.091756 26923 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0814 09:40:38.091766 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.091778 26923 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0814 09:40:38.091790 26923 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.091816 26923 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0814 09:40:38.091827 26923 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0814 09:40:38.092365 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.092393 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.092411 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.092428 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0814 09:40:38.092444 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0814 09:40:38.098366 26923 pir_interpreter.cc:161] PirInterpreter(): 0x47a38190 on Place(gpu:0)
1901: I0814 09:40:38.098412 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_1
1901: I0814 09:40:38.098426 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_2
1901: I0814 09:40:38.098441 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_3
1901: I0814 09:40:38.098449 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_4
1901: I0814 09:40:38.098459 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_5
1901: I0814 09:40:38.098467 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_6
1901: I0814 09:40:38.098477 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_7
1901: I0814 09:40:38.098485 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_8
1901: I0814 09:40:38.098495 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_9
1901: I0814 09:40:38.098503 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_10
1901: I0814 09:40:38.098513 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_11
1901: I0814 09:40:38.098521 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_12
1901: I0814 09:40:38.098539 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_14
1901: I0814 09:40:38.098553 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_16
1901: I0814 09:40:38.098567 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_18
1901: I0814 09:40:38.098579 26923 scope.cc:202] Create variable 0x47a381901723628438098393739_inner_var_20
1901: I0814 09:40:38.098865 26923 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47a46aa0
1901: 1 -> 0x47a381901723628438098393739_inner_var_1 -> 0x47ee4df0
1901: 2 -> 0x47a381901723628438098393739_inner_var_2 -> 0x47eeac60
1901: 3 -> 0x47a381901723628438098393739_inner_var_3 -> 0x47ee4e50
1901: 4 -> 0x47a381901723628438098393739_inner_var_4 -> 0x47a29fb0
1901: 5 -> 0x47a381901723628438098393739_inner_var_5 -> 0x480033c0
1901: 6 -> 0x47a381901723628438098393739_inner_var_6 -> 0x47ed3bb0
1901: 7 -> 0x47a381901723628438098393739_inner_var_7 -> 0x47a32c50
1901: 8 -> 0x47a381901723628438098393739_inner_var_8 -> 0x480136e0
1901: 9 -> 0x47a381901723628438098393739_inner_var_9 -> 0x47eac9a0
1901: 10 -> 0x47a381901723628438098393739_inner_var_10 -> 0x47ae4560
1901: 11 -> 0x47a381901723628438098393739_inner_var_11 -> 0x47adf120
1901: 12 -> 0x47a381901723628438098393739_inner_var_12 -> 0x47f057d0
1901: 13 -> fetch0@fetch -> 0x47f10810
1901: 14 -> 0x47a381901723628438098393739_inner_var_14 -> 0x47a37f30
1901: 15 -> fetch1@fetch -> 0x47fe2a70
1901: 16 -> 0x47a381901723628438098393739_inner_var_16 -> 0x1adc93d0
1901: 17 -> fetch2@fetch -> 0x48012240
1901: 18 -> 0x47a381901723628438098393739_inner_var_18 -> 0x1ac937d0
1901: 19 -> fetch3@fetch -> 0x47a39ed0
1901: 20 -> 0x47a381901723628438098393739_inner_var_20 -> 0x1ac1d050
1901: 21 -> fetch4@fetch -> 0x47a46790
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0814 09:40:38.100399 26991 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0814 09:40:38.100395 26990 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0814 09:40:38.100437 26992 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0814 09:40:38.100479 26993 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0814 09:40:38.100504 26994 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0814 09:40:38.100533 26994 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.100570 26994 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0814 09:40:38.100610 26994 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47a381901723628438098393739_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.100791 26994 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.100947 26994 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47a381901723628438098393739_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.100996 26994 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_5:[dtype=;place=;dim=;lod={};, 0x47a381901723628438098393739_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.101034 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.101092 26993 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.101106 26994 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.101281 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101312 26994 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47a381901723628438098393739_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.101375 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101400 26993 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.101408 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101408 26994 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_7:[dtype=;place=;dim=;lod={};, 0x47a381901723628438098393739_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.101445 26992 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.101492 26992 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.101536 26994 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.101584 26992 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101691 26994 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47a381901723628438098393739_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.101745 26992 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101770 26992 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.101774 26994 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_9:[dtype=;place=;dim=;lod={};, 0x47a381901723628438098393739_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.101784 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.101778 26992 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101802 26993 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.101840 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101927 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101948 26993 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.101953 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.101980 26994 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.102134 26994 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47a381901723628438098393739_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.102177 26994 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_11:[dtype=;place=;dim=;lod={};, 0x47a381901723628438098393739_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.102185 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.102202 26993 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.102236 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.102286 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.102311 26993 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.102317 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.102384 26994 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.102537 26994 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47a381901723628438098393739_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x47a381901723628438098393739_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0814 09:40:38.102589 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0814 09:40:38.102608 26993 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0814 09:40:38.102634 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47a381901723628438098393739_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47a381901723628438098393739_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.102677 26993 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.102694 26993 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.102699 26993 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47a381901723628438098393739_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0814 09:40:38.102727 26923 pir_interpreter.cc:1766] main_thread_blocker_(0x47a38300) got event_name: TaskCompletion
1901: I0814 09:40:38.102751 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.102777 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.102787 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.102797 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.102807 26923 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0814 09:40:38.104295 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1ac7c870 for it.
1901: I0814 09:40:38.104400 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.104430 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.104614 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.104708 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47fce110)  to GradNodeAccumulation (addr: 0x1ac7c870)
1901: I0814 09:40:38.104825 26923 backward.cc:459] Run in Grad
1901: I0814 09:40:38.104837 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.104856 26923 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47fce110 to ptr: 0x47ee5000
1901: I0814 09:40:38.104866 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.104900 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.104928 26923 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1ac7c870 to ptr: 0x47ffb020
1901: I0814 09:40:38.104950 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47ee5000
1901: I0814 09:40:38.104959 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.104993 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.105057 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.105067 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47ee5000, Found pending node: GradNodeAccumulation addr: 0x47ffb020
1901: I0814 09:40:38.105072 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.105099 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47ffb020
1901: I0814 09:40:38.105108 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.105111 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.105116 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.105121 26923 backward.cc:435] Finish Backward
1901: I0814 09:40:38.105785 26923 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0814 09:40:38.105803 26923 dygraph_functions.cc:77659] { Input: []} 
1901: I0814 09:40:38.105887 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.105911 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.106051 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.106124 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47fce110)  to GradNodeAccumulation (addr: 0x1ac7c870)
1901: I0814 09:40:38.106207 26923 backward.cc:442] Run in Backward
1901: I0814 09:40:38.106215 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.106221 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.106251 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.106274 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47fce110
1901: I0814 09:40:38.106282 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.106323 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.106379 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.106407 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47fce110, Found pending node: GradNodeAccumulation addr: 0x1ac7c870
1901: I0814 09:40:38.106415 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.106434 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1ac7c870
1901: I0814 09:40:38.106441 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.106446 26923 accumulation_node.cc:40] Move Tensor ptr: 0x47efbd60
1901: I0814 09:40:38.106451 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.106454 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.106900 26923 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.107013 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.107038 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.107200 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47ee5000)  to GradNodeAccumulation (addr: 0x44b78ef0)
1901: I0814 09:40:38.107309 26923 backward.cc:442] Run in Backward
1901: I0814 09:40:38.107318 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.107326 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.107357 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.107380 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47ee5000
1901: I0814 09:40:38.107388 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.107415 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.107462 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.107487 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47ee5000, Found pending node: GradNodeAccumulation addr: 0x44b78ef0
1901: I0814 09:40:38.107496 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.107514 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x44b78ef0
1901: I0814 09:40:38.107522 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.107527 26923 accumulation_node.cc:40] Move Tensor ptr: 0x457d2090
1901: I0814 09:40:38.107530 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.107534 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.108237 26923 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.108328 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.108354 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.108537 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.108633 26923 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47ee5000)  to GradNodeAccumulation (addr: 0x44b78ef0)
1901: I0814 09:40:38.108748 26923 backward.cc:459] Run in Grad
1901: I0814 09:40:38.108758 26923 backward.cc:113] Start Backward
1901: I0814 09:40:38.108772 26923 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47ee5000 to ptr: 0x47fce110
1901: I0814 09:40:38.108780 26923 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0814 09:40:38.108809 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.108834 26923 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x44b78ef0 to ptr: 0x47ffb020
1901: I0814 09:40:38.108853 26923 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47fce110
1901: I0814 09:40:38.108861 26923 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0814 09:40:38.108891 26923 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.109009 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.109017 26923 backward.cc:335] Node: NanmedianGradNode addr:0x47fce110, Found pending node: GradNodeAccumulation addr: 0x47ffb020
1901: I0814 09:40:38.109023 26923 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0814 09:40:38.109040 26923 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x47ffb020
1901: I0814 09:40:38.109047 26923 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.109052 26923 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0814 09:40:38.109057 26923 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0814 09:40:38.109062 26923 backward.cc:435] Finish Backward
1901: I0814 09:40:38.109961 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.110038 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.110064 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.110224 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.111582 26923 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x44b78ef0 for it.
1901: I0814 09:40:38.111629 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.111647 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.113765 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.113792 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.114706 26923 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0814 09:40:38.114728 26923 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0814 09:40:38.115515 26923 dygraph_functions.cc:33459] Running AD API: full
1901: I0814 09:40:38.115532 26923 dygraph_functions.cc:33480] { Input: []} 
1901: I0814 09:40:38.115626 26923 dygraph_functions.cc:33459] Running AD API: full
1901: I0814 09:40:38.115634 26923 dygraph_functions.cc:33480] { Input: []} 
1901: I0814 09:40:38.115692 26923 dygraph_functions.cc:33459] Running AD API: full
1901: I0814 09:40:38.115700 26923 dygraph_functions.cc:33480] { Input: []} 
1901: I0814 09:40:38.115753 26923 dygraph_functions.cc:82227] Running AD API: arange
1901: I0814 09:40:38.115787 26923 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.115938 26923 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0814 09:40:38.115958 26923 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.115978 26923 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0814 09:40:38.116048 26923 dygraph_functions.cc:14224] Running AD API: cast
1901: I0814 09:40:38.116063 26923 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.116134 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.116194 26923 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0814 09:40:38.116210 26923 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0814 09:40:38.116415 26923 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0814 09:40:38.117697 26923 mmap_allocator.cc:348] PID: 26923, MemoryMapFdSet: set size - 0
1901: I0814 09:40:38.129489 26923 mmap_allocator.cc:348] PID: 26923, MemoryMapFdSet: set size - 0
1901: I0814 09:40:38.191910 26993 thread_data_registry.h:135] Add data {current : -16, peak : 0} from thread 9005339895796172907 to 4836739362280921674 , after update, data is {current : -20, peak : 0}.
1901: I0814 09:40:38.191941 26993 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 9005339895796172907 to 4836739362280921674 , after update, data is {current : 0, peak : 4}.
1901: I0814 09:40:38.191980 26992 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 4836739362280921674 to 3026594354929503193 , after update, data is {current : 0, peak : 1252}.
1901: I0814 09:40:38.192004 26992 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 4836739362280921674 to 3026594354929503193 , after update, data is {current : 0, peak : 16}.
1901: I0814 09:40:38.192221 26994 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 3026594354929503193 to 4427487881527490888 , after update, data is {current : 0, peak : 260}.
1901: I0814 09:40:38.192247 26994 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 3026594354929503193 to 4427487881527490888 , after update, data is {current : 20026, peak : 40004}.
1901: I0814 09:40:38.192255 26994 thread_data_registry.h:135] Add data {current : 0, peak : 1252} from thread 3026594354929503193 to 4427487881527490888 , after update, data is {current : 162560, peak : 560633}.
1901: I0814 09:40:38.326673 26923 mmap_allocator.cc:348] PID: 26923, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................   Passed   11.05 sec

The following tests passed:
	test_nanmedian

100% tests passed, 0 tests failed out of 1

Total Test time (real) =  11.22 sec
