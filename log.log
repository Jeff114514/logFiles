UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
UpdateCTestConfiguration  from :/home/code/Paddle/build/DartConfiguration.tcl
Test project /home/code/Paddle/build
Constructing a list of tests
Done constructing a list of tests
Updating test list for fixtures
Added 0 tests to meet fixture requirements
Checking test dependency graph...
Checking test dependency graph end
test 1901
    Start 1901: test_nanmedian

1901: Test command: /home/cmake-3.18.0-Linux-x86_64/bin/cmake "-E" "env" "PYTHONPATH=/home/code/Paddle/build/python" "/usr/bin/python" "/home/code/Paddle/tools/test_runner.py" "test_nanmedian"
1901: Environment variables: 
1901:  FLAGS_PIR_OPTEST_WHITE_LIST=True
1901: Test timeout computed to be: 10000000
1901: grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
1901: WARNING: Logging before InitGoogleLogging() is written to STDERR
1901: I0815 09:12:28.893108 19499 dynamic_loader.cc:176] Set paddle lib path : /usr/local/lib/python3.9/dist-packages/paddle/libs
1901: I0815 09:12:29.679008 19499 init.cc:100] Before Parse: argc is 2, Init commandline: dummy --tryfromenv=reader_queue_speed_test_mode,use_xqa_optim,enable_cublas_tensor_op_math,new_executor_use_cuda_graph,logging_trunc_pir_py_code,use_autotune,cinn_subgraph_graphviz_dir,conv2d_disable_cudnn,local_exe_sub_scope_limit,use_auto_growth_v2,nccl_dir,fraction_of_cuda_pinned_memory_to_use,op_dir,prim_skip_dynamic,free_idle_chunk,free_when_no_cache_hit,enable_dump_main_program,apply_pass_to_program,enable_gpu_memory_usage_log_mb,run_kp_kernel,dygraph_debug,eager_delete_scope,set_to_1d,pir_apply_shape_optimization_pass,save_static_runtime_data,enable_fusion_fallback,cupti_dir,enable_cinn_auto_tune,enable_auto_rdma_trans,accuracy_check_rtol_fp32,prim_check_ops,dist_threadpool_size,executor_log_deps_every_microseconds,graph_load_in_parallel,gpugraph_sparse_table_storage_mode,memory_fraction_of_eager_deletion,gpugraph_hbm_table_load_factor,enable_cinn_compile_cache,check_nan_inf,custom_device_mem_record,fleet_executor_with_standalone,sort_sum_gradient,search_cache_max_number,accuracy_check_atol_fp16,use_cinn,use_fast_math,curand_dir,pir_subgraph_saving_dir,enable_async_trace,cublas_dir,embedding_deterministic,static_runtime_data_save_path,dynamic_static_unified_comm,convert_all_blocks,gpugraph_merge_grads_segment_size,cusparse_dir,cinn_compile_thread_num,lapack_dir,gpugraph_enable_hbm_table_collision_stat,enable_pir_with_pt_in_dy2st,add_dependency_for_communication_op,initial_gpu_memory_in_mb,dataloader_use_file_descriptor,fraction_of_cpu_memory_to_use,graph_metapath_split_opt,check_nan_inf_level,enable_pir_api,gpugraph_enable_segment_merge_grads,prim_backward,cse_max_count,multiple_of_cupti_buffer_size,tracer_onednn_ops_off,init_allocated_mem,enable_cinn_accuracy_check,nccl_blocking_wait,enable_graph_multi_node_sampling,cuda_malloc_async_pool_memory_throttle_ratio,gpugraph_offload_gather_copy_maxsize,prim_enable_dynamic,cusolver_dir,cusparselt_dir,logging_pir_py_code_dir,accuracy_check_atol_fp32,sync_nccl_allreduce,use_cuda_malloc_async_allocator,fraction_of_gpu_memory_to_use,all_blocks_convert_trt,pir_apply_inplace_pass,inner_op_parallelism,new_executor_serial_run,print_ir,enable_interpretercore_launch_cinn,gpugraph_dedup_pull_push_mode,use_system_allocator,reallocate_gpu_memory_in_mb,gpu_memory_limit_mb,query_dest_rank_by_multi_node,enable_fuse_parallel_matmul_pass,enable_pir_in_executor,cudnn_batchnorm_spatial_persistent,gpugraph_offload_param_stat,new_executor_sequential_run,fuse_parameter_groups_size,use_cuda_managed_memory,enable_dependency_builder_debug_info,gemm_use_half_precision_compute_type,allow_cinn_ops,new_executor_use_local_scope,gpugraph_offload_param_extends,tracer_profile_fname,manually_trans_conv_filter,tracer_onednn_ops_on,graph_embedding_split_infer_mode,gpugraph_parallel_copyer_split_maxsize,log_memory_stats,call_stack_level,cudnn_exhaustive_search,new_executor_use_inplace,selected_gpus,graph_get_neighbor_id,fast_eager_deletion_mode,use_auto_growth_pinned_allocator,max_inplace_grad_add,tensor_operants_mode,get_host_by_name_time,prim_all,enable_tracker_all2all,accuracy_check_atol_bf16,enable_unused_var_check,use_virtual_memory_auto_growth,paddle_num_threads,fuse_parameter_memory_size,enable_pir_in_executor_trace_run,enable_all2all_use_fp16,jit_engine_type,auto_growth_chunk_size_in_mb,win_cuda_bin_dir,enable_exit_when_partial_worker,eager_delete_tensor_gb,cuda_dir,cublaslt_device_best_config,gpugraph_storage_mode,use_pinned_memory,print_sub_graph_dir,accuracy_check_rtol_bf16,mkl_dir,pinned_memory_as_cpu_backend,cudnn_dir,enable_collect_shape,enable_gpu_memory_usage_log,gpugraph_parallel_stream_num,tensorrt_dir,trt_ibuilder_cache,enable_record_memory,enable_opt_get_features,sync_after_alloc,logging_pir_py_code_dump_symbolic_dims,allocator_strategy,enable_adjust_op_order,prim_forward,static_executor_perfstat_filepath,enable_neighbor_list_use_uva,pir_debug,new_executor_static_build,gpugraph_slot_feasign_max_num,multi_node_sample_use_gpu_table,mklml_dir,allreduce_record_one_event,gpugraph_enable_print_op_debug,enable_sparse_inner_gather,gpu_allocator_retry_time,use_shm_cache,cudnn_deterministic,dump_chunk_info,low_precision_op_list,use_stream_safe_cuda_allocator,accuracy_check_rtol_fp16,print_allocator_trace_info,auto_free_cudagraph_allocations_on_launch,prim_forward_blacklist,cache_inference_while_scope,async_trace_count,gpugraph_force_device_batch_num_equal,cublaslt_exhaustive_search_times,disable_dyshape_in_train,host_trace_level,logging_pir_py_code_int_tensor_element_limit,gpugraph_enable_gpu_direct_access,gpugraph_load_node_list_into_hbm,ir_inplace_kernel_blacklist,benchmark_nccl,enable_api_kernel_fallback,pir_broadcast_tree_limit,deny_cinn_ops,use_mkldnn,prim_enabled,gpugraph_debug_gpu_memory,conv_workspace_size_limit,nvidia_package_dir,benchmark,check_infer_symbolic,use_stride_kernel,npu_storage_format,cudnn_exhaustive_search_times,alloc_fill_value,enable_blaslt_global_search,enable_cse_in_dy2st,einsum_opt,initial_cpu_memory_in_mb,graph_neighbor_size_percent,check_kernel_launch,enable_auto_detect_gpu_topo,cuda_memory_async_pool_realease_threshold 
1901: I0815 09:12:29.679117 19499 init.cc:108] After Parse: argc is 2
1901: I0815 09:12:36.745024 19499 scope.cc:202] Create variable X
1901: I0815 09:12:36.745100 19499 scope.cc:202] Create variable Out
1901: I0815 09:12:36.745116 19499 scope.cc:202] Create variable MedianIndex
1901: I0815 09:12:36.745263 19499 op_registry.cc:112] CreateOp directly from OpDesc is deprecated. It should only beused in unit tests. Use CreateOp(const OpDesc& op_desc) instead.
1901: I0815 09:12:36.745904 19499 allocator_facade.cc:212] selected allocator strategy:1
1901: I0815 09:12:36.746197 19499 dynamic_loader.cc:226] Try to find library: libcuda.so from default system path.
1901: I0815 09:12:39.161849 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.161907 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.162036 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.162046 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.163066 19499 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:12:39.163089 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.163130 19499 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:12:39.163137 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.163556 19499 pybind.cc:1827] need skip: 0
1901: I0815 09:12:39.163647 19499 pybind.cc:1827] need skip: 0
1901: I0815 09:12:39.164048 19499 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 09:12:39.164342 19499 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 09:12:39.164358 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:12:39.164438 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 09:12:39.164450 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:12:39.167410 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.168090 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.168107 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.168121 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.171150 19499 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:12:39.171166 19499 scope.cc:202] Create variable feed
1901: I0815 09:12:39.171237 19499 program_interpreter.cc:243] New Executor is Running.
1901: I0815 09:12:39.171245 19499 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:12:39.171255 19499 scope.cc:202] Create variable MedianIndex
1901: I0815 09:12:39.171267 19499 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x44d4bb80 type is 7
1901: I0815 09:12:39.171279 19499 scope.cc:202] Create variable Out
1901: I0815 09:12:39.171285 19499 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44d4c0f0 type is 7
1901: I0815 09:12:39.171290 19499 scope.cc:202] Create variable Out@GRAD
1901: I0815 09:12:39.171293 19499 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44d4c5a0 type is 7
1901: I0815 09:12:39.171298 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.171309 19499 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44d4ce80 type is 7
1901: I0815 09:12:39.171315 19499 scope.cc:202] Create variable X@GRAD
1901: I0815 09:12:39.171319 19499 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44d4d0f0 type is 7
1901: I0815 09:12:39.171324 19499 scope.cc:202] Create variable _generated_var_0
1901: I0815 09:12:39.171327 19499 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x44d4d330 type is 7
1901: I0815 09:12:39.171334 19499 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 09:12:39.171337 19499 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x44d4d590 type is 7
1901: I0815 09:12:39.171341 19499 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x44d4c4f0 type is 9
1901: I0815 09:12:39.171347 19499 scope.cc:202] Create variable fetch
1901: I0815 09:12:39.171350 19499 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x44d4d310 type is 10
1901: I0815 09:12:39.171468 19499 interpreter_util.cc:594] Static build: 0
1901: I0815 09:12:39.171474 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.171478 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.171483 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: W0815 09:12:39.172093 19499 gpu_resources.cc:119] Please NOTE: device: 0, GPU Compute Capability: 6.1, Driver API Version: 12.0, Runtime API Version: 12.0
1901: I0815 09:12:39.172334 19499 dynamic_loader.cc:226] Try to find library: libcudnn.so from default system path.
1901: W0815 09:12:39.173352 19499 gpu_resources.cc:164] device: 0, cuDNN Version: 8.8.
1901: I0815 09:12:39.173537 19499 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.173560 19499 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.173703 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.173713 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.173733 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.178063 19499 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178084 19499 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178100 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.178179 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.178260 19499 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178272 19499 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178330 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.178354 19499 interpreter_util.cc:647] Standalone Executor is Used.
1901: I0815 09:12:39.178376 19499 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178385 19499 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178402 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:12:39.178500 19499 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178510 19499 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178527 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:12:39.178640 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.178663 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.178685 19499 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.178694 19499 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44d28d10Variable Type 7
1901: I0815 09:12:39.178714 19499 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.178737 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.178762 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.178783 19499 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.178898 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.178932 19499 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:12:39.179514 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.179561 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.180572 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.180593 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.180635 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.180644 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.181253 19499 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:12:39.181269 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.181313 19499 op_desc.cc:1111] CompileTime infer shape on mean
1901: I0815 09:12:39.181320 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.181597 19499 pybind.cc:1827] need skip: 0
1901: I0815 09:12:39.181649 19499 pybind.cc:1827] need skip: 0
1901: I0815 09:12:39.181968 19499 op_desc.cc:1111] CompileTime infer shape on fill_constant
1901: I0815 09:12:39.182044 19499 op_desc.cc:1111] CompileTime infer shape on mean_grad
1901: I0815 09:12:39.182052 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:12:39.182121 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian_grad
1901: I0815 09:12:39.182129 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:12:39.184178 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.184672 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.184685 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.184690 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.188261 19499 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:12:39.188277 19499 scope.cc:202] Create variable feed
1901: I0815 09:12:39.188313 19499 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:12:39.188323 19499 scope.cc:202] Create variable MedianIndex
1901: I0815 09:12:39.188326 19499 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x448b8920 type is 7
1901: I0815 09:12:39.188333 19499 scope.cc:202] Create variable Out
1901: I0815 09:12:39.188338 19499 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x44d45eb0 type is 7
1901: I0815 09:12:39.188344 19499 scope.cc:202] Create variable Out@GRAD
1901: I0815 09:12:39.188346 19499 interpreter_util.cc:1206] Create Variable Out@GRAD locally, which pointer is 0x44d2d7b0 type is 7
1901: I0815 09:12:39.188351 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.188354 19499 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x44dc9aa0 type is 7
1901: I0815 09:12:39.188359 19499 scope.cc:202] Create variable X@GRAD
1901: I0815 09:12:39.188364 19499 interpreter_util.cc:1206] Create Variable X@GRAD locally, which pointer is 0x44dc9ba0 type is 7
1901: I0815 09:12:39.188369 19499 scope.cc:202] Create variable _generated_var_0
1901: I0815 09:12:39.188372 19499 interpreter_util.cc:1206] Create Variable _generated_var_0 locally, which pointer is 0x4489ca40 type is 7
1901: I0815 09:12:39.188377 19499 scope.cc:202] Create variable _generated_var_0@GRAD
1901: I0815 09:12:39.188380 19499 interpreter_util.cc:1206] Create Variable _generated_var_0@GRAD locally, which pointer is 0x4489ca80 type is 7
1901: I0815 09:12:39.188385 19499 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x4489c900 type is 9
1901: I0815 09:12:39.188390 19499 scope.cc:202] Create variable fetch
1901: I0815 09:12:39.188395 19499 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x4489ca20 type is 10
1901: I0815 09:12:39.188480 19499 interpreter_util.cc:594] Static build: 0
1901: I0815 09:12:39.188486 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.188491 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.188495 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.188537 19499 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.188550 19499 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.188596 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.188604 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.188620 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.189086 19499 operator.cc:2295] op type:mean, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189100 19499 interpreter_util.cc:844] mean : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189113 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.189162 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.189220 19499 operator.cc:2295] op type:fill_constant, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189230 19499 interpreter_util.cc:844] fill_constant : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189266 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.189297 19499 operator.cc:2295] op type:mean_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189314 19499 interpreter_util.cc:844] mean_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189330 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all_grad; inputs: X, Out@GRAD; attributes: ; outputs: X@GRAD
1901: I0815 09:12:39.189400 19499 operator.cc:2295] op type:nanmedian_grad, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189410 19499 interpreter_util.cc:844] nanmedian_grad : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189426 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian_grad; inputs: X, MedianIndex, Out@GRAD; attributes: axis, keepdim, mode; outputs: X@GRAD
1901: I0815 09:12:39.189525 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.189536 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.189550 19499 scope.cc:202] Create variable X@GRAD_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.189558 19499 data_transfer.cc:396] Create Variable X@GRAD_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x44dddd50Variable Type 7
1901: I0815 09:12:39.189572 19499 data_transfer.cc:439] Insert memcpy_d2h with X@GRAD(Place(gpu:0)) -> X@GRAD_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.189587 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.189605 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.189620 19499 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.189672 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.189694 19499 fetch_v2_op.cc:138] Fetch variable X@GRAD_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:12:39.190109 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: mean_all; inputs: X; attributes: ; outputs: Out
1901: I0815 09:12:39.190142 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.191717 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.191895 19499 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a14a7e0 for it.
1901: I0815 09:12:39.191943 19499 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.192806 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.192862 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.193392 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x44d1e0b0)  to GradNodeAccumulation (addr: 0x4392e660)
1901: I0815 09:12:39.193524 19499 dygraph_functions.cc:51757] Running AD API: mean
1901: I0815 09:12:39.193550 19499 dygraph_functions.cc:51814] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.193635 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.193657 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from MeanGradNode (addr: 0x44d2b1f0)  to NanmedianGradNode (addr: 0x44d1e0b0)
1901: I0815 09:12:39.193747 19499 backward.cc:442] Run in Backward
1901: I0815 09:12:39.193759 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.193784 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.193836 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.193868 19499 backward.cc:255] Preparing GradNode:MeanGradNode addr:0x44d2b1f0
1901: I0815 09:12:39.193883 19499 nodes.cc:25338] Running AD API GRAD: mean_grad
1901: I0815 09:12:39.193928 19499 nodes.cc:25394] { Input: [ 
1901: ( grad_out , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.193996 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.194020 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.194033 19499 backward.cc:335] Node: MeanGradNode addr:0x44d2b1f0, Found pending node: NanmedianGradNode addr: 0x44d1e0b0
1901: I0815 09:12:39.194041 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.194074 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x44d1e0b0
1901: I0815 09:12:39.194089 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.194115 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.194170 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.194195 19499 backward.cc:335] Node: NanmedianGradNode addr:0x44d1e0b0, Found pending node: GradNodeAccumulation addr: 0x4392e660
1901: I0815 09:12:39.194203 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.194221 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4392e660
1901: I0815 09:12:39.194233 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.194242 19499 accumulation_node.cc:40] Move Tensor ptr: 0x434e8a50
1901: I0815 09:12:39.194245 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.194252 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: /home/code/Paddle/build/python/paddle/base/framework.py:667: VisibleDeprecationWarning: [93m
1901: Warning:
1901: API "paddle.base.dygraph.tensor_patch_methods.gradient" is deprecated since 2.1.0, and will be removed in future versions.
1901:     Reason: Please use tensor.grad, which returns the tensor value of the gradient. [0m
1901:   return func(*args, **kwargs)
1901: I0815 09:12:39.203121 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.203279 19499 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.203336 19499 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a14a7e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.mean" (%1) {axis:(pd_op.IntArray)[],keepdim:false,stop_gradient:[false]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%4) = "pd_op.full" () {dtype:(pd_op.DataType)float32,place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> builtin.tensor<1xf32>
1901:     (%5) = "pd_op.full_like" (%3, %4) {dtype:(pd_op.DataType)float16,place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<1xf32>) -> builtin.tensor<f16>
1901:     (%6) = "pd_op.mean_grad" (%1, %5) {axis:(pd_op.IntArray)[],keepdim:false,reduce_all:false,stop_gradient:[false]} : (builtin.tensor<f16>, builtin.tensor<f16>) -> builtin.tensor<f16>
1901:     (%7) = "pd_op.nanmedian_grad" (%0, %2, %6) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[false]} : (builtin.tensor<100x100xf16>, builtin.tensor<2xi64>, builtin.tensor<f16>) -> builtin.tensor<100x100xf16>
1901:     (%8) = "pd_op.fetch" (%7) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[false]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<100x100xf16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: I0815 09:12:39.252688 19499 pir_interpreter.cc:161] PirInterpreter(): 0x47083db0 on Place(gpu:0)
1901: I0815 09:12:39.252734 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.252763 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_1
1901: I0815 09:12:39.252774 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_2
1901: I0815 09:12:39.252782 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_3
1901: I0815 09:12:39.252790 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_4
1901: I0815 09:12:39.252799 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_5
1901: I0815 09:12:39.252806 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_6
1901: I0815 09:12:39.252815 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_7
1901: I0815 09:12:39.252822 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_8
1901: I0815 09:12:39.252830 19499 scope.cc:202] Create variable 0x47083db01723713159252719107_inner_var_9
1901: I0815 09:12:39.252837 19499 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:12:39.253238 19499 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:12:39.253252 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.253257 19499 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: I0815 09:12:39.253311 19499 pir_interpreter.cc:1455] New Executor is Running ...
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[false]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[false,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "mean(phi_kernel)" (%2) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean",op_name:"pd_op.mean",stop_gradient:[false]} : (gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%5) = "full(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"full",op_name:"pd_op.full",place:(pd_op.Place)Place(cpu),shape:(pd_op.IntArray)[1],stop_gradient:[true],value:(Double)1} : () -> cpu_tensor<1xf32>
1901:     (%6) = "full_like(phi_kernel)" (%4, %5) {dtype:(pd_op.DataType)float16,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"full_like",op_name:"pd_op.full_like",place:(pd_op.Place)Place(undefined:0),stop_gradient:[false]} : (gpu_tensor<f16>, cpu_tensor<1xf32>) -> gpu_tensor<f16>
1901:     (%7) = "mean_grad(phi_kernel)" (%2, %6) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"mean_grad",op_name:"pd_op.mean_grad",reduce_all:false,stop_gradient:[false]} : (gpu_tensor<f16>, gpu_tensor<f16>) -> gpu_tensor<f16>
1901:     (%8) = "nanmedian_grad(phi_kernel)" (%1, %3, %7) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian_grad",mode:"avg",op_name:"pd_op.nanmedian_grad",stop_gradient:[false]} : (gpu_tensor<100x100xf16>, gpu_tensor<2xi64>, gpu_tensor<f16>) -> gpu_tensor<100x100xf16>
1901:     (%9) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901:     (%10) = "fetch(phi_kernel)" (%9) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[false]} : (cpu_tensor<100x100xf16>) -> cpu_tensor<100x100xf16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.mean ( 2 ) 
1901: 3: ( 5 )  = pd_op.full
1901: 4: ( 6 )  = pd_op.full_like ( 5 )  ( 4 ) 
1901: 5: ( 7 )  = pd_op.mean_grad ( 6 )  ( 2 ) 
1901: 6: ( 8 )  = pd_op.nanmedian_grad ( 7 )  ( 3 )  ( 1 ) 
1901: 7: ( 9 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 8: ( 10 )  = pd_op.fetch ( 9 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x47083d30
1901: 1 -> 0x47083db01723713159252719107_inner_var_1 -> 0x47083d90
1901: 2 -> 0x47083db01723713159252719107_inner_var_2 -> 0x47081870
1901: 3 -> 0x47083db01723713159252719107_inner_var_3 -> 0x470834a0
1901: 4 -> 0x47083db01723713159252719107_inner_var_4 -> 0x47082340
1901: 5 -> 0x47083db01723713159252719107_inner_var_5 -> 0x470845c0
1901: 6 -> 0x47083db01723713159252719107_inner_var_6 -> 0x470849e0
1901: 7 -> 0x47083db01723713159252719107_inner_var_7 -> 0x47084e00
1901: 8 -> 0x47083db01723713159252719107_inner_var_8 -> 0x47081240
1901: 9 -> 0x47083db01723713159252719107_inner_var_9 -> 0x47085220
1901: 10 -> fetch0@fetch -> 0x47085a30
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 4 
1901: 3 -> 4 
1901: 4 -> 5 
1901: 5 -> 6 
1901: 6 -> 7 
1901: 7 -> 8 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->3[pd_op.full]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.mean]->
1901: 2 downstreams: 
1901: 3 downstreams: 4[pd_op.full_like]->
1901: 4 downstreams: 5[pd_op.mean_grad]->
1901: 5 downstreams: 6[pd_op.nanmedian_grad]->
1901: 6 downstreams: 7[pd_op.memcpy_d2h]->
1901: 7 downstreams: 8[pd_op.fetch]->
1901: 8 downstreams: 
1901: I0815 09:12:39.254256 19499 pir_interpreter.cc:1481] pir interpreter is running by multi-thread mode ...
1901: I0815 09:12:39.254487 19536 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:12:39.254621 19537 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:12:39.254621 19538 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:12:39.254696 19539 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:12:39.254770 19540 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:12:39.254806 19541 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:12:39.254787 19539 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x47083db01723713159252719107_inner_var_5:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.254875 19541 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.254940 19541 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:12:39.254952 19539 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.full type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.full), inputs:{}, outputs:{0x47083db01723713159252719107_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};]}.
1901: I0815 09:12:39.254998 19541 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47083db01723713159252719107_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_3:[dtype=;place=;dim=;lod={};, 0x47083db01723713159252719107_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.255506 19541 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x47083db01723713159252719107_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x47083db01723713159252719107_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.255539 19541 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean), inputs:{0x47083db01723713159252719107_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.255594 19541 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.255610 19541 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.mean type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean), inputs:{0x47083db01723713159252719107_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.255636 19541 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.full_like), inputs:{0x47083db01723713159252719107_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x47083db01723713159252719107_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.255689 19541 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.255762 19541 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.full_like type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.full_like), inputs:{0x47083db01723713159252719107_inner_var_5:[dtype=float;place=Place(cpu);dim=1;lod={};], 0x47083db01723713159252719107_inner_var_4:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.255795 19541 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x47083db01723713159252719107_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47083db01723713159252719107_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_7:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.255868 19541 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.255884 19541 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.mean_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.mean_grad), inputs:{0x47083db01723713159252719107_inner_var_6:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47083db01723713159252719107_inner_var_2:[dtype=unknown_dtype;place=unknown_place;dim=;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.255908 19541 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x47083db01723713159252719107_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47083db01723713159252719107_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x47083db01723713159252719107_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.255988 19541 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.nanmedian_grad type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian_grad), inputs:{0x47083db01723713159252719107_inner_var_7:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};], 0x47083db01723713159252719107_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};], 0x47083db01723713159252719107_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:12:39.256067 19539 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47083db01723713159252719107_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_9:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.256100 19539 tensor_utils.cc:57] TensorCopy 100, 100 from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.256218 19539 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x47083db01723713159252719107_inner_var_8:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x47083db01723713159252719107_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 09:12:39.256254 19539 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x47083db01723713159252719107_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.256281 19539 tensor_utils.cc:57] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.256318 19539 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x47083db01723713159252719107_inner_var_9:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=100, 100;lod={};]}.
1901: I0815 09:12:39.256356 19499 pir_interpreter.cc:1766] main_thread_blocker_(0x47083f20) got event_name: TaskCompletion
1901: I0815 09:12:39.256387 19499 tensor_util.cc:48] TensorCopy 100, 100 from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.259562 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.259590 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.259657 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.259668 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.260861 19536 thread_data_registry.h:135] Add data {current : -20004, peak : 0} from thread 640426721361945317 to 8630640789550076609 , after update, data is {current : -20004, peak : 16}.
1901: I0815 09:12:39.260888 19536 thread_data_registry.h:135] Add data {current : -20024, peak : 0} from thread 640426721361945317 to 8630640789550076609 , after update, data is {current : 0, peak : 330659}.
1901: I0815 09:12:39.261073 19539 thread_data_registry.h:135] Add data {current : 40004, peak : 40004} from thread 17871418867372770050 to 8630640789550076609 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 09:12:39.261255 19541 thread_data_registry.h:135] Add data {current : 20000, peak : 40004} from thread 8630640789550076609 to 9866486909015717903 , after update, data is {current : 20000, peak : 40004}.
1901: I0815 09:12:39.261267 19541 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 8630640789550076609 to 9866486909015717903 , after update, data is {current : 120000, peak : 440631}.
1901: I0815 09:12:39.262648 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.263214 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.263705 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.263721 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.263727 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.266067 19499 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:12:39.266086 19499 scope.cc:202] Create variable feed
1901: I0815 09:12:39.266119 19499 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:12:39.266129 19499 scope.cc:202] Create variable MedianIndex
1901: I0815 09:12:39.266134 19499 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x470f7230 type is 7
1901: I0815 09:12:39.266145 19499 scope.cc:202] Create variable Out
1901: I0815 09:12:39.266149 19499 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x470f67c0 type is 7
1901: I0815 09:12:39.266157 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.266161 19499 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x470f71b0 type is 7
1901: I0815 09:12:39.266166 19499 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x470f67e0 type is 9
1901: I0815 09:12:39.266173 19499 scope.cc:202] Create variable fetch
1901: I0815 09:12:39.266180 19499 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x470f75e0 type is 10
1901: I0815 09:12:39.266254 19499 interpreter_util.cc:594] Static build: 0
1901: I0815 09:12:39.266261 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.266266 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.266271 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.266335 19499 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.266351 19499 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.266422 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.266433 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.266453 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.266949 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.266965 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.266985 19499 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.266993 19499 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x470fb680Variable Type 7
1901: I0815 09:12:39.267014 19499 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.267035 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.267059 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[::phi::dtype::float16]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.267078 19499 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.267125 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.267149 19499 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:12:39.267197 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.267207 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.267225 19499 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.267232 19499 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4709d200Variable Type 7
1901: I0815 09:12:39.267246 19499 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.267261 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.267280 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.267295 19499 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.267341 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.267371 19499 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:12:39.267663 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.267691 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.269003 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.269027 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.269078 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.269089 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.270979 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.271544 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.271983 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.271996 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.272001 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.274266 19499 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:12:39.274345 19499 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:12:39.274358 19499 scope.cc:202] Create variable MedianIndex
1901: I0815 09:12:39.274364 19499 interpreter_util.cc:1206] Create Variable MedianIndex locally, which pointer is 0x470cba40 type is 7
1901: I0815 09:12:39.274374 19499 scope.cc:202] Create variable Out
1901: I0815 09:12:39.274379 19499 interpreter_util.cc:1206] Create Variable Out locally, which pointer is 0x470cad70 type is 7
1901: I0815 09:12:39.274385 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.274389 19499 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x470cb770 type is 7
1901: I0815 09:12:39.274394 19499 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x470f67e0 type is 9
1901: I0815 09:12:39.274400 19499 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x470f75e0 type is 10
1901: I0815 09:12:39.274474 19499 interpreter_util.cc:594] Static build: 0
1901: I0815 09:12:39.274482 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.274488 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.274493 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.274533 19499 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.274549 19499 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.274605 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.274614 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.274633 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.275152 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.275169 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.275188 19499 scope.cc:202] Create variable Out_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.275195 19499 data_transfer.cc:396] Create Variable Out_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x470cfea0Variable Type 7
1901: I0815 09:12:39.275213 19499 data_transfer.cc:439] Insert memcpy_d2h with Out(Place(gpu:0)) -> Out_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.275231 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.275254 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.275272 19499 tensor_utils.cc:57] TensorCopy 1, 1 from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.275321 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.275344 19499 fetch_v2_op.cc:138] Fetch variable Out_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:12:39.275391 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.275401 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.275419 19499 scope.cc:202] Create variable MedianIndex_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.275426 19499 data_transfer.cc:396] Create Variable MedianIndex_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x470cfec0Variable Type 7
1901: I0815 09:12:39.275439 19499 data_transfer.cc:439] Insert memcpy_d2h with MedianIndex(Place(gpu:0)) -> MedianIndex_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.275454 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.275475 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[int64_t]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.275490 19499 tensor_utils.cc:57] TensorCopy 1, 1, 2 from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.275525 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.275547 19499 fetch_v2_op.cc:138] Fetch variable MedianIndex_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:12:39.275811 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.275839 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.379860 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a14a7e0 for it.
1901: I0815 09:12:39.380268 19499 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.380353 19499 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.380947 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.380995 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.382193 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a14a7e0 for it.
1901: I0815 09:12:39.382354 19499 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.382414 19499 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.383458 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.383494 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.385777 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a14a7e0 for it.
1901: I0815 09:12:39.385926 19499 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.385973 19499 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 09:12:39.389205 19499 pir_interpreter.cc:161] PirInterpreter(): 0x470f1ae0 on Place(gpu:0)
1901: I0815 09:12:39.389245 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.389266 19499 scope.cc:202] Create variable 0x470f1ae01723713159389233005_inner_var_1
1901: I0815 09:12:39.389279 19499 scope.cc:202] Create variable 0x470f1ae01723713159389233005_inner_var_2
1901: I0815 09:12:39.389289 19499 scope.cc:202] Create variable 0x470f1ae01723713159389233005_inner_var_3
1901: I0815 09:12:39.389308 19499 scope.cc:202] Create variable 0x470f1ae01723713159389233005_inner_var_4
1901: I0815 09:12:39.389320 19499 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:12:39.389701 19499 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:12:39.389717 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.389721 19499 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x44e9adc0
1901: 1 -> 0x470f1ae01723713159389233005_inner_var_1 -> 0x470a4460
1901: 2 -> 0x470f1ae01723713159389233005_inner_var_2 -> 0x44e02080
1901: 3 -> 0x470f1ae01723713159389233005_inner_var_3 -> 0x44dc9c40
1901: 4 -> 0x470f1ae01723713159389233005_inner_var_4 -> 0x470ff8d0
1901: 5 -> fetch0@fetch -> 0x470957b0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 09:12:39.390390 19543 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:12:39.390574 19544 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:12:39.390599 19545 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:12:39.390678 19546 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:12:39.390712 19547 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:12:39.390766 19548 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:12:39.390825 19548 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470f1ae01723713159389233005_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.390866 19548 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470f1ae01723713159389233005_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:12:39.390902 19548 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470f1ae01723713159389233005_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470f1ae01723713159389233005_inner_var_3:[dtype=;place=;dim=;lod={};, 0x470f1ae01723713159389233005_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.391335 19548 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470f1ae01723713159389233005_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470f1ae01723713159389233005_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x470f1ae01723713159389233005_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.391410 19547 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470f1ae01723713159389233005_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470f1ae01723713159389233005_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.391444 19547 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.391510 19547 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470f1ae01723713159389233005_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470f1ae01723713159389233005_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.391541 19547 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470f1ae01723713159389233005_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.391561 19547 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.391573 19547 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470f1ae01723713159389233005_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.391602 19499 pir_interpreter.cc:1766] main_thread_blocker_(0x470f1c50) got event_name: TaskCompletion
1901: I0815 09:12:39.391624 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.392133 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.392264 19499 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.392316 19499 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x1a14a7e0 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 09:12:39.394418 19499 pir_interpreter.cc:161] PirInterpreter(): 0x470b1600 on Place(gpu:0)
1901: I0815 09:12:39.394443 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.394459 19499 scope.cc:202] Create variable 0x470b16001723713159394437622_inner_var_1
1901: I0815 09:12:39.394469 19499 scope.cc:202] Create variable 0x470b16001723713159394437622_inner_var_2
1901: I0815 09:12:39.394475 19499 scope.cc:202] Create variable 0x470b16001723713159394437622_inner_var_3
1901: I0815 09:12:39.394484 19499 scope.cc:202] Create variable 0x470b16001723713159394437622_inner_var_4
1901: I0815 09:12:39.394491 19499 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:12:39.394750 19499 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:12:39.394763 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.394766 19499 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x44e9a590
1901: 1 -> 0x470b16001723713159394437622_inner_var_1 -> 0x470fbfd0
1901: 2 -> 0x470b16001723713159394437622_inner_var_2 -> 0x470cafd0
1901: 3 -> 0x470b16001723713159394437622_inner_var_3 -> 0x470a18f0
1901: 4 -> 0x470b16001723713159394437622_inner_var_4 -> 0x470fbff0
1901: 5 -> fetch0@fetch -> 0x470fa020
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 09:12:39.395291 19549 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:12:39.395493 19550 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:12:39.395556 19551 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:12:39.395601 19552 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:12:39.395654 19553 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:12:39.395713 19554 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:12:39.395748 19554 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470b16001723713159394437622_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.395769 19554 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470b16001723713159394437622_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:12:39.395793 19554 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470b16001723713159394437622_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470b16001723713159394437622_inner_var_3:[dtype=;place=;dim=;lod={};, 0x470b16001723713159394437622_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.396209 19554 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470b16001723713159394437622_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470b16001723713159394437622_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x470b16001723713159394437622_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.396296 19553 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470b16001723713159394437622_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470b16001723713159394437622_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.396342 19553 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.396401 19553 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470b16001723713159394437622_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470b16001723713159394437622_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.396432 19553 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470b16001723713159394437622_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.396450 19553 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.396462 19553 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470b16001723713159394437622_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.396492 19499 pir_interpreter.cc:1766] main_thread_blocker_(0x470b1770) got event_name: TaskCompletion
1901: I0815 09:12:39.396512 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.397567 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a14a7e0 for it.
1901: I0815 09:12:39.397699 19499 eager.cc:133] Tensor(Out_out_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.397740 19499 eager.cc:133] Tensor(MedianIndex_out_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float16,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> builtin.tensor<100x100xf16>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<100x100xf16>) -> builtin.tensor<f16>, builtin.tensor<2xi64>
1901:     (%3) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f16>) -> builtin.tensor<f16>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: I0815 09:12:39.399744 19499 pir_interpreter.cc:161] PirInterpreter(): 0x470a46a0 on Place(gpu:0)
1901: I0815 09:12:39.399768 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.399783 19499 scope.cc:202] Create variable 0x470a46a01723713159399764254_inner_var_1
1901: I0815 09:12:39.399793 19499 scope.cc:202] Create variable 0x470a46a01723713159399764254_inner_var_2
1901: I0815 09:12:39.399801 19499 scope.cc:202] Create variable 0x470a46a01723713159399764254_inner_var_3
1901: I0815 09:12:39.399809 19499 scope.cc:202] Create variable 0x470a46a01723713159399764254_inner_var_4
1901: I0815 09:12:39.399817 19499 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:12:39.400074 19499 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:12:39.400086 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.400089 19499 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float16,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[100,100],stop_gradient:[true]} : () -> undefined_tensor<100x100xf16>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<100x100xf16>) -> gpu_tensor<100x100xf16>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float16>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<100x100xf16>) -> gpu_tensor<f16>, gpu_tensor<2xi64>
1901:     (%4) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f16>) -> cpu_tensor<f16>
1901:     (%5) = "fetch(phi_kernel)" (%4) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float16>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f16>) -> cpu_tensor<f16>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 4 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 3: ( 5 )  = pd_op.fetch ( 4 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x470f9680
1901: 1 -> 0x470a46a01723713159399764254_inner_var_1 -> 0x470f9700
1901: 2 -> 0x470a46a01723713159399764254_inner_var_2 -> 0x470b3ad0
1901: 3 -> 0x470a46a01723713159399764254_inner_var_3 -> 0x470a1180
1901: 4 -> 0x470a46a01723713159399764254_inner_var_4 -> 0x471007f0
1901: 5 -> fetch0@fetch -> 0x470ae0a0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 
1901: 1 -> 2 
1901: 2 -> 3 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->
1901: 1 downstreams: 2[pd_op.memcpy_d2h]->
1901: 2 downstreams: 3[pd_op.fetch]->
1901: 3 downstreams: 
1901: I0815 09:12:39.400591 19555 nonblocking_threadpool.h:251] GarbageCollector_thread_0 started 
1901: I0815 09:12:39.400787 19556 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:12:39.400831 19557 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:12:39.400852 19558 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:12:39.400918 19559 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:12:39.400978 19560 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:12:39.401017 19560 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470a46a01723713159399764254_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.401042 19560 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470a46a01723713159399764254_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}.
1901: I0815 09:12:39.401070 19560 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470a46a01723713159399764254_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470a46a01723713159399764254_inner_var_3:[dtype=;place=;dim=;lod={};, 0x470a46a01723713159399764254_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.401484 19560 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470a46a01723713159399764254_inner_var_1:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=100, 100;lod={};]}, outputs:{0x470a46a01723713159399764254_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x470a46a01723713159399764254_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.401542 19559 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470a46a01723713159399764254_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470a46a01723713159399764254_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.401572 19559 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.401626 19559 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470a46a01723713159399764254_inner_var_2:[dtype=::phi::dtype::float16;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470a46a01723713159399764254_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.401656 19559 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470a46a01723713159399764254_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.401674 19559 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.401685 19559 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470a46a01723713159399764254_inner_var_4:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=::phi::dtype::float16;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.401711 19499 pir_interpreter.cc:1766] main_thread_blocker_(0x470a4810) got event_name: TaskCompletion
1901: I0815 09:12:39.401728 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.401868 19499 shape_analysis.cc:506] InferShapeOrDataForValue,  defining_op: pd_op.fetch id:48
1901: I0815 09:12:39.401974 19499 unary_infer_sym.cc:1363] NanmedianOpInferSymbolicShape
1901: I0815 09:12:39.444514 19543 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 8630640789550076609 to 17859259188556308552 , after update, data is {current : -2, peak : 16}.
1901: I0815 09:12:39.444525 19543 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 8630640789550076609 to 3720705441164540315 , after update, data is {current : -36, peak : 0}.
1901: I0815 09:12:39.444691 19547 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 17815795795921329121 to 17859259188556308552 , after update, data is {current : 2, peak : 16}.
1901: I0815 09:12:39.444885 19548 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 2541430147938225884 to 17859259188556308552 , after update, data is {current : 2, peak : 16}.
1901: I0815 09:12:39.444895 19548 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 2541430147938225884 to 3720705441164540315 , after update, data is {current : -18, peak : 330659}.
1901: I0815 09:12:39.445044 19549 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 14605276488273740011 to 17859259188556308552 , after update, data is {current : 0, peak : 16}.
1901: I0815 09:12:39.445051 19549 thread_data_registry.h:135] Add data {current : -18, peak : 0} from thread 14605276488273740011 to 3720705441164540315 , after update, data is {current : -36, peak : 330659}.
1901: I0815 09:12:39.445194 19553 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 13329470720233177685 to 17859259188556308552 , after update, data is {current : 4, peak : 16}.
1901: I0815 09:12:39.445367 19554 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 2907293719993254343 to 17859259188556308552 , after update, data is {current : 4, peak : 16}.
1901: I0815 09:12:39.445377 19554 thread_data_registry.h:135] Add data {current : 18, peak : 330659} from thread 2907293719993254343 to 3720705441164540315 , after update, data is {current : -18, peak : 330659}.
1901: I0815 09:12:39.445500 19555 thread_data_registry.h:135] Add data {current : -2, peak : 0} from thread 3720705441164540315 to 17859259188556308552 , after update, data is {current : 2, peak : 16}.
1901: I0815 09:12:39.445508 19555 thread_data_registry.h:135] Add data {current : -18, peak : 330659} from thread 3720705441164540315 to 17859259188556308552 , after update, data is {current : 0, peak : 330659}.
1901: I0815 09:12:39.445645 19559 thread_data_registry.h:135] Add data {current : 4, peak : 4} from thread 14945256808064946647 to 17859259188556308552 , after update, data is {current : 6, peak : 16}.
1901: I0815 09:12:39.445806 19560 thread_data_registry.h:135] Add data {current : 6, peak : 16} from thread 17859259188556308552 to 9866486909015717903 , after update, data is {current : 20006, peak : 40004}.
1901: I0815 09:12:39.445816 19560 thread_data_registry.h:135] Add data {current : 0, peak : 330659} from thread 17859259188556308552 to 9866486909015717903 , after update, data is {current : 200000, peak : 560633}.
1901: I0815 09:12:39.449931 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.450026 19499 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 512(0x7f36cc027c00), and remaining 0
1901: I0815 09:12:39.450114 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.450141 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.450382 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.451123 19499 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.451198 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.451223 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.451411 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.452075 19499 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.452143 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.452168 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.452328 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.452939 19499 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.453009 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.453033 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.453183 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:464: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data)
1901: I0815 09:12:39.453861 19499 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.453914 19499 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f36cc018e00), and remaining 0
1901: I0815 09:12:39.453963 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.453986 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.454447 19499 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.454512 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.454535 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.454979 19499 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.455041 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.455065 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.455473 19499 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.455536 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.455559 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.456104 19499 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.456175 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.456199 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.456382 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.457001 19499 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.457072 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.457095 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.457247 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.457913 19499 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.457983 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.458007 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.458187 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.458793 19499 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.458863 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.458889 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.459038 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.459702 19499 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.459771 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.459796 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.459985 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.460624 19499 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.460695 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.460721 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.460871 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.461576 19499 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.461647 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.461673 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.461838 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.462502 19499 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.462574 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.462599 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.462749 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.463445 19499 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.463514 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.463539 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.463717 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.464335 19499 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.464406 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.464430 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.464583 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.465095 19499 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.465157 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.465181 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.465333 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.465994 19499 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.466058 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.466082 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.466223 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.466861 19499 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.466926 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.466950 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.467192 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: /home/code/Paddle/build/test/legacy_test/test_nanmedian.py:478: RuntimeWarning: All-NaN slice encountered
1901:   np_res = np.nanmedian(data, axis)
1901: I0815 09:12:39.469120 19499 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.469190 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.469216 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.469404 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.470731 19499 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.470803 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.470829 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.471030 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.472332 19499 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.472404 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.472430 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.472608 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.473807 19499 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.473878 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.473904 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.474138 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.475353 19499 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.475422 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.475447 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.475623 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.476893 19499 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.476964 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.476990 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.477164 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.478462 19499 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.478533 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.478559 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.478734 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.479930 19499 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.480002 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.480027 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.480242 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.481544 19499 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.481616 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.481639 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.481817 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.483006 19499 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.483078 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.483101 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.483311 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.484511 19499 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.484583 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.484608 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.484786 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.486057 19499 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.486129 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.486155 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.486339 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.487526 19499 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.487597 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.487622 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.487793 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.489053 19499 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.489125 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.489148 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.489331 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.490528 19499 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.490600 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.490625 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.490797 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.491988 19499 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.492059 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.492084 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.492256 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.492970 19499 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.493039 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.493064 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.493232 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.495855 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.495883 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.496721 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.496743 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.497507 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.497529 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.498292 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.498324 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.499064 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.499085 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.501598 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.502127 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.502650 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.503162 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.503681 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.504518 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.504536 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.504544 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.509438 19499 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:12:39.509511 19499 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:12:39.509523 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.509529 19499 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x474a8420 type is 7
1901: I0815 09:12:39.509541 19499 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x470f67e0 type is 9
1901: I0815 09:12:39.509546 19499 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x470f75e0 type is 10
1901: I0815 09:12:39.509552 19499 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 09:12:39.509555 19499 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x470be240 type is 7
1901: I0815 09:12:39.509562 19499 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 09:12:39.509564 19499 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x474a82d0 type is 7
1901: I0815 09:12:39.509570 19499 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 09:12:39.509574 19499 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x44882480 type is 7
1901: I0815 09:12:39.509579 19499 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 09:12:39.509582 19499 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x470bdc30 type is 7
1901: I0815 09:12:39.509588 19499 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 09:12:39.509591 19499 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x474a84a0 type is 7
1901: I0815 09:12:39.509598 19499 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 09:12:39.509603 19499 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x474a8660 type is 7
1901: I0815 09:12:39.509608 19499 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 09:12:39.509613 19499 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x474a8870 type is 7
1901: I0815 09:12:39.509617 19499 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 09:12:39.509620 19499 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x474a8ad0 type is 7
1901: I0815 09:12:39.509625 19499 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 09:12:39.509629 19499 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x474a8d30 type is 7
1901: I0815 09:12:39.509634 19499 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 09:12:39.509639 19499 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x474a8f90 type is 7
1901: I0815 09:12:39.509776 19499 interpreter_util.cc:594] Static build: 0
1901: I0815 09:12:39.509784 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.509789 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.509793 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.509860 19499 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.509876 19499 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.509948 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.509958 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.509975 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.510151 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.510362 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.510376 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.510394 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.510526 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.510715 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.510727 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.510744 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.510869 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.511050 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.511062 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.511080 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.511222 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.511423 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.511436 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.511453 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.511601 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.511795 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.511807 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.511824 19499 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.511832 19499 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x4748f280Variable Type 7
1901: I0815 09:12:39.511853 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.511873 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.511898 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.511915 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.511958 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.511978 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:12:39.512023 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512034 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512050 19499 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.512058 19499 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474b3770Variable Type 7
1901: I0815 09:12:39.512071 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.512086 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.512105 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.512120 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.512153 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.512178 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:12:39.512224 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512234 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512249 19499 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.512256 19499 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x470f6690Variable Type 7
1901: I0815 09:12:39.512270 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.512284 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.512310 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.512326 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.512357 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.512369 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 09:12:39.512410 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512420 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512434 19499 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.512441 19499 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474b4680Variable Type 7
1901: I0815 09:12:39.512454 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.512467 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.512485 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.512499 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.512531 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.512544 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 09:12:39.512583 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512593 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.512607 19499 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.512614 19499 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474b6000Variable Type 7
1901: I0815 09:12:39.512629 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.512641 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.512657 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.512671 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.512702 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.512717 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 09:12:39.513331 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.513366 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.513386 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.513406 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.513424 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"avg",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<2xi64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 09:12:39.519522 19499 pir_interpreter.cc:161] PirInterpreter(): 0x474b58e0 on Place(gpu:0)
1901: I0815 09:12:39.519553 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.519572 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_1
1901: I0815 09:12:39.519584 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_2
1901: I0815 09:12:39.519595 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_3
1901: I0815 09:12:39.519608 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_4
1901: I0815 09:12:39.519618 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_5
1901: I0815 09:12:39.519625 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_6
1901: I0815 09:12:39.519635 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_7
1901: I0815 09:12:39.519644 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_8
1901: I0815 09:12:39.519652 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_9
1901: I0815 09:12:39.519660 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_10
1901: I0815 09:12:39.519670 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_11
1901: I0815 09:12:39.519680 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_12
1901: I0815 09:12:39.519690 19499 scope.cc:202] Create variable fetch0@fetch
1901: I0815 09:12:39.519704 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_14
1901: I0815 09:12:39.519714 19499 scope.cc:202] Create variable fetch1@fetch
1901: I0815 09:12:39.519723 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_16
1901: I0815 09:12:39.519733 19499 scope.cc:202] Create variable fetch2@fetch
1901: I0815 09:12:39.519740 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_18
1901: I0815 09:12:39.519750 19499 scope.cc:202] Create variable fetch3@fetch
1901: I0815 09:12:39.519758 19499 scope.cc:202] Create variable 0x474b58e01723713159519546008_inner_var_20
1901: I0815 09:12:39.519768 19499 scope.cc:202] Create variable fetch4@fetch
1901: I0815 09:12:39.520041 19499 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: I0815 09:12:39.520056 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.520059 19499 feed_fetch_method.cc:58] Reset X to phi::DenseTensor
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"avg",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<2xi64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x4748cb10
1901: 1 -> 0x474b58e01723713159519546008_inner_var_1 -> 0x474d5de0
1901: 2 -> 0x474b58e01723713159519546008_inner_var_2 -> 0x470bde60
1901: 3 -> 0x474b58e01723713159519546008_inner_var_3 -> 0x475d5800
1901: 4 -> 0x474b58e01723713159519546008_inner_var_4 -> 0x4748ca10
1901: 5 -> 0x474b58e01723713159519546008_inner_var_5 -> 0x474d5c80
1901: 6 -> 0x474b58e01723713159519546008_inner_var_6 -> 0x474cd880
1901: 7 -> 0x474b58e01723713159519546008_inner_var_7 -> 0x475aa600
1901: 8 -> 0x474b58e01723713159519546008_inner_var_8 -> 0x474b3e10
1901: 9 -> 0x474b58e01723713159519546008_inner_var_9 -> 0x475aad20
1901: 10 -> 0x474b58e01723713159519546008_inner_var_10 -> 0x474bf460
1901: 11 -> 0x474b58e01723713159519546008_inner_var_11 -> 0x475d9c80
1901: 12 -> 0x474b58e01723713159519546008_inner_var_12 -> 0x474d5e00
1901: 13 -> fetch0@fetch -> 0x47593c90
1901: 14 -> 0x474b58e01723713159519546008_inner_var_14 -> 0x474a7cc0
1901: 15 -> fetch1@fetch -> 0x470d8490
1901: 16 -> 0x474b58e01723713159519546008_inner_var_16 -> 0x47593c70
1901: 17 -> fetch2@fetch -> 0x475e5440
1901: 18 -> 0x474b58e01723713159519546008_inner_var_18 -> 0x470d8470
1901: 19 -> fetch3@fetch -> 0x47493880
1901: 20 -> 0x474b58e01723713159519546008_inner_var_20 -> 0x475e5420
1901: 21 -> fetch4@fetch -> 0x474704c0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 09:12:39.521512 19561 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:12:39.521606 19562 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:12:39.521620 19565 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:12:39.521669 19563 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:12:39.521687 19565 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.521724 19564 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:12:39.521749 19565 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 09:12:39.521809 19565 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_3:[dtype=;place=;dim=;lod={};, 0x474b58e01723713159519546008_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.522080 19565 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.522239 19565 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474b58e01723713159519546008_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.522294 19565 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_5:[dtype=;place=;dim=;lod={};, 0x474b58e01723713159519546008_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.522337 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.522379 19564 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.522425 19565 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.522471 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.522588 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.522611 19564 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.522611 19565 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474b58e01723713159519546008_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.522626 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.522658 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.522660 19565 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_7:[dtype=;place=;dim=;lod={};, 0x474b58e01723713159519546008_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.522675 19564 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.522732 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.522791 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.522809 19564 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.522819 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.522835 19565 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.522979 19565 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474b58e01723713159519546008_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.523020 19565 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_9:[dtype=;place=;dim=;lod={};, 0x474b58e01723713159519546008_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523028 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523043 19564 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.523079 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.523137 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523154 19564 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.523164 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.523192 19565 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.523345 19565 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474b58e01723713159519546008_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.523387 19565 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_11:[dtype=;place=;dim=;lod={};, 0x474b58e01723713159519546008_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523396 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523411 19564 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.523443 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.523509 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523525 19564 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.523537 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.523569 19565 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.523722 19565 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x474b58e01723713159519546008_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=2;lod={};, 0x474b58e01723713159519546008_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.523772 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523787 19564 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.523814 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x474b58e01723713159519546008_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x474b58e01723713159519546008_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.523847 19564 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.523862 19564 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.523872 19564 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x474b58e01723713159519546008_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.523900 19499 pir_interpreter.cc:1766] main_thread_blocker_(0x474b5a50) got event_name: TaskCompletion
1901: I0815 09:12:39.523924 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.523949 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.523960 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.523970 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.523981 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.525610 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.525699 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.525727 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.525913 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.526011 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47498b80)  to GradNodeAccumulation (addr: 0x4392e660)
1901: I0815 09:12:39.526136 19499 backward.cc:459] Run in Grad
1901: I0815 09:12:39.526153 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.526206 19499 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47498b80 to ptr: 0x470b7ac0
1901: I0815 09:12:39.526217 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.526261 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.526293 19499 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x4392e660 to ptr: 0x4746ff20
1901: I0815 09:12:39.526331 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x470b7ac0
1901: I0815 09:12:39.526340 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.526373 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.526435 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.526444 19499 backward.cc:335] Node: NanmedianGradNode addr:0x470b7ac0, Found pending node: GradNodeAccumulation addr: 0x4746ff20
1901: I0815 09:12:39.526449 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.526476 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4746ff20
1901: I0815 09:12:39.526484 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.526487 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.526494 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.526499 19499 backward.cc:435] Finish Backward
1901: I0815 09:12:39.527176 19499 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 09:12:39.527194 19499 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 09:12:39.527292 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.527325 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.527467 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.527539 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47498b80)  to GradNodeAccumulation (addr: 0x4392e660)
1901: I0815 09:12:39.527634 19499 backward.cc:442] Run in Backward
1901: I0815 09:12:39.527642 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.527648 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.527678 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.527704 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47498b80
1901: I0815 09:12:39.527711 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.527740 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.527791 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.527817 19499 backward.cc:335] Node: NanmedianGradNode addr:0x47498b80, Found pending node: GradNodeAccumulation addr: 0x4392e660
1901: I0815 09:12:39.527825 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.527842 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4392e660
1901: I0815 09:12:39.527849 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.527853 19499 accumulation_node.cc:40] Move Tensor ptr: 0x474a9d00
1901: I0815 09:12:39.527858 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.527861 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.529681 19499 layout_autotune.cc:83] The number of layout agnostic OPs: 523, heavily layout sensitive OPs: 39, lightly layout sensitive OPs: 135
1901: I0815 09:12:39.530196 19499 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.530320 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.530346 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.530514 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x1a0fa930)  to GradNodeAccumulation (addr: 0x1a105bd0)
1901: I0815 09:12:39.530615 19499 backward.cc:442] Run in Backward
1901: I0815 09:12:39.530623 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.530630 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.530663 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.530685 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x1a0fa930
1901: I0815 09:12:39.530694 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.530722 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.530771 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.530794 19499 backward.cc:335] Node: NanmedianGradNode addr:0x1a0fa930, Found pending node: GradNodeAccumulation addr: 0x1a105bd0
1901: I0815 09:12:39.530802 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.530819 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a105bd0
1901: I0815 09:12:39.530826 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.530830 19499 accumulation_node.cc:40] Move Tensor ptr: 0x44d0bd00
1901: I0815 09:12:39.530833 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.530838 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.531579 19499 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.531656 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.531682 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.531880 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.531973 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47498b80)  to GradNodeAccumulation (addr: 0x1a105bd0)
1901: I0815 09:12:39.532091 19499 backward.cc:459] Run in Grad
1901: I0815 09:12:39.532102 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.532115 19499 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47498b80 to ptr: 0x470bd020
1901: I0815 09:12:39.532123 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.532153 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.532177 19499 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1a105bd0 to ptr: 0x4746ff20
1901: I0815 09:12:39.532196 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x470bd020
1901: I0815 09:12:39.532203 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.532232 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.532368 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.532378 19499 backward.cc:335] Node: NanmedianGradNode addr:0x470bd020, Found pending node: GradNodeAccumulation addr: 0x4746ff20
1901: I0815 09:12:39.532384 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.532399 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4746ff20
1901: I0815 09:12:39.532407 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.532410 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.532415 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.532419 19499 backward.cc:435] Finish Backward
1901: I0815 09:12:39.533294 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.533380 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.533404 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.533562 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.534976 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.535032 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.535054 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.551321 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.551369 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.552539 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.552563 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.553583 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.553709 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.553746 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.553987 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.554615 19499 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.554697 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.554723 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.562430 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.563050 19499 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.563128 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.563158 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.563338 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.563937 19499 eager.cc:133] Tensor(generated_tensor_3) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.564013 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.564040 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.564211 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.564847 19499 eager.cc:133] Tensor(generated_tensor_4) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.564898 19499 auto_growth_best_fit_allocator.cc:159] Not found and reallocate 1024(0x7f36cc019200), and remaining 0
1901: I0815 09:12:39.564954 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.564980 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.565485 19499 eager.cc:133] Tensor(generated_tensor_5) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.565557 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.565583 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.566102 19499 eager.cc:133] Tensor(generated_tensor_6) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.566172 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.566198 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.572758 19499 eager.cc:133] Tensor(generated_tensor_7) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.572839 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.572868 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.573426 19499 eager.cc:133] Tensor(generated_tensor_8) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.573491 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.573514 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.573691 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.574254 19499 eager.cc:133] Tensor(generated_tensor_9) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.574339 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.574366 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.574539 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.575143 19499 eager.cc:133] Tensor(generated_tensor_10) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.575217 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.575245 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.575421 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.575999 19499 eager.cc:133] Tensor(generated_tensor_11) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.576073 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.576100 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.576270 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.580235 19499 eager.cc:133] Tensor(generated_tensor_12) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.580327 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.580356 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.580536 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.581117 19499 eager.cc:133] Tensor(generated_tensor_13) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.581194 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.581223 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.581408 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.582022 19499 eager.cc:133] Tensor(generated_tensor_14) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.582096 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.582124 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.582285 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.582898 19499 eager.cc:133] Tensor(generated_tensor_15) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.582975 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.583003 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.583168 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.590797 19499 eager.cc:133] Tensor(generated_tensor_16) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.590878 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.590906 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.591086 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.591671 19499 eager.cc:133] Tensor(generated_tensor_17) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.591749 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.591778 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.591950 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.592480 19499 eager.cc:133] Tensor(generated_tensor_18) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.592535 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.592556 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.592677 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.593281 19499 eager.cc:133] Tensor(generated_tensor_19) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.593355 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.593380 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.593528 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.594164 19499 eager.cc:133] Tensor(generated_tensor_20) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.594238 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.594265 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.599468 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.600200 19499 eager.cc:133] Tensor(generated_tensor_21) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.600271 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.600297 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.600541 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=2, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.601219 19499 eager.cc:133] Tensor(generated_tensor_22) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.601286 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.601323 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.601506 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.602146 19499 eager.cc:133] Tensor(generated_tensor_23) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.602216 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.602241 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.604473 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.605177 19499 eager.cc:133] Tensor(generated_tensor_24) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.605247 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.605273 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.605477 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.606101 19499 eager.cc:133] Tensor(generated_tensor_25) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.606168 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.606194 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.606377 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.606997 19499 eager.cc:133] Tensor(generated_tensor_26) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.607064 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.607089 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.607262 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.608207 19499 eager.cc:133] Tensor(generated_tensor_27) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.608279 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.608315 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.608492 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.609139 19499 eager.cc:133] Tensor(generated_tensor_28) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.609208 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.609233 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.609421 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.610036 19499 eager.cc:133] Tensor(generated_tensor_29) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.610105 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.610131 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.610313 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=12, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.610915 19499 eager.cc:133] Tensor(generated_tensor_30) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.610983 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.611009 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.611188 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.613654 19499 eager.cc:133] Tensor(generated_tensor_31) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.613727 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.613754 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.613931 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=10, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.614557 19499 eager.cc:133] Tensor(generated_tensor_32) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.614626 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.614651 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.614820 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.615437 19499 eager.cc:133] Tensor(generated_tensor_33) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.615506 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.615531 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.615696 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=30, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.617089 19499 eager.cc:133] Tensor(generated_tensor_34) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.617177 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.617201 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.617370 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.618031 19499 eager.cc:133] Tensor(generated_tensor_35) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.618103 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.618127 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.618309 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=60, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.618934 19499 eager.cc:133] Tensor(generated_tensor_36) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.619004 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.619028 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.619199 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.619933 19499 eager.cc:133] Tensor(generated_tensor_37) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.620011 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.620039 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.620242 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.622417 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.622440 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.623086 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.623104 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.623713 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.623731 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.624353 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.624372 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.624981 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.624998 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.626802 19564 thread_data_registry.h:135] Add data {current : -20, peak : 0} from thread 17815795795921329121 to 2541430147938225884 , after update, data is {current : 0, peak : 1260}.
1901: I0815 09:12:39.626814 19564 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 17815795795921329121 to 2541430147938225884 , after update, data is {current : 20, peak : 24}.
1901: I0815 09:12:39.627262 19565 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 2541430147938225884 to 9866486909015717903 , after update, data is {current : 0, peak : 260}.
1901: I0815 09:12:39.627278 19565 thread_data_registry.h:135] Add data {current : 20, peak : 24} from thread 2541430147938225884 to 9866486909015717903 , after update, data is {current : 20026, peak : 40004}.
1901: I0815 09:12:39.627285 19565 thread_data_registry.h:135] Add data {current : 0, peak : 1260} from thread 2541430147938225884 to 9866486909015717903 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 09:12:39.628871 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.629308 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.629724 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.630131 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.630548 19499 op_desc.cc:1111] CompileTime infer shape on fetch_v2
1901: I0815 09:12:39.631354 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.631371 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.631376 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.635455 19499 feed_fetch_method.cc:53] SetFeedVariable name=feed index=0
1901: I0815 09:12:39.635504 19499 interpreter_util.cc:1169] Creating Variables
1901: I0815 09:12:39.635516 19499 scope.cc:202] Create variable X
1901: I0815 09:12:39.635522 19499 interpreter_util.cc:1206] Create Variable X locally, which pointer is 0x475dc600 type is 7
1901: I0815 09:12:39.635530 19499 interpreter_util.cc:1201] Create Variable feed global, which pointer is 0x470f67e0 type is 9
1901: I0815 09:12:39.635537 19499 interpreter_util.cc:1201] Create Variable fetch global, which pointer is 0x470f75e0 type is 10
1901: I0815 09:12:39.635542 19499 scope.cc:202] Create variable nanmedian_0.tmp_0
1901: I0815 09:12:39.635545 19499 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_0 locally, which pointer is 0x474b2b90 type is 7
1901: I0815 09:12:39.635550 19499 scope.cc:202] Create variable nanmedian_0.tmp_1
1901: I0815 09:12:39.635555 19499 interpreter_util.cc:1206] Create Variable nanmedian_0.tmp_1 locally, which pointer is 0x475dc4b0 type is 7
1901: I0815 09:12:39.635560 19499 scope.cc:202] Create variable nanmedian_1.tmp_0
1901: I0815 09:12:39.635562 19499 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_0 locally, which pointer is 0x475dc780 type is 7
1901: I0815 09:12:39.635566 19499 scope.cc:202] Create variable nanmedian_1.tmp_1
1901: I0815 09:12:39.635571 19499 interpreter_util.cc:1206] Create Variable nanmedian_1.tmp_1 locally, which pointer is 0x475dc990 type is 7
1901: I0815 09:12:39.635574 19499 scope.cc:202] Create variable nanmedian_2.tmp_0
1901: I0815 09:12:39.635577 19499 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_0 locally, which pointer is 0x475dcbf0 type is 7
1901: I0815 09:12:39.635582 19499 scope.cc:202] Create variable nanmedian_2.tmp_1
1901: I0815 09:12:39.635586 19499 interpreter_util.cc:1206] Create Variable nanmedian_2.tmp_1 locally, which pointer is 0x475dce50 type is 7
1901: I0815 09:12:39.635591 19499 scope.cc:202] Create variable nanmedian_3.tmp_0
1901: I0815 09:12:39.635594 19499 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_0 locally, which pointer is 0x475dd060 type is 7
1901: I0815 09:12:39.635599 19499 scope.cc:202] Create variable nanmedian_3.tmp_1
1901: I0815 09:12:39.635602 19499 interpreter_util.cc:1206] Create Variable nanmedian_3.tmp_1 locally, which pointer is 0x475dd2c0 type is 7
1901: I0815 09:12:39.635607 19499 scope.cc:202] Create variable nanmedian_4.tmp_0
1901: I0815 09:12:39.635610 19499 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_0 locally, which pointer is 0x475dd520 type is 7
1901: I0815 09:12:39.635615 19499 scope.cc:202] Create variable nanmedian_4.tmp_1
1901: I0815 09:12:39.635618 19499 interpreter_util.cc:1206] Create Variable nanmedian_4.tmp_1 locally, which pointer is 0x475dd780 type is 7
1901: I0815 09:12:39.635742 19499 interpreter_util.cc:594] Static build: 0
1901: I0815 09:12:39.635748 19499 conditional_block_op_helper.cc:105] Found conditional_block op num: 0, conditional_block_grad op num: 0
1901: I0815 09:12:39.635752 19499 pylayer_op_helper.cc:103] Found pylayer op num: 0, pylayer_grad op num: 0
1901: I0815 09:12:39.635756 19499 while_op_helper.cc:154] Found while op num: 0, while grad op num: 0
1901: I0815 09:12:39.635818 19499 operator.cc:2295] op type:feed, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.635833 19499 interpreter_util.cc:844] feed : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.635895 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.635903 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.635918 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.636068 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.636251 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.636261 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.636277 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.636396 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.636574 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.636584 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.636600 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.636708 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.636876 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.636885 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.636900 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.637022 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.637207 19499 operator.cc:2295] op type:nanmedian, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.637217 19499 interpreter_util.cc:844] nanmedian : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.637230 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.637359 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.637537 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.637547 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.637562 19499 scope.cc:202] Create variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.637569 19499 data_transfer.cc:396] Create Variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47592b50Variable Type 7
1901: I0815 09:12:39.637588 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_0.tmp_0(Place(gpu:0)) -> nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.637604 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.637627 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.637642 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.637677 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.637693 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_0.tmp_0_device_Place(gpu:0)_Place(cpu)'s 0 column.
1901: I0815 09:12:39.637730 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.637738 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.637753 19499 scope.cc:202] Create variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.637758 19499 data_transfer.cc:396] Create Variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x470ea680Variable Type 7
1901: I0815 09:12:39.637771 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_1.tmp_0(Place(gpu:0)) -> nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.637784 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.637797 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.637809 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.637838 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.637863 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_1.tmp_0_device_Place(gpu:0)_Place(cpu)'s 1 column.
1901: I0815 09:12:39.637902 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.637910 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.637923 19499 scope.cc:202] Create variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.637930 19499 data_transfer.cc:396] Create Variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x475b02b0Variable Type 7
1901: I0815 09:12:39.637941 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_2.tmp_0(Place(gpu:0)) -> nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.637952 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.637966 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.637977 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.638003 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.638015 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_2.tmp_0_device_Place(gpu:0)_Place(cpu)'s 2 column.
1901: I0815 09:12:39.638047 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.638056 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.638067 19499 scope.cc:202] Create variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.638072 19499 data_transfer.cc:396] Create Variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x47592a30Variable Type 7
1901: I0815 09:12:39.638084 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_3.tmp_0(Place(gpu:0)) -> nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.638095 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.638108 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.638118 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.638144 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.638156 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_3.tmp_0_device_Place(gpu:0)_Place(cpu)'s 3 column.
1901: I0815 09:12:39.638186 19499 operator.cc:2295] op type:fetch_v2, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.638195 19499 interpreter_util.cc:844] fetch_v2 : finally selected kernel_key: {data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(cpu)]; library_type[PLAIN]}
1901: I0815 09:12:39.638206 19499 scope.cc:202] Create variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)
1901: I0815 09:12:39.638212 19499 data_transfer.cc:396] Create Variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu) locally, which pointer is 0x474df000Variable Type 7
1901: I0815 09:12:39.638224 19499 data_transfer.cc:439] Insert memcpy_d2h with nanmedian_4.tmp_0(Place(gpu:0)) -> nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)(Place(cpu)).
1901: I0815 09:12:39.638235 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.638247 19499 operator.cc:2295] op type:memcpy_d2h, expected_kernel_key:{data_type[float]; data_layout[Undefined(AnyLayout)]; place[Place(gpu:0)]; library_type[PLAIN]}
1901: I0815 09:12:39.638258 19499 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.638285 19499 data_transfer.cc:232] Run memcpy_d2h done.
1901: I0815 09:12:39.638296 19499 fetch_v2_op.cc:138] Fetch variable nanmedian_4.tmp_0_device_Place(gpu:0)_Place(cpu)'s 4 column.
1901: I0815 09:12:39.638872 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.638900 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.638917 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.638933 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: I0815 09:12:39.638950 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: memcpy_d2h; inputs: X; attributes: dst_place_type; outputs: Out
1901: IR before lowering = {
1901:     (%0) = "pd_op.data" () {dtype:(pd_op.DataType)float32,name:"X",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> builtin.tensor<2x3x4x5xf32>
1901:     (%1, %2) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%3, %4) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%5, %6) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%7, %8) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%9, %10) = "pd_op.nanmedian" (%0) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,mode:"min",stop_gradient:[true,true]} : (builtin.tensor<2x3x4x5xf32>) -> builtin.tensor<f32>, builtin.tensor<i64>
1901:     (%11) = "pd_op.fetch" (%1) {col:(Int32)0,name:"fetch0",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%12) = "pd_op.fetch" (%3) {col:(Int32)1,name:"fetch1",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%13) = "pd_op.fetch" (%5) {col:(Int32)2,name:"fetch2",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%14) = "pd_op.fetch" (%7) {col:(Int32)3,name:"fetch3",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901:     (%15) = "pd_op.fetch" (%9) {col:(Int32)4,name:"fetch4",persistable:[true],stop_gradient:[true]} : (builtin.tensor<f32>) -> builtin.tensor<f32>
1901: }
1901: 
1901: IR after lowering = {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: I0815 09:12:39.644616 19499 pir_interpreter.cc:161] PirInterpreter(): 0x470acbc0 on Place(gpu:0)
1901: I0815 09:12:39.644657 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_1
1901: I0815 09:12:39.644668 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_2
1901: I0815 09:12:39.644675 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_3
1901: I0815 09:12:39.644683 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_4
1901: I0815 09:12:39.644690 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_5
1901: I0815 09:12:39.644697 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_6
1901: I0815 09:12:39.644706 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_7
1901: I0815 09:12:39.644713 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_8
1901: I0815 09:12:39.644721 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_9
1901: I0815 09:12:39.644727 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_10
1901: I0815 09:12:39.644734 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_11
1901: I0815 09:12:39.644743 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_12
1901: I0815 09:12:39.644757 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_14
1901: I0815 09:12:39.644768 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_16
1901: I0815 09:12:39.644780 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_18
1901: I0815 09:12:39.644791 19499 scope.cc:202] Create variable 0x470acbc01723713159644639942_inner_var_20
1901: I0815 09:12:39.645053 19499 feed_fetch_method.cc:53] SetFeedVariable name=X index=0
1901: ======================== The network executed by pir interpreter ========================
1901: {
1901:     (%0) = "data(phi_kernel)" () {dtype:(pd_op.DataType)float32,kernel_key:<backend:Undefined|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"data",name:"X",op_name:"pd_op.data",place:(pd_op.Place)Place(undefined:0),shape:(pd_op.IntArray)[2,3,4,5],stop_gradient:[true]} : () -> undefined_tensor<2x3x4x5xf32>
1901:     (%1) = "shadow_feed(phi_kernel)" (%0) {kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"shadow_feed",op_name:"pd_op.shadow_feed"} : (undefined_tensor<2x3x4x5xf32>) -> gpu_tensor<2x3x4x5xf32>
1901:     (%2, %3) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%4, %5) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%6, %7) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%8, %9) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%10, %11) = "nanmedian(phi_kernel)" (%1) {axis:(pd_op.IntArray)[0,1,2,3],keepdim:false,kernel_key:<backend:GPU|layout:NCHW|dtype:float32>,kernel_name:"nanmedian",mode:"min",op_name:"pd_op.nanmedian",stop_gradient:[true,true]} : (gpu_tensor<2x3x4x5xf32>) -> gpu_tensor<f32>, gpu_tensor<i64>
1901:     (%12) = "memcpy_d2h(phi_kernel)" (%2) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%13) = "fetch(phi_kernel)" (%12) {col:(Int32)0,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch0",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%14) = "memcpy_d2h(phi_kernel)" (%4) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%15) = "fetch(phi_kernel)" (%14) {col:(Int32)1,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch1",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%16) = "memcpy_d2h(phi_kernel)" (%6) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%17) = "fetch(phi_kernel)" (%16) {col:(Int32)2,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch2",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%18) = "memcpy_d2h(phi_kernel)" (%8) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%19) = "fetch(phi_kernel)" (%18) {col:(Int32)3,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch3",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%20) = "memcpy_d2h(phi_kernel)" (%10) {dst_place_type:(Int32)0,kernel_key:<backend:GPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"memcpy_d2h",op_name:"pd_op.memcpy_d2h"} : (gpu_tensor<f32>) -> cpu_tensor<f32>
1901:     (%21) = "fetch(phi_kernel)" (%20) {col:(Int32)4,kernel_key:<backend:CPU|layout:Undefined(AnyLayout)|dtype:float32>,kernel_name:"fetch",name:"fetch4",op_name:"pd_op.fetch",persistable:[true],stop_gradient:[true]} : (cpu_tensor<f32>) -> cpu_tensor<f32>
1901: }
1901: 
1901: ======================== The instruction executed by pir interpreter ========================
1901: {outputs} =  instruction_name[idx] ({inputs})
1901: 0: ( 1 )  = pd_op.shadow_feed ( 0 ) 
1901: 1: ( 3 ) ( 2 )  = pd_op.nanmedian ( 1 ) 
1901: 2: ( 5 ) ( 4 )  = pd_op.nanmedian ( 1 ) 
1901: 3: ( 7 ) ( 6 )  = pd_op.nanmedian ( 1 ) 
1901: 4: ( 9 ) ( 8 )  = pd_op.nanmedian ( 1 ) 
1901: 5: ( 11 ) ( 10 )  = pd_op.nanmedian ( 1 ) 
1901: 6: ( 12 )  = pd_op.memcpy_d2h ( 2 ) 
1901: 7: ( 13 )  = pd_op.fetch ( 12 ) 
1901: 8: ( 14 )  = pd_op.memcpy_d2h ( 4 ) 
1901: 9: ( 15 )  = pd_op.fetch ( 14 ) 
1901: 10: ( 16 )  = pd_op.memcpy_d2h ( 6 ) 
1901: 11: ( 17 )  = pd_op.fetch ( 16 ) 
1901: 12: ( 18 )  = pd_op.memcpy_d2h ( 8 ) 
1901: 13: ( 19 )  = pd_op.fetch ( 18 ) 
1901: 14: ( 20 )  = pd_op.memcpy_d2h ( 10 ) 
1901: 15: ( 21 )  = pd_op.fetch ( 20 ) 
1901: ---------------------------var_id -> var_name -> variable*---------------------------
1901: 0 -> X -> 0x474707f0
1901: 1 -> 0x470acbc01723713159644639942_inner_var_1 -> 0x4746be50
1901: 2 -> 0x470acbc01723713159644639942_inner_var_2 -> 0x47542660
1901: 3 -> 0x470acbc01723713159644639942_inner_var_3 -> 0x47548950
1901: 4 -> 0x470acbc01723713159644639942_inner_var_4 -> 0x4708e940
1901: 5 -> 0x470acbc01723713159644639942_inner_var_5 -> 0x475d1800
1901: 6 -> 0x470acbc01723713159644639942_inner_var_6 -> 0x4746bfc0
1901: 7 -> 0x470acbc01723713159644639942_inner_var_7 -> 0x1a257780
1901: 8 -> 0x470acbc01723713159644639942_inner_var_8 -> 0x4752f9b0
1901: 9 -> 0x470acbc01723713159644639942_inner_var_9 -> 0x470b3a00
1901: 10 -> 0x470acbc01723713159644639942_inner_var_10 -> 0x475e3910
1901: 11 -> 0x470acbc01723713159644639942_inner_var_11 -> 0x1a2751e0
1901: 12 -> 0x470acbc01723713159644639942_inner_var_12 -> 0x474b31d0
1901: 13 -> fetch0@fetch -> 0x47593c90
1901: 14 -> 0x470acbc01723713159644639942_inner_var_14 -> 0x475c5210
1901: 15 -> fetch1@fetch -> 0x470d8490
1901: 16 -> 0x470acbc01723713159644639942_inner_var_16 -> 0x1a141150
1901: 17 -> fetch2@fetch -> 0x475e5440
1901: 18 -> 0x470acbc01723713159644639942_inner_var_18 -> 0x1a0f4460
1901: 19 -> fetch3@fetch -> 0x47493880
1901: 20 -> 0x470acbc01723713159644639942_inner_var_20 -> 0x470a1220
1901: 21 -> fetch4@fetch -> 0x474704c0
1901: 
1901: 
1901: ======================= The dependency of all instruction ========================
1901: id -> down_stream_id
1901: 0 -> 1 2 3 4 5 
1901: 1 -> 6 
1901: 2 -> 8 
1901: 3 -> 10 
1901: 4 -> 12 
1901: 5 -> 14 
1901: 6 -> 7 
1901: 8 -> 9 
1901: 10 -> 11 
1901: 12 -> 13 
1901: 14 -> 15 
1901: 
1901: 
1901: ======================== pir interpreter trace order ========================
1901: 
1901: Leaf nodes: 0[pd_op.shadow_feed]->
1901: 0 downstreams: 1[pd_op.nanmedian]->2[pd_op.nanmedian]->3[pd_op.nanmedian]->4[pd_op.nanmedian]->5[pd_op.nanmedian]->
1901: 1 downstreams: 6[pd_op.memcpy_d2h]->
1901: 2 downstreams: 8[pd_op.memcpy_d2h]->
1901: 3 downstreams: 10[pd_op.memcpy_d2h]->
1901: 4 downstreams: 12[pd_op.memcpy_d2h]->
1901: 5 downstreams: 14[pd_op.memcpy_d2h]->
1901: 6 downstreams: 7[pd_op.fetch]->
1901: 7 downstreams: 
1901: 8 downstreams: 9[pd_op.fetch]->
1901: 9 downstreams: 
1901: 10 downstreams: 11[pd_op.fetch]->
1901: 11 downstreams: 
1901: 12 downstreams: 13[pd_op.fetch]->
1901: 13 downstreams: 
1901: 14 downstreams: 15[pd_op.fetch]->
1901: 15 downstreams: 
1901: I0815 09:12:39.646332 19566 nonblocking_threadpool.h:251] HostTasks_thread_0 started 
1901: I0815 09:12:39.646350 19567 nonblocking_threadpool.h:251] HostTasks_thread_1 started 
1901: I0815 09:12:39.646422 19568 nonblocking_threadpool.h:251] HostTasks_thread_2 started 
1901: I0815 09:12:39.646436 19570 nonblocking_threadpool.h:251] DeviceKernelLaunch_thread_0 started 
1901: I0815 09:12:39.646478 19569 nonblocking_threadpool.h:251] HostTasks_thread_3 started 
1901: I0815 09:12:39.646466 19570 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.646504 19570 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:0 name:pd_op.shadow_feed type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.shadow_feed), inputs:{X:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}.
1901: I0815 09:12:39.646543 19570 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_3:[dtype=;place=;dim=;lod={};, 0x470acbc01723713159644639942_inner_var_2:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.646745 19570 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.646900 19570 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:1 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_3:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x470acbc01723713159644639942_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.646948 19570 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_5:[dtype=;place=;dim=;lod={};, 0x470acbc01723713159644639942_inner_var_4:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.646968 19569 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_12:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.647002 19569 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.647065 19570 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.647100 19569 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:6 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_3
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_2:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647220 19570 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:2 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_5:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x470acbc01723713159644639942_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.647251 19569 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647274 19569 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.647269 19570 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_7:[dtype=;place=;dim=;lod={};, 0x470acbc01723713159644639942_inner_var_6:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.647282 19569 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:7 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_3
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_12:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch0@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647305 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_14:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.647337 19568 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.647420 19570 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.647411 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:8 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_4:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647567 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647588 19568 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.647594 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:9 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_14:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch1@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647599 19570 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:3 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_7:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x470acbc01723713159644639942_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.647639 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_16:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.647639 19570 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_9:[dtype=;place=;dim=;lod={};, 0x470acbc01723713159644639942_inner_var_8:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.647658 19568 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.647703 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:10 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_6:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647760 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647778 19568 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.647783 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:11 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_16:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch2@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.647815 19570 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.647969 19570 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:4 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_9:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x470acbc01723713159644639942_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.648010 19570 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: Before: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_11:[dtype=;place=;dim=;lod={};, 0x470acbc01723713159644639942_inner_var_10:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.648016 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_18:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.648029 19568 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.648065 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:12 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_8:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.648104 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.648121 19568 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.648128 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:13 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_18:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch3@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.648180 19570 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.648339 19570 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:5 name:pd_op.nanmedian type:kGpuAsync runs on DeviceKernelLaunch_thread_0
1901: After: Place(gpu:0) Op(pd_op.nanmedian), inputs:{0x470acbc01723713159644639942_inner_var_1:[dtype=float;place=Place(gpu:0);dim=2, 3, 4, 5;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_11:[dtype=int64_t;place=Place(gpu:0);dim=;lod={};, 0x470acbc01723713159644639942_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}.
1901: I0815 09:12:39.648386 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: Before: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_20:[dtype=;place=;dim=;lod={};]}.
1901: I0815 09:12:39.648402 19568 tensor_utils.cc:57] TensorCopy  from Place(gpu:0) to Place(cpu)
1901: I0815 09:12:39.648430 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:14 name:pd_op.memcpy_d2h type:kGpuSync runs on HostTasks_thread_2
1901: After: Place(gpu:0) Op(pd_op.memcpy_d2h), inputs:{0x470acbc01723713159644639942_inner_var_10:[dtype=float;place=Place(gpu:0);dim=;lod={};]}, outputs:{0x470acbc01723713159644639942_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.648463 19568 pir_interpreter.cc:1876] 
1901: begin: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: Before: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.648479 19568 tensor_utils.cc:57] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.648484 19568 pir_interpreter.cc:1916] 
1901: done: RunInstructionBase OP id:15 name:pd_op.fetch type:kCpuSync runs on HostTasks_thread_2
1901: After: Place(cpu) Op(pd_op.fetch), inputs:{0x470acbc01723713159644639942_inner_var_20:[dtype=float;place=Place(cpu);dim=;lod={};]}, outputs:{fetch4@fetch:[dtype=float;place=Place(cpu);dim=;lod={};]}.
1901: I0815 09:12:39.648507 19499 pir_interpreter.cc:1766] main_thread_blocker_(0x470acd30) got event_name: TaskCompletion
1901: I0815 09:12:39.648528 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.648555 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.648566 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.648573 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.648583 19499 tensor_util.cc:48] TensorCopy  from Place(cpu) to Place(cpu)
1901: I0815 09:12:39.650381 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x1a105bd0 for it.
1901: I0815 09:12:39.650471 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.650504 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.650689 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=20, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.650787 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47471460)  to GradNodeAccumulation (addr: 0x1a105bd0)
1901: I0815 09:12:39.650915 19499 backward.cc:459] Run in Grad
1901: I0815 09:12:39.650926 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.650945 19499 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x47471460 to ptr: 0x470a7d80
1901: I0815 09:12:39.650956 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.650990 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.651019 19499 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x1a105bd0 to ptr: 0x4746ff20
1901: I0815 09:12:39.651044 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x470a7d80
1901: I0815 09:12:39.651052 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.651086 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.651168 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.651177 19499 backward.cc:335] Node: NanmedianGradNode addr:0x470a7d80, Found pending node: GradNodeAccumulation addr: 0x4746ff20
1901: I0815 09:12:39.651183 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.651209 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4746ff20
1901: I0815 09:12:39.651216 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.651222 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.651228 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.651232 19499 backward.cc:435] Finish Backward
1901: I0815 09:12:39.651923 19499 dygraph_functions.cc:77638] Running AD API: uniform
1901: I0815 09:12:39.651940 19499 dygraph_functions.cc:77659] { Input: []} 
1901: I0815 09:12:39.652026 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.652048 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.652189 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.652266 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x47471460)  to GradNodeAccumulation (addr: 0x1a105bd0)
1901: I0815 09:12:39.652371 19499 backward.cc:442] Run in Backward
1901: I0815 09:12:39.652379 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.652387 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.652420 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.652444 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47471460
1901: I0815 09:12:39.652453 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.652483 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.652554 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.652580 19499 backward.cc:335] Node: NanmedianGradNode addr:0x47471460, Found pending node: GradNodeAccumulation addr: 0x1a105bd0
1901: I0815 09:12:39.652590 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.652608 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x1a105bd0
1901: I0815 09:12:39.652616 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.652622 19499 accumulation_node.cc:40] Move Tensor ptr: 0x4749d470
1901: I0815 09:12:39.652626 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.652630 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.653098 19499 eager.cc:133] Tensor(generated_tensor_1) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.653206 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.653230 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.653407 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x470a7d80)  to GradNodeAccumulation (addr: 0x4392e660)
1901: I0815 09:12:39.653510 19499 backward.cc:442] Run in Backward
1901: I0815 09:12:39.653519 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.653527 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.653559 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=1, vec_size=4, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.653584 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x470a7d80
1901: I0815 09:12:39.653592 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.653620 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.653668 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.653693 19499 backward.cc:335] Node: NanmedianGradNode addr:0x470a7d80, Found pending node: GradNodeAccumulation addr: 0x4392e660
1901: I0815 09:12:39.653700 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.653719 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4392e660
1901: I0815 09:12:39.653726 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.653730 19499 accumulation_node.cc:40] Move Tensor ptr: 0x5fcd400
1901: I0815 09:12:39.653734 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.653738 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.654476 19499 eager.cc:133] Tensor(generated_tensor_2) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.654560 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.654585 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.654771 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=5, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.654861 19499 grad_node_info.cc:394] Add Edges for slot: 0, the Edge is from NanmedianGradNode (addr: 0x470a7d80)  to GradNodeAccumulation (addr: 0x4392e660)
1901: I0815 09:12:39.654981 19499 backward.cc:459] Run in Grad
1901: I0815 09:12:39.654990 19499 backward.cc:113] Start Backward
1901: I0815 09:12:39.655004 19499 general_grad.h:515] Copied Node: NanmedianGradNode ptr: 0x470a7d80 to ptr: 0x47471460
1901: I0815 09:12:39.655012 19499 backward.cc:197] Fill grad input tensor 0 with 1.0
1901: I0815 09:12:39.655042 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=4, vec_size=1, block_size=64, grid_size=1, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.655066 19499 general_grad.h:562] Copied Node: GradNodeAccumulation ptr: 0x4392e660 to ptr: 0x4746ff20
1901: I0815 09:12:39.655086 19499 backward.cc:255] Preparing GradNode:NanmedianGradNode addr:0x47471460
1901: I0815 09:12:39.655093 19499 nodes.cc:26680] Running AD API GRAD: nanmedian_grad
1901: I0815 09:12:39.655121 19499 nodes.cc:26740] { Input: [ 
1901: ( out_grad , [[ Not specified tensor log level ]]),  
1901: ( x , [[ Not specified tensor log level ]]),  
1901: ( medians , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.655243 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.655252 19499 backward.cc:335] Node: NanmedianGradNode addr:0x47471460, Found pending node: GradNodeAccumulation addr: 0x4746ff20
1901: I0815 09:12:39.655258 19499 backward.cc:376] Sum or Move grad inputs for edge slot: 0, rank: 0
1901: I0815 09:12:39.655274 19499 backward.cc:255] Preparing GradNode:GradNodeAccumulation addr:0x4746ff20
1901: I0815 09:12:39.655282 19499 accumulation_node.cc:157] Running AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.655285 19499 accumulation_node.cc:194] Finish AD API Grad: GradNodeAccumulation
1901: I0815 09:12:39.655292 19499 backward.cc:306] retain_graph is false, need to clear the TensorWrapper of nodes.
1901: I0815 09:12:39.655295 19499 backward.cc:435] Finish Backward
1901: I0815 09:12:39.656211 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.656289 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.656324 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.656483 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=120, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.657848 19499 eager.cc:133] Tensor(generated_tensor_0) have not GradNode, add GradNodeAccumulation0x4392e660 for it.
1901: I0815 09:12:39.657892 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.657910 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.660202 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.660231 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.661202 19499 op_desc.cc:1111] CompileTime infer shape on nanmedian
1901: I0815 09:12:39.661226 19499 infershape_utils.cc:546] BuildInferMetaContext: op kernel signature - Kernel Signature - name: nanmedian; inputs: X; attributes: axis, keepdim, mode; outputs: Out, MedianIndex
1901: I0815 09:12:39.662026 19499 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 09:12:39.662045 19499 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 09:12:39.662144 19499 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 09:12:39.662151 19499 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 09:12:39.662214 19499 dygraph_functions.cc:33459] Running AD API: full
1901: I0815 09:12:39.662220 19499 dygraph_functions.cc:33480] { Input: []} 
1901: I0815 09:12:39.662278 19499 dygraph_functions.cc:82227] Running AD API: arange
1901: I0815 09:12:39.662321 19499 dygraph_functions.cc:82291] { Input: [ 
1901: ( start , [[ Not specified tensor log level ]]),  
1901: ( end , [[ Not specified tensor log level ]]),  
1901: ( step , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.662475 19499 dygraph_functions.cc:62112] Running AD API: reshape
1901: I0815 09:12:39.662497 19499 dygraph_functions.cc:62169] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.662518 19499 api.cc:40807] Perform View between Output and Input Tensor, share allocation and inplace version.
1901: I0815 09:12:39.662586 19499 dygraph_functions.cc:14224] Running AD API: cast
1901: I0815 09:12:39.662603 19499 dygraph_functions.cc:14268] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.662676 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=200, vec_size=1, block_size=64, grid_size=4, limit_blocks=2147483647, limit_threads=512
1901: I0815 09:12:39.662740 19499 dygraph_functions.cc:54355] Running AD API: nanmedian
1901: I0815 09:12:39.662755 19499 dygraph_functions.cc:54415] { Input: [ 
1901: ( x , [[ Not specified tensor log level ]]), ]} 
1901: I0815 09:12:39.662947 19499 gpu_launch_config.h:156] Get 1-D launch config: numel=100, vec_size=1, block_size=64, grid_size=2, limit_blocks=2147483647, limit_threads=512
1901: test_nanmedian failed
1901:  ss.E.................
1901: ======================================================================
1901: ERROR: test_check_output (test_nanmedian.TestNanmedianFP16Op)
1901: ----------------------------------------------------------------------
1901: Traceback (most recent call last):
1901:   File "/home/code/Paddle/build/test/legacy_test/test_nanmedian.py", line 617, in test_check_output
1901:     self.check_output(check_pir=True)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2934, in check_output
1901:     res = self.check_output_with_place(
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2786, in check_output_with_place
1901:     symbol_checker.check()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2637, in check
1901:     self.infer_and_compare_symbol()
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 2645, in infer_and_compare_symbol
1901:     self.op_test._infer_and_compare_symbol(place)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1712, in _infer_and_compare_symbol
1901:     self._compare_symbol(program, outs)
1901:   File "/home/code/Paddle/build/test/legacy_test/op_test.py", line 1633, in _compare_symbol
1901:     shape_analysis.get_shape_or_data_for_var(
1901: RuntimeError: (PreconditionNotMet) The op operand index [1] must less than operands size[1].
1901:   [Hint: Expected index < num_operands_, but received index:1 >= num_operands_:1.] (at /home/code/Paddle/paddle/pir/src/core/operation.cc:420)
1901: 
1901: 
1901: ----------------------------------------------------------------------
1901: Ran 21 tests in 2.920s
1901: 
1901: FAILED (errors=1, skipped=2)
1901: 
1901: I0815 09:12:39.664400 19499 mmap_allocator.cc:348] PID: 19499, MemoryMapFdSet: set size - 0
1901: I0815 09:12:39.677110 19499 mmap_allocator.cc:348] PID: 19499, MemoryMapFdSet: set size - 0
1901: I0815 09:12:39.773059 19568 thread_data_registry.h:135] Add data {current : -16, peak : 0} from thread 11322475872768797868 to 16518600806774098736 , after update, data is {current : 4, peak : 1252}.
1901: I0815 09:12:39.773085 19568 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 11322475872768797868 to 16518600806774098736 , after update, data is {current : 0, peak : 16}.
1901: I0815 09:12:39.773140 19569 thread_data_registry.h:135] Add data {current : -4, peak : 0} from thread 17871418867372770050 to 16518600806774098736 , after update, data is {current : 0, peak : 1252}.
1901: I0815 09:12:39.773162 19569 thread_data_registry.h:135] Add data {current : 0, peak : 4} from thread 17871418867372770050 to 16518600806774098736 , after update, data is {current : 0, peak : 16}.
1901: I0815 09:12:39.773412 19570 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 16518600806774098736 to 9866486909015717903 , after update, data is {current : 0, peak : 260}.
1901: I0815 09:12:39.773430 19570 thread_data_registry.h:135] Add data {current : 0, peak : 16} from thread 16518600806774098736 to 9866486909015717903 , after update, data is {current : 20026, peak : 40004}.
1901: I0815 09:12:39.773435 19570 thread_data_registry.h:135] Add data {current : 0, peak : 1252} from thread 16518600806774098736 to 9866486909015717903 , after update, data is {current : 162560, peak : 560633}.
1901: I0815 09:12:39.965809 19499 mmap_allocator.cc:348] PID: 19499, MemoryMapFdSet: set size - 0
1/1 Test #1901: test_nanmedian ...................***Failed   12.07 sec

0% tests passed, 1 tests failed out of 1

Total Test time (real) =  12.25 sec

The following tests FAILED:
	1901 - test_nanmedian (Failed)
